<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Capítulo 6 Interpretación de Resultados de Regresión | Modelado de Regresión con Aplicaciones Actuariales y Financieras</title>
  <meta name="description" content="Spanish Translation of ‘Regression Modeling with Actuarial and Financial Applications’" />
  <meta name="generator" content="bookdown 0.39 and GitBook 2.6.7" />

  <meta property="og:title" content="Capítulo 6 Interpretación de Resultados de Regresión | Modelado de Regresión con Aplicaciones Actuariales y Financieras" />
  <meta property="og:type" content="book" />
  
  <meta property="og:description" content="Spanish Translation of ‘Regression Modeling with Actuarial and Financial Applications’" />
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Capítulo 6 Interpretación de Resultados de Regresión | Modelado de Regresión con Aplicaciones Actuariales y Financieras" />
  
  <meta name="twitter:description" content="Spanish Translation of ‘Regression Modeling with Actuarial and Financial Applications’" />
  

<meta name="author" content="Edward (Jed) Frees, University of Wisconsin - Madison, Australian National University" />



  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="C5VarSelect.html"/>
<link rel="next" href="C7Trends.html"/>
<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/anchor-sections-1.1.0/anchor-sections.css" rel="stylesheet" />
<link href="libs/anchor-sections-1.1.0/anchor-sections-hash.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.1.0/anchor-sections.js"></script>
<script src="libs/kePrint-0.0.1/kePrint.js"></script>
<link href="libs/lightable-0.0.1/lightable.css" rel="stylesheet" />

<!-- Mathjax Version 2-->
<script type='text/x-mathjax-config'>
		MathJax.Hub.Config({
			extensions: ['tex2jax.js'],
			jax: ['input/TeX', 'output/HTML-CSS'],
			tex2jax: {
				inlineMath: [ ['$','$'], ['\\(','\\)'] ],
				displayMath: [ ['$$','$$'], ['\\[','\\]'] ],
				processEscapes: true
			},
			'HTML-CSS': { availableFonts: ['TeX'] }
		});
</script>

<script type="text/javascript"  src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/MathJax.js?config=TeX-AMS_HTML"> </script>

<script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
<script type="text/javascript" src="https://unpkg.com/survey-jquery/survey.jquery.min.js"></script>
<link href="https://unpkg.com/survey-jquery/modern.min.css" type="text/css" rel="stylesheet">
<script src="https://unpkg.com/showdown/dist/showdown.min.js"></script>


<!-- Various toggle functions used throughout --> 
<script language="javascript">
function toggle(id1,id2) {
	var ele = document.getElementById(id1); var text = document.getElementById(id2);
	if (ele.style.display == "block") {ele.style.display = "none"; text.innerHTML = "Show Solution";}
		else {ele.style.display = "block"; text.innerHTML = "Hide Solution";}}
function togglecode(id1,id2) {
   var ele = document.getElementById(id1); var text = document.getElementById(id2);
   if (ele.style.display == "block") {ele.style.display = "none"; text.innerHTML = "Show R Code";}
      else {ele.style.display = "block"; text.innerHTML = "Hide R Code";}}
function toggleEX(id1,id2) {
   var ele = document.getElementById(id1); var text = document.getElementById(id2);
   if (ele.style.display == "block") {ele.style.display = "none"; text.innerHTML = "Show Example";}
      else {ele.style.display = "block"; text.innerHTML = "Hide Example";}}
function toggleTheory(id1,id2) {
   var ele = document.getElementById(id1); var text = document.getElementById(id2);
   if (ele.style.display == "block") {ele.style.display = "none"; text.innerHTML = "Show Theory";}
      else {ele.style.display = "block"; text.innerHTML = "Hide Theory";}}
function toggleSolution(id1,id2) {
   var ele = document.getElementById(id1); var text = document.getElementById(id2);
   if (ele.style.display == "block") {ele.style.display = "none"; text.innerHTML = "Show Solution";}
      else {ele.style.display = "block"; text.innerHTML = "Hide Solution";}}      
function toggleQuiz(id1,id2) {
   var ele = document.getElementById(id1); var text = document.getElementById(id2);
   if (ele.style.display == "block") {ele.style.display = "none"; text.innerHTML = "Show Quiz Solution";}
      else {ele.style.display = "block"; text.innerHTML = "Hide Quiz Solution";}}      
</script>

<!-- A few functions for revealing definitions -->
<script language="javascript">
<!--   $( function() {
    $("#tabs").tabs();
  } ); -->

$(document).ready(function(){
    $('[data-toggle="tooltip"]').tooltip();
});

$(document).ready(function(){
    $('[data-toggle="popover"]').popover(); 
});
</script>

<script language="javascript">
function openTab(evt, tabName) {
    var i, tabcontent, tablinks;
    tabcontent = document.getElementsByClassName("tabcontent");
    for (i = 0; i < tabcontent.length; i++) {
        tabcontent[i].style.display = "none";
    }
    tablinks = document.getElementsByClassName("tablinks");
    for (i = 0; i < tablinks.length; i++) {
        tablinks[i].className = tablinks[i].className.replace(" active", "");
    }
    document.getElementById(tabName).style.display = "block";
    evt.currentTarget.className += " active";
}

// Get the element with id="defaultOpen" and click on it
document.getElementById("defaultOpen").click();
</script>

<!-- Google tag (gtag.js) -->
<script async src="https://www.googletagmanager.com/gtag/js?id=G-YYYQB838NG"></script>
<script>
  window.dataLayer = window.dataLayer || [];
  function gtag(){dataLayer.push(arguments);}
  gtag('js', new Date());

  gtag('config', 'G-YYYQB838NG');
</script>



<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { display: inline-block; text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { color: #008000; } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { color: #008000; font-weight: bold; } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<style type="text/css">
  
  div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Modelado de Regresión</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Prefacio</a>
<ul>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#prólogo"><i class="fa fa-check"></i>Prólogo</a>
<ul>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#para-quién-es-este-libro"><i class="fa fa-check"></i>¿Para Quién Es Este Libro?</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#de-qué-trata-este-libro"><i class="fa fa-check"></i>¿De Qué Trata Este Libro?</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#cómo-transmite-este-libro-su-mensaje"><i class="fa fa-check"></i>¿Cómo Transmite Este Libro Su Mensaje?</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#agradecimientos"><i class="fa fa-check"></i>Agradecimientos</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#dedicación"><i class="fa fa-check"></i>Dedicación</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="traducción.html"><a href="traducción.html"><i class="fa fa-check"></i>Traducción</a></li>
<li class="chapter" data-level="1" data-path="regresión-y-la-distribución-normal.html"><a href="regresión-y-la-distribución-normal.html"><i class="fa fa-check"></i><b>1</b> Regresión y la Distribución Normal</a>
<ul>
<li class="chapter" data-level="1.1" data-path="regresión-y-la-distribución-normal.html"><a href="regresión-y-la-distribución-normal.html#Sec11"><i class="fa fa-check"></i><b>1.1</b> ¿Qué es el Análisis de Regresión?</a></li>
<li class="chapter" data-level="1.2" data-path="regresión-y-la-distribución-normal.html"><a href="regresión-y-la-distribución-normal.html#Sec12"><i class="fa fa-check"></i><b>1.2</b> Ajuste de Datos a una Distribución Normal</a></li>
<li class="chapter" data-level="1.3" data-path="regresión-y-la-distribución-normal.html"><a href="regresión-y-la-distribución-normal.html#Sec13"><i class="fa fa-check"></i><b>1.3</b> Transformaciones de Potencia</a></li>
<li class="chapter" data-level="1.4" data-path="regresión-y-la-distribución-normal.html"><a href="regresión-y-la-distribución-normal.html#Sec14"><i class="fa fa-check"></i><b>1.4</b> Muestreo y el Papel de la Normalidad</a></li>
<li class="chapter" data-level="1.5" data-path="regresión-y-la-distribución-normal.html"><a href="regresión-y-la-distribución-normal.html#Sec15"><i class="fa fa-check"></i><b>1.5</b> Regresión y Diseños de Muestreo</a></li>
<li class="chapter" data-level="1.6" data-path="regresión-y-la-distribución-normal.html"><a href="regresión-y-la-distribución-normal.html#Sec16"><i class="fa fa-check"></i><b>1.6</b> Aplicaciones Actuariales de la Regresión</a></li>
<li class="chapter" data-level="1.7" data-path="regresión-y-la-distribución-normal.html"><a href="regresión-y-la-distribución-normal.html#Sec17"><i class="fa fa-check"></i><b>1.7</b> Lecturas Adicionales y Referencias</a></li>
<li class="chapter" data-level="1.8" data-path="regresión-y-la-distribución-normal.html"><a href="regresión-y-la-distribución-normal.html#Sec18"><i class="fa fa-check"></i><b>1.8</b> Ejercicios</a></li>
<li class="chapter" data-level="1.9" data-path="regresión-y-la-distribución-normal.html"><a href="regresión-y-la-distribución-normal.html#Sec19"><i class="fa fa-check"></i><b>1.9</b> Suplemento Técnico - Teorema del Límite Central</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="C2BasicLR.html"><a href="C2BasicLR.html"><i class="fa fa-check"></i><b>2</b> Regresión Lineal Básica</a>
<ul>
<li class="chapter" data-level="2.1" data-path="C2BasicLR.html"><a href="C2BasicLR.html#Sec21"><i class="fa fa-check"></i><b>2.1</b> Correlaciones y Mínimos Cuadrados</a></li>
<li class="chapter" data-level="2.2" data-path="C2BasicLR.html"><a href="C2BasicLR.html#Sec22"><i class="fa fa-check"></i><b>2.2</b> Modelo Básico de Regresión Lineal</a></li>
<li class="chapter" data-level="2.3" data-path="C2BasicLR.html"><a href="C2BasicLR.html#Sec23"><i class="fa fa-check"></i><b>2.3</b> ¿Es Útil el Modelo? Algunas Medidas de Resumen Básicas</a>
<ul>
<li class="chapter" data-level="2.3.1" data-path="C2BasicLR.html"><a href="C2BasicLR.html#Sec231"><i class="fa fa-check"></i><b>2.3.1</b> Particionando la Variabilidad</a></li>
<li class="chapter" data-level="2.3.2" data-path="C2BasicLR.html"><a href="C2BasicLR.html#Sec232"><i class="fa fa-check"></i><b>2.3.2</b> El Tamaño de una Desviación Típica: <em>s</em></a></li>
</ul></li>
<li class="chapter" data-level="2.4" data-path="C2BasicLR.html"><a href="C2BasicLR.html#Sec24"><i class="fa fa-check"></i><b>2.4</b> Propiedades de los Estimadores del Coeficiente de Regresión</a></li>
<li class="chapter" data-level="2.5" data-path="C2BasicLR.html"><a href="C2BasicLR.html#Sec25"><i class="fa fa-check"></i><b>2.5</b> Inferencia Estadística</a>
<ul>
<li class="chapter" data-level="2.5.1" data-path="C2BasicLR.html"><a href="C2BasicLR.html#Sec251"><i class="fa fa-check"></i><b>2.5.1</b> ¿Es Importante la Variable Explicativa?: La Prueba <em>t</em></a></li>
<li class="chapter" data-level="2.5.2" data-path="C2BasicLR.html"><a href="C2BasicLR.html#Sec252"><i class="fa fa-check"></i><b>2.5.2</b> Intervalos de Confianza</a></li>
<li class="chapter" data-level="2.5.3" data-path="C2BasicLR.html"><a href="C2BasicLR.html#Sec253"><i class="fa fa-check"></i><b>2.5.3</b> Intervalos de Predicción</a></li>
</ul></li>
<li class="chapter" data-level="2.6" data-path="C2BasicLR.html"><a href="C2BasicLR.html#Sec26"><i class="fa fa-check"></i><b>2.6</b> Construyendo un Mejor Modelo: Análisis de Residuos</a></li>
<li class="chapter" data-level="2.7" data-path="C2BasicLR.html"><a href="C2BasicLR.html#Sec27"><i class="fa fa-check"></i><b>2.7</b> Aplicación: Modelo de Valoración de Activos Financieros</a></li>
<li class="chapter" data-level="2.8" data-path="C2BasicLR.html"><a href="C2BasicLR.html#Sec28"><i class="fa fa-check"></i><b>2.8</b> Salida Computacional Ilustrativa de Regresión</a></li>
<li class="chapter" data-level="2.9" data-path="C2BasicLR.html"><a href="C2BasicLR.html#Sec29"><i class="fa fa-check"></i><b>2.9</b> Lecturas Adicionales y Referencias</a></li>
<li class="chapter" data-level="2.10" data-path="C2BasicLR.html"><a href="C2BasicLR.html#Sec210"><i class="fa fa-check"></i><b>2.10</b> Ejercicios</a></li>
<li class="chapter" data-level="2.11" data-path="C2BasicLR.html"><a href="C2BasicLR.html#Sec211"><i class="fa fa-check"></i><b>2.11</b> Suplemento Técnico - Elementos del Álgebra de Matrices</a>
<ul>
<li class="chapter" data-level="2.11.1" data-path="C2BasicLR.html"><a href="C2BasicLR.html#Sec2111"><i class="fa fa-check"></i><b>2.11.1</b> Definiciones Básicas</a></li>
<li class="chapter" data-level="2.11.2" data-path="C2BasicLR.html"><a href="C2BasicLR.html#Sec2112"><i class="fa fa-check"></i><b>2.11.2</b> Algunas Matrices Especiales</a></li>
<li class="chapter" data-level="2.11.3" data-path="C2BasicLR.html"><a href="C2BasicLR.html#Sec2113"><i class="fa fa-check"></i><b>2.11.3</b> Operaciones Básicas</a></li>
<li class="chapter" data-level="2.11.4" data-path="C2BasicLR.html"><a href="C2BasicLR.html#Sec2114"><i class="fa fa-check"></i><b>2.11.4</b> Matrices Aleatorias</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="3" data-path="C3BasicMLR.html"><a href="C3BasicMLR.html"><i class="fa fa-check"></i><b>3</b> Regresión Lineal Múltiple - I</a>
<ul>
<li class="chapter" data-level="3.1" data-path="C3BasicMLR.html"><a href="C3BasicMLR.html#Sec31"><i class="fa fa-check"></i><b>3.1</b> Método de Mínimos Cuadrados</a></li>
<li class="chapter" data-level="3.2" data-path="C3BasicMLR.html"><a href="C3BasicMLR.html#Sec32"><i class="fa fa-check"></i><b>3.2</b> Modelo de Regresión Lineal y Propiedades de los Estimadores</a>
<ul>
<li class="chapter" data-level="3.2.1" data-path="C3BasicMLR.html"><a href="C3BasicMLR.html#Sec321"><i class="fa fa-check"></i><b>3.2.1</b> Función de Regresión</a></li>
<li class="chapter" data-level="3.2.2" data-path="C3BasicMLR.html"><a href="C3BasicMLR.html#Sec322"><i class="fa fa-check"></i><b>3.2.2</b> Interpretación del Coeficiente de Regresión</a></li>
<li class="chapter" data-level="3.2.3" data-path="C3BasicMLR.html"><a href="C3BasicMLR.html#Sec323"><i class="fa fa-check"></i><b>3.2.3</b> Suposiciones del Modelo</a></li>
<li class="chapter" data-level="3.2.4" data-path="C3BasicMLR.html"><a href="C3BasicMLR.html#Sec324"><i class="fa fa-check"></i><b>3.2.4</b> Propiedades de los Estimadores de los Coeficientes de Regresión</a></li>
</ul></li>
<li class="chapter" data-level="3.3" data-path="C3BasicMLR.html"><a href="C3BasicMLR.html#Sec33"><i class="fa fa-check"></i><b>3.3</b> Estimación y Bondad de Ajuste</a></li>
<li class="chapter" data-level="3.4" data-path="C3BasicMLR.html"><a href="C3BasicMLR.html#Sec34"><i class="fa fa-check"></i><b>3.4</b> Inferencia Estadística para un Coeficiente Único</a>
<ul>
<li class="chapter" data-level="3.4.1" data-path="C3BasicMLR.html"><a href="C3BasicMLR.html#Sec341"><i class="fa fa-check"></i><b>3.4.1</b> La Prueba <em>t</em></a></li>
<li class="chapter" data-level="3.4.2" data-path="C3BasicMLR.html"><a href="C3BasicMLR.html#Sec342"><i class="fa fa-check"></i><b>3.4.2</b> Intervalos de Confianza</a></li>
<li class="chapter" data-level="3.4.3" data-path="C3BasicMLR.html"><a href="C3BasicMLR.html#Sec343"><i class="fa fa-check"></i><b>3.4.3</b> Gráficos de Variables Añadidas</a></li>
<li class="chapter" data-level="3.4.4" data-path="C3BasicMLR.html"><a href="C3BasicMLR.html#Sec344"><i class="fa fa-check"></i><b>3.4.4</b> Coeficientes de Correlación Parcial</a></li>
</ul></li>
<li class="chapter" data-level="3.5" data-path="C3BasicMLR.html"><a href="C3BasicMLR.html#Sec35"><i class="fa fa-check"></i><b>3.5</b> Algunas Variables Explicativas Especiales</a>
<ul>
<li class="chapter" data-level="3.5.1" data-path="C3BasicMLR.html"><a href="C3BasicMLR.html#Sec351"><i class="fa fa-check"></i><b>3.5.1</b> Variables Binarias</a></li>
<li class="chapter" data-level="3.5.2" data-path="C3BasicMLR.html"><a href="C3BasicMLR.html#Sec352"><i class="fa fa-check"></i><b>3.5.2</b> Transformación de Variables Explicativas</a></li>
<li class="chapter" data-level="3.5.3" data-path="C3BasicMLR.html"><a href="C3BasicMLR.html#Sec353"><i class="fa fa-check"></i><b>3.5.3</b> Términos de Interacción</a></li>
</ul></li>
<li class="chapter" data-level="3.6" data-path="C3BasicMLR.html"><a href="C3BasicMLR.html#Sec36"><i class="fa fa-check"></i><b>3.6</b> Lectura Adicional y Referencias</a></li>
<li class="chapter" data-level="3.7" data-path="C3BasicMLR.html"><a href="C3BasicMLR.html#Sec37"><i class="fa fa-check"></i><b>3.7</b> Ejercicios</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="C4MLRANOVA.html"><a href="C4MLRANOVA.html"><i class="fa fa-check"></i><b>4</b> Regresión Lineal Múltiple - II</a>
<ul>
<li class="chapter" data-level="4.1" data-path="C4MLRANOVA.html"><a href="C4MLRANOVA.html#Sec41"><i class="fa fa-check"></i><b>4.1</b> El Papel de las Variables Binarias</a></li>
<li class="chapter" data-level="4.2" data-path="C4MLRANOVA.html"><a href="C4MLRANOVA.html#Sec42"><i class="fa fa-check"></i><b>4.2</b> Inferencia Estadística para Varios Coeficientes</a>
<ul>
<li class="chapter" data-level="4.2.1" data-path="C4MLRANOVA.html"><a href="C4MLRANOVA.html#Sec421"><i class="fa fa-check"></i><b>4.2.1</b> Conjuntos de Coeficientes de Regresión</a></li>
<li class="chapter" data-level="4.2.2" data-path="C4MLRANOVA.html"><a href="C4MLRANOVA.html#Sec422"><i class="fa fa-check"></i><b>4.2.2</b> La Hipótesis Lineal General</a></li>
<li class="chapter" data-level="4.2.3" data-path="C4MLRANOVA.html"><a href="C4MLRANOVA.html#Sec423"><i class="fa fa-check"></i><b>4.2.3</b> Estimando y Prediciendo Varios Coeficientes</a></li>
</ul></li>
<li class="chapter" data-level="4.3" data-path="C4MLRANOVA.html"><a href="C4MLRANOVA.html#Sec43"><i class="fa fa-check"></i><b>4.3</b> Modelo ANOVA de Un Factor</a></li>
<li class="chapter" data-level="4.4" data-path="C4MLRANOVA.html"><a href="C4MLRANOVA.html#Sec44"><i class="fa fa-check"></i><b>4.4</b> Combinando Variables Explicativas Categóricas y Continuas</a></li>
<li class="chapter" data-level="4.5" data-path="C4MLRANOVA.html"><a href="C4MLRANOVA.html#Sec45"><i class="fa fa-check"></i><b>4.5</b> Lecturas Adicionales y Referencias</a></li>
<li class="chapter" data-level="4.6" data-path="C4MLRANOVA.html"><a href="C4MLRANOVA.html#Sec46"><i class="fa fa-check"></i><b>4.6</b> Ejercicios</a></li>
<li class="chapter" data-level="4.7" data-path="C4MLRANOVA.html"><a href="C4MLRANOVA.html#Sec47"><i class="fa fa-check"></i><b>4.7</b> Suplemento Técnico - Expresiones Matriciales</a>
<ul>
<li class="chapter" data-level="4.7.1" data-path="C4MLRANOVA.html"><a href="C4MLRANOVA.html#Sec471"><i class="fa fa-check"></i><b>4.7.1</b> Expresión de Modelos con Variables Categóricas en Forma Matricial</a></li>
<li class="chapter" data-level="4.7.2" data-path="C4MLRANOVA.html"><a href="C4MLRANOVA.html#Sec472"><i class="fa fa-check"></i><b>4.7.2</b> Cálculo Recursivo de Mínimos Cuadrados</a></li>
<li class="chapter" data-level="4.7.3" data-path="C4MLRANOVA.html"><a href="C4MLRANOVA.html#Sec473"><i class="fa fa-check"></i><b>4.7.3</b> Modelo Lineal General</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="5" data-path="C5VarSelect.html"><a href="C5VarSelect.html"><i class="fa fa-check"></i><b>5</b> Selección de Variables</a>
<ul>
<li class="chapter" data-level="5.1" data-path="C5VarSelect.html"><a href="C5VarSelect.html#Sec51"><i class="fa fa-check"></i><b>5.1</b> Un Enfoque Iterativo para el Análisis de Datos y Modelado</a></li>
<li class="chapter" data-level="5.2" data-path="C5VarSelect.html"><a href="C5VarSelect.html#Sec52"><i class="fa fa-check"></i><b>5.2</b> Procedimientos Automáticos de Selección de Variables</a></li>
<li class="chapter" data-level="5.3" data-path="C5VarSelect.html"><a href="C5VarSelect.html#Sec53"><i class="fa fa-check"></i><b>5.3</b> Análisis de Residuales</a>
<ul>
<li class="chapter" data-level="5.3.1" data-path="C5VarSelect.html"><a href="C5VarSelect.html#Sec531"><i class="fa fa-check"></i><b>5.3.1</b> Residuales</a></li>
<li class="chapter" data-level="5.3.2" data-path="C5VarSelect.html"><a href="C5VarSelect.html#Sec532"><i class="fa fa-check"></i><b>5.3.2</b> Uso de los Residuales para Identificar Valores Atípicos</a></li>
<li class="chapter" data-level="5.3.3" data-path="C5VarSelect.html"><a href="C5VarSelect.html#Sec533"><i class="fa fa-check"></i><b>5.3.3</b> Uso de los Residuales para Seleccionar Variables Explicativas</a></li>
</ul></li>
<li class="chapter" data-level="5.4" data-path="C5VarSelect.html"><a href="C5VarSelect.html#Sec54"><i class="fa fa-check"></i><b>5.4</b> Puntos Influyentes</a>
<ul>
<li class="chapter" data-level="5.4.1" data-path="C5VarSelect.html"><a href="C5VarSelect.html#Sec541"><i class="fa fa-check"></i><b>5.4.1</b> Apalancamiento</a></li>
<li class="chapter" data-level="5.4.2" data-path="C5VarSelect.html"><a href="C5VarSelect.html#Sec542"><i class="fa fa-check"></i><b>5.4.2</b> Distancia de Cook</a></li>
</ul></li>
<li class="chapter" data-level="5.5" data-path="C5VarSelect.html"><a href="C5VarSelect.html#Sec55"><i class="fa fa-check"></i><b>5.5</b> Colinealidad</a>
<ul>
<li class="chapter" data-level="5.5.1" data-path="C5VarSelect.html"><a href="C5VarSelect.html#Sec551"><i class="fa fa-check"></i><b>5.5.1</b> ¿Qué es la Colinealidad?</a></li>
<li class="chapter" data-level="5.5.2" data-path="C5VarSelect.html"><a href="C5VarSelect.html#Sec552"><i class="fa fa-check"></i><b>5.5.2</b> Factores de Inflación de Varianza</a></li>
<li class="chapter" data-level="5.5.3" data-path="C5VarSelect.html"><a href="C5VarSelect.html#Sec553"><i class="fa fa-check"></i><b>5.5.3</b> Colinealidad e Influencia</a></li>
<li class="chapter" data-level="5.5.4" data-path="C5VarSelect.html"><a href="C5VarSelect.html#Sec554"><i class="fa fa-check"></i><b>5.5.4</b> Variables Suprensoras</a></li>
<li class="chapter" data-level="5.5.5" data-path="C5VarSelect.html"><a href="C5VarSelect.html#Sec555"><i class="fa fa-check"></i><b>5.5.5</b> Variables Ortogonales</a></li>
</ul></li>
<li class="chapter" data-level="5.6" data-path="C5VarSelect.html"><a href="C5VarSelect.html#Sec56"><i class="fa fa-check"></i><b>5.6</b> Criterios de Selección</a>
<ul>
<li class="chapter" data-level="5.6.1" data-path="C5VarSelect.html"><a href="C5VarSelect.html#Sec561"><i class="fa fa-check"></i><b>5.6.1</b> Bondad de Ajuste</a></li>
<li class="chapter" data-level="5.6.2" data-path="C5VarSelect.html"><a href="C5VarSelect.html#Sec562"><i class="fa fa-check"></i><b>5.6.2</b> Validación del Modelo</a></li>
<li class="chapter" data-level="5.6.3" data-path="C5VarSelect.html"><a href="C5VarSelect.html#Sec563"><i class="fa fa-check"></i><b>5.6.3</b> Validación Cruzada</a></li>
</ul></li>
<li class="chapter" data-level="5.7" data-path="C5VarSelect.html"><a href="C5VarSelect.html#Sec57"><i class="fa fa-check"></i><b>5.7</b> Heterocedasticidad</a>
<ul>
<li class="chapter" data-level="5.7.1" data-path="C5VarSelect.html"><a href="C5VarSelect.html#Sec571"><i class="fa fa-check"></i><b>5.7.1</b> Detección de Heterocedasticidad</a></li>
<li class="chapter" data-level="5.7.2" data-path="C5VarSelect.html"><a href="C5VarSelect.html#Sec572"><i class="fa fa-check"></i><b>5.7.2</b> Errores Estándar Consistentes con Heterocedasticidad</a></li>
<li class="chapter" data-level="5.7.3" data-path="C5VarSelect.html"><a href="C5VarSelect.html#Sec573"><i class="fa fa-check"></i><b>5.7.3</b> Mínimos Cuadrados Ponderados</a></li>
<li class="chapter" data-level="5.7.4" data-path="C5VarSelect.html"><a href="C5VarSelect.html#Sec574"><i class="fa fa-check"></i><b>5.7.4</b> Transformaciones</a></li>
</ul></li>
<li class="chapter" data-level="5.8" data-path="C5VarSelect.html"><a href="C5VarSelect.html#Sec58"><i class="fa fa-check"></i><b>5.8</b> Lectura Adicional y Referencias</a></li>
<li class="chapter" data-level="5.9" data-path="C5VarSelect.html"><a href="C5VarSelect.html#Sec59"><i class="fa fa-check"></i><b>5.9</b> Ejercicios</a></li>
<li class="chapter" data-level="5.10" data-path="C5VarSelect.html"><a href="C5VarSelect.html#Sec510"><i class="fa fa-check"></i><b>5.10</b> Suplementos Técnicos para el Capítulo 5</a>
<ul>
<li class="chapter" data-level="5.10.1" data-path="C5VarSelect.html"><a href="C5VarSelect.html#Sec5101"><i class="fa fa-check"></i><b>5.10.1</b> Matriz de Proyección</a></li>
<li class="chapter" data-level="5.10.2" data-path="C5VarSelect.html"><a href="C5VarSelect.html#Sec5102"><i class="fa fa-check"></i><b>5.10.2</b> Estadísticas Leave-One-Out</a></li>
<li class="chapter" data-level="5.10.3" data-path="C5VarSelect.html"><a href="C5VarSelect.html#Sec5103"><i class="fa fa-check"></i><b>5.10.3</b> Omisión de Variables</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="6" data-path="interpretación-de-resultados-de-regresión.html"><a href="interpretación-de-resultados-de-regresión.html"><i class="fa fa-check"></i><b>6</b> Interpretación de Resultados de Regresión</a>
<ul>
<li class="chapter" data-level="6.1" data-path="interpretación-de-resultados-de-regresión.html"><a href="interpretación-de-resultados-de-regresión.html#Sec61"><i class="fa fa-check"></i><b>6.1</b> Lo que nos dice el proceso de modelado</a>
<ul>
<li class="chapter" data-level="6.1.1" data-path="interpretación-de-resultados-de-regresión.html"><a href="interpretación-de-resultados-de-regresión.html#Sec611"><i class="fa fa-check"></i><b>6.1.1</b> Interpretación de efectos individuales</a></li>
<li class="chapter" data-level="6.1.2" data-path="interpretación-de-resultados-de-regresión.html"><a href="interpretación-de-resultados-de-regresión.html#Sec612"><i class="fa fa-check"></i><b>6.1.2</b> Otras Interpretaciones</a></li>
</ul></li>
<li class="chapter" data-level="6.2" data-path="interpretación-de-resultados-de-regresión.html"><a href="interpretación-de-resultados-de-regresión.html#Sec62"><i class="fa fa-check"></i><b>6.2</b> La Importancia de la Selección de Variables</a>
<ul>
<li class="chapter" data-level="6.2.1" data-path="interpretación-de-resultados-de-regresión.html"><a href="interpretación-de-resultados-de-regresión.html#Sec621"><i class="fa fa-check"></i><b>6.2.1</b> Sobreajuste del Modelo</a></li>
<li class="chapter" data-level="6.2.2" data-path="interpretación-de-resultados-de-regresión.html"><a href="interpretación-de-resultados-de-regresión.html#Sec622"><i class="fa fa-check"></i><b>6.2.2</b> Subajuste del Modelo</a></li>
</ul></li>
<li class="chapter" data-level="6.3" data-path="interpretación-de-resultados-de-regresión.html"><a href="interpretación-de-resultados-de-regresión.html#Sec63"><i class="fa fa-check"></i><b>6.3</b> La Importancia de la Recolección de Datos</a>
<ul>
<li class="chapter" data-level="6.3.1" data-path="interpretación-de-resultados-de-regresión.html"><a href="interpretación-de-resultados-de-regresión.html#Sec631"><i class="fa fa-check"></i><b>6.3.1</b> Error en el Marco Muestral y Selección Adversa</a></li>
<li class="chapter" data-level="6.3.2" data-path="interpretación-de-resultados-de-regresión.html"><a href="interpretación-de-resultados-de-regresión.html#Sec632"><i class="fa fa-check"></i><b>6.3.2</b> Regiones de Muestreo Limitadas</a></li>
<li class="chapter" data-level="6.3.3" data-path="interpretación-de-resultados-de-regresión.html"><a href="interpretación-de-resultados-de-regresión.html#Sec633"><i class="fa fa-check"></i><b>6.3.3</b> Variables Dependientes Limitadas, Censura y Truncamiento</a></li>
<li class="chapter" data-level="6.3.4" data-path="interpretación-de-resultados-de-regresión.html"><a href="interpretación-de-resultados-de-regresión.html#Sec634"><i class="fa fa-check"></i><b>6.3.4</b> Variables Omitidas y Endógenas</a></li>
<li class="chapter" data-level="6.3.5" data-path="interpretación-de-resultados-de-regresión.html"><a href="interpretación-de-resultados-de-regresión.html#Sec635"><i class="fa fa-check"></i><b>6.3.5</b> Datos Faltantes</a></li>
</ul></li>
<li class="chapter" data-level="6.4" data-path="interpretación-de-resultados-de-regresión.html"><a href="interpretación-de-resultados-de-regresión.html#Sec64"><i class="fa fa-check"></i><b>6.4</b> Modelos de Datos Faltantes</a>
<ul>
<li class="chapter" data-level="6.4.1" data-path="interpretación-de-resultados-de-regresión.html"><a href="interpretación-de-resultados-de-regresión.html#Sec641"><i class="fa fa-check"></i><b>6.4.1</b> Faltante al Azar</a></li>
<li class="chapter" data-level="6.4.2" data-path="interpretación-de-resultados-de-regresión.html"><a href="interpretación-de-resultados-de-regresión.html#Sec642"><i class="fa fa-check"></i><b>6.4.2</b> Datos Faltantes No Ignorables</a></li>
</ul></li>
<li class="chapter" data-level="6.5" data-path="interpretación-de-resultados-de-regresión.html"><a href="interpretación-de-resultados-de-regresión.html#Sec65"><i class="fa fa-check"></i><b>6.5</b> Aplicación: Eficiencia en el Costo de los Gestores de Riesgos</a></li>
<li class="chapter" data-level="6.6" data-path="interpretación-de-resultados-de-regresión.html"><a href="interpretación-de-resultados-de-regresión.html#Sec66"><i class="fa fa-check"></i><b>6.6</b> Lecturas Adicionales y Referencias</a></li>
<li class="chapter" data-level="6.7" data-path="interpretación-de-resultados-de-regresión.html"><a href="interpretación-de-resultados-de-regresión.html#Sec67"><i class="fa fa-check"></i><b>6.7</b> Ejercicios</a></li>
<li class="chapter" data-level="6.8" data-path="interpretación-de-resultados-de-regresión.html"><a href="interpretación-de-resultados-de-regresión.html#Sec68"><i class="fa fa-check"></i><b>6.8</b> Suplementos Técnicos para el Capítulo 6</a>
<ul>
<li class="chapter" data-level="6.8.1" data-path="interpretación-de-resultados-de-regresión.html"><a href="interpretación-de-resultados-de-regresión.html#Sec681"><i class="fa fa-check"></i><b>6.8.1</b> Efectos de la Especificación Incorrecta del Modelo</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="7" data-path="C7Trends.html"><a href="C7Trends.html"><i class="fa fa-check"></i><b>7</b> Modelado de Tendencias</a>
<ul>
<li class="chapter" data-level="7.1" data-path="C7Trends.html"><a href="C7Trends.html#introducción-1"><i class="fa fa-check"></i><b>7.1</b> Introducción</a>
<ul>
<li class="chapter" data-level="" data-path="C7Trends.html"><a href="C7Trends.html#series-temporales-y-procesos-estocásticos"><i class="fa fa-check"></i>Series Temporales y Procesos Estocásticos</a></li>
<li class="chapter" data-level="" data-path="C7Trends.html"><a href="C7Trends.html#series-temporales-versus-modelos-causales"><i class="fa fa-check"></i>Series Temporales versus Modelos Causales</a></li>
</ul></li>
<li class="chapter" data-level="7.2" data-path="C7Trends.html"><a href="C7Trends.html#S7:Trends"><i class="fa fa-check"></i><b>7.2</b> Ajuste de Tendencias en el Tiempo</a>
<ul>
<li class="chapter" data-level="" data-path="C7Trends.html"><a href="C7Trends.html#comprendiendo-patrones-en-el-tiempo"><i class="fa fa-check"></i>Comprendiendo Patrones en el Tiempo</a></li>
<li class="chapter" data-level="" data-path="C7Trends.html"><a href="C7Trends.html#ajuste-de-tendencias-en-el-tiempo"><i class="fa fa-check"></i>Ajuste de Tendencias en el Tiempo</a></li>
<li class="chapter" data-level="" data-path="C7Trends.html"><a href="C7Trends.html#ajuste-de-tendencias-estacionales"><i class="fa fa-check"></i>Ajuste de Tendencias Estacionales</a></li>
<li class="chapter" data-level="" data-path="C7Trends.html"><a href="C7Trends.html#confiabilidad-de-los-pronósticos-de-series-temporales"><i class="fa fa-check"></i>Confiabilidad de los Pronósticos de Series Temporales</a></li>
</ul></li>
<li class="chapter" data-level="7.3" data-path="C7Trends.html"><a href="C7Trends.html#S7:RandomWalk"><i class="fa fa-check"></i><b>7.3</b> Estacionariedad y Modelos de Paseo Aleatorio</a>
<ul>
<li class="chapter" data-level="" data-path="C7Trends.html"><a href="C7Trends.html#ruido-blanco"><i class="fa fa-check"></i>Ruido Blanco</a></li>
<li class="chapter" data-level="" data-path="C7Trends.html"><a href="C7Trends.html#paseo-aleatorio"><i class="fa fa-check"></i>Paseo Aleatorio</a></li>
</ul></li>
<li class="chapter" data-level="7.4" data-path="C7Trends.html"><a href="C7Trends.html#inferencia-usando-modelos-de-paseo-aleatorio"><i class="fa fa-check"></i><b>7.4</b> Inferencia usando Modelos de Paseo Aleatorio</a>
<ul>
<li class="chapter" data-level="" data-path="C7Trends.html"><a href="C7Trends.html#propiedades-del-modelo"><i class="fa fa-check"></i>Propiedades del Modelo</a></li>
<li class="chapter" data-level="" data-path="C7Trends.html"><a href="C7Trends.html#pronósticos"><i class="fa fa-check"></i>Pronósticos</a></li>
<li class="chapter" data-level="" data-path="C7Trends.html"><a href="C7Trends.html#identificación-de-estacionariedad"><i class="fa fa-check"></i>Identificación de Estacionariedad</a></li>
<li class="chapter" data-level="" data-path="C7Trends.html"><a href="C7Trends.html#identificación-de-paseos-aleatorios"><i class="fa fa-check"></i>Identificación de Paseos Aleatorios</a></li>
<li class="chapter" data-level="" data-path="C7Trends.html"><a href="C7Trends.html#paseo-aleatorio-versus-modelo-de-tendencia-lineal-en-el-tiempo"><i class="fa fa-check"></i>Paseo Aleatorio versus Modelo de Tendencia Lineal en el Tiempo</a></li>
</ul></li>
<li class="chapter" data-level="7.5" data-path="C7Trends.html"><a href="C7Trends.html#filtrado-para-lograr-estacionariedad"><i class="fa fa-check"></i><b>7.5</b> Filtrado para Lograr Estacionariedad</a>
<ul>
<li class="chapter" data-level="" data-path="C7Trends.html"><a href="C7Trends.html#transformaciones"><i class="fa fa-check"></i>Transformaciones</a></li>
</ul></li>
<li class="chapter" data-level="7.6" data-path="C7Trends.html"><a href="C7Trends.html#evaluación-de-pronósticos"><i class="fa fa-check"></i><b>7.6</b> Evaluación de Pronósticos</a></li>
<li class="chapter" data-level="7.7" data-path="C7Trends.html"><a href="C7Trends.html#lecturas-adicionales-y-referencias"><i class="fa fa-check"></i><b>7.7</b> Lecturas Adicionales y Referencias</a></li>
<li class="chapter" data-level="7.8" data-path="C7Trends.html"><a href="C7Trends.html#ejercicios"><i class="fa fa-check"></i><b>7.8</b> Ejercicios</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="C8AR.html"><a href="C8AR.html"><i class="fa fa-check"></i><b>8</b> Autocorrelaciones y Modelos Autorregresivos</a>
<ul>
<li class="chapter" data-level="8.1" data-path="C8AR.html"><a href="C8AR.html#S8:Autocorrs"><i class="fa fa-check"></i><b>8.1</b> Autocorrelaciones</a>
<ul>
<li class="chapter" data-level="" data-path="C8AR.html"><a href="C8AR.html#aplicación-retornos-de-bonos-con-inflación"><i class="fa fa-check"></i>Aplicación: Retornos de Bonos con Inflación</a></li>
</ul></li>
<li class="chapter" data-level="8.2" data-path="C8AR.html"><a href="C8AR.html#modelos-autorregresivos-de-orden-uno"><i class="fa fa-check"></i><b>8.2</b> Modelos Autorregresivos de Orden Uno</a></li>
<li class="chapter" data-level="8.3" data-path="C8AR.html"><a href="C8AR.html#S8:Estimation"><i class="fa fa-check"></i><b>8.3</b> Estimación y Verificación de Diagnóstico</a></li>
<li class="chapter" data-level="8.4" data-path="C8AR.html"><a href="C8AR.html#S8:AR1Smooth"><i class="fa fa-check"></i><b>8.4</b> Suavización y Predicción</a></li>
<li class="chapter" data-level="8.5" data-path="C8AR.html"><a href="C8AR.html#S8:BoxJenkins"><i class="fa fa-check"></i><b>8.5</b> Modelado y Pronóstico de Box-Jenkins</a>
<ul>
<li class="chapter" data-level="8.5.1" data-path="C8AR.html"><a href="C8AR.html#modelos"><i class="fa fa-check"></i><b>8.5.1</b> Modelos</a></li>
<li class="chapter" data-level="8.5.2" data-path="C8AR.html"><a href="C8AR.html#pronóstico"><i class="fa fa-check"></i><b>8.5.2</b> Pronóstico</a></li>
</ul></li>
<li class="chapter" data-level="8.6" data-path="C8AR.html"><a href="C8AR.html#aplicación-tasas-de-cambio-de-hong-kong"><i class="fa fa-check"></i><b>8.6</b> Aplicación: Tasas de Cambio de Hong Kong</a></li>
<li class="chapter" data-level="8.7" data-path="C8AR.html"><a href="C8AR.html#lecturas-adicionales-y-referencias-1"><i class="fa fa-check"></i><b>8.7</b> Lecturas Adicionales y Referencias</a></li>
</ul></li>
<li class="chapter" data-level="9" data-path="C9Forecast.html"><a href="C9Forecast.html"><i class="fa fa-check"></i><b>9</b> Pronósticos y Modelos de Series Temporales</a>
<ul>
<li class="chapter" data-level="9.1" data-path="C9Forecast.html"><a href="C9Forecast.html#suavización-con-promedios-móviles"><i class="fa fa-check"></i><b>9.1</b> Suavización con Promedios Móviles</a></li>
<li class="chapter" data-level="9.2" data-path="C9Forecast.html"><a href="C9Forecast.html#S9:ExponSmooth"><i class="fa fa-check"></i><b>9.2</b> Suavización Exponencial</a></li>
<li class="chapter" data-level="9.3" data-path="C9Forecast.html"><a href="C9Forecast.html#S9:SeasonalTSModels"><i class="fa fa-check"></i><b>9.3</b> Modelos de Series Temporales Estacionales</a></li>
<li class="chapter" data-level="9.4" data-path="C9Forecast.html"><a href="C9Forecast.html#pruebas-de-raíces-unitarias"><i class="fa fa-check"></i><b>9.4</b> Pruebas de Raíces Unitarias</a></li>
<li class="chapter" data-level="9.5" data-path="C9Forecast.html"><a href="C9Forecast.html#modelos-archgarch"><i class="fa fa-check"></i><b>9.5</b> Modelos ARCH/GARCH</a></li>
<li class="chapter" data-level="9.6" data-path="C9Forecast.html"><a href="C9Forecast.html#lecturas-y-referencias-adicionales"><i class="fa fa-check"></i><b>9.6</b> Lecturas y Referencias Adicionales</a></li>
</ul></li>
<li class="chapter" data-level="10" data-path="C10Panel.html"><a href="C10Panel.html"><i class="fa fa-check"></i><b>10</b> Modelos de Datos Longitudinales y de Panel</a>
<ul>
<li class="chapter" data-level="10.1" data-path="C10Panel.html"><a href="C10Panel.html#S10:Intro"><i class="fa fa-check"></i><b>10.1</b> ¿Qué son los Datos Longitudinales y de Panel?</a></li>
<li class="chapter" data-level="10.2" data-path="C10Panel.html"><a href="C10Panel.html#S10:Visual"><i class="fa fa-check"></i><b>10.2</b> Visualización de Datos Longitudinales y de Panel</a></li>
<li class="chapter" data-level="10.3" data-path="C10Panel.html"><a href="C10Panel.html#S10:FEModels"><i class="fa fa-check"></i><b>10.3</b> Modelos Básicos de Efectos Fijos</a></li>
<li class="chapter" data-level="10.4" data-path="C10Panel.html"><a href="C10Panel.html#S10:FEModels2"><i class="fa fa-check"></i><b>10.4</b> Modelos Extendidos de Efectos Fijos</a></li>
<li class="chapter" data-level="10.5" data-path="C10Panel.html"><a href="C10Panel.html#S10:REModels"><i class="fa fa-check"></i><b>10.5</b> Modelos de Efectos Aleatorios</a></li>
<li class="chapter" data-level="10.6" data-path="C10Panel.html"><a href="C10Panel.html#S10:References"><i class="fa fa-check"></i><b>10.6</b> Lecturas Adicionales y Referencias</a></li>
</ul></li>
<li class="chapter" data-level="11" data-path="C11Binary.html"><a href="C11Binary.html"><i class="fa fa-check"></i><b>11</b> Variables Dependientes Categóricas</a>
<ul>
<li class="chapter" data-level="11.1" data-path="C11Binary.html"><a href="C11Binary.html#S:Sec111"><i class="fa fa-check"></i><b>11.1</b> Variables Dependientes Binarias</a></li>
<li class="chapter" data-level="11.2" data-path="C11Binary.html"><a href="C11Binary.html#S:Sec112"><i class="fa fa-check"></i><b>11.2</b> Modelos de Regresión Logística y Probit</a>
<ul>
<li class="chapter" data-level="11.2.1" data-path="C11Binary.html"><a href="C11Binary.html#S:Sec1121"><i class="fa fa-check"></i><b>11.2.1</b> Uso de Funciones No Lineales de Variables Explicativas</a></li>
<li class="chapter" data-level="11.2.2" data-path="C11Binary.html"><a href="C11Binary.html#S:Sec1122"><i class="fa fa-check"></i><b>11.2.2</b> Interpretación del Umbral</a></li>
<li class="chapter" data-level="11.2.3" data-path="C11Binary.html"><a href="C11Binary.html#S:Sec1123"><i class="fa fa-check"></i><b>11.2.3</b> Interpretación de Utilidad Aleatoria</a></li>
<li class="chapter" data-level="11.2.4" data-path="C11Binary.html"><a href="C11Binary.html#S:Sec1124"><i class="fa fa-check"></i><b>11.2.4</b> Regresión Logística</a></li>
</ul></li>
<li class="chapter" data-level="11.3" data-path="C11Binary.html"><a href="C11Binary.html#S:Sec113"><i class="fa fa-check"></i><b>11.3</b> Inferencia para Modelos de Regresión Logística y Probit</a>
<ul>
<li class="chapter" data-level="11.3.1" data-path="C11Binary.html"><a href="C11Binary.html#estimación-de-parámetros"><i class="fa fa-check"></i><b>11.3.1</b> Estimación de Parámetros</a></li>
<li class="chapter" data-level="11.3.2" data-path="C11Binary.html"><a href="C11Binary.html#inferencia-adicional"><i class="fa fa-check"></i><b>11.3.2</b> Inferencia Adicional</a></li>
</ul></li>
<li class="chapter" data-level="11.4" data-path="C11Binary.html"><a href="C11Binary.html#S:Sec114"><i class="fa fa-check"></i><b>11.4</b> Aplicación: Gastos Médicos</a></li>
<li class="chapter" data-level="11.5" data-path="C11Binary.html"><a href="C11Binary.html#S:Sec115"><i class="fa fa-check"></i><b>11.5</b> Variables Dependientes Nominales</a>
<ul>
<li class="chapter" data-level="11.5.1" data-path="C11Binary.html"><a href="C11Binary.html#S:Sec1151"><i class="fa fa-check"></i><b>11.5.1</b> Logit Generalizado</a></li>
<li class="chapter" data-level="11.5.2" data-path="C11Binary.html"><a href="C11Binary.html#S:Sec1152"><i class="fa fa-check"></i><b>11.5.2</b> Logit Multinomial</a></li>
<li class="chapter" data-level="11.5.3" data-path="C11Binary.html"><a href="C11Binary.html#S:Sec1153"><i class="fa fa-check"></i><b>11.5.3</b> Logit Anidado</a></li>
</ul></li>
<li class="chapter" data-level="11.6" data-path="C11Binary.html"><a href="C11Binary.html#S:Sec116"><i class="fa fa-check"></i><b>11.6</b> Variables Dependientes Ordinales</a>
<ul>
<li class="chapter" data-level="11.6.1" data-path="C11Binary.html"><a href="C11Binary.html#logit-acumulativo"><i class="fa fa-check"></i><b>11.6.1</b> Logit Acumulativo</a></li>
<li class="chapter" data-level="11.6.2" data-path="C11Binary.html"><a href="C11Binary.html#probit-acumulativo"><i class="fa fa-check"></i><b>11.6.2</b> Probit Acumulativo</a></li>
</ul></li>
<li class="chapter" data-level="11.7" data-path="C11Binary.html"><a href="C11Binary.html#S:Sec117"><i class="fa fa-check"></i><b>11.7</b> Lecturas Adicionales y Referencias</a></li>
<li class="chapter" data-level="11.8" data-path="C11Binary.html"><a href="C11Binary.html#S:Sec118"><i class="fa fa-check"></i><b>11.8</b> Ejercicios</a></li>
<li class="chapter" data-level="11.9" data-path="C11Binary.html"><a href="C11Binary.html#S:Sec119"><i class="fa fa-check"></i><b>11.9</b> Suplementos Técnicos - Inferencia Basada en Verosimilitud</a>
<ul>
<li class="chapter" data-level="11.9.1" data-path="C11Binary.html"><a href="C11Binary.html#S:Sec1191"><i class="fa fa-check"></i><b>11.9.1</b> Propiedades de las Funciones de Verosimilitud</a></li>
<li class="chapter" data-level="11.9.2" data-path="C11Binary.html"><a href="C11Binary.html#S:Sec1192"><i class="fa fa-check"></i><b>11.9.2</b> Estimadores de Máxima Verosimilitud</a></li>
<li class="chapter" data-level="11.9.3" data-path="C11Binary.html"><a href="C11Binary.html#S:Sec1193"><i class="fa fa-check"></i><b>11.9.3</b> Pruebas de Hipótesis</a></li>
<li class="chapter" data-level="11.9.4" data-path="C11Binary.html"><a href="C11Binary.html#S:Sec1194"><i class="fa fa-check"></i><b>11.9.4</b> Criterios de Información</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="12" data-path="C12Count.html"><a href="C12Count.html"><i class="fa fa-check"></i><b>12</b> Variables Dependientes de Conteo</a>
<ul>
<li class="chapter" data-level="12.1" data-path="C12Count.html"><a href="C12Count.html#S:Sec121"><i class="fa fa-check"></i><b>12.1</b> Regresión de Poisson</a>
<ul>
<li class="chapter" data-level="12.1.1" data-path="C12Count.html"><a href="C12Count.html#S:Sec1211"><i class="fa fa-check"></i><b>12.1.1</b> Distribución de Poisson</a></li>
<li class="chapter" data-level="12.1.2" data-path="C12Count.html"><a href="C12Count.html#S:Sec1212"><i class="fa fa-check"></i><b>12.1.2</b> Modelo de Regresión</a></li>
<li class="chapter" data-level="12.1.3" data-path="C12Count.html"><a href="C12Count.html#S:Sec1213"><i class="fa fa-check"></i><b>12.1.3</b> Estimación</a></li>
<li class="chapter" data-level="12.1.4" data-path="C12Count.html"><a href="C12Count.html#S:Sec1214"><i class="fa fa-check"></i><b>12.1.4</b> Inferencia Adicional</a></li>
</ul></li>
<li class="chapter" data-level="12.2" data-path="C12Count.html"><a href="C12Count.html#S:Sec122"><i class="fa fa-check"></i><b>12.2</b> Aplicación: Seguro de Automóviles en Singapur</a></li>
<li class="chapter" data-level="12.3" data-path="C12Count.html"><a href="C12Count.html#S:Sec123"><i class="fa fa-check"></i><b>12.3</b> Sobre dispersión y Modelos Binomiales Negativos</a></li>
<li class="chapter" data-level="12.4" data-path="C12Count.html"><a href="C12Count.html#S:Sec124"><i class="fa fa-check"></i><b>12.4</b> Otros Modelos de Conteo</a>
<ul>
<li class="chapter" data-level="12.4.1" data-path="C12Count.html"><a href="C12Count.html#modelos-inflados-en-ceros"><i class="fa fa-check"></i><b>12.4.1</b> Modelos Inflados en Ceros</a></li>
<li class="chapter" data-level="12.4.2" data-path="C12Count.html"><a href="C12Count.html#modelos-hurdle"><i class="fa fa-check"></i><b>12.4.2</b> Modelos Hurdle</a></li>
<li class="chapter" data-level="12.4.3" data-path="C12Count.html"><a href="C12Count.html#modelos-de-heterogeneidad"><i class="fa fa-check"></i><b>12.4.3</b> Modelos de Heterogeneidad</a></li>
<li class="chapter" data-level="12.4.4" data-path="C12Count.html"><a href="C12Count.html#modelos-de-clases-latentes"><i class="fa fa-check"></i><b>12.4.4</b> Modelos de Clases Latentes</a></li>
</ul></li>
<li class="chapter" data-level="12.5" data-path="C12Count.html"><a href="C12Count.html#S:Sec125"><i class="fa fa-check"></i><b>12.5</b> Lecturas Adicionales y Referencias</a></li>
<li class="chapter" data-level="12.6" data-path="C12Count.html"><a href="C12Count.html#S:Sec126"><i class="fa fa-check"></i><b>12.6</b> Ejercicios</a></li>
</ul></li>
<li class="chapter" data-level="13" data-path="C13GLM.html"><a href="C13GLM.html"><i class="fa fa-check"></i><b>13</b> Modelos Lineales Generalizados</a>
<ul>
<li class="chapter" data-level="13.1" data-path="C13GLM.html"><a href="C13GLM.html#S:Sec131"><i class="fa fa-check"></i><b>13.1</b> Introducción</a></li>
<li class="chapter" data-level="13.2" data-path="C13GLM.html"><a href="C13GLM.html#S:Sec132"><i class="fa fa-check"></i><b>13.2</b> Modelo GLM</a>
<ul>
<li class="chapter" data-level="13.2.1" data-path="C13GLM.html"><a href="C13GLM.html#S:Sec1321"><i class="fa fa-check"></i><b>13.2.1</b> Familia Exponencial Lineal de Distribuciones</a></li>
<li class="chapter" data-level="13.2.2" data-path="C13GLM.html"><a href="C13GLM.html#S:Sec1322"><i class="fa fa-check"></i><b>13.2.2</b> Funciones de Enlace</a></li>
</ul></li>
<li class="chapter" data-level="13.3" data-path="C13GLM.html"><a href="C13GLM.html#S:Sec133"><i class="fa fa-check"></i><b>13.3</b> Estimación</a>
<ul>
<li class="chapter" data-level="13.3.1" data-path="C13GLM.html"><a href="C13GLM.html#S:Sec1331"><i class="fa fa-check"></i><b>13.3.1</b> Estimación de Máxima Verosimilitud para Enlaces Canónicos</a></li>
<li class="chapter" data-level="13.3.2" data-path="C13GLM.html"><a href="C13GLM.html#sobredispersión"><i class="fa fa-check"></i><b>13.3.2</b> Sobredispersión</a></li>
<li class="chapter" data-level="13.3.3" data-path="C13GLM.html"><a href="C13GLM.html#S:Sec1333"><i class="fa fa-check"></i><b>13.3.3</b> Estadísticas de Bondad de Ajuste</a></li>
</ul></li>
<li class="chapter" data-level="13.4" data-path="C13GLM.html"><a href="C13GLM.html#S:Sec134"><i class="fa fa-check"></i><b>13.4</b> Aplicación: Gastos Médicos</a></li>
<li class="chapter" data-level="13.5" data-path="C13GLM.html"><a href="C13GLM.html#S:Sec135"><i class="fa fa-check"></i><b>13.5</b> Residuales</a></li>
<li class="chapter" data-level="13.6" data-path="C13GLM.html"><a href="C13GLM.html#S:Sec136"><i class="fa fa-check"></i><b>13.6</b> Distribución de Tweedie</a></li>
<li class="chapter" data-level="13.7" data-path="C13GLM.html"><a href="C13GLM.html#S:Sec137"><i class="fa fa-check"></i><b>13.7</b> Lecturas adicionales y referencias</a></li>
<li class="chapter" data-level="13.8" data-path="C13GLM.html"><a href="C13GLM.html#S:Sec138"><i class="fa fa-check"></i><b>13.8</b> Ejercicios</a></li>
<li class="chapter" data-level="13.9" data-path="C13GLM.html"><a href="C13GLM.html#S:Sec139"><i class="fa fa-check"></i><b>13.9</b> Suplementos Técnicos - Familia Exponencial</a>
<ul>
<li class="chapter" data-level="13.9.1" data-path="C13GLM.html"><a href="C13GLM.html#S:Sec1391"><i class="fa fa-check"></i><b>13.9.1</b> Familia Exponencial Lineal de Distribuciones</a></li>
<li class="chapter" data-level="13.9.2" data-path="C13GLM.html"><a href="C13GLM.html#S:Sec1392"><i class="fa fa-check"></i><b>13.9.2</b> Momentos</a></li>
<li class="chapter" data-level="13.9.3" data-path="C13GLM.html"><a href="C13GLM.html#S:Sec1393"><i class="fa fa-check"></i><b>13.9.3</b> Estimación de Máxima Verosimilitud para Enlaces Generales</a></li>
<li class="chapter" data-level="13.9.4" data-path="C13GLM.html"><a href="C13GLM.html#S:Sec1394"><i class="fa fa-check"></i><b>13.9.4</b> Mínimos Cuadrados Reponderados Iterativos</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="14" data-path="C14Survival.html"><a href="C14Survival.html"><i class="fa fa-check"></i><b>14</b> Modelos de Supervivencia</a>
<ul>
<li class="chapter" data-level="14.1" data-path="C14Survival.html"><a href="C14Survival.html#introducción-2"><i class="fa fa-check"></i><b>14.1</b> Introducción</a></li>
<li class="chapter" data-level="14.2" data-path="C14Survival.html"><a href="C14Survival.html#S:Sec142"><i class="fa fa-check"></i><b>14.2</b> Censura y Truncamiento</a>
<ul>
<li class="chapter" data-level="14.2.1" data-path="C14Survival.html"><a href="C14Survival.html#definiciones-y-ejemplos"><i class="fa fa-check"></i><b>14.2.1</b> Definiciones y Ejemplos</a></li>
<li class="chapter" data-level="14.2.2" data-path="C14Survival.html"><a href="C14Survival.html#inferencia-por-verosimilitud"><i class="fa fa-check"></i><b>14.2.2</b> Inferencia por Verosimilitud</a></li>
<li class="chapter" data-level="14.2.3" data-path="C14Survival.html"><a href="C14Survival.html#estimador-producto-límite"><i class="fa fa-check"></i><b>14.2.3</b> Estimador Producto-Límite</a></li>
</ul></li>
<li class="chapter" data-level="14.3" data-path="C14Survival.html"><a href="C14Survival.html#S:Sec143"><i class="fa fa-check"></i><b>14.3</b> Modelo de Tiempo de Fallo Acelerado</a></li>
<li class="chapter" data-level="14.4" data-path="C14Survival.html"><a href="C14Survival.html#S:Sec144"><i class="fa fa-check"></i><b>14.4</b> Modelo de Riesgos Proporcionales</a>
<ul>
<li class="chapter" data-level="14.4.1" data-path="C14Survival.html"><a href="C14Survival.html#S:Sec1441"><i class="fa fa-check"></i><b>14.4.1</b> Riesgos Proporcionales</a></li>
<li class="chapter" data-level="14.4.2" data-path="C14Survival.html"><a href="C14Survival.html#S:Sec1442"><i class="fa fa-check"></i><b>14.4.2</b> Inferencia</a></li>
</ul></li>
<li class="chapter" data-level="14.5" data-path="C14Survival.html"><a href="C14Survival.html#S:Sec145"><i class="fa fa-check"></i><b>14.5</b> Eventos Recurrentes</a></li>
<li class="chapter" data-level="14.6" data-path="C14Survival.html"><a href="C14Survival.html#S:Sec146"><i class="fa fa-check"></i><b>14.6</b> Lecturas Adicionales y Referencias</a></li>
</ul></li>
<li class="chapter" data-level="15" data-path="C15Misc.html"><a href="C15Misc.html"><i class="fa fa-check"></i><b>15</b> Temas Misceláneos de Regresión</a>
<ul>
<li class="chapter" data-level="15.1" data-path="C15Misc.html"><a href="C15Misc.html#S:Sec151"><i class="fa fa-check"></i><b>15.1</b> Modelos Lineales Mixtos</a>
<ul>
<li class="chapter" data-level="15.1.1" data-path="C15Misc.html"><a href="C15Misc.html#mínimos-cuadrados-ponderados-2"><i class="fa fa-check"></i><b>15.1.1</b> Mínimos Cuadrados Ponderados</a></li>
<li class="chapter" data-level="15.1.2" data-path="C15Misc.html"><a href="C15Misc.html#S:Sec1512"><i class="fa fa-check"></i><b>15.1.2</b> Estimación de Componentes de Varianza</a></li>
<li class="chapter" data-level="15.1.3" data-path="C15Misc.html"><a href="C15Misc.html#mejor-predicción-lineal-insesgada"><i class="fa fa-check"></i><b>15.1.3</b> Mejor Predicción Lineal Insesgada</a></li>
</ul></li>
<li class="chapter" data-level="15.2" data-path="C15Misc.html"><a href="C15Misc.html#regresión-bayesiana"><i class="fa fa-check"></i><b>15.2</b> Regresión Bayesiana</a></li>
<li class="chapter" data-level="15.3" data-path="C15Misc.html"><a href="C15Misc.html#S:Sec153"><i class="fa fa-check"></i><b>15.3</b> Estimación de Densidad y Suavizado de Diagramas de Dispersión</a></li>
<li class="chapter" data-level="15.4" data-path="C15Misc.html"><a href="C15Misc.html#S:Sec154"><i class="fa fa-check"></i><b>15.4</b> Modelos Aditivos Generalizados</a></li>
<li class="chapter" data-level="15.5" data-path="C15Misc.html"><a href="C15Misc.html#bootstrapping"><i class="fa fa-check"></i><b>15.5</b> Bootstrapping</a></li>
<li class="chapter" data-level="15.6" data-path="C15Misc.html"><a href="C15Misc.html#lecturas-adicionales-y-referencias-2"><i class="fa fa-check"></i><b>15.6</b> Lecturas Adicionales y Referencias</a></li>
</ul></li>
<li class="chapter" data-level="16" data-path="C16FreqSev.html"><a href="C16FreqSev.html"><i class="fa fa-check"></i><b>16</b> Modelos de Frecuencia-Severidad</a>
<ul>
<li class="chapter" data-level="16.1" data-path="C16FreqSev.html"><a href="C16FreqSev.html#S:Sec161"><i class="fa fa-check"></i><b>16.1</b> Introducción</a></li>
<li class="chapter" data-level="16.2" data-path="C16FreqSev.html"><a href="C16FreqSev.html#S:Sec162"><i class="fa fa-check"></i><b>16.2</b> Modelo Tobit</a></li>
<li class="chapter" data-level="16.3" data-path="C16FreqSev.html"><a href="C16FreqSev.html#S:Sec163"><i class="fa fa-check"></i><b>16.3</b> Aplicación: Gastos Médicos</a></li>
<li class="chapter" data-level="16.4" data-path="C16FreqSev.html"><a href="C16FreqSev.html#S:Sec164"><i class="fa fa-check"></i><b>16.4</b> Modelo de Dos Partes</a></li>
<li class="chapter" data-level="16.5" data-path="C16FreqSev.html"><a href="C16FreqSev.html#S:Sec165"><i class="fa fa-check"></i><b>16.5</b> Modelo de Pérdidas Agregadas</a></li>
<li class="chapter" data-level="16.6" data-path="C16FreqSev.html"><a href="C16FreqSev.html#S:Sec166"><i class="fa fa-check"></i><b>16.6</b> Lecturas Adicionales y Referencias</a></li>
<li class="chapter" data-level="16.7" data-path="C16FreqSev.html"><a href="C16FreqSev.html#S:Sec167"><i class="fa fa-check"></i><b>16.7</b> Ejercicios</a></li>
</ul></li>
<li class="chapter" data-level="17" data-path="C17Fat.html"><a href="C17Fat.html"><i class="fa fa-check"></i><b>17</b> Modelos de Regresión con Colas Gruesas</a>
<ul>
<li class="chapter" data-level="17.1" data-path="C17Fat.html"><a href="C17Fat.html#introducción-3"><i class="fa fa-check"></i><b>17.1</b> Introducción</a></li>
<li class="chapter" data-level="17.2" data-path="C17Fat.html"><a href="C17Fat.html#S:Sec172"><i class="fa fa-check"></i><b>17.2</b> Transformaciones</a></li>
<li class="chapter" data-level="17.3" data-path="C17Fat.html"><a href="C17Fat.html#S:Sec173"><i class="fa fa-check"></i><b>17.3</b> Modelos Lineales Generalizados</a>
<ul>
<li class="chapter" data-level="17.3.1" data-path="C17Fat.html"><a href="C17Fat.html#S:Sec1731"><i class="fa fa-check"></i><b>17.3.1</b> ¿Qué significa “Cola Gruesa”?</a></li>
<li class="chapter" data-level="17.3.2" data-path="C17Fat.html"><a href="C17Fat.html#S:Sec1732"><i class="fa fa-check"></i><b>17.3.2</b> Aplicación: Asilos de Ancianos en Wisconsin</a></li>
</ul></li>
<li class="chapter" data-level="17.4" data-path="C17Fat.html"><a href="C17Fat.html#S:Sec174"><i class="fa fa-check"></i><b>17.4</b> Distribuciones Generalizadas</a>
<ul>
<li class="chapter" data-level="" data-path="C17Fat.html"><a href="C17Fat.html#aplicación-hogares-de-ancianos-en-wisconsin"><i class="fa fa-check"></i>Aplicación: Hogares de Ancianos en Wisconsin</a></li>
</ul></li>
<li class="chapter" data-level="17.5" data-path="C17Fat.html"><a href="C17Fat.html#S:Sec175"><i class="fa fa-check"></i><b>17.5</b> Regresión por Cuantiles</a></li>
<li class="chapter" data-level="17.6" data-path="C17Fat.html"><a href="C17Fat.html#S:Sec176"><i class="fa fa-check"></i><b>17.6</b> Modelos de Valores Extremos</a></li>
<li class="chapter" data-level="17.7" data-path="C17Fat.html"><a href="C17Fat.html#lecturas-adicionales-y-referencias-3"><i class="fa fa-check"></i><b>17.7</b> Lecturas Adicionales y Referencias</a></li>
<li class="chapter" data-level="17.8" data-path="C17Fat.html"><a href="C17Fat.html#ejercicios-1"><i class="fa fa-check"></i><b>17.8</b> Ejercicios</a></li>
</ul></li>
<li class="chapter" data-level="18" data-path="C18Cred.html"><a href="C18Cred.html"><i class="fa fa-check"></i><b>18</b> Credibilidad y Bonus-Malus</a>
<ul>
<li class="chapter" data-level="18.1" data-path="C18Cred.html"><a href="C18Cred.html#clasificación-de-riesgos-y-experiencia"><i class="fa fa-check"></i><b>18.1</b> Clasificación de Riesgos y Experiencia</a></li>
<li class="chapter" data-level="18.2" data-path="C18Cred.html"><a href="C18Cred.html#S:Sec182"><i class="fa fa-check"></i><b>18.2</b> Credibilidad</a>
<ul>
<li class="chapter" data-level="18.2.1" data-path="C18Cred.html"><a href="C18Cred.html#S:Sec1821"><i class="fa fa-check"></i><b>18.2.1</b> Credibilidad de Fluctuación Limitada</a></li>
<li class="chapter" data-level="18.2.2" data-path="C18Cred.html"><a href="C18Cred.html#S:Sec1822"><i class="fa fa-check"></i><b>18.2.2</b> Credibilidad de Máxima Precisión</a></li>
</ul></li>
<li class="chapter" data-level="18.3" data-path="C18Cred.html"><a href="C18Cred.html#S:Sec183"><i class="fa fa-check"></i><b>18.3</b> Credibilidad y Regresión</a>
<ul>
<li class="chapter" data-level="18.3.1" data-path="C18Cred.html"><a href="C18Cred.html#modelo-de-efectos-aleatorios-unidireccional"><i class="fa fa-check"></i><b>18.3.1</b> Modelo de Efectos Aleatorios Unidireccional</a></li>
<li class="chapter" data-level="18.3.2" data-path="C18Cred.html"><a href="C18Cred.html#modelos-longitudinales"><i class="fa fa-check"></i><b>18.3.2</b> Modelos Longitudinales</a></li>
</ul></li>
<li class="chapter" data-level="18.4" data-path="C18Cred.html"><a href="C18Cred.html#S:Sec184"><i class="fa fa-check"></i><b>18.4</b> Bonus-Malus</a></li>
</ul></li>
<li class="chapter" data-level="19" data-path="C19Triangles.html"><a href="C19Triangles.html"><i class="fa fa-check"></i><b>19</b> Triángulos de Reclamos</a>
<ul>
<li class="chapter" data-level="19.1" data-path="C19Triangles.html"><a href="C19Triangles.html#introducción-4"><i class="fa fa-check"></i><b>19.1</b> Introducción</a>
<ul>
<li class="chapter" data-level="19.1.1" data-path="C19Triangles.html"><a href="C19Triangles.html#S:Sec1911"><i class="fa fa-check"></i><b>19.1.1</b> Evolución de los Reclamos</a></li>
<li class="chapter" data-level="19.1.2" data-path="C19Triangles.html"><a href="C19Triangles.html#S:Sec1912"><i class="fa fa-check"></i><b>19.1.2</b> Triángulos de Reclamos</a></li>
<li class="chapter" data-level="19.1.3" data-path="C19Triangles.html"><a href="C19Triangles.html#S:Sec1913"><i class="fa fa-check"></i><b>19.1.3</b> Método de Escalera de Cadenas</a></li>
</ul></li>
<li class="chapter" data-level="19.2" data-path="C19Triangles.html"><a href="C19Triangles.html#S:Sec192"><i class="fa fa-check"></i><b>19.2</b> Regresión Usando Funciones del Tiempo como Variables Explicativas</a>
<ul>
<li class="chapter" data-level="19.2.1" data-path="C19Triangles.html"><a href="C19Triangles.html#S:Sec1921"><i class="fa fa-check"></i><b>19.2.1</b> Modelo Lognormal</a></li>
<li class="chapter" data-level="19.2.2" data-path="C19Triangles.html"><a href="C19Triangles.html#S:Sec1922"><i class="fa fa-check"></i><b>19.2.2</b> Curva de Hoerl</a></li>
<li class="chapter" data-level="19.2.3" data-path="C19Triangles.html"><a href="C19Triangles.html#S:Sec1923"><i class="fa fa-check"></i><b>19.2.3</b> Modelos de Poisson</a></li>
</ul></li>
<li class="chapter" data-level="19.3" data-path="C19Triangles.html"><a href="C19Triangles.html#S:Sec193"><i class="fa fa-check"></i><b>19.3</b> Usando Desarrollos Pasados</a>
<ul>
<li class="chapter" data-level="19.3.1" data-path="C19Triangles.html"><a href="C19Triangles.html#S:Sec1931"><i class="fa fa-check"></i><b>19.3.1</b> Modelo de Mack</a></li>
<li class="chapter" data-level="19.3.2" data-path="C19Triangles.html"><a href="C19Triangles.html#S:Sec1932"><i class="fa fa-check"></i><b>19.3.2</b> Modelos Distribucionales</a></li>
</ul></li>
<li class="chapter" data-level="19.4" data-path="C19Triangles.html"><a href="C19Triangles.html#lecturas-adicionales-y-referencias-4"><i class="fa fa-check"></i><b>19.4</b> Lecturas Adicionales y Referencias</a></li>
<li class="chapter" data-level="19.5" data-path="C19Triangles.html"><a href="C19Triangles.html#ejercicios-2"><i class="fa fa-check"></i><b>19.5</b> Ejercicios</a></li>
</ul></li>
<li class="chapter" data-level="20" data-path="C20Report.html"><a href="C20Report.html"><i class="fa fa-check"></i><b>20</b> Redacción de Informes: Comunicando Resultados del Análisis de Datos</a>
<ul>
<li class="chapter" data-level="20.1" data-path="C20Report.html"><a href="C20Report.html#S20:Overview"><i class="fa fa-check"></i><b>20.1</b> Visión General</a></li>
<li class="chapter" data-level="20.2" data-path="C20Report.html"><a href="C20Report.html#S20:Methods"><i class="fa fa-check"></i><b>20.2</b> Métodos para Comunicar Datos</a>
<ul>
<li class="chapter" data-level="" data-path="C20Report.html"><a href="C20Report.html#datos-dentro-del-texto"><i class="fa fa-check"></i>Datos Dentro del Texto</a></li>
<li class="chapter" data-level="" data-path="C20Report.html"><a href="C20Report.html#gráficos"><i class="fa fa-check"></i>Gráficos</a></li>
</ul></li>
<li class="chapter" data-level="20.3" data-path="C20Report.html"><a href="C20Report.html#S20:Organize"><i class="fa fa-check"></i><b>20.3</b> Cómo Organizar</a>
<ul>
<li class="chapter" data-level="" data-path="C20Report.html"><a href="C20Report.html#título-y-resumen"><i class="fa fa-check"></i>Título y Resumen</a></li>
<li class="chapter" data-level="" data-path="C20Report.html"><a href="C20Report.html#introducción-5"><i class="fa fa-check"></i>Introducción</a></li>
<li class="chapter" data-level="" data-path="C20Report.html"><a href="C20Report.html#selección-e-interpretación-del-modelo"><i class="fa fa-check"></i>Selección e Interpretación del Modelo</a></li>
<li class="chapter" data-level="" data-path="C20Report.html"><a href="C20Report.html#referencias-y-apéndice"><i class="fa fa-check"></i>Referencias y Apéndice</a></li>
</ul></li>
<li class="chapter" data-level="20.4" data-path="C20Report.html"><a href="C20Report.html#sugerencias-adicionales-para-la-redacción-de-informes"><i class="fa fa-check"></i><b>20.4</b> Sugerencias Adicionales para la Redacción de Informes</a></li>
<li class="chapter" data-level="20.5" data-path="C20Report.html"><a href="C20Report.html#estudio-de-caso-reclamos-de-automóviles-en-suecia"><i class="fa fa-check"></i><b>20.5</b> Estudio de Caso: Reclamos de Automóviles en Suecia</a></li>
<li class="chapter" data-level="20.6" data-path="C20Report.html"><a href="C20Report.html#lecturas-adicionales-y-referencias-5"><i class="fa fa-check"></i><b>20.6</b> Lecturas Adicionales y Referencias</a></li>
<li class="chapter" data-level="20.7" data-path="C20Report.html"><a href="C20Report.html#ejercicio"><i class="fa fa-check"></i><b>20.7</b> Ejercicio</a></li>
</ul></li>
<li class="chapter" data-level="21" data-path="C21Design.html"><a href="C21Design.html"><i class="fa fa-check"></i><b>21</b> Diseñando Gráficos Efectivos</a>
<ul>
<li class="chapter" data-level="21.1" data-path="C21Design.html"><a href="C21Design.html#S21:Intro"><i class="fa fa-check"></i><b>21.1</b> Introducción</a></li>
<li class="chapter" data-level="21.2" data-path="C21Design.html"><a href="C21Design.html#S21:GDesign"><i class="fa fa-check"></i><b>21.2</b> Las Elecciones de Diseño Gráfico Marcan la Diferencia</a></li>
<li class="chapter" data-level="21.3" data-path="C21Design.html"><a href="C21Design.html#S21:DesignGuide"><i class="fa fa-check"></i><b>21.3</b> Directrices de Diseño</a>
<ul>
<li class="chapter" data-level="" data-path="C21Design.html"><a href="C21Design.html#directriz-uno-evitar-chartjunk"><i class="fa fa-check"></i>Directriz Uno: Evitar Chartjunk</a></li>
<li class="chapter" data-level="" data-path="C21Design.html"><a href="C21Design.html#directriz-dos-usar-múltiplos-pequeños-para-fomentar-comparaciones-y-evaluar-cambios"><i class="fa fa-check"></i>Directriz Dos: Usar Múltiplos Pequeños para Fomentar Comparaciones y Evaluar Cambios</a></li>
<li class="chapter" data-level="" data-path="C21Design.html"><a href="C21Design.html#directriz-tres-utilice-gráficos-complejos-para-representar-patrones-complejos"><i class="fa fa-check"></i>Directriz Tres: Utilice Gráficos Complejos para Representar Patrones Complejos</a></li>
<li class="chapter" data-level="" data-path="C21Design.html"><a href="C21Design.html#directriz-cuatro-relacione-el-tamaño-del-gráfico-con-el-contenido-informativo"><i class="fa fa-check"></i>Directriz Cuatro: Relacione el Tamaño del Gráfico con el Contenido Informativo</a></li>
<li class="chapter" data-level="" data-path="C21Design.html"><a href="C21Design.html#directriz-cinco-utilizar-formas-gráficas-que-promuevan-comparaciones"><i class="fa fa-check"></i>Directriz Cinco: Utilizar Formas Gráficas que Promuevan Comparaciones</a></li>
<li class="chapter" data-level="" data-path="C21Design.html"><a href="C21Design.html#directriz-seis-integrar-gráficos-y-texto"><i class="fa fa-check"></i>Directriz Seis: Integrar Gráficos y Texto</a></li>
<li class="chapter" data-level="" data-path="C21Design.html"><a href="C21Design.html#directriz-siete-demostrar-un-mensaje-importante"><i class="fa fa-check"></i>Directriz Siete: Demostrar un Mensaje Importante</a></li>
<li class="chapter" data-level="" data-path="C21Design.html"><a href="C21Design.html#directriz-ocho-conozca-a-su-audiencia"><i class="fa fa-check"></i>Directriz Ocho: Conozca a su Audiencia</a></li>
</ul></li>
<li class="chapter" data-level="21.4" data-path="C21Design.html"><a href="C21Design.html#S21:EmpiricalFoundations"><i class="fa fa-check"></i><b>21.4</b> Fundamentos Empíricos para las Directrices</a>
<ul>
<li class="chapter" data-level="21.4.1" data-path="C21Design.html"><a href="C21Design.html#gráficos-como-unidades-de-estudio"><i class="fa fa-check"></i><b>21.4.1</b> Gráficos como Unidades de Estudio</a></li>
</ul></li>
<li class="chapter" data-level="21.5" data-path="C21Design.html"><a href="C21Design.html#S21:Conclude"><i class="fa fa-check"></i><b>21.5</b> Observaciones Finales</a></li>
<li class="chapter" data-level="21.6" data-path="C21Design.html"><a href="C21Design.html#S21:References"><i class="fa fa-check"></i><b>21.6</b> Lecturas Adicionales y Referencias</a></li>
</ul></li>
<li class="chapter" data-level="22" data-path="apéndices.html"><a href="apéndices.html"><i class="fa fa-check"></i><b>22</b> Apéndices</a>
<ul>
<li class="chapter" data-level="" data-path="apéndices.html"><a href="apéndices.html#apéndice-a1.-inferencia-estadística-básica"><i class="fa fa-check"></i>Apéndice A1. Inferencia Estadística Básica</a>
<ul>
<li class="chapter" data-level="" data-path="apéndices.html"><a href="apéndices.html#distribuciones-de-funciones-de-variables-aleatorias"><i class="fa fa-check"></i>Distribuciones de Funciones de Variables Aleatorias</a></li>
<li class="chapter" data-level="" data-path="apéndices.html"><a href="apéndices.html#estimación-y-predicción"><i class="fa fa-check"></i>Estimación y Predicción</a></li>
<li class="chapter" data-level="" data-path="apéndices.html"><a href="apéndices.html#pruebas-de-hipótesis"><i class="fa fa-check"></i>Pruebas de Hipótesis</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="apéndices.html"><a href="apéndices.html#apéndice-a2.-álgebra-de-matrices"><i class="fa fa-check"></i>Apéndice A2. Álgebra de Matrices</a>
<ul>
<li class="chapter" data-level="" data-path="apéndices.html"><a href="apéndices.html#definiciones-básicas"><i class="fa fa-check"></i>Definiciones Básicas</a></li>
<li class="chapter" data-level="" data-path="apéndices.html"><a href="apéndices.html#revisión-de-operaciones-básicas"><i class="fa fa-check"></i>Revisión de Operaciones Básicas</a></li>
<li class="chapter" data-level="" data-path="apéndices.html"><a href="apéndices.html#definiciones-adicionales"><i class="fa fa-check"></i>Definiciones Adicionales</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="apéndices.html"><a href="apéndices.html#apéndice-a3.-tablas-de-probabilidad"><i class="fa fa-check"></i>Apéndice A3. Tablas de Probabilidad</a>
<ul>
<li class="chapter" data-level="" data-path="apéndices.html"><a href="apéndices.html#distribución-normal"><i class="fa fa-check"></i>Distribución Normal</a></li>
<li class="chapter" data-level="" data-path="apéndices.html"><a href="apéndices.html#distribución-chi-cuadrado"><i class="fa fa-check"></i>Distribución Chi-Cuadrado</a></li>
<li class="chapter" data-level="" data-path="apéndices.html"><a href="apéndices.html#distribución-t"><i class="fa fa-check"></i>Distribución <em>t</em></a></li>
<li class="chapter" data-level="" data-path="apéndices.html"><a href="apéndices.html#distribución-f"><i class="fa fa-check"></i>Distribución <em>F</em></a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="" data-path="respuestas-breves-a-ejercicios-seleccionados.html"><a href="respuestas-breves-a-ejercicios-seleccionados.html"><i class="fa fa-check"></i>Respuestas Breves a Ejercicios Seleccionados</a></li>
<li class="divider"></li>
<li><a href="https://github.com/OpenActTextDev/RegressionSpanish/" target="blank">Regresión en Español en GitHub</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Modelado de Regresión con Aplicaciones Actuariales y Financieras</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="interpretación-de-resultados-de-regresión" class="section level1 hasAnchor" number="6">
<h1><span class="header-section-number">Capítulo 6</span> Interpretación de Resultados de Regresión<a href="interpretación-de-resultados-de-regresión.html#interpretación-de-resultados-de-regresión" class="anchor-section" aria-label="Anchor link to header"></a></h1>
<p><em>Vista previa del capítulo</em>. Un analista de regresión recopila datos, selecciona un modelo y luego informa sobre los hallazgos del estudio, en ese orden. Este capítulo considera estos tres temas en <em>orden inverso</em>, enfatizando cómo cada etapa del estudio está influenciada por los pasos precedentes. Una aplicación, determinar las características de una empresa que influyen en su efectividad para gestionar el riesgo, ilustra el proceso de modelado de regresión de principio a fin.</p>
<hr />
<p>Estudiar un problema utilizando un proceso de modelado de regresión implica un compromiso sustancial de tiempo y energía. Primero, uno debe adoptar el concepto de <em>pensamiento estadístico</em>, es decir, estar dispuesto a utilizar los datos activamente como parte de un proceso de toma de decisiones. En segundo lugar, uno debe apreciar la utilidad de un modelo que se usa para aproximar una situación real. Después de hacer este compromiso sustancial, hay una tendencia natural a “sobrevender” los resultados de métodos estadísticos como el análisis de regresión. Al sobrevender cualquier conjunto de ideas, los consumidores eventualmente se sienten decepcionados cuando los resultados no cumplen con sus expectativas. Este capítulo comienza en la Sección <a href="interpretación-de-resultados-de-regresión.html#Sec61">6.1</a> resumiendo lo que podemos esperar aprender razonablemente del modelado de regresión.</p>
<p>Los modelos están diseñados para ser mucho más simples que las relaciones entre entidades que existen en el mundo real. Un modelo es simplemente una aproximación de la realidad. Como dijo George Box (1979), “Todos los modelos son incorrectos, pero algunos son útiles”. Desarrollar el modelo, el tema del Capítulo 5, es parte del arte de la estadística. Aunque los principios de la selección de variables son ampliamente aceptados, la aplicación de estos principios puede variar considerablemente entre los analistas. El producto resultante tiene ciertos valores estéticos y de ninguna manera está predeterminado. La estadística se puede considerar como el arte de razonar con datos. La Sección <a href="interpretación-de-resultados-de-regresión.html#Sec62">6.2</a> subrayará la importancia de la selección de variables.</p>
<p>La formulación del modelo y la recopilación de datos forman la primera etapa del proceso de modelado. Los estudiantes de estadística suelen sorprenderse por la dificultad de relacionar ideas sobre relaciones con los datos disponibles. Estas dificultades incluyen la falta de datos fácilmente disponibles y la necesidad de usar ciertos datos como sustitutos de la información ideal que no está disponible numéricamente. La Sección <a href="interpretación-de-resultados-de-regresión.html#Sec63">6.3</a> describirá varios tipos de dificultades que pueden surgir al recopilar datos. La Sección <a href="interpretación-de-resultados-de-regresión.html#Sec64">6.4</a> describirá algunos modelos para aliviar estas dificultades.</p>
<div id="Sec61" class="section level2 hasAnchor" number="6.1">
<h2><span class="header-section-number">6.1</span> Lo que nos dice el proceso de modelado<a href="interpretación-de-resultados-de-regresión.html#Sec61" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>La inferencia del modelo es la etapa final del proceso de modelado. Al estudiar el comportamiento de los modelos, esperamos aprender algo sobre el mundo real. Los modelos sirven para imponer un orden en la realidad y proporcionar una base para entender la realidad a través de la naturaleza del orden impuesto. Además, los modelos estadísticos se basan en el razonamiento con los datos disponibles de una muestra. Por lo tanto, los modelos sirven como una guía importante para predecir el comportamiento de observaciones fuera de la muestra disponible.</p>
<div id="Sec611" class="section level3 hasAnchor" number="6.1.1">
<h3><span class="header-section-number">6.1.1</span> Interpretación de efectos individuales<a href="interpretación-de-resultados-de-regresión.html#Sec611" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Al interpretar los resultados de una regresión múltiple, el objetivo principal es a menudo transmitir la importancia de las variables individuales, o efectos, sobre un resultado de interés. La interpretación depende de si los efectos son o no significativamente sustantivos, estadísticamente significativos y causales.</p>
<p><strong>Significado Sustantivo</strong>. Los lectores de un estudio de regresión primero quieren entender la dirección y magnitud de los efectos individuales. ¿Las mujeres tienen más o menos reclamaciones que los hombres en un estudio de reclamaciones de seguros? Si es menos, ¿cuánto menos? Puedes responder a estas preguntas a través de una tabla de coeficientes de regresión. Además, para dar una idea de la fiabilidad de las estimaciones, también puede ser útil incluir el error estándar o un intervalo de confianza, como se introdujo en la Sección 3.4.2.</p>
<p>Recuerda que los coeficientes de regresión son estimaciones de las derivadas parciales de la función de regresión</p>
<p><span class="math display">\[
\mathrm{E~}y = \beta_0 + \beta_1 x_1 + \ldots + \beta_k x_k.
\]</span></p>
<p>Al interpretar los coeficientes para variables explicativas continuas, es útil hacerlo en términos de cambios significativos de cada <span class="math inline">\(x\)</span>. Por ejemplo, si la población es una variable explicativa, podemos hablar del cambio esperado en <span class="math inline">\(y\)</span> por cada cambio de 1,000 o un millón en la población. Además, al interpretar los coeficientes de regresión, comenta sobre su significado “sustantivo”. Por ejemplo, supongamos que encontramos una diferencia en las reclamaciones entre hombres y mujeres, pero la diferencia estimada es solo del 1% de las reclamaciones esperadas. Esta diferencia puede ser estadísticamente significativa pero no económicamente relevante. La significación sustantiva se refiere a la importancia en el campo de estudio; en ciencia actuarial, esto es típicamente de relevancia financiera o económica, pero también podría ser no monetaria, como los efectos sobre la esperanza de vida futura.</p>
<p><strong>Significado Estadístico</strong>. ¿Son los efectos debidos al azar? La maquinaria de pruebas de hipótesis introducida en la Sección 3.4.1 proporciona un mecanismo formal para responder a esta pregunta. Las pruebas de hipótesis son útiles porque proporcionan un estándar formal y acordado para decidir si una variable hace una contribución importante a una respuesta esperada. Al interpretar los resultados, los investigadores suelen citar un <span class="math inline">\(t\)</span>-ratio o un <span class="math inline">\(p\)</span>-valor para demostrar significación estadística.</p>
<p>En algunas situaciones, es de interés comentar sobre las variables que <em>no</em> son estadísticamente significativas. Los efectos que no son estadísticamente significativos tienen errores estándar que son grandes en relación con los coeficientes de regresión. En la Sección 5.5.2, expresamos este error estándar como</p>
<p><span class="math display" id="eq:eq61">\[\begin{equation}
se(b_{j}) = s \frac{\sqrt{VIF_{j}}}{s_{x_{j}} \sqrt{n-1}}.
\tag{6.1}
\end{equation}\]</span></p>
<p>Una posible explicación para la falta de significancia estadística es una gran variación en el término de perturbación. Al expresar el error estándar en esta forma, vemos que cuanto mayor es la variación natural, medida por <span class="math inline">\(s\)</span>, más difícil es rechazar la hipótesis nula de ningún efecto (<span class="math inline">\(H_0\)</span>), manteniendo todo lo demás constante.</p>
<p>Una segunda posible explicación para la falta de significancia estadística es la alta colinealidad, medida por <span class="math inline">\(VIF_j\)</span>. Una variable puede estar confundida con otras variables de manera que, a partir de los datos que se están analizando, sea imposible distinguir los efectos de una variable de otra.</p>
<p>Una tercera posible explicación es el tamaño de la muestra. Supongamos que se utiliza un mecanismo similar a extracciones de una población estable para observar las variables explicativas. Entonces, la desviación estándar de <span class="math inline">\(x_j\)</span>, <span class="math inline">\(s_{x_j}\)</span>, debería ser estable a medida que aumenta el número de extracciones. De manera similar, también deberían serlo <span class="math inline">\(R_j^2\)</span> y <span class="math inline">\(s^2\)</span>. Entonces, el error estándar <span class="math inline">\(se(b_j)\)</span> debería disminuir a medida que el tamaño de la muestra, <span class="math inline">\(n\)</span>, aumenta. Por el contrario, un tamaño de muestra más pequeño significa un error estándar mayor, manteniendo todo lo demás constante. Esto significa que es posible que no podamos detectar la importancia de las variables en muestras de tamaño pequeño o moderado.</p>
<p>Por lo tanto, en un mundo ideal, si no se detecta significancia estadística donde se había hipotetizado (y completamente esperado), se podría: (i) obtener una medida más precisa de <span class="math inline">\(y\)</span>, reduciendo así su variabilidad natural, (ii) rediseñar el esquema de recolección de muestras para que las variables explicativas relevantes sean menos redundantes y (iii) recopilar más datos. Normalmente, estas opciones no están disponibles con datos observacionales, pero puede ser útil señalar los próximos pasos en un programa de investigación.</p>
<p>Los analistas ocasionalmente observan relaciones estadísticamente significativas que no se anticiparon; esto podría deberse a un tamaño de muestra grande. Anteriormente, mencionamos que una muestra pequeña puede no proporcionar suficiente información para detectar relaciones significativas. La otra cara de este argumento es que, para muestras grandes, tenemos la oportunidad de detectar la importancia de variables que podrían pasar desapercibidas en muestras de tamaño pequeño o incluso moderado. Desafortunadamente, esto también significa que las variables con coeficientes de parámetro pequeños, que contribuyen poco a entender la variación en la respuesta, pueden ser juzgadas como significativas utilizando nuestros procedimientos de toma de decisiones. Esto sirve para resaltar la diferencia entre significancia sustantiva y estadística: en particular, para muestras grandes, los investigadores encuentran variables que son <em>estadísticamente significativas pero prácticamente poco importantes</em>. En estos casos, puede ser prudente que el investigador omita variables de la especificación del modelo cuando su presencia no esté de acuerdo con la teoría aceptada, incluso si se consideran estadísticamente significativas.</p>
<p><strong>Efectos Causales</strong>. Si cambiamos <span class="math inline">\(x\)</span>, ¿cambiaría <span class="math inline">\(y\)</span>? Como estudiantes de ciencias básicas, aprendimos principios que involucran acciones y reacciones. Agregar masa a una bola en movimiento aumenta la fuerza de su impacto contra una pared. Sin embargo, en las ciencias sociales, las relaciones son probabilísticas, no deterministas, y por lo tanto más sutiles. Por ejemplo, a medida que la edad (<span class="math inline">\(x\)</span>) aumenta, la probabilidad de morir en un año (<span class="math inline">\(y\)</span>) aumenta para la mayoría de las curvas de mortalidad humana. Comprender la causalidad, incluso la probabilística, es la raíz de toda la ciencia y proporciona la base para la toma de decisiones informada.</p>
<p>Es importante reconocer que los procesos causales generalmente no pueden demostrarse exclusivamente a partir de los datos; los datos solo pueden presentar evidencia empírica relevante que sirva como un eslabón en una cadena de razonamiento sobre los mecanismos causales. Para la causalidad, hay tres condiciones necesarias: (i) asociación estadística entre variables, (ii) orden temporal apropiado y (iii) la eliminación de hipótesis alternativas o el establecimiento de un mecanismo causal formal.</p>
<p>Como ejemplo, recordemos el estudio de Galton en la Sección 1.1, que relaciona la altura de los hijos adultos (<span class="math inline">\(y\)</span>) con un índice de la altura de los padres (<span class="math inline">\(x\)</span>). Para este estudio, estaba claro que hay una fuerte asociación estadística entre <span class="math inline">\(x\)</span> e <span class="math inline">\(y\)</span>. La demografía también deja claro que las mediciones de los padres (<span class="math inline">\(x\)</span>) preceden a las mediciones de los hijos (<span class="math inline">\(y\)</span>). Lo que no es seguro es el mecanismo causal. Por ejemplo, en la Sección 1.5, mencionamos la posibilidad de que una variable omitida, como la dieta familiar, podría estar influyendo tanto en <span class="math inline">\(x\)</span> como en <span class="math inline">\(y\)</span>. Se necesitan evidencias y teorías de la biología humana y la genética para establecer un mecanismo causal formal.</p>
<hr />
<p><strong>Ejemplo: Raza, Redlining y Precios del Seguro de Automóviles.</strong> En un artículo con este título, Harrington y Niehaus (1998) investigaron si las compañías de seguros participaban en conductas discriminatorias (raciales), conocidas comúnmente como <em>redlining</em>. La discriminación racial es ilegal y las compañías de seguros no pueden usar la raza para determinar los precios. El término <em>redlining</em> se refiere a la práctica de trazar líneas rojas en un mapa para indicar áreas que las aseguradoras no cubrirán, áreas que típicamente contienen una alta proporción de minorías.</p>
<p>Para investigar si existe o no discriminación racial en los precios del seguro, Harrington y Niehaus recopilaron datos de primas y reclamaciones de seguros de automóviles de pasajeros privados del Departamento de Seguros de Missouri para el período 1988-1992. Aunque las compañías de seguros no mantienen información sobre raza/etnicidad en sus datos de primas y reclamaciones, dicha información está disponible a nivel de código postal en la Oficina del Censo de EE. UU. Al agregar las primas y las reclamaciones al nivel de código postal, Harrington y Niehaus pudieron evaluar si las áreas con un mayor porcentaje de población negra pagaban más por el seguro (PCTBLACK).</p>
<p>Una medida de precios ampliamente utilizada es la razón de siniestralidad, definida como la relación entre reclamaciones y primas. Esta medida la rentabilidad de las aseguradoras; si existe discriminación racial en los precios, se esperaría ver una baja razón de siniestralidad en áreas con una alta proporción de minorías. Harrington y Niehaus usaron esto como la variable dependiente, después de tomar logaritmos para abordar la asimetría en la distribución de la razón de siniestralidad.</p>
<p>Harrington y Niehaus (1998) estudiaron 270 códigos postales alrededor de seis ciudades principales en Missouri, donde había grandes concentraciones de minorías. La Tabla <a href="interpretación-de-resultados-de-regresión.html#tab:Tab61">6.1</a> presenta los hallazgos de la cobertura comprensiva, aunque los autores también investigaron la cobertura de colisión y de responsabilidad civil. Además de la variable principal de interés, PCTBLACK, se introdujeron algunas variables de control relacionadas con la distribución por edades (PCT1824 y PCT55UP), estado civil (MARRIED), población (ln TOTPOP) y empleo (PCTUNEMP). El tamaño de la póliza se midió indirectamente a través del valor promedio del automóvil (ln AVCARV).</p>
<p>La Tabla <a href="interpretación-de-resultados-de-regresión.html#tab:Tab61">6.1</a> informa que solo el tamaño de la póliza y la población son determinantes estadísticamente significativos de las razones de siniestralidad. De hecho, el coeficiente asociado con PCTBLACK tiene un signo positivo, lo que indica que las primas son más bajas en áreas con altas concentraciones de minorías (aunque no significativo). En un mercado de seguros eficiente, esperaríamos que los precios estuvieran estrechamente alineados con las reclamaciones y que existieran pocos patrones generales.</p>
<table class=" lightable-classic table table-striped table-condensed" style="font-size: 12px; font-family: Cambria; width: auto !important; margin-left: auto; margin-right: auto; margin-left: auto; margin-right: auto;border-bottom: 0;border-bottom: 0;">
<caption style="font-size: initial !important;">
<span id="tab:Tab61">Tabla 6.1: </span><strong>Resultados de la Regresión de la Razón de Siniestralidad</strong>
</caption>
<thead>
<tr>
<th style="text-align:left;">
Variable
</th>
<th style="text-align:left;">
Descripción
</th>
<th style="text-align:center;">
Coeficiente de Regresión
</th>
<th style="text-align:center;">
<span class="math inline">\(t\)</span>-Estadístico
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;width: 2.5cm; border-right:1px solid;border-right:1px solid;">
Intercept
</td>
<td style="text-align:left;width: 3cm; width: 6cm; border-right:1px solid;">
</td>
<td style="text-align:center;width: 3cm; ">
1.98
</td>
<td style="text-align:center;width: 3cm; ">
2.73
</td>
</tr>
<tr>
<td style="text-align:left;width: 2.5cm; border-right:1px solid;border-right:1px solid;">
PCTBLACK
</td>
<td style="text-align:left;width: 3cm; width: 6cm; border-right:1px solid;">
Proporción de la población negra
</td>
<td style="text-align:center;width: 3cm; ">
0.11
</td>
<td style="text-align:center;width: 3cm; ">
0.63
</td>
</tr>
<tr>
<td style="text-align:left;width: 2.5cm; border-right:1px solid;border-right:1px solid;">
ln TOTPOP
</td>
<td style="text-align:left;width: 3cm; width: 6cm; border-right:1px solid;">
Logaritmo de la población total
</td>
<td style="text-align:center;width: 3cm; ">
-0.1
</td>
<td style="text-align:center;width: 3cm; ">
-4.43
</td>
</tr>
<tr>
<td style="text-align:left;width: 2.5cm; border-right:1px solid;border-right:1px solid;">
PCT1824
</td>
<td style="text-align:left;width: 3cm; width: 6cm; border-right:1px solid;">
Porcentaje de la población entre 18 y 24 años
</td>
<td style="text-align:center;width: 3cm; ">
-0.23
</td>
<td style="text-align:center;width: 3cm; ">
-0.5
</td>
</tr>
<tr>
<td style="text-align:left;width: 2.5cm; border-right:1px solid;border-right:1px solid;">
PCT55UP
</td>
<td style="text-align:left;width: 3cm; width: 6cm; border-right:1px solid;">
Porcentaje de la población de 55 años o más
</td>
<td style="text-align:center;width: 3cm; ">
-0.47
</td>
<td style="text-align:center;width: 3cm; ">
-1.76
</td>
</tr>
<tr>
<td style="text-align:left;width: 2.5cm; border-right:1px solid;border-right:1px solid;">
MARRIED
</td>
<td style="text-align:left;width: 3cm; width: 6cm; border-right:1px solid;">
Porcentaje de la población casada
</td>
<td style="text-align:center;width: 3cm; ">
-0.32
</td>
<td style="text-align:center;width: 3cm; ">
-0.9
</td>
</tr>
<tr>
<td style="text-align:left;width: 2.5cm; border-right:1px solid;border-right:1px solid;">
PCTUNEMP
</td>
<td style="text-align:left;width: 3cm; width: 6cm; border-right:1px solid;">
Porcentaje de la población desempleada
</td>
<td style="text-align:center;width: 3cm; ">
0.11
</td>
<td style="text-align:center;width: 3cm; ">
0.1
</td>
</tr>
<tr>
<td style="text-align:left;width: 2.5cm; border-right:1px solid;border-right:1px solid;">
ln AVCARV
</td>
<td style="text-align:left;width: 3cm; width: 6cm; border-right:1px solid;">
Logaritmo del valor promedio del automóvil asegurado
</td>
<td style="text-align:center;width: 3cm; ">
-0.87
</td>
<td style="text-align:center;width: 3cm; ">
-3.26
</td>
</tr>
</tbody>
<tfoot>
<tr>
<td style="padding: 0; " colspan="100%">
<span style="font-style: italic;">Fuente:</span> <sup></sup> Harrington y Niehaus (1998)
</td>
</tr>
</tfoot>
<tfoot>
<tr>
<td style="padding: 0; " colspan="100%">
<span style="font-style: italic;"><span class="math inline">\(R_a^2\)</span> </span> <sup></sup> 0.11
</td>
</tr>
</tfoot>
</table>
<p>Ciertamente, los hallazgos de Harrington y Niehaus (1998) son inconsistentes con la hipótesis de discriminación racial en los precios. Establecer una falta de significancia estadística suele ser más difícil que establecer significancia. En el artículo de Harrington y Niehaus (1998), hay muchas especificaciones de modelos alternativas que evalúan la robustez de sus hallazgos frente a diferentes procedimientos de selección de variables y diferentes subconjuntos de datos. La Tabla <a href="interpretación-de-resultados-de-regresión.html#tab:Tab61">6.1</a> presenta los estimadores de los coeficientes y los <span class="math inline">\(t\)</span>-ratios calculados utilizando mínimos cuadrados ponderados, con el tamaño de la población como pesos. Los autores también utilizaron mínimos cuadrados (ordinarios) con errores estándar robustos, obteniendo resultados similares.</p>
</div>
<div id="Sec612" class="section level3 hasAnchor" number="6.1.2">
<h3><span class="header-section-number">6.1.2</span> Otras Interpretaciones<a href="interpretación-de-resultados-de-regresión.html#Sec612" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Cuando se toman colectivamente, las combinaciones lineales de los coeficientes de regresión pueden interpretarse como la función de regresión:</p>
<p><span class="math display">\[
\mathrm{E~}y = \beta_0 + \beta_1 x_1 + \cdots + \beta_k x_k.
\]</span></p>
<p>Al presentar los resultados de regresión, los lectores quieren saber qué tan bien el modelo se ajusta a los datos. La Sección 5.6.1 resumió varias estadísticas de bondad de ajuste que se informan rutinariamente en investigaciones de regresión.</p>
<p><strong>Función de Regresión y Precios.</strong> Al evaluar los datos de reclamaciones de seguros, la función de regresión representa las reclamaciones esperadas y, por lo tanto, forma la base de la función de precios. (Vea el ejemplo en el Capítulo 4). En este caso, la forma de la función de regresión y los niveles para combinaciones clave de variables explicativas son de interés.</p>
<p><strong>Estudios de Referencia (Benchmarking).</strong> En algunas investigaciones, el propósito principal puede ser determinar si una observación específica está “en línea” con las otras disponibles. Por ejemplo, en el Capítulo 20 examinaremos los salarios de los CEOs. El propósito principal de dicho análisis podría haber sido ver si el salario de una persona es alto o bajo en comparación con otros en la muestra, <em>controlando</em> por características como la industria y los años de experiencia. El residuo resume la desviación de la respuesta respecto a la esperada según el modelo. Si el residuo es inusualmente grande o pequeño, entonces interpretamos esto como que existen circunstancias inusuales asociadas con esta observación. Este análisis no sugiere la naturaleza ni las causas de estas circunstancias; simplemente indica que la observación es inusual en comparación con las demás en la muestra. Para algunas investigaciones, como en litigios relacionados con paquetes de compensación, esta es una declaración poderosa.</p>
<p><strong>Predicción.</strong> Muchas aplicaciones actuariales conciernen a la predicción, donde el interés radica en describir la distribución de una variable aleatoria que aún no se ha realizado. Al establecer reservas, los actuarios de compañías de seguros están estableciendo pasivos para futuras reclamaciones que predicen que se realizarán y, por lo tanto, se convertirán en gastos eventuales de la compañía. La predicción, o <em>pronóstico</em>, es la principal motivación de la mayoría de los análisis de datos de series temporales, que se trata en los Capítulos 7-10.</p>
<p>La predicción de una sola variable aleatoria en el contexto de la regresión lineal múltiple se introdujo en la Sección 4.2.3. Aquí, asumimos que tenemos disponible un conjunto dado de características, <span class="math inline">\(\mathbf{x}_{\ast}=(1,x_{\ast 1},\ldots,x_{\ast k})^{\prime }\)</span>. Según nuestro modelo, la nueva respuesta es:</p>
<p><span class="math display">\[
y_{\ast}=\beta_0 + \beta_1 x_{\ast 1} + \cdots + \beta_k x_{\ast k} + \varepsilon_{\ast}.
\]</span></p>
<p>Utilizamos como nuestro predictor puntual:</p>
<p><span class="math display">\[
\hat{y}_{\ast}=b_{0} + b_{1} x_{\ast 1} + \cdots + b_{k} x_{\ast k}.
\]</span></p>
<p>Como en la Sección 2.5.3, podemos descomponer el error de predicción en el error de estimación más el error aleatorio, de la siguiente manera:</p>
<p><span class="math display">\[
\begin{array}{ccccc}
\underbrace{y^{\ast}-\widehat{y}^{\ast}} &amp; = &amp;
\underbrace{\beta_0 - b_{0} + (\beta_1 - b_{1})x_{\ast 1} + \cdots + (\beta_k - b_{k})x_{\ast k}} &amp; + &amp; \underbrace{\varepsilon ^{\ast}} \\
{\small \text{error de predicción}} &amp; {\small =} &amp;
{\small \text{error en la estimación de la} } &amp;
{\small +} &amp; {\small \text{desviación} }\\
&amp;  &amp; {\small \text{función de regresión en } x_{\ast 1}, \ldots, x_{\ast k}} &amp; &amp; {\small \text{adicional} }
\end{array}
\]</span></p>
<p>Esta descomposición nos permite proporcionar una distribución para el error de predicción. Es habitual asumir una normalidad aproximada. Con esta suposición adicional, resumimos esta distribución utilizando un intervalo de predicción</p>
<p><span class="math display" id="eq:eq62">\[\begin{equation}
\hat{y}_{\ast} \pm t_{n-(k+1),1-\alpha /2} ~ se(pred),
\tag{6.2}
\end{equation}\]</span></p>
<p>donde</p>
<p><span class="math display">\[
se(pred) = s \sqrt{1 + \mathbf{x}_{\ast}^{\prime }(\mathbf{X}^{\prime} \mathbf{X})^{-1} \mathbf{x}_{\ast}}.
\]</span></p>
<p>Aquí, el valor <span class="math inline">\(t\)</span> <span class="math inline">\(t_{n-(k+1),1-\alpha /2}\)</span> es un percentil de la distribución <span class="math inline">\(t\)</span> con <span class="math inline">\(df=n-(k+1)\)</span> grados de libertad. Esto extiende la ecuación (2.7).</p>
<p>Comunicar el rango de resultados probables es un objetivo importante. Al analizar datos, puede haber varias técnicas alternativas de predicción disponibles. Incluso dentro de la clase de modelos de regresión, cada uno de los varios modelos candidatos producirá una predicción diferente. Es importante proporcionar una distribución o rango de posibles errores. Los consumidores ingenuos pueden desilusionarse fácilmente con los resultados de las predicciones de los modelos de regresión. A estos consumidores se les dice (correctamente) que el modelo de regresión es óptimo, basado en ciertos criterios bien definidos, y luego se les proporciona una predicción puntual, como <span class="math inline">\(\hat{y}_{\ast}\)</span>. Sin conocimiento de un intervalo, el consumidor tiene expectativas sobre el rendimiento de la predicción, generalmente más altas de lo que justifica la información disponible en la muestra. Un intervalo de predicción no solo proporciona una única predicción óptima puntual, sino también un rango de fiabilidad.</p>
<p>Al hacer las predicciones, hay una suposición importante: la nueva observación sigue el mismo modelo que se utilizó en la muestra. Por lo tanto, las condiciones básicas sobre la distribución de los errores deben permanecer sin cambios para las nuevas observaciones. También es importante que el nivel de las variables predictoras, <span class="math inline">\(x_{\ast 1},\ldots,x_{\ast k}\)</span>, sea similar al de las observaciones disponibles en la muestra. Si una o varias de las variables predictoras difieren drásticamente de las de la muestra disponible, entonces la predicción resultante puede ser inadecuada. Por ejemplo, sería imprudente usar el modelo desarrollado en las Secciones 2.1 a 2.3 para predecir la lotería de una región con una población de <span class="math inline">\(x_{\ast}=400,000\)</span>, más de diez veces la mayor población en nuestra muestra. Aunque sería fácil introducir <span class="math inline">\(x_{\ast}=400,000\)</span> en nuestras fórmulas, el resultado tendría poco sentido intuitivo. Extrapolar relaciones más allá de los datos observados requiere experiencia tanto en la naturaleza de los datos como en la metodología estadística. En la Sección <a href="interpretación-de-resultados-de-regresión.html#Sec63">6.3</a>, identificaremos este problema como un sesgo potencial debido a la región de muestreo.</p>
</div>
</div>
<div id="Sec62" class="section level2 hasAnchor" number="6.2">
<h2><span class="header-section-number">6.2</span> La Importancia de la Selección de Variables<a href="interpretación-de-resultados-de-regresión.html#Sec62" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Por un lado, elegir un modelo teórico que represente exactamente los eventos del mundo real es probablemente una tarea imposible. Por otro lado, elegir un modelo que represente aproximadamente el mundo real es un asunto práctico importante. Cuanto más cerca esté nuestro modelo del mundo real, más precisas serán las afirmaciones que hagamos, sugeridas por el modelo. Aunque no podemos obtener el modelo correcto, podemos seleccionar un modelo útil o al menos adecuado.</p>
<p>Los usuarios de la estadística, desde el principiante hasta el experto experimentado, siempre seleccionarán un modelo inadecuado de vez en cuando. La pregunta clave es: <em>¿Qué tan importante es seleccionar un modelo adecuado</em>? Aunque no se puede prever cada tipo de error, hay algunos principios orientadores que son útiles tener en cuenta al seleccionar un modelo.</p>
<div id="Sec621" class="section level3 hasAnchor" number="6.2.1">
<h3><span class="header-section-number">6.2.1</span> Sobreajuste del Modelo<a href="interpretación-de-resultados-de-regresión.html#Sec621" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Este tipo de error ocurre cuando se añaden variables superfluas o extrañas al modelo especificado. Si solo se añaden un pequeño número de variables extrañas, como una o dos, entonces este tipo de error probablemente no distorsionará de manera significativa la mayoría de los tipos de conclusiones que puedan alcanzarse con el modelo ajustado. Por ejemplo, sabemos que cuando añadimos una variable al modelo, la suma de cuadrados de los errores no aumenta. Si la variable es extraña, entonces la suma de cuadrados de los errores tampoco disminuirá de manera apreciable. De hecho, añadir una variable extraña puede aumentar <span class="math inline">\(s^2\)</span> porque el denominador es más pequeño por un grado de libertad. Sin embargo, para conjuntos de datos de tamaño de muestra moderado, el efecto es mínimo. Sin embargo, añadir varias variables extrañas puede inflar <span class="math inline">\(s^{2}\)</span> de manera apreciable. Además, existe la posibilidad de que añadir variables explicativas extrañas induzca, o empeore, la presencia de colinealidad.</p>
<p>Un punto más importante es que, al añadir variables extrañas, nuestras estimaciones de los coeficientes de regresión permanecen <em>insesgadas</em>. Considere el siguiente ejemplo.</p>
<hr />
<p><strong>Ejemplo: Regresión usando una Variable Explicativa.</strong> Suponga que el modelo verdadero de las respuestas es</p>
<p><span class="math display">\[
y_i = \beta_0 + \varepsilon_i, \quad i = 1, \ldots, n.
\]</span></p>
<p>Bajo este modelo, el nivel de una variable explicativa genérica <span class="math inline">\(x\)</span> no afecta el valor de la respuesta <span class="math inline">\(y\)</span>. Si fuéramos a predecir la respuesta en cualquier nivel de <span class="math inline">\(x\)</span>, la predicción tendría un valor esperado de <span class="math inline">\(\beta_0\)</span>. Sin embargo, supongamos que equivocadamente ajustamos el modelo</p>
<p><span class="math display">\[
y_i = \beta_0^{\ast} + \beta_1^{\ast}x_i + \varepsilon_i^{\ast}.
\]</span></p>
<p>Con este modelo, la predicción en un nivel genérico <span class="math inline">\(x\)</span> es <span class="math inline">\(b_{0}^{\ast} + b_{1}^{\ast}x\)</span> donde <span class="math inline">\(b_{0}^{\ast}\)</span> y <span class="math inline">\(b_{1}^{\ast}\)</span> son las estimaciones de mínimos cuadrados ordinarios de <span class="math inline">\(\beta_0^{\ast}\)</span> y <span class="math inline">\(\beta_1^{\ast}\)</span>, respectivamente. No es demasiado difícil confirmar que</p>
<p><span class="math display">\[
\text{Sesgo} = \text{E}(b_{0}^{\ast} + b_{1}^{\ast}x) - \text{E}y = 0,
\]</span></p>
<p>donde las esperanzas se calculan usando el modelo verdadero. Por lo tanto, al usar un modelo ligeramente más grande del que deberíamos, no pagamos en términos de cometer un error persistente a largo plazo, como el representado por el sesgo. El precio de cometer este error es que nuestro error estándar es ligeramente mayor de lo que sería si hubiéramos elegido el modelo correcto.</p>
<hr />
</div>
<div id="Sec622" class="section level3 hasAnchor" number="6.2.2">
<h3><span class="header-section-number">6.2.2</span> Subajuste del Modelo<a href="interpretación-de-resultados-de-regresión.html#Sec622" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Este tipo de error ocurre cuando se omiten variables importantes en la especificación del modelo; es más grave que el sobreajuste. Omitir variables importantes puede causar cantidades apreciables de sesgo en nuestras estimaciones resultantes. Además, debido a este sesgo, las estimaciones resultantes de <span class="math inline">\(s^{2}\)</span> son más grandes de lo necesario. Un <span class="math inline">\(s\)</span> más grande infla nuestros intervalos de predicción y produce pruebas inexactas de hipótesis sobre la importancia de las variables explicativas. Para ver los efectos de subajustar un modelo, volvemos al ejemplo anterior.</p>
<hr />
<p><strong>Ejemplo: Regresión usando una Variable Explicativa - Continuación.</strong> Ahora invertimos los roles de los modelos descritos antes. Supongamos que el modelo verdadero es</p>
<p><span class="math display">\[
y_i = \beta_0 + \beta_1 x_i + \varepsilon_i
\]</span></p>
<p>y que ajustamos erróneamente el modelo,</p>
<p><span class="math display">\[
y_i = \beta_0^{\ast} + \varepsilon_i^{\ast}.
\]</span></p>
<p>Por lo tanto, hemos omitido inadvertidamente los efectos de la variable explicativa <span class="math inline">\(x\)</span>. Con el modelo ajustado, usaríamos <span class="math inline">\(\bar{y}\)</span> para nuestra predicción en un nivel genérico de <span class="math inline">\(x\)</span>. A partir del modelo verdadero, tenemos <span class="math inline">\(\bar{y} = \beta_0 + \beta_1 \bar{x} + \bar{\varepsilon}\)</span>. El sesgo de la predicción en <span class="math inline">\(x\)</span> es</p>
<p><span class="math display">\[
\begin{array}{ll}
\text{Sesgo} &amp;= \text{E} \bar{y} - \text{E} (\beta_0 + \beta_1 x + \varepsilon) \\
&amp;= \text{E} (\beta_0 + \beta_1 \bar{x} + \bar{\varepsilon}) - (\beta_0 + \beta_1 x) \\
&amp;= \beta_1 (\bar{x} - x).
\end{array}
\]</span></p>
<p>Si <span class="math inline">\(\beta_1\)</span> es positivo, entonces subestimamos para valores grandes de <span class="math inline">\(x\)</span>, resultando en un sesgo negativo, y sobreestimamos para valores pequeños de <span class="math inline">\(x\)</span> (en relación con <span class="math inline">\(\overline{x}\)</span>). Así, hay un error persistente a largo plazo al omitir la variable explicativa <span class="math inline">\(x\)</span>. De manera similar, se puede verificar que este tipo de error produce estimaciones sesgadas de los parámetros de regresión y un valor inflado de <span class="math inline">\(s^{2}\)</span>.</p>
<hr />
<p>Por supuesto, nadie quiere sobreajustar o subajustar el modelo. Sin embargo, los datos de las ciencias sociales a menudo son desordenados y puede ser difícil saber si incluir o no una variable en el modelo. Al seleccionar variables, los analistas a menudo se guían por el principio de parsimonia, también conocido como la Navaja de Occam, que establece que cuando hay varias explicaciones posibles para un fenómeno, se debe usar la más simple. Hay varios argumentos para preferir modelos más simples:</p>
<ul>
<li>Una explicación más simple es más fácil de interpretar.</li>
<li>Los modelos simples, también conocidos como modelos “parsimoniosos”, a menudo funcionan bien con datos fuera de la muestra.</li>
<li>Las variables superfluas pueden causar problemas de colinealidad, lo que dificulta la interpretación de los coeficientes individuales.</li>
</ul>
<p>El punto de vista opuesto se puede resumir en una cita a menudo atribuida a Albert Einstein, que dice que debemos usar “el modelo más simple posible, pero no más simple”. Esta sección demuestra que subajustar un modelo, omitiendo variables importantes, es típicamente un error más grave que incluir variables superfluas que aportan poco a nuestra capacidad de explicar los datos. Incluir variables superfluas disminuye los grados de libertad y aumenta la estimación de la variabilidad, lo cual suele ser de menor preocupación en las aplicaciones actuariales.</p>
<p>En caso de duda, deje la variable en el modelo.</p>
</div>
</div>
<div id="Sec63" class="section level2 hasAnchor" number="6.3">
<h2><span class="header-section-number">6.3</span> La Importancia de la Recolección de Datos<a href="interpretación-de-resultados-de-regresión.html#Sec63" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>El proceso de modelado de regresión comienza con la recolección de datos. Habiendo estudiado los resultados y el proceso de selección de variables, ahora podemos discutir las entradas al proceso. No es sorprendente que haya una larga lista de posibles dificultades que se encuentran con frecuencia al recolectar datos para regresión. En esta sección, identificamos las principales dificultades potenciales y proporcionamos algunas vías para evitar estas dificultades.</p>
<div id="Sec631" class="section level3 hasAnchor" number="6.3.1">
<h3><span class="header-section-number">6.3.1</span> Error en el Marco Muestral y Selección Adversa<a href="interpretación-de-resultados-de-regresión.html#Sec631" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>El error en el marco muestral ocurre cuando el marco muestral, la lista de la cual se extrae la muestra, no es una aproximación adecuada de la población de interés. Al final, una muestra debe ser un subconjunto representativo de una población más grande, o universo, de interés. Si la muestra no es representativa, tomar una muestra más grande no elimina el sesgo; simplemente repite el mismo error una y otra vez.</p>
<hr />
<p><strong>Ejemplo: Encuesta de Literary Digest.</strong> Quizás el ejemplo más conocido de error en el marco muestral es de la encuesta de <em>Literary Digest</em> en 1936. Esta encuesta se realizó para predecir el ganador de las elecciones presidenciales de Estados Unidos en 1936. Los dos principales candidatos eran Franklin D. Roosevelt, el demócrata, y Alfred Landon, el republicano. <em>Literary Digest</em>, una revista prominente en ese momento, realizó una encuesta a diez millones de votantes. De los encuestados, 2.4 millones respondieron, prediciendo una victoria “arrolladora” de Landon por un margen de 57% a 43%. Sin embargo, la elección real resultó en una victoria abrumadora de Roosevelt, por un margen de 62% a 38%. ¿Qué salió mal?</p>
<p>Hubo varios problemas con la encuesta de <em>Literary Digest</em>. Quizás el más importante fue el error en el marco muestral. Para desarrollar su marco muestral, <em>Literary Digest</em> utilizó direcciones de guías telefónicas y listas de membresía de clubes. En 1936, Estados Unidos estaba en el fondo de la Gran Depresión; los teléfonos y las membresías de clubes eran un lujo que solo las personas de altos ingresos podían permitirse. Así, la lista de <em>Literary Digest</em> incluía una cantidad no representativa de personas de altos ingresos. En elecciones presidenciales anteriores realizadas por <em>Literary Digest</em>, los ricos y los pobres tendían a votar de manera similar y esto no era un problema. Sin embargo, los problemas económicos fueron los principales temas políticos en las elecciones presidenciales de 1936. Como resultó ser, los pobres tendían a votar por Roosevelt y los ricos por Landon. Como resultado, los resultados de la encuesta de <em>Literary Digest</em> fueron gravemente erróneos. Tomar una muestra grande, incluso de tamaño 2.4 millones, no ayudó; el error básico se repitió una y otra vez.</p>
<hr />
<p>El sesgo en el marco muestral ocurre cuando la muestra no es un subconjunto representativo de la población de interés. Al analizar los datos de las compañías de seguros, este sesgo puede surgir debido a la <em>selección adversa</em>. En muchos mercados de seguros, las compañías diseñan y fijan los precios de los contratos y los asegurados deciden si desean o no entrar en un acuerdo contractual (de hecho, los asegurados “solicitan” un seguro, por lo que los aseguradores también tienen el derecho de no entrar en el acuerdo). Por lo tanto, alguien es más probable que entre en un acuerdo si cree que la aseguradora está subestimando su riesgo, especialmente a la luz de las características del asegurado que no son observadas por la aseguradora. Por ejemplo, es bien sabido que la experiencia de mortalidad de una muestra de compradores de rentas vitalicias no es representativa de la población en general; las personas que compran rentas vitalicias tienden a ser saludables en relación con la población general. No compraría una renta vitalicia que pague un beneficio periódico mientras esté vivo si tuviera mala salud y pensara que su probabilidad de una larga vida es baja. La selección adversa surge porque los “malos riesgos”, aquellos con reclamos mayores de los esperados, son más propensos a entrar en contratos que los “buenos riesgos” correspondientes. Aquí, la expectativa se desarrolla en función de características (variables explicativas) que pueden ser observadas por la aseguradora.</p>
<p>Por supuesto, existe un gran mercado para las rentas vitalicias y otras formas de seguros en las que existe selección adversa. Las compañías de seguros pueden fijar precios adecuados para estos mercados redefiniendo su “población de interés” para que no sea la población general, sino la población de asegurados potenciales. Así, por ejemplo, al fijar el precio de las rentas vitalicias, las aseguradoras utilizan datos de mortalidad de rentistas, no datos de la población general. De esta manera, pueden evitar posibles desajustes entre la población y la muestra. Más generalmente, la experiencia de casi cualquier compañía difiere de la población general debido a los estándares de suscripción y las filosofías de ventas. Algunas compañías buscan “riesgos preferidos” ofreciendo descuentos educativos, bonos por buen manejo, etc., mientras que otras buscan asegurados de alto riesgo. La muestra de asegurados de la compañía diferirá de la población general y el grado de la diferencia puede ser un aspecto interesante para cuantificar en un análisis.</p>
<p>El sesgo en el marco muestral puede ser particularmente importante cuando una compañía busca comercializar un nuevo producto para el cual no tiene datos de experiencia. Identificar un mercado objetivo y su relación con la población general es un aspecto importante de un plan de desarrollo de mercado.</p>
</div>
<div id="Sec632" class="section level3 hasAnchor" number="6.3.2">
<h3><span class="header-section-number">6.3.2</span> Regiones de Muestreo Limitadas<a href="interpretación-de-resultados-de-regresión.html#Sec632" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Una región de muestreo limitada puede dar lugar a un sesgo potencial cuando intentamos extrapolar fuera de la región de muestreo. Para ilustrarlo, considere la Figura <a href="interpretación-de-resultados-de-regresión.html#fig:Fig61">6.1</a>. Aquí, con base en los datos de la región de muestreo, una línea puede parecer una representación apropiada. Sin embargo, si una curva cuadrática es la verdadera respuesta esperada, cualquier pronóstico que esté lejos de la región de muestreo estará seriamente sesgado.</p>

<div class="figure" style="text-align: center"><span style="display:block;" id="fig:Fig61"></span>
<img src="RegressionMarkdown_files/figure-html/Fig61-1.png" alt="La extrapolación fuera de la región de muestreo puede estar sesgada" width="60%" />
<p class="caption">
Figura 6.1: <strong>La extrapolación fuera de la región de muestreo puede estar sesgada</strong>
</p>
</div>
<p>Otro problema debido a una región de muestreo limitada, aunque no sea un sesgo, que puede surgir es la dificultad para estimar un coeficiente de regresión. En el Capítulo 5, vimos que una menor dispersión de una variable, ceteris paribus, significa una estimación menos confiable del coeficiente de pendiente asociado con esa variable. Es decir, a partir de la Sección 5.5.2 o de la ecuación <a href="interpretación-de-resultados-de-regresión.html#eq:eq61">(6.1)</a>, vemos que cuanto menor es la dispersión de <span class="math inline">\(x_{j}\)</span>, medida por <span class="math inline">\(s_{x_{j}}\)</span>, mayor es el error estándar de <span class="math inline">\(b_{j},se(b_{j})\)</span>. Llevado al extremo, donde <span class="math inline">\(s_{x_{j}}=0\)</span>, podríamos tener una situación como la ilustrada en la Figura <a href="interpretación-de-resultados-de-regresión.html#fig:Fig62">6.2</a>. Para la situación extrema ilustrada en la Figura <a href="interpretación-de-resultados-de-regresión.html#fig:Fig62">6.2</a>, no hay suficiente variación en <span class="math inline">\(x\)</span> para estimar el parámetro de pendiente correspondiente.</p>

<div class="figure" style="text-align: center"><span style="display:block;" id="fig:Fig62"></span>
<img src="RegressionMarkdown_files/figure-html/Fig62-1.png" alt="La falta de variación en \(x\) significa que no podemos ajustar una línea única que relacione \(x\) y \(y\)." width="60%" />
<p class="caption">
Figura 6.2: <strong>La falta de variación en <span class="math inline">\(x\)</span> significa que no podemos ajustar una línea única que relacione <span class="math inline">\(x\)</span> y <span class="math inline">\(y\)</span>.</strong>
</p>
</div>
</div>
<div id="Sec633" class="section level3 hasAnchor" number="6.3.3">
<h3><span class="header-section-number">6.3.3</span> Variables Dependientes Limitadas, Censura y Truncamiento<a href="interpretación-de-resultados-de-regresión.html#Sec633" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>En algunas aplicaciones, la variable dependiente está limitada a ciertos rangos. Para entender por qué esto es un problema, primero recordemos que bajo el modelo de regresión lineal, la variable dependiente es igual a la función de regresión más un error aleatorio. Normalmente, se supone que el error aleatorio se distribuye aproximadamente de manera normal, por lo que la respuesta varía de forma continua. Sin embargo, si los resultados de la variable dependiente están restringidos o limitados, entonces los resultados no son puramente continuos. Esto significa que nuestra suposición de errores normales no es estrictamente correcta y puede no ser una buena aproximación.</p>
<p>Para ilustrar esto, la Figura <a href="interpretación-de-resultados-de-regresión.html#fig:Fig63">6.3</a> muestra un gráfico del ingreso de un individuo (<span class="math inline">\(x\)</span>) versus la cantidad de seguro adquirido (<span class="math inline">\(y\)</span>). La muestra en este gráfico representa dos submuestras: aquellos que compraron seguro, correspondientes a <span class="math inline">\(y&gt;0\)</span>, y aquellos que no lo hicieron, correspondientes al “precio” <span class="math inline">\(y=0\)</span>. Ajustar una única línea a estos datos desinformaría a los usuarios sobre los efectos de <span class="math inline">\(x\)</span> sobre <span class="math inline">\(y\)</span>.</p>

<div class="figure" style="text-align: center"><span style="display:block;" id="fig:Fig63"></span>
<img src="RegressionMarkdown_files/figure-html/Fig63-1.png" alt="Cuando los individuos no compran nada, se registran como ventas de \(y=0\)." width="60%" />
<p class="caption">
Figura 6.3: <strong>Cuando los individuos no compran nada, se registran como ventas de <span class="math inline">\(y=0\)</span>.</strong>
</p>
</div>

<div class="figure" style="text-align: center"><span style="display:block;" id="fig:Fig64"></span>
<img src="RegressionMarkdown_files/figure-html/Fig64-1.png" alt="Si se omiten las respuestas por debajo de la línea horizontal en \(y=d\), la línea de regresión ajustada puede ser muy diferente de la verdadera línea de regresión." width="60%" />
<p class="caption">
Figura 6.4: <strong>Si se omiten las respuestas por debajo de la línea horizontal en <span class="math inline">\(y=d\)</span>, la línea de regresión ajustada puede ser muy diferente de la verdadera línea de regresión.</strong>
</p>
</div>
<p>Si consideráramos solo a aquellos que compraron seguro, entonces todavía tendríamos un límite inferior implícito de cero (si un precio de seguro debe ser mayor que cero). Sin embargo, los precios deben estar cerca de este límite para una región de muestreo dada y, por lo tanto, no representar un problema práctico importante. Al incluir a varias personas que no compraron seguro (y, por lo tanto, gastaron $0 en seguro), nuestra región de muestreo ahora claramente incluye este límite inferior.</p>
<p>Hay varias maneras en las que las variables dependientes pueden estar restringidas o <em>censuradas</em>. La Figura <a href="interpretación-de-resultados-de-regresión.html#fig:Fig63">6.3</a> ilustra el caso en el que el valor de <span class="math inline">\(y\)</span> no puede ser inferior a cero. Como otro ejemplo, los siniestros de seguros a menudo están restringidos a ser menores o iguales a un límite superior especificado en la póliza de seguro. Si la censura es severa, los mínimos cuadrados ordinarios producen resultados sesgados. En el Capítulo 15 se describen enfoques especializados, conocidos como modelos de <em>regresión censurada</em>, para manejar este problema.</p>
<p>La Figura <a href="interpretación-de-resultados-de-regresión.html#fig:Fig64">6.4</a> ilustra otra limitación comúnmente encontrada en el valor de la variable dependiente. Para esta ilustración, suponga que <span class="math inline">\(y\)</span> representa una pérdida asegurada y que <span class="math inline">\(d\)</span> representa el deducible de una póliza de seguro. En este escenario, es práctica común que las aseguradoras no registren pérdidas por debajo de <span class="math inline">\(d\)</span> (generalmente no son reportadas por los asegurados). En este caso, se dice que los datos están <em>truncados</em>. No es sorprendente que existan <em>modelos de regresión truncada</em> para manejar esta situación. Como regla general, los datos truncados representan una fuente de sesgo más grave que los datos censurados. Cuando los datos están truncados, no tenemos valores de las variables dependientes y, por lo tanto, tenemos menos información que cuando los datos están censurados. Consulte el Capítulo 15 para obtener más detalles.</p>
</div>
<div id="Sec634" class="section level3 hasAnchor" number="6.3.4">
<h3><span class="header-section-number">6.3.4</span> Variables Omitidas y Endógenas<a href="interpretación-de-resultados-de-regresión.html#Sec634" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Por supuesto, los analistas prefieren incluir todas las variables importantes. Sin embargo, un problema común es que puede que no tengamos los recursos ni la previsión para recopilar y analizar todos los datos relevantes. Además, a veces se nos prohíbe incluir ciertas variables. Por ejemplo, en la tarificación de seguros, generalmente se nos impide usar la etnia como una variable de tarificación. Además, hay muchas tablas de mortalidad y otras tablas de decremento que son “unisex”, es decir, no distinguen entre géneros.</p>
<p>Omitir variables importantes puede afectar nuestra capacidad para ajustar la función de regresión; esto puede afectar el rendimiento dentro de la muestra (explicación) así como fuera de la muestra (predicción). Si la variable omitida no está correlacionada con otras variables explicativas, entonces la omisión no afectará la estimación de los coeficientes de regresión. Sin embargo, típicamente este no es el caso. La Sección 3.4.3, el Ejemplo del Refrigerador, ilustra un caso grave en el que la dirección de un resultado estadísticamente significativo se invirtió con la presencia de una variable explicativa. En este ejemplo, encontramos que en una muestra transversal de refrigeradores existía una correlación significativamente positiva entre el precio y el costo anual de energía para operar el refrigerador. Esta correlación positiva era contraintuitiva porque uno esperaría que precios más altos significaran menores gastos anuales en operar un refrigerador. Sin embargo, cuando incluimos varias variables adicionales, en particular, medidas del tamaño de un refrigerador, encontramos una relación significativamente negativa entre el precio y los costos de energía. Nuevamente, al omitir estas variables adicionales, hubo un sesgo importante al usar la regresión para entender la relación entre el precio y los costos de energía.</p>
<p>Las variables omitidas pueden llevar a la presencia de variables explicativas endógenas. Una variable exógena es aquella que se puede considerar “dada” para los propósitos en cuestión. Una variable endógena es aquella que no cumple con el requisito de exogeneidad. Una variable omitida puede afectar tanto a <span class="math inline">\(y\)</span> como a <span class="math inline">\(x\)</span> y, en este sentido, inducir una relación entre las dos variables. Si la relación entre <span class="math inline">\(x\)</span> y <span class="math inline">\(y\)</span> se debe a una variable omitida, es difícil condicionar en <span class="math inline">\(x\)</span> al estimar un modelo para <span class="math inline">\(y\)</span>.</p>
<p>Hasta ahora, las variables explicativas han sido tratadas como no estocásticas. Para muchas aplicaciones en ciencias sociales, es más intuitivo considerar que las <span class="math inline">\(x\)</span> son estocásticas y realizar inferencias condicionales a sus realizaciones. Por ejemplo, bajo esquemas de muestreo comunes, podemos estimar la función de regresión condicional
<span class="math display">\[
\mathrm{E~}\left(y|x_1, \ldots, x_k \right) = \beta_0 + \beta_1 x_1 + \ldots + \beta_k x_k.
\]</span>
Esto se conoce como un modelo “basado en el muestreo”.</p>
<p>En la literatura económica, Goldberger (1972) define un <em>modelo estructural</em> como un modelo estocástico que representa una relación causal, no una relación que simplemente captura asociaciones estadísticas. Los modelos estructurales pueden contener fácilmente variables explicativas endógenas. Para ilustrar, consideremos un ejemplo que relaciona reclamaciones y primas. Para muchas líneas de negocio, las clases de primas son simplemente funciones no lineales de factores exógenos como la edad, el género, etc. Para otras líneas de negocio, las primas cobradas son una función del historial de reclamaciones previo. Consideremos las ecuaciones del modelo que relacionan las reclamaciones (<span class="math inline">\(y_{it}, t=1, 2\)</span>) con las primas (<span class="math inline">\(x_{it}, t=1, 2\)</span>):
<span class="math display">\[\begin{eqnarray*}
y_{i2} = \beta_{0,C} + \beta_{1,C} y_{i1} + \beta_{2,C} x_{i2} + \varepsilon_{i1} \\
x_{i2} = \beta_{0,P} + \beta_{1,P}  y_{i1} + \beta_{2,P}  x_{i1} + \varepsilon_{i2}.
\end{eqnarray*}\]</span>
En este modelo, las reclamaciones y las primas del período actual (<span class="math inline">\(t=2\)</span>) se ven afectadas por las reclamaciones y primas del período anterior. Este es un ejemplo de un modelo de <em>ecuaciones estructurales</em> que requiere técnicas especiales de estimación. ¡Nuestros procedimientos de estimación habituales están sesgados!</p>
<hr />
<p><strong>Ejemplo: Raza, Discriminación y Precios de Seguros de Automóviles - Continuación.</strong> Aunque Harrington y Niehaus (1998) no encontraron discriminación racial en la tarificación de seguros, sus resultados sobre el acceso al seguro fueron inconclusos. Los aseguradores ofrecen contratos de riesgo “estándar” y “preferido” a los solicitantes que cumplen con estándares restrictivos de suscripción, en comparación con los contratos de riesgo “subestándar” donde los estándares de suscripción son más relajados. Los reclamos esperados son más bajos para los contratos de riesgo estándar y preferido, y por lo tanto, las primas son más bajas, que para los contratos subestándar. Harrington y Niehaus examinaron la proporción de solicitantes a quienes se les ofrecieron contratos subestándar, NSSHARE, y encontraron que estaba significativamente relacionada positivamente con PCTBLACK, la proporción de la población negra. Esto sugiere evidencia de discriminación racial; ellos afirman que esta es una interpretación inapropiada debido al sesgo por variables omitidas.</p>
<p>Harrington y Niehaus argumentan que la proporción de solicitantes a quienes se les ofrecieron contratos subestándar debería estar positivamente relacionada con los costos esperados de los reclamos. Además, los costos esperados de los reclamos están fuertemente relacionados con PCTBLACK, porque las minorías en la muestra tendían a tener ingresos más bajos. Así, las variables no observadas, como los ingresos, tienden a impulsar la relación positiva entre NSSHARE y PCTBLACK. Debido a que los datos se analizan a nivel de código postal y no a nivel individual, el potencial sesgo por variables omitidas hizo que el análisis fuera inconcluso.</p>
<hr />
</div>
<div id="Sec635" class="section level3 hasAnchor" number="6.3.5">
<h3><span class="header-section-number">6.3.5</span> Datos Faltantes<a href="interpretación-de-resultados-de-regresión.html#Sec635" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>En los ejemplos de datos, ilustraciones, estudios de caso y ejercicios de este texto, hay muchas instancias en las que ciertos datos están <em>faltantes</em> o no disponibles para el análisis. En cada caso, los datos no se perdieron de manera descuidada, sino que no estaban disponibles debido a razones sustantivas asociadas con la recolección de datos. Por ejemplo, cuando examinamos los rendimientos de acciones de una muestra de empresas, vimos que algunas empresas no tenían un promedio de ganancias por acción de cinco años. La razón era simplemente que no habían estado en existencia durante cinco años. Como otro ejemplo, al examinar las esperanzas de vida, algunos países no reportaron la tasa de fertilidad total porque les faltaban recursos administrativos para capturar estos datos. Los datos faltantes son un aspecto inescapable al analizar datos en las ciencias sociales.</p>
<p>Cuando la razón para la falta de disponibilidad de datos no está relacionada con los valores reales de los datos, se dice que los datos están <em>faltantes al azar</em>. Existen varias técnicas para manejar datos faltantes al azar, ninguna de las cuales es claramente superior a las otras. Una “técnica” es simplemente ignorar el problema. Por lo tanto, faltar al azar a veces se denomina el <em>caso ignorable</em> de datos faltantes.</p>
<p>Si hay solo unos pocos datos faltantes, en comparación con el número total disponible, una estrategia ampliamente empleada es eliminar las observaciones correspondientes a los datos faltantes. Suponiendo que los datos están faltantes al azar, se pierde poca información al eliminar una pequeña porción de los datos. Además, con esta estrategia, no necesitamos hacer suposiciones adicionales sobre las relaciones entre los datos.</p>
<p>Si los datos faltantes provienen principalmente de una variable, podemos considerar omitir esta variable. Aquí, la motivación es que perdemos menos información al omitir esta variable en comparación con retener la variable pero perder las observaciones asociadas con los datos faltantes.</p>
<p>Otra estrategia es completar, o <em>imputar</em>, los datos faltantes. Hay muchas variaciones de la estrategia de imputación. Todas asumen algún tipo de relaciones entre las variables además de las suposiciones del modelo de regresión. Aunque estos métodos producen resultados razonables, hay que tener en cuenta que cualquier tipo de valores imputados no presenta la misma variabilidad inherente que los datos reales. Así, los resultados de los análisis basados en valores imputados a menudo reflejan menos variabilidad que aquellos con datos reales.</p>
<hr />
<p><strong>Ejemplo: Gastos de Compañías de Seguros - Continuación.</strong> Al examinar la información financiera de las compañías, los analistas a menudo se ven obligados a omitir una cantidad considerable de información al utilizar modelos de regresión para buscar relaciones. Para ilustrar, Segal (2002) examinó los estados financieros de seguros de vida a partir de datos proporcionados por la Asociación Nacional de Comisionados de Seguros (NAIC). Inicialmente, consideró 733 observaciones de empresas-año durante el período 1995-1998. Sin embargo, 154 observaciones fueron excluidas debido a primas, beneficios y otras variables explicativas inconsistentes o negativas. También se excluyeron las pequeñas empresas que representaban 131 observaciones. Las pequeñas empresas consisten en menos de 10 empleados y agentes, costos operativos menores a $1 millón o menos de 1,000 pólizas de vida vendidas. La muestra resultante fue de <span class="math inline">\(n=448\)</span> observaciones. Las restricciones de muestra se basaron en variables explicativas; este procedimiento no necesariamente sesga los resultados. Segal argumentó que su muestra final seguía siendo representativa de la población de interés. Hubo alrededor de 110 empresas en cada uno de los años 1995-1998. En 1998, los activos agregados de las empresas en la muestra representaban aproximadamente $650 mil millones, un tercio de la industria de seguros de vida.</p>
<hr />
</div>
</div>
<div id="Sec64" class="section level2 hasAnchor" number="6.4">
<h2><span class="header-section-number">6.4</span> Modelos de Datos Faltantes<a href="interpretación-de-resultados-de-regresión.html#Sec64" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Para entender los mecanismos que conducen a respuestas no planificadas, los modelamos de manera estocástica. Sea <span class="math inline">\(r_i\)</span> una variable binaria para la <span class="math inline">\(i\)</span>-ésima observación, con un uno indicando que esta respuesta se observa y un cero indicando que la respuesta está faltante. Sea <span class="math inline">\(\mathbf{r} = (r_1, \ldots, r_n)^{\prime}\)</span> que resume la disponibilidad de datos para todos los sujetos. El interés radica en si las respuestas influyen en el mecanismo de datos faltantes. Para la notación, usamos <span class="math inline">\(\mathbf{Y} = (y_1, \ldots, y_n)^{\prime}\)</span> para ser la colección de todas las respuestas potencialmente observadas.</p>
<div id="Sec641" class="section level3 hasAnchor" number="6.4.1">
<h3><span class="header-section-number">6.4.1</span> Faltante al Azar<a href="interpretación-de-resultados-de-regresión.html#Sec641" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>En el caso en que <span class="math inline">\(\mathbf{Y}\)</span> no afecta la distribución de <span class="math inline">\(\mathbf{r}\)</span>, seguimos a Rubin (1976) y llamamos a este caso <em>faltante completamente al azar (MCAR)</em>. Específicamente, los datos faltantes son MCAR si <span class="math inline">\(\mathrm{f}(\mathbf{r} | \mathbf{Y}) = \mathrm{f}(\mathbf{r})\)</span>, donde f(.) es una función genérica de masa de probabilidad. Una extensión de esta idea se encuentra en Little (1995), donde se añade el adjetivo “dependiente de covariables” cuando <span class="math inline">\(\mathbf{Y}\)</span> no afecta la distribución de <span class="math inline">\(\mathbf{r}\)</span>, condicionado a las covariables. Si las covariables se resumen como <span class="math inline">\(\mathbf{X}\)</span>, entonces la condición corresponde a la relación <span class="math inline">\(\mathrm{f}(\mathbf{r} | \mathbf{Y, X}) = \mathrm{f}(\mathbf{r | X})\)</span>. Para ilustrar este punto, considere un ejemplo de Little y Rubin (1987) donde <span class="math inline">\(\mathbf{X}\)</span> corresponde a la edad y <span class="math inline">\(\mathbf{Y}\)</span> corresponde a los ingresos de todas las observaciones potenciales. Si la probabilidad de estar faltante no depende de los ingresos, entonces los datos faltantes son MCAR. Si la probabilidad de estar faltante varía según la edad pero no por ingresos entre las observaciones dentro de un grupo de edad, entonces los datos faltantes son MCAR dependientes de covariables. Bajo esta última especificación, es posible que los datos faltantes varíen según los ingresos. Por ejemplo, las personas más jóvenes pueden ser menos propensas a responder una encuesta. Esto muestra que la característica “faltante al azar” depende del propósito del análisis. Específicamente, es posible que un análisis de los efectos conjuntos de edad e ingresos pueda encontrar patrones graves de datos faltantes, mientras que un análisis de ingresos controlado por edad no sufre patrones graves de sesgo.</p>
<p>Little y Rubin (1987) abogan por modelar los mecanismos de datos faltantes. Para ilustrar, considere un enfoque de máxima verosimilitud utilizando un modelo de selección para el mecanismo de datos faltantes. Ahora, particione <span class="math inline">\(\mathbf{Y}\)</span> en componentes observados y faltantes utilizando la notación <span class="math inline">\(\mathbf{Y} =\{\mathbf{Y}_{obs}, \mathbf{Y}_{miss}\}\)</span>. Con el enfoque de máxima verosimilitud, basamos la inferencia en las variables aleatorias observadas. Por lo tanto, usamos una verosimilitud proporcional a la función conjunta <span class="math inline">\(\mathrm{f}(\mathbf{r}, \mathbf{Y}_{obs})\)</span>. También especificamos un <em>modelo de selección</em> especificando la función de masa condicional <span class="math inline">\(\mathrm{f}(\mathbf{r} | \mathbf{Y})\)</span>.</p>
<p>Supongamos que las respuestas observadas y las distribuciones del modelo de selección se caracterizan por vectores de parámetros <span class="math inline">\(\boldsymbol \theta\)</span> y <span class="math inline">\(\boldsymbol \psi\)</span>, respectivamente. Entonces, con la relación <span class="math inline">\(\mathrm{f}(\mathbf{r}, \mathbf{Y}_{obs},\boldsymbol \theta, \boldsymbol \psi) = \mathrm{f}(\mathbf{Y}_{obs}, \boldsymbol \theta) \times \mathrm{f}(\mathbf{r} | \mathbf{Y}_{obs}, \boldsymbol \psi)\)</span>, podemos expresar la verosimilitud logarítmica de las variables aleatorias observadas como</p>
<p><span class="math display">\[
L(\boldsymbol \theta, \boldsymbol \psi) = \mathrm{ln~}
\mathrm{f}(\mathbf{r}, \mathbf{Y}_{obs}, \boldsymbol \theta,
\boldsymbol \psi) = \mathrm{ln~} \mathrm{f}(\mathbf{Y}_{obs},
\boldsymbol \theta) + \mathrm{ln~} \mathrm{f}(\mathbf{r} |
\mathbf{Y}_{obs}, \boldsymbol \psi).
\]</span>
(Véase la Sección 11.9 si desea un repaso sobre la inferencia de verosimilitud). En el caso en que los datos son MCAR, entonces <span class="math inline">\(\mathrm{f}(\mathbf{r} | \mathbf{Y}_{obs}, \boldsymbol \psi) = \mathrm{f}(\mathbf{r} | \boldsymbol \psi)\)</span> no depende de <span class="math inline">\(\mathbf{Y}_{obs}\)</span>. Little y Rubin (1987) también consideran el caso en que la distribución del modelo del mecanismo de selección no depende de <span class="math inline">\(\mathbf{Y}_{miss}\)</span> pero puede depender de <span class="math inline">\(\mathbf{Y}_{obs}\)</span>. En este caso, lo llaman <em>datos faltantes al azar (MAR)</em>.</p>
<p>En los casos tanto de MAR como de MCAR, vemos que la verosimilitud puede maximizarse sobre los parámetros, por separado para cada caso. En particular, si uno está interesado únicamente en el estimador de máxima verosimilitud de <span class="math inline">\(\boldsymbol \theta\)</span>, entonces el mecanismo del modelo de selección puede ser “ignorado”. Por lo tanto, ambas situaciones a menudo se denominan <em>caso ignorables</em>.</p>
<hr />
<p><strong>Ejemplo: Gastos Dentales.</strong> Sea <span class="math inline">\(y\)</span> el gasto anual en dentista de un hogar y <span class="math inline">\(x\)</span> el ingreso. Considere los siguientes cinco mecanismos de selección.</p>
<ul>
<li>El hogar no es seleccionado (faltante) con una probabilidad sin tener en cuenta el nivel de gasto dental. En este caso, el mecanismo de selección es MCAR.</li>
<li>El hogar no es seleccionado si el gasto dental es menor a $100. En este caso, el mecanismo de selección depende de la respuesta observada y faltante. El mecanismo de selección no puede ser ignorado.</li>
<li>El hogar no es seleccionado si el ingreso es menor a $20,000. En este caso, el mecanismo de selección es MCAR, dependiente de covariables. Es decir, suponiendo que el propósito del análisis es entender los gastos dentales condicionado al conocimiento del ingreso, estratificar según el ingreso no sesga gravemente el análisis.</li>
<li>La probabilidad de que un hogar sea seleccionado aumenta con el gasto dental. Por ejemplo, supongamos que la probabilidad de ser seleccionado es una función lineal de <span class="math inline">\(\exp(\psi y_i)/(1+ \exp(\psi y_i))\)</span>. En este caso, el mecanismo de selección depende de la respuesta observada y faltante. El mecanismo de selección no puede ser ignorado.</li>
<li>El hogar es seguido durante <span class="math inline">\(T\)</span> = 2 períodos. En el segundo período, un hogar no es seleccionado si el gasto del primer período es menor a $100. En este caso, el mecanismo de selección es MAR. Es decir, el mecanismo de selección se basa en una respuesta observada.</li>
</ul>
<hr />
<p>Los segundos y cuartos mecanismos de selección representan situaciones donde el mecanismo de selección debe ser modelado explícitamente; estos son casos no ignorables. En estas situaciones, sin ajustes explícitos, los procedimientos que ignoran el efecto de selección pueden producir resultados gravemente sesgados. Para ilustrar una corrección para el sesgo de selección en un caso simple, presentamos un ejemplo de Little y Rubin (1987). La Sección <a href="interpretación-de-resultados-de-regresión.html#Sec642">6.4.2</a> describe mecanismos adicionales.</p>
<hr />
<p><strong>Ejemplo: Alturas Históricas.</strong> Little y Rubin (1987) discuten datos de Wachter y Trusell (1982) sobre <span class="math inline">\(y\)</span>, la altura de hombres reclutados para servir en el ejército. La muestra está sujeta a censura en el sentido de que se impusieron estándares mínimos de altura para la admisión en el ejército. Así, el mecanismo de selección es</p>
<p><span class="math display">\[
r_i = \left\{
              \begin{array}{ll}
                1 &amp; y_i &gt; c_i \\
                0 &amp; \mathrm{de lo contrario} \\
              \end{array}
            \right. ,
\]</span>
donde <span class="math inline">\(c_i\)</span> es el estándar mínimo de altura conocido impuesto en el momento del reclutamiento. El mecanismo de selección es no ignorables porque depende de la altura del individuo, <span class="math inline">\(y\)</span>.</p>
<p>Para este ejemplo, se dispone de información adicional para proporcionar inferencia de modelos confiables. Específicamente, basándonos en otros estudios de alturas masculinas, podemos suponer que la población de alturas sigue una distribución normal. Así, la verosimilitud de las observaciones puede escribirse y la inferencia puede proceder directamente. Para ilustrar, supongamos que <span class="math inline">\(c_i = c\)</span> es constante. Sean <span class="math inline">\(\mu\)</span> y <span class="math inline">\(\sigma\)</span> la media y la desviación estándar de <span class="math inline">\(y\)</span>. Supongamos además que tenemos una muestra aleatoria de <span class="math inline">\(n + m\)</span> hombres en la que <span class="math inline">\(m\)</span> hombres están por debajo del estándar mínimo de altura <span class="math inline">\(c\)</span> y observamos <span class="math inline">\(\mathbf{Y}_{obs} = (y_1, \ldots, y_n)^{\prime}\)</span>. La distribución conjunta para los observables es</p>
<p><span class="math display">\[\begin{eqnarray*}
\mathrm{f}(\mathbf{r}, \mathbf{Y}_{obs}, \mu, \sigma) &amp;=&amp;
\mathrm{f}(\mathbf{Y}_{obs}, \mu, \sigma) \times
\mathrm{f}(\mathbf{r} | \mathbf{Y}_{obs}) \\
&amp;=&amp; \left\{ \prod_{i=1}^n   \mathrm{f}(y_i | y_i &gt; c) \times
\mathrm{Pr}(y_i &gt; c) \right\}
\times \left\{\mathrm{Pr}(y_i \leq c)\right\}^m.
\end{eqnarray*}\]</span>
Ahora, sean <span class="math inline">\(\phi\)</span> y <span class="math inline">\(\Phi\)</span> la densidad y la función de distribución para la distribución normal estándar. Así, la verosimilitud logarítmica es
<span class="math display">\[\begin{eqnarray*}
L(\mu, \sigma) &amp;=&amp; \mathrm{ln~} \mathrm{f}(\mathbf{r},
\mathbf{Y}_{obs}, \mu, \sigma) \\
&amp;=&amp; \sum_{i=1}^n \mathrm{ln}\left\{ \frac{1}{\sigma} \phi \left(
\frac{y_i-\mu}{\sigma} \right)
\right\}
+  m~ \mathrm{ln}\left\{ \Phi \left(
\frac{c-\mu}{\sigma}\right) \right\} .
\end{eqnarray*}\]</span>
Esto es fácil de maximizar en <span class="math inline">\(\mu\)</span> y <span class="math inline">\(\sigma\)</span>. Si se ignoraran los mecanismos de censura, entonces se derivarían estimaciones de los datos observados a partir de la “verosimilitud logarítmica,”
<span class="math display">\[
\sum_{i=1}^n \mathrm{ln}\left\{ \frac{1}{\sigma} \phi \left(
\frac{y_i-\mu}{\sigma} \right)
\right\},
\]</span>
lo que daría resultados diferentes y sesgados.</p>
<hr />
</div>
<div id="Sec642" class="section level3 hasAnchor" number="6.4.2">
<h3><span class="header-section-number">6.4.2</span> Datos Faltantes No Ignorables<a href="interpretación-de-resultados-de-regresión.html#Sec642" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Para los datos faltantes no ignorables, Little (1995) recomienda:</p>
<ul>
<li>Evitar respuestas faltantes siempre que sea posible utilizando procedimientos de seguimiento adecuados.</li>
<li>Recoger covariables que sean útiles para predecir los valores faltantes.</li>
<li>Recoger la mayor cantidad de información posible sobre la naturaleza del mecanismo de datos faltantes.</li>
</ul>
<p>Para el último punto, si se sabe poco sobre el mecanismo de datos faltantes, es difícil emplear un procedimiento estadístico robusto para corregir el sesgo de selección.</p>
<p>Existen muchos modelos de mecanismos de datos faltantes. Una visión general aparece en Little y Rubin (1987). Little (1995) examina el problema de la deserción. En lugar de revisar esta literatura en desarrollo, presentamos un modelo ampliamente utilizado para datos faltantes no ignorables.</p>
<div id="procedimiento-de-dos-etapas-de-heckman" class="section level4 unnumbered hasAnchor">
<h4>Procedimiento de Dos Etapas de Heckman<a href="interpretación-de-resultados-de-regresión.html#procedimiento-de-dos-etapas-de-heckman" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>Heckman (1976) asume que el mecanismo de respuesta de muestreo está gobernado por la variable latente (no observada) <span class="math inline">\(r_i^{\ast}\)</span> donde
<span class="math display">\[
r_i^{\ast} = \mathbf{z}_i^{\prime} \boldsymbol \gamma + \eta_i.
\]</span>
Las variables en <span class="math inline">\(\mathbf{z}_i\)</span> pueden o no incluir las variables en <span class="math inline">\(\mathbf{x}_i\)</span>. Observamos <span class="math inline">\(y_i\)</span> si <span class="math inline">\(r_i^{\ast}&gt;0\)</span>, es decir, si <span class="math inline">\(r_i^{\ast}\)</span> cruza el umbral 0. Así, observamos
<span class="math display">\[
r_i = \left\{
              \begin{array}{ll}
                1 &amp; r_i^{\ast}&gt;0 \\
                0 &amp; \mathrm{de lo contrario} \\
              \end{array}
            \right. .
\]</span>
Para completar la especificación, asumimos que {(<span class="math inline">\(\varepsilon_i,\eta_i\)</span>)} son distribuidos idénticamente e independientemente, y que la distribución conjunta de {(<span class="math inline">\(\varepsilon_i,\eta_i\)</span>)} es bivariada normal con medias cero, varianzas <span class="math inline">\(\sigma^2\)</span> y <span class="math inline">\(\sigma_{\eta}^2\)</span>, y correlación <span class="math inline">\(\rho\)</span>. Note que si el parámetro de correlación <span class="math inline">\(\rho\)</span> es igual a cero, entonces los modelos de respuesta y selección son independientes. En este caso, los datos son MCAR y los procedimientos de estimación habituales son no sesgados y asintóticamente eficientes.</p>
<p>Bajo estas suposiciones, cálculos básicos de la normal multivariada muestran que
<span class="math display">\[
\mathrm{E~}(y_i | r_i^{\ast}&gt;0) = \mathbf{x}_i^{\prime} \boldsymbol
\beta + \beta_{\lambda} \lambda(\mathbf{z}_i^{\prime} \boldsymbol
\gamma),
\]</span>
donde <span class="math inline">\(\beta_{\lambda} = \rho \sigma\)</span> y <span class="math inline">\(\lambda(a)=\phi(a)/\Phi(a)\)</span>. Aquí, <span class="math inline">\(\lambda(.)\)</span> es la inversa de la llamada “razón de Mills.” Este cálculo sugiere el siguiente procedimiento en dos etapas para estimar los parámetros de interés.</p>
<div class="blackbox">
<p><em>Procedimiento de Dos Etapas de Heckman</em></p>
<ol style="list-style-type: decimal">
<li>Utilice los datos {(<span class="math inline">\(r_i, \mathbf{z}_i\)</span>)} y un modelo de regresión probit para estimar <span class="math inline">\(\boldsymbol \gamma\)</span>. Llame a este estimador <span class="math inline">\(\mathbf{g}_H\)</span>.</li>
<li>Utilice el estimador de la etapa (1) para crear una nueva variable explicativa, <span class="math inline">\(x_{i,K+1} = \lambda(\mathbf{z}_i^{\prime}\mathbf{g}_H)\)</span>. Realice un modelo de regresión utilizando las <span class="math inline">\(K\)</span> variables explicativas <span class="math inline">\(\mathbf{x}_i\)</span>, así como la variable explicativa adicional <span class="math inline">\(x_{i,K+1}\)</span>. Use <span class="math inline">\(\mathbf{b}_H\)</span> y <span class="math inline">\(b_{\lambda,H}\)</span> para denotar los estimadores de <span class="math inline">\(\boldsymbol \beta\)</span> y <span class="math inline">\(\beta_{\lambda}\)</span>, respectivamente.</li>
</ol>
</div>
<p><br></p>
<p>El Capítulo 11 introducirá las regresiones probit. También observamos que el método de dos etapas no funciona en ausencia de covariables para predecir la respuesta y, para fines prácticos, requiere variables en <span class="math inline">\(\mathbf{z}\)</span> que no están en <span class="math inline">\(\mathbf{x}\)</span> (ver Little y Rubin, 1987).</p>
<p>Para probar el sesgo de selección, podemos probar la hipótesis nula <span class="math inline">\(H_0:\beta_{\lambda}=0\)</span> en la segunda etapa debido a la relación <span class="math inline">\(\beta_{\lambda}= \rho \sigma\)</span>. Al realizar esta prueba, se deben usar errores estándar corregidos por heterocedasticidad. Esto se debe a que la varianza condicional <span class="math inline">\(\mathrm{Var}(y_i | r_i^{\ast}&gt;0)\)</span> depende de la observación <span class="math inline">\(i\)</span>. Específicamente, <span class="math inline">\(\mathrm{Var}(y_i | r_i^{\ast}&gt;0) = \sigma^2 (1-\rho^2 \delta_i),\)</span> donde <span class="math inline">\(\delta_i= \lambda_i(\lambda_i + \mathbf{z}_i^{\prime} \boldsymbol \gamma)\)</span> y <span class="math inline">\(\lambda_i = \phi(\mathbf{z}_i^{\prime} \boldsymbol \gamma)/\Phi(\mathbf{z}_i^{\prime} \boldsymbol \gamma).\)</span></p>
<p>Este procedimiento asume normalidad para las variables latentes de selección para formar las variables aumentadas. Existen otras formas de distribución en la literatura, incluyendo las distribuciones logística y uniforme. Una crítica más profunda, planteada por Little (1985), es que el procedimiento se basa en suposiciones que no se pueden probar utilizando los datos disponibles. Esta crítica es análoga al ejemplo de alturas históricas donde nos basamos en gran medida en la curva normal para inferir la distribución de alturas por debajo del punto de censura. A pesar de estas críticas, el procedimiento de Heckman se usa ampliamente en las ciencias sociales.</p>
</div>
<div id="algoritmo-em" class="section level4 unnumbered hasAnchor">
<h4>Algoritmo EM<a href="interpretación-de-resultados-de-regresión.html#algoritmo-em" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>La Sección <a href="interpretación-de-resultados-de-regresión.html#Sec642">6.4.2</a> se ha centrado en introducir modelos específicos de no respuesta no ignorables. Los modelos generales robustos de no respuesta no están disponibles. En cambio, una estrategia más apropiada es centrarse en una situación específica, recoger la mayor cantidad de información posible sobre la naturaleza del problema de selección y luego desarrollar un modelo para este problema de selección específico.</p>
<p>El algoritmo EM es un dispositivo computacional para calcular los parámetros del modelo. Aunque es específico para cada modelo, ha encontrado aplicaciones en una amplia variedad de modelos que involucran datos faltantes. Computacionalmente, el algoritmo itera entre los pasos de “E”, para la expectativa condicional, y “M”, para la maximización. El paso E encuentra la expectativa condicional de los datos faltantes dado los datos observados y los valores actuales de los parámetros estimados. Esto es análogo a la tradición de imputar datos faltantes. Una innovación clave del algoritmo EM es que se imputan estadísticas suficientes para los valores faltantes, no los puntos de datos individuales. Para el paso M, se actualizan las estimaciones de los parámetros maximizando una log-verosimilitud observada. Tanto las estadísticas suficientes como la log-verosimilitud dependen de la especificación del modelo.</p>
<p>Existen muchas introducciones al algoritmo EM en la literatura. Little y Rubin (1987) proporcionan un tratamiento detallado.</p>
</div>
</div>
</div>
<div id="Sec65" class="section level2 hasAnchor" number="6.5">
<h2><span class="header-section-number">6.5</span> Aplicación: Eficiencia en el Costo de los Gestores de Riesgos<a href="interpretación-de-resultados-de-regresión.html#Sec65" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Esta sección examina datos de una encuesta sobre la eficiencia en el costo de las prácticas de gestión de riesgos. Las prácticas de gestión de riesgos son actividades llevadas a cabo por una empresa para minimizar el costo potencial de futuras pérdidas, como el evento de un incendio en un almacén o un accidente que lesione a los empleados. Esta sección desarrolla un modelo que se puede utilizar para hacer afirmaciones sobre el costo de la gestión de riesgos.</p>
<p>Un esquema del proceso de modelado de regresión es el siguiente. Comenzamos proporcionando una introducción al problema y dando un breve contexto sobre los datos. Ciertas teorías previas nos llevarán a presentar un ajuste preliminar del modelo. Usando técnicas diagnósticas, será evidente que varias suposiciones que sustentan este modelo no están en acuerdo con los datos. Esto nos llevará a volver al principio y comenzar el análisis desde cero. Lo que aprendemos de un examen detallado de los datos nos llevará a postular algunos modelos revisados. Finalmente, para comunicar ciertos aspectos del nuevo modelo, exploraremos presentaciones gráficas del modelo recomendado.</p>
<div id="introducción" class="section level4 unnumbered hasAnchor">
<h4>Introducción<a href="interpretación-de-resultados-de-regresión.html#introducción" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>Los datos para este estudio fueron proporcionados por la Profesora Joan Schmit y se discuten en más detalle en el artículo “Cost effectiveness of risk management practices,” Schmit y Roth (1990). Los datos provienen de un cuestionario enviado a 374 gestores de riesgos de grandes organizaciones con sede en EE. UU. El propósito del estudio fue relacionar la eficacia en costos con la filosofía de gestión de controlar la exposición de la empresa a diversas pérdidas por propiedad y accidentes, después de ajustar por efectos de la empresa como el tamaño y el tipo de industria.</p>
<p>Primero, algunas advertencias. Los datos de encuestas a menudo se basan en muestras de conveniencia, no en muestras probabilísticas. Al igual que con todos los conjuntos de datos observacionales, la metodología de regresión es una herramienta útil para resumir los datos. Sin embargo, debemos ser cautelosos al hacer inferencias basadas en este tipo de conjunto de datos. Para esta encuesta en particular, 162 gestores devolvieron encuestas completas, resultando en una buena tasa de respuesta del <span class="math inline">\(43\%\)</span>. Sin embargo, para las variables incluidas en el análisis (definidas más adelante), solo se completaron 73 formularios, resultando en una tasa de respuesta completa del <span class="math inline">\(20\%\)</span>. ¿Por qué una diferencia tan dramática? Los gestores, al igual que la mayoría de las personas, generalmente no tienen problemas en responder a consultas sobre sus actitudes u opiniones acerca de diversos temas. Cuando se les pregunta sobre hechos concretos, en este caso el tamaño de los activos de la empresa o las primas de seguros, o bien consideran que la información es confidencial y son reacios a responder incluso cuando se les garantiza anonimato, o simplemente no están dispuestos a tomarse el tiempo para buscar la información. Desde el punto de vista del encuestador, esto es desafortunado porque, por lo general, los datos “actitudinales” son imprecisos (alta varianza en comparación con la media) en comparación con los datos financieros concretos. El inconveniente es que estos últimos datos a menudo son difíciles de obtener. De hecho, para esta encuesta, se enviaron varios cuestionarios previos para determinar la disposición de los gestores a responder preguntas específicas. A partir de los cuestionarios previos, los investigadores redujeron drásticamente el número de preguntas financieras que planeaban hacer.</p>
<p>Una medida de la eficacia en el costo de la gestión de riesgos, FIRMCOST, es la variable dependiente. Esta variable se define como las primas totales por propiedad y accidentes y las pérdidas no aseguradas como un porcentaje de los activos totales. Es un proxy para los gastos anuales asociados con eventos asegurables, estandarizados por el tamaño de la empresa. Aquí, para las variables financieras, ASSUME es el monto de retención por ocurrencia como porcentaje de los activos totales, CAP indica si la empresa posee una compañía de seguros cautiva, SIZELOG es el logaritmo de los activos totales e INDCOST es una medida del riesgo de la industria de la empresa. Las variables actitudinales incluyen CENTRAL, una medida de la importancia de los gestores locales en la elección de la cantidad de riesgo a retener, y SOPH, una medida del grado de importancia en el uso de herramientas analíticas, como la regresión, en la toma de decisiones de gestión de riesgos.</p>
<p>En el artículo, los investigadores describieron varias debilidades de las definiciones utilizadas, pero argumentan que estas definiciones proporcionan información útil, basada en la disposición de los gestores de riesgos a obtener información confiable. Los investigadores también describieron varias teorías sobre relaciones que podrían ser confirmadas por los datos. Específicamente, hipotetizaron:</p>
<ul>
<li>Existe una relación inversa entre la retención de riesgo (ASSUME) y el costo (FIRMCOST). La idea detrás de esta teoría es que mayores montos de retención deberían significar menores gastos para una empresa, resultando en menores costos.</li>
<li>El uso de una compañía de seguros cautiva (CAP) resulta en menores costos. Presumiblemente, una cautiva se usa solo cuando es costo-efectiva y, en consecuencia, esta variable debería indicar menores costos si se utiliza efectivamente.</li>
<li>Existe una relación inversa entre la medida de centralización (CENTRAL) y el costo (FIRMCOST). Presumiblemente, los gestores locales podrían tomar decisiones más costo-efectivas porque están más familiarizados con las circunstancias locales relacionadas con la gestión de riesgos que los gestores ubicados centralmente.</li>
<li>Existe una relación inversa entre la medida de sofisticación (SOPH) y el costo (FIRMCOST). Presumiblemente, herramientas analíticas más sofisticadas ayudan a las empresas a gestionar el riesgo de manera más eficaz, resultando en menores costos.</li>
</ul>
</div>
<div id="análisis-preliminar" class="section level4 unnumbered hasAnchor">
<h4>Análisis Preliminar<a href="interpretación-de-resultados-de-regresión.html#análisis-preliminar" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>Para probar las teorías descritas anteriormente, se puede utilizar el marco de análisis de regresión. Para ello, se plantea el modelo</p>
<p><span class="math display">\[
\small{
\begin{array}{ll}
\text{FIRMCOST} &amp;=&amp;\beta_0 +\beta_1 \text{ ASSUME}+\beta_{2}\text{ CAP}
+\beta_{3}\text{ SIZELOG}+\beta_4\text{ INDCOST} \\
&amp;&amp;+\beta_5\text{ CENTRAL}+\beta_6\text{ SOPH}+ \varepsilon.
\end{array}
}
\]</span></p>
<p>Con este modelo, cada teoría se puede interpretar en términos de los coeficientes de regresión. Por ejemplo, <span class="math inline">\(\beta_1\)</span> se puede interpretar como el cambio esperado en el costo por unidad de cambio en el nivel de retención (ASSUME). Así, si la primera hipótesis es verdadera, esperamos que <span class="math inline">\(\beta_1\)</span> sea negativo. Para probar esto, podemos estimar <span class="math inline">\(b_{1}\)</span> y usar nuestras pruebas de hipótesis para decidir si <span class="math inline">\(b_{1}\)</span> es significativamente menor que cero. Las variables SIZELOG e INDCOST se incluyen en el modelo para controlar los efectos de estas variables. Estas variables no están directamente bajo el control del gestor de riesgos y, por lo tanto, no son de interés principal. Sin embargo, la inclusión de estas variables puede explicar una parte importante de la variabilidad.</p>
<p>Los datos de 73 gestores fueron ajustados utilizando este modelo de regresión. La Tabla <a href="interpretación-de-resultados-de-regresión.html#tab:Tab62">6.2</a> resume el modelo ajustado.</p>
<table class=" lightable-classic table table-striped table-condensed" style="font-size: 12px; font-family: Cambria; width: auto !important; margin-left: auto; margin-right: auto; margin-left: auto; margin-right: auto;">
<caption style="font-size: initial !important;">
<span id="tab:Tab62">Tabla 6.2: </span><strong>Resultados de la Regresión del Ajuste del Modelo Preliminar</strong>
</caption>
<thead>
<tr>
<th style="text-align:left;">
</th>
<th style="text-align:right;">
Coeficiente
</th>
<th style="text-align:right;">
Error Estándar
</th>
<th style="text-align:right;">
<span class="math inline">\(t\)</span>-Estadístico
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;width: 2.5cm; border-right:1px solid;">
(Intercept)
</td>
<td style="text-align:right;width: 3cm; ">
59.765
</td>
<td style="text-align:right;width: 3cm; ">
19.065
</td>
<td style="text-align:right;width: 3cm; ">
3.135
</td>
</tr>
<tr>
<td style="text-align:left;width: 2.5cm; border-right:1px solid;">
ASSUME
</td>
<td style="text-align:right;width: 3cm; ">
-0.300
</td>
<td style="text-align:right;width: 3cm; ">
0.222
</td>
<td style="text-align:right;width: 3cm; ">
-1.353
</td>
</tr>
<tr>
<td style="text-align:left;width: 2.5cm; border-right:1px solid;">
CAP
</td>
<td style="text-align:right;width: 3cm; ">
5.498
</td>
<td style="text-align:right;width: 3cm; ">
3.848
</td>
<td style="text-align:right;width: 3cm; ">
1.429
</td>
</tr>
<tr>
<td style="text-align:left;width: 2.5cm; border-right:1px solid;">
SIZELOG
</td>
<td style="text-align:right;width: 3cm; ">
-6.836
</td>
<td style="text-align:right;width: 3cm; ">
1.923
</td>
<td style="text-align:right;width: 3cm; ">
-3.555
</td>
</tr>
<tr>
<td style="text-align:left;width: 2.5cm; border-right:1px solid;">
INDCOST
</td>
<td style="text-align:right;width: 3cm; ">
23.078
</td>
<td style="text-align:right;width: 3cm; ">
8.304
</td>
<td style="text-align:right;width: 3cm; ">
2.779
</td>
</tr>
<tr>
<td style="text-align:left;width: 2.5cm; border-right:1px solid;">
CENTRAL
</td>
<td style="text-align:right;width: 3cm; ">
0.133
</td>
<td style="text-align:right;width: 3cm; ">
1.441
</td>
<td style="text-align:right;width: 3cm; ">
0.092
</td>
</tr>
<tr>
<td style="text-align:left;width: 2.5cm; border-right:1px solid;">
SOPH
</td>
<td style="text-align:right;width: 3cm; ">
-0.137
</td>
<td style="text-align:right;width: 3cm; ">
0.347
</td>
<td style="text-align:right;width: 3cm; ">
-0.394
</td>
</tr>
</tbody>
</table>
<p>El coeficiente de determinación ajustado es <span class="math inline">\(R_{a}^{2}=18.8\%\)</span>, el ratio <span class="math inline">\(F\)</span> es 3.78 y la desviación estándar residual es <span class="math inline">\(s=14.56\)</span>.</p>
<p>Con base en las estadísticas resumidas del modelo de regresión, podemos concluir que las medidas de centralización y sofisticación no tienen un impacto en nuestra medida de eficacia en costos. Para ambas variables, el ratio <span class="math inline">\(t\)</span> es bajo, menos de 1.0 en valor absoluto. El efecto de la retención de riesgo parece ser solo algo importante. El coeficiente tiene el signo apropiado, aunque está solo 1.35 errores estándar por debajo de cero. Esto no se consideraría estadísticamente significativo al nivel del 5%, aunque sí al nivel del 10% (el valor <span class="math inline">\(p\)</span> es 9%). Quizás lo más desconcertante es el coeficiente asociado con la variable CAP. Teorizamos que este coeficiente sería negativo. Sin embargo, en nuestro análisis de los datos, el coeficiente resulta ser positivo y está 1.43 errores estándar por encima de cero. Esto no solo nos lleva a desmentir nuestra teoría, sino también a buscar nuevas ideas que estén en concordancia con la información aprendida de los datos. Schmit y Roth sugieren razones que pueden ayudarnos a interpretar los resultados de nuestras pruebas de hipótesis. Por ejemplo, sugieren que los gestores en la muestra pueden no tener las herramientas más sofisticadas disponibles cuando gestionan riesgos, lo que resulta en un coeficiente no significativo asociado con SOPH. También discutieron sugerencias alternativas, así como interpretaciones para los otros resultados de las pruebas de hipótesis.</p>
<p>¿Qué tan robusto es este modelo? La Sección <a href="interpretación-de-resultados-de-regresión.html#Sec62">6.2</a> enfatizó algunos de los peligros de trabajar con un modelo inadecuado. Algunos lectores pueden sentirse incómodos con el modelo seleccionado anteriormente porque dos de las seis variables tienen <span class="math inline">\(t\)</span>-ratios menores a 1 en valor absoluto y cuatro de las seis tienen <span class="math inline">\(t\)</span>-ratios menores a 1.5 en valor absoluto. Quizás aún más importante, los histogramas de los residuos estandarizados y las palancas, en la Figura <a href="interpretación-de-resultados-de-regresión.html#fig:Fig65">6.5</a>, muestran que varias observaciones son puntos atípicos y de alta influencia. Para ilustrar, el residuo más grande resulta ser <span class="math inline">\(e_{15}=83.73\)</span>. La suma de cuadrados del error es <span class="math inline">\(Error~SS\)</span> = <span class="math inline">\((n-(k+1))s^{2}\)</span> =
<span class="math inline">\((73-7)(14.56)^{2}=13,987\)</span>. Así, la
15ª observación representa el 50.1% de la suma de cuadrados del error <span class="math inline">\((=83.73^{2}/13,987)\)</span>, sugiriendo que esta única observación de las 73 tiene un impacto dominante en el ajuste del modelo. Además, los gráficos de residuos estandarizados versus valores ajustados, no presentados aquí, mostraron evidencia de residuos heterocedásticos. Con base en estas observaciones, parece razonable evaluar la robustez del modelo.</p>

<div class="figure" style="text-align: center"><span style="display:block;" id="fig:Fig65"></span>
<img src="RegressionMarkdown_files/figure-html/Fig65-1.png" alt="Histogramas de residuos estandarizados y palancas del ajuste preliminar del modelo de regresión." width="60%" />
<p class="caption">
Figura 6.5: <strong>Histogramas de residuos estandarizados y palancas del ajuste preliminar del modelo de regresión.</strong>
</p>
</div>
<h5 style="text-align: center;">
<a id="displayCode.Tab62.Hide" href="javascript:togglecode('toggleCode.Tab62.Hide','displayCode.Tab62.Hide');"><i><strong>Código R para producir la Tabla 6.2 y la Figura 6.5</strong></i></a>
</h5>
<div id="toggleCode.Tab62.Hide" style="display: none">
<div class="sourceCode" id="cb54"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb54-1"><a href="interpretación-de-resultados-de-regresión.html#cb54-1" tabindex="-1"></a><span class="do">## Análisis del Gestor de Riesgos</span></span>
<span id="cb54-2"><a href="interpretación-de-resultados-de-regresión.html#cb54-2" tabindex="-1"></a><span class="co"># Tabla 6.2</span></span>
<span id="cb54-3"><a href="interpretación-de-resultados-de-regresión.html#cb54-3" tabindex="-1"></a>survey <span class="ot">&lt;-</span> <span class="fu">read.csv</span>(<span class="st">&quot;CSVData/RiskSurvey.csv&quot;</span>, <span class="at">header=</span><span class="cn">TRUE</span>)</span>
<span id="cb54-4"><a href="interpretación-de-resultados-de-regresión.html#cb54-4" tabindex="-1"></a>varSurvey <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="st">&quot;FIRMCOST&quot;</span>,<span class="st">&quot;ASSUME&quot;</span>,<span class="st">&quot;CAP&quot;</span>,<span class="st">&quot;SIZELOG&quot;</span>,<span class="st">&quot;INDCOST&quot;</span>,<span class="st">&quot;CENTRAL&quot;</span>,<span class="st">&quot;SOPH&quot;</span>)</span>
<span id="cb54-5"><a href="interpretación-de-resultados-de-regresión.html#cb54-5" tabindex="-1"></a>survey1 <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(survey[varSurvey])</span>
<span id="cb54-6"><a href="interpretación-de-resultados-de-regresión.html#cb54-6" tabindex="-1"></a></span>
<span id="cb54-7"><a href="interpretación-de-resultados-de-regresión.html#cb54-7" tabindex="-1"></a><span class="co">#  PRIMERA REGRESIÓN</span></span>
<span id="cb54-8"><a href="interpretación-de-resultados-de-regresión.html#cb54-8" tabindex="-1"></a>lmsurvey1<span class="ot">&lt;-</span><span class="fu">lm</span>(FIRMCOST<span class="sc">~</span>ASSUME<span class="sc">+</span>CAP<span class="sc">+</span>SIZELOG<span class="sc">+</span>INDCOST<span class="sc">+</span>CENTRAL<span class="sc">+</span>SOPH,<span class="at">data=</span>survey1)</span>
<span id="cb54-9"><a href="interpretación-de-resultados-de-regresión.html#cb54-9" tabindex="-1"></a>sum1 <span class="ot">&lt;-</span> <span class="fu">summary</span>(lmsurvey1)</span>
<span id="cb54-10"><a href="interpretación-de-resultados-de-regresión.html#cb54-10" tabindex="-1"></a>tableout <span class="ot">&lt;-</span> sum1<span class="sc">$</span>coefficients[,<span class="dv">1</span><span class="sc">:</span><span class="dv">3</span>]</span>
<span id="cb54-11"><a href="interpretación-de-resultados-de-regresión.html#cb54-11" tabindex="-1"></a><span class="fu">colnames</span>(tableout) <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="st">&quot;Coeficiente&quot;</span>, <span class="st">&quot;Error Estándar&quot;</span>, <span class="st">&quot;$t$-Estadístico&quot;</span>)</span>
<span id="cb54-12"><a href="interpretación-de-resultados-de-regresión.html#cb54-12" tabindex="-1"></a><span class="fu">TableGen1</span>(<span class="at">TableData=</span>tableout , </span>
<span id="cb54-13"><a href="interpretación-de-resultados-de-regresión.html#cb54-13" tabindex="-1"></a>         <span class="at">TextTitle=</span><span class="st">&#39;Resultados de la Regresión del Ajuste del Modelo Preliminar&#39;</span>, </span>
<span id="cb54-14"><a href="interpretación-de-resultados-de-regresión.html#cb54-14" tabindex="-1"></a>         <span class="at">Align=</span><span class="st">&#39;r&#39;</span>,  <span class="at">ColumnSpec=</span><span class="dv">1</span><span class="sc">:</span><span class="dv">3</span>, <span class="at">Digits =</span> <span class="dv">3</span>,</span>
<span id="cb54-15"><a href="interpretación-de-resultados-de-regresión.html#cb54-15" tabindex="-1"></a>         <span class="at">ColWidth =</span> <span class="st">&quot;3cm&quot;</span>)</span></code></pre></div>
<div class="sourceCode" id="cb55"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb55-1"><a href="interpretación-de-resultados-de-regresión.html#cb55-1" tabindex="-1"></a>ri1 <span class="ot">&lt;-</span> <span class="fu">rstandard</span>(lmsurvey1)</span>
<span id="cb55-2"><a href="interpretación-de-resultados-de-regresión.html#cb55-2" tabindex="-1"></a>hii1 <span class="ot">&lt;-</span> <span class="fu">hatvalues</span>(lmsurvey1)</span>
<span id="cb55-3"><a href="interpretación-de-resultados-de-regresión.html#cb55-3" tabindex="-1"></a></span>
<span id="cb55-4"><a href="interpretación-de-resultados-de-regresión.html#cb55-4" tabindex="-1"></a><span class="co">#  FIGURA 6.5</span></span>
<span id="cb55-5"><a href="interpretación-de-resultados-de-regresión.html#cb55-5" tabindex="-1"></a><span class="fu">par</span>(<span class="at">mfrow=</span><span class="fu">c</span>(<span class="dv">1</span>, <span class="dv">2</span>),<span class="at">mar=</span><span class="fu">c</span>(<span class="fl">4.1</span>,<span class="fl">4.5</span>,.<span class="dv">2</span>,.<span class="dv">2</span>))</span>
<span id="cb55-6"><a href="interpretación-de-resultados-de-regresión.html#cb55-6" tabindex="-1"></a><span class="fu">hist</span>(ri1, <span class="at">nclass=</span><span class="dv">16</span>, <span class="at">main=</span><span class="st">&quot;&quot;</span>, <span class="at">xlab=</span><span class="st">&quot;Residuos Estandarizados&quot;</span>,<span class="at">las=</span><span class="dv">1</span>,<span class="at">cex.lab=</span><span class="fl">1.5</span>)</span>
<span id="cb55-7"><a href="interpretación-de-resultados-de-regresión.html#cb55-7" tabindex="-1"></a><span class="fu">hist</span>(hii1, <span class="at">nclass=</span><span class="dv">16</span>, <span class="at">main=</span><span class="st">&quot;&quot;</span>, <span class="at">xlab=</span><span class="st">&quot;Palancas&quot;</span>,<span class="at">las=</span><span class="dv">1</span>,<span class="at">cex.lab=</span><span class="fl">1.5</span>)</span></code></pre></div>
</div>
</div>
<div id="volviendo-a-lo-básico" class="section level4 unnumbered hasAnchor">
<h4>Volviendo a lo Básico<a href="interpretación-de-resultados-de-regresión.html#volviendo-a-lo-básico" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>Para entender mejor los datos, comenzamos examinando las estadísticas resumen básicas en la Tabla <a href="interpretación-de-resultados-de-regresión.html#tab:Tab63">6.3</a> y los histogramas correspondientes en la Figura <a href="interpretación-de-resultados-de-regresión.html#fig:Fig66">6.6</a>. En la Tabla <a href="interpretación-de-resultados-de-regresión.html#tab:Tab63">6.3</a>, el valor más alto de FIRMCOST es 97.55, que está más de cinco desviaciones estándar por encima de la media
<span class="math inline">\([10.97+5(16.16)=91.77]\)</span>. Un examen de los datos muestra que este punto es la observación 15, la misma observación que fue un punto atípico en el ajuste preliminar de la regresión. Sin embargo, el histograma de FIRMCOST en la Figura <a href="interpretación-de-resultados-de-regresión.html#fig:Fig66">6.6</a> revela que este no es el único punto inusual. Otras dos observaciones tienen valores inusualmente altos de FIRMCOST, resultando en una distribución sesgada hacia la derecha. El histograma, en la Figura <a href="interpretación-de-resultados-de-regresión.html#fig:Fig66">6.6</a>, de la variable ASSUME muestra que esta distribución también está sesgada hacia la derecha, posiblemente debido únicamente a dos grandes observaciones. De las estadísticas resumen básicas en la Tabla <a href="interpretación-de-resultados-de-regresión.html#tab:Tab63">6.3</a>, vemos que el valor más alto de ASSUME está más de siete desviaciones estándar por encima de la media. Esta observación podría resultar influyente en el ajuste posterior del modelo de regresión. El diagrama de dispersión de FIRMCOST versus ASSUME en la Figura <a href="interpretación-de-resultados-de-regresión.html#fig:Fig66">6.6</a> nos dice que la observación con el valor más alto de FIRMCOST no es la misma que la observación con el valor más alto de ASSUME.</p>
<table class=" lightable-classic table table-striped table-condensed" style="font-size: 12px; font-family: Cambria; width: auto !important; margin-left: auto; margin-right: auto; margin-left: auto; margin-right: auto;">
<caption style="font-size: initial !important;">
<span id="tab:Tab63">Tabla 6.3: </span><strong>Estadísticas Resumen de <span class="math inline">\(n=73\)</span> Encuestas sobre Gestión de Riesgos</strong>
</caption>
<thead>
<tr>
<th style="text-align:left;">
</th>
<th style="text-align:right;">
Media
</th>
<th style="text-align:right;">
Mediana
</th>
<th style="text-align:right;">
Desviación Estándar
</th>
<th style="text-align:right;">
Mínimo
</th>
<th style="text-align:right;">
Máximo
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;width: 2.5cm; border-right:1px solid;">
FIRMCOST
</td>
<td style="text-align:right;width: 1.6cm; ">
10.973
</td>
<td style="text-align:right;width: 1.6cm; ">
6.08
</td>
<td style="text-align:right;width: 1.6cm; ">
16.159
</td>
<td style="text-align:right;width: 1.6cm; ">
0.20
</td>
<td style="text-align:right;width: 1.6cm; ">
97.55
</td>
</tr>
<tr>
<td style="text-align:left;width: 2.5cm; border-right:1px solid;">
ASSUME
</td>
<td style="text-align:right;width: 1.6cm; ">
2.574
</td>
<td style="text-align:right;width: 1.6cm; ">
0.51
</td>
<td style="text-align:right;width: 1.6cm; ">
8.445
</td>
<td style="text-align:right;width: 1.6cm; ">
0.00
</td>
<td style="text-align:right;width: 1.6cm; ">
61.82
</td>
</tr>
<tr>
<td style="text-align:left;width: 2.5cm; border-right:1px solid;">
CAP
</td>
<td style="text-align:right;width: 1.6cm; ">
0.342
</td>
<td style="text-align:right;width: 1.6cm; ">
0.00
</td>
<td style="text-align:right;width: 1.6cm; ">
0.478
</td>
<td style="text-align:right;width: 1.6cm; ">
0.00
</td>
<td style="text-align:right;width: 1.6cm; ">
1.00
</td>
</tr>
<tr>
<td style="text-align:left;width: 2.5cm; border-right:1px solid;">
SIZELOG
</td>
<td style="text-align:right;width: 1.6cm; ">
8.332
</td>
<td style="text-align:right;width: 1.6cm; ">
8.27
</td>
<td style="text-align:right;width: 1.6cm; ">
0.963
</td>
<td style="text-align:right;width: 1.6cm; ">
5.27
</td>
<td style="text-align:right;width: 1.6cm; ">
10.60
</td>
</tr>
<tr>
<td style="text-align:left;width: 2.5cm; border-right:1px solid;">
INDCOST
</td>
<td style="text-align:right;width: 1.6cm; ">
0.418
</td>
<td style="text-align:right;width: 1.6cm; ">
0.34
</td>
<td style="text-align:right;width: 1.6cm; ">
0.216
</td>
<td style="text-align:right;width: 1.6cm; ">
0.09
</td>
<td style="text-align:right;width: 1.6cm; ">
1.22
</td>
</tr>
<tr>
<td style="text-align:left;width: 2.5cm; border-right:1px solid;">
CENTRAL
</td>
<td style="text-align:right;width: 1.6cm; ">
2.247
</td>
<td style="text-align:right;width: 1.6cm; ">
2.00
</td>
<td style="text-align:right;width: 1.6cm; ">
1.256
</td>
<td style="text-align:right;width: 1.6cm; ">
1.00
</td>
<td style="text-align:right;width: 1.6cm; ">
5.00
</td>
</tr>
<tr>
<td style="text-align:left;width: 2.5cm; border-right:1px solid;">
SOPH
</td>
<td style="text-align:right;width: 1.6cm; ">
21.192
</td>
<td style="text-align:right;width: 1.6cm; ">
23.00
</td>
<td style="text-align:right;width: 1.6cm; ">
5.304
</td>
<td style="text-align:right;width: 1.6cm; ">
5.00
</td>
<td style="text-align:right;width: 1.6cm; ">
31.00
</td>
</tr>
</tbody>
</table>
<p><em>Fuente</em>: Schmit y Roth, (1990)</p>
<p>A partir de los histogramas de SIZELOG, INDCOST, CENTRAL y SOPH, vemos que estas distribuciones no están fuertemente sesgadas. Tomar logaritmos del tamaño de los activos totales de la empresa ha servido para hacer la distribución más simétrica que en las unidades originales. A partir del histograma y las estadísticas resumen, vemos que CENTRAL es una variable discreta, que toma valores del uno al cinco. La otra variable discreta es CAP, una variable binaria que toma solo valores cero y uno. El histograma y el gráfico de dispersión correspondiente a CAP no se presentan aquí. Es más informativo proporcionar una <em>tabla de medias</em> de cada variable por niveles de CAP, como en la Tabla <a href="interpretación-de-resultados-de-regresión.html#tab:Tab64">6.4</a>. A partir de esta tabla, vemos que 25 de las 73 empresas encuestadas tienen aseguradoras cautivas. Además, por un lado, el FIRMCOST promedio para las empresas con aseguradoras cautivas <span class="math inline">\((CAP = 1)\)</span> es mayor que para las que no tienen <span class="math inline">\((CAP = 0)\)</span>. Por otro lado, al pasar a la escala logarítmica, sucede lo contrario; es decir, el COSTLOG promedio para las empresas con aseguradoras cautivas <span class="math inline">\((CAP = 1)\)</span> es mayor que para las que no tienen <span class="math inline">\((CAP = 0)\)</span>.</p>
<table class=" lightable-classic table table-striped table-condensed" style="font-size: 12px; font-family: Cambria; width: auto !important; margin-left: auto; margin-right: auto; margin-left: auto; margin-right: auto;">
<caption style="font-size: initial !important;">
<span id="tab:Tab64">Tabla 6.4: </span><strong>Tabla de Medias por Nivel de CAP</strong>
</caption>
<thead>
<tr>
<th style="text-align:left;">
</th>
<th style="text-align:right;">
<span class="math inline">\(n\)</span>
</th>
<th style="text-align:right;">
FIRMCOST
</th>
<th style="text-align:right;">
ASSUME
</th>
<th style="text-align:right;">
SIZELOG
</th>
<th style="text-align:right;">
INDCOST
</th>
<th style="text-align:right;">
CENTRAL
</th>
<th style="text-align:right;">
SOPH
</th>
<th style="text-align:right;">
COSTLOG
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;width: 2.5cm; border-right:1px solid;">
CAP = 0
</td>
<td style="text-align:right;width: 1.5cm; ">
48
</td>
<td style="text-align:right;width: 1.5cm; ">
9.954
</td>
<td style="text-align:right;width: 1.5cm; ">
1.175
</td>
<td style="text-align:right;width: 1.5cm; ">
8.196
</td>
<td style="text-align:right;width: 1.5cm; ">
0.399
</td>
<td style="text-align:right;width: 1.5cm; ">
2.250
</td>
<td style="text-align:right;width: 1.5cm; ">
21.521
</td>
<td style="text-align:right;">
1.820
</td>
</tr>
<tr>
<td style="text-align:left;width: 2.5cm; border-right:1px solid;">
CAP = 1
</td>
<td style="text-align:right;width: 1.5cm; ">
25
</td>
<td style="text-align:right;width: 1.5cm; ">
12.931
</td>
<td style="text-align:right;width: 1.5cm; ">
5.258
</td>
<td style="text-align:right;width: 1.5cm; ">
8.592
</td>
<td style="text-align:right;width: 1.5cm; ">
0.455
</td>
<td style="text-align:right;width: 1.5cm; ">
2.240
</td>
<td style="text-align:right;width: 1.5cm; ">
20.560
</td>
<td style="text-align:right;">
1.595
</td>
</tr>
<tr>
<td style="text-align:left;width: 2.5cm; border-right:1px solid;">
TOTAL
</td>
<td style="text-align:right;width: 1.5cm; ">
73
</td>
<td style="text-align:right;width: 1.5cm; ">
10.973
</td>
<td style="text-align:right;width: 1.5cm; ">
2.574
</td>
<td style="text-align:right;width: 1.5cm; ">
8.332
</td>
<td style="text-align:right;width: 1.5cm; ">
0.418
</td>
<td style="text-align:right;width: 1.5cm; ">
2.247
</td>
<td style="text-align:right;width: 1.5cm; ">
21.192
</td>
<td style="text-align:right;">
1.743
</td>
</tr>
</tbody>
</table>

<div class="figure" style="text-align: center"><span style="display:block;" id="fig:Fig66"></span>
<img src="RegressionMarkdown_files/figure-html/Fig66-1.png" alt="Histogramas y gráficos de dispersión de FIRMCOST y varias variables explicativas. Las distribuciones de FIRMCOST y ASSUME están fuertemente sesgadas hacia la derecha. Hay una relación negativa entre FIRMCOST y SIZELOG, aunque no lineal." width="80%" />
<p class="caption">
Figura 6.6: <strong>Histogramas y gráficos de dispersión de FIRMCOST y varias variables explicativas.</strong> Las distribuciones de FIRMCOST y ASSUME están fuertemente sesgadas hacia la derecha. Hay una relación negativa entre FIRMCOST y SIZELOG, aunque no lineal.
</p>
</div>
<h5 style="text-align: center;">
<a id="displayCode.Tab63.Hide" href="javascript:togglecode('toggleCode.Tab63.Hide','displayCode.Tab63.Hide');"><i><strong>Código R para producir las Tablas 6.3 y 6.4 y la Figura 6.6</strong></i></a>
</h5>
<div id="toggleCode.Tab63.Hide" style="display: none">
<div class="sourceCode" id="cb56"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb56-1"><a href="interpretación-de-resultados-de-regresión.html#cb56-1" tabindex="-1"></a><span class="co">#  TABLA 6.3 ESTADÍSTICAS RESUMEN</span></span>
<span id="cb56-2"><a href="interpretación-de-resultados-de-regresión.html#cb56-2" tabindex="-1"></a>BookSummStats <span class="ot">&lt;-</span> <span class="cf">function</span>(Xymat){</span>
<span id="cb56-3"><a href="interpretación-de-resultados-de-regresión.html#cb56-3" tabindex="-1"></a>meanSummary <span class="ot">&lt;-</span> <span class="fu">sapply</span>(Xymat, mean,  <span class="at">na.rm=</span><span class="cn">TRUE</span>) </span>
<span id="cb56-4"><a href="interpretación-de-resultados-de-regresión.html#cb56-4" tabindex="-1"></a>sdSummary   <span class="ot">&lt;-</span> <span class="fu">sapply</span>(Xymat, sd,    <span class="at">na.rm=</span><span class="cn">TRUE</span>) </span>
<span id="cb56-5"><a href="interpretación-de-resultados-de-regresión.html#cb56-5" tabindex="-1"></a>minSummary  <span class="ot">&lt;-</span> <span class="fu">sapply</span>(Xymat, min,   <span class="at">na.rm=</span><span class="cn">TRUE</span>) </span>
<span id="cb56-6"><a href="interpretación-de-resultados-de-regresión.html#cb56-6" tabindex="-1"></a>maxSummary  <span class="ot">&lt;-</span> <span class="fu">sapply</span>(Xymat, max,   <span class="at">na.rm=</span><span class="cn">TRUE</span>) </span>
<span id="cb56-7"><a href="interpretación-de-resultados-de-regresión.html#cb56-7" tabindex="-1"></a>medSummary  <span class="ot">&lt;-</span> <span class="fu">sapply</span>(Xymat, median,<span class="at">na.rm=</span><span class="cn">TRUE</span>) </span>
<span id="cb56-8"><a href="interpretación-de-resultados-de-regresión.html#cb56-8" tabindex="-1"></a>tableMat  <span class="ot">&lt;-</span> <span class="fu">cbind</span>(meanSummary, medSummary, sdSummary, minSummary, maxSummary)</span>
<span id="cb56-9"><a href="interpretación-de-resultados-de-regresión.html#cb56-9" tabindex="-1"></a><span class="fu">return</span>(tableMat)</span>
<span id="cb56-10"><a href="interpretación-de-resultados-de-regresión.html#cb56-10" tabindex="-1"></a>}</span>
<span id="cb56-11"><a href="interpretación-de-resultados-de-regresión.html#cb56-11" tabindex="-1"></a>tableMat  <span class="ot">&lt;-</span> <span class="fu">BookSummStats</span>(survey1)</span>
<span id="cb56-12"><a href="interpretación-de-resultados-de-regresión.html#cb56-12" tabindex="-1"></a><span class="fu">colnames</span>(tableMat)  <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="st">&quot;Media&quot;</span>, <span class="st">&quot;Mediana&quot;</span>, <span class="st">&quot;Desviación Estándar&quot;</span>, </span>
<span id="cb56-13"><a href="interpretación-de-resultados-de-regresión.html#cb56-13" tabindex="-1"></a>                         <span class="st">&quot;Mínimo&quot;</span>, <span class="st">&quot;Máximo&quot;</span>)</span>
<span id="cb56-14"><a href="interpretación-de-resultados-de-regresión.html#cb56-14" tabindex="-1"></a><span class="fu">rownames</span>(tableMat)  <span class="ot">&lt;-</span> varSurvey</span>
<span id="cb56-15"><a href="interpretación-de-resultados-de-regresión.html#cb56-15" tabindex="-1"></a><span class="fu">TableGen1</span>(<span class="at">TableData=</span>tableMat, </span>
<span id="cb56-16"><a href="interpretación-de-resultados-de-regresión.html#cb56-16" tabindex="-1"></a>         <span class="at">TextTitle=</span><span class="st">&#39;Estadísticas Resumen de $n=73$ Encuestas sobre Gestión de Riesgos&#39;</span>, </span>
<span id="cb56-17"><a href="interpretación-de-resultados-de-regresión.html#cb56-17" tabindex="-1"></a>         <span class="at">Align=</span><span class="st">&#39;r&#39;</span>, <span class="at">Digits=</span><span class="dv">3</span>, <span class="at">ColumnSpec=</span><span class="dv">1</span><span class="sc">:</span><span class="dv">5</span>,</span>
<span id="cb56-18"><a href="interpretación-de-resultados-de-regresión.html#cb56-18" tabindex="-1"></a>         <span class="at">ColWidth =</span> ColWidth5)</span></code></pre></div>
<div class="sourceCode" id="cb57"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb57-1"><a href="interpretación-de-resultados-de-regresión.html#cb57-1" tabindex="-1"></a><span class="co"># Tabla 6.4</span></span>
<span id="cb57-2"><a href="interpretación-de-resultados-de-regresión.html#cb57-2" tabindex="-1"></a>varSum <span class="ot">&lt;-</span><span class="cf">function</span>(var){</span>
<span id="cb57-3"><a href="interpretación-de-resultados-de-regresión.html#cb57-3" tabindex="-1"></a>   rows12 <span class="ot">&lt;-</span> Hmisc<span class="sc">::</span><span class="fu">summarize</span>(var, survey1<span class="sc">$</span>CAP, mean )[[<span class="dv">2</span>]]</span>
<span id="cb57-4"><a href="interpretación-de-resultados-de-regresión.html#cb57-4" tabindex="-1"></a>   row3 <span class="ot">&lt;-</span> <span class="fu">mean</span>(var)  </span>
<span id="cb57-5"><a href="interpretación-de-resultados-de-regresión.html#cb57-5" tabindex="-1"></a>   <span class="fu">return</span>( <span class="fu">c</span>(rows12, row3) )</span>
<span id="cb57-6"><a href="interpretación-de-resultados-de-regresión.html#cb57-6" tabindex="-1"></a>   }</span>
<span id="cb57-7"><a href="interpretación-de-resultados-de-regresión.html#cb57-7" tabindex="-1"></a>tableout1 <span class="ot">&lt;-</span> <span class="fu">cbind</span>(</span>
<span id="cb57-8"><a href="interpretación-de-resultados-de-regresión.html#cb57-8" tabindex="-1"></a>  <span class="fu">varSum</span>(survey[,<span class="dv">1</span>]),  <span class="fu">varSum</span>(survey[,<span class="dv">2</span>]),</span>
<span id="cb57-9"><a href="interpretación-de-resultados-de-regresión.html#cb57-9" tabindex="-1"></a>  <span class="fu">varSum</span>(survey[,<span class="dv">4</span>]),  <span class="fu">varSum</span>(survey[,<span class="dv">5</span>]),</span>
<span id="cb57-10"><a href="interpretación-de-resultados-de-regresión.html#cb57-10" tabindex="-1"></a>  <span class="fu">varSum</span>(survey[,<span class="dv">6</span>]),  <span class="fu">varSum</span>(survey[,<span class="dv">7</span>]),</span>
<span id="cb57-11"><a href="interpretación-de-resultados-de-regresión.html#cb57-11" tabindex="-1"></a>  <span class="fu">varSum</span>(<span class="fu">log</span>(survey[,<span class="dv">1</span>])) )</span>
<span id="cb57-12"><a href="interpretación-de-resultados-de-regresión.html#cb57-12" tabindex="-1"></a>num.cap <span class="ot">&lt;-</span> <span class="fu">c</span>(Hmisc<span class="sc">::</span><span class="fu">summarize</span>(survey[,<span class="dv">1</span>], survey1<span class="sc">$</span>CAP, length )[[<span class="dv">2</span>]] ,</span>
<span id="cb57-13"><a href="interpretación-de-resultados-de-regresión.html#cb57-13" tabindex="-1"></a>             <span class="fu">length</span>(survey[,<span class="dv">1</span>])  )</span>
<span id="cb57-14"><a href="interpretación-de-resultados-de-regresión.html#cb57-14" tabindex="-1"></a>tableout <span class="ot">&lt;-</span> <span class="fu">cbind</span>(num.cap, tableout1)   </span>
<span id="cb57-15"><a href="interpretación-de-resultados-de-regresión.html#cb57-15" tabindex="-1"></a><span class="fu">colnames</span>(tableout) <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="st">&quot;$n$&quot;</span>,</span>
<span id="cb57-16"><a href="interpretación-de-resultados-de-regresión.html#cb57-16" tabindex="-1"></a>  <span class="st">&quot;FIRMCOST&quot;</span>,<span class="st">&quot;ASSUME&quot;</span>,<span class="st">&quot;SIZELOG&quot;</span>,<span class="st">&quot;INDCOST&quot;</span>,<span class="st">&quot;CENTRAL&quot;</span>,<span class="st">&quot;SOPH&quot;</span>,<span class="st">&quot;COSTLOG&quot;</span>)</span>
<span id="cb57-17"><a href="interpretación-de-resultados-de-regresión.html#cb57-17" tabindex="-1"></a><span class="fu">rownames</span>(tableout) <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="st">&quot;CAP = 0&quot;</span>, <span class="st">&quot;CAP = 1&quot;</span>, <span class="st">&quot;TOTAL&quot;</span>)</span>
<span id="cb57-18"><a href="interpretación-de-resultados-de-regresión.html#cb57-18" tabindex="-1"></a></span>
<span id="cb57-19"><a href="interpretación-de-resultados-de-regresión.html#cb57-19" tabindex="-1"></a><span class="fu">TableGen1</span>(<span class="at">TableData=</span>tableout , </span>
<span id="cb57-20"><a href="interpretación-de-resultados-de-regresión.html#cb57-20" tabindex="-1"></a>         <span class="at">TextTitle=</span><span class="st">&#39;Tabla de Medias por Nivel de CAP&#39;</span>, </span>
<span id="cb57-21"><a href="interpretación-de-resultados-de-regresión.html#cb57-21" tabindex="-1"></a>         <span class="at">Align=</span><span class="st">&#39;r&#39;</span>,  <span class="at">ColumnSpec=</span><span class="dv">1</span><span class="sc">:</span><span class="dv">7</span>, <span class="at">Digits =</span> <span class="dv">3</span>)</span></code></pre></div>
<div class="sourceCode" id="cb58"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb58-1"><a href="interpretación-de-resultados-de-regresión.html#cb58-1" tabindex="-1"></a><span class="co">#  FIGURA 6.6</span></span>
<span id="cb58-2"><a href="interpretación-de-resultados-de-regresión.html#cb58-2" tabindex="-1"></a><span class="fu">layout</span>(<span class="fu">matrix</span>(<span class="fu">c</span>(<span class="dv">1</span>,<span class="dv">2</span>,<span class="dv">3</span>,<span class="dv">4</span>,<span class="dv">5</span>,<span class="dv">6</span>,<span class="dv">7</span>,<span class="dv">8</span>,<span class="dv">9</span>,<span class="dv">10</span>,<span class="dv">11</span>,<span class="dv">12</span>),<span class="at">byrow=</span><span class="cn">TRUE</span>,<span class="at">ncol=</span><span class="dv">6</span>))</span>
<span id="cb58-3"><a href="interpretación-de-resultados-de-regresión.html#cb58-3" tabindex="-1"></a><span class="fu">par</span>(<span class="st">&quot;oma&quot;</span><span class="ot">=</span><span class="fu">c</span>(<span class="dv">3</span>,<span class="dv">3</span>,<span class="dv">3</span>,<span class="dv">3</span>),<span class="st">&quot;mai&quot;</span><span class="ot">=</span><span class="fu">c</span>(<span class="dv">0</span>,<span class="dv">0</span>,<span class="fl">0.1</span>,<span class="dv">0</span>))</span>
<span id="cb58-4"><a href="interpretación-de-resultados-de-regresión.html#cb58-4" tabindex="-1"></a></span>
<span id="cb58-5"><a href="interpretación-de-resultados-de-regresión.html#cb58-5" tabindex="-1"></a><span class="fu">plot.new</span>()</span>
<span id="cb58-6"><a href="interpretación-de-resultados-de-regresión.html#cb58-6" tabindex="-1"></a><span class="fu">hist</span>(survey1<span class="sc">$</span>ASSUME,<span class="at">breaks=</span><span class="dv">18</span>,<span class="at">main=</span><span class="st">&quot;ASSUME&quot;</span>,<span class="at">xaxt=</span><span class="st">&quot;n&quot;</span>,<span class="at">yaxt=</span><span class="st">&quot;n&quot;</span>,<span class="at">xlab=</span><span class="st">&quot;&quot;</span>,<span class="at">ylab=</span><span class="st">&quot;&quot;</span>)</span>
<span id="cb58-7"><a href="interpretación-de-resultados-de-regresión.html#cb58-7" tabindex="-1"></a><span class="fu">hist</span>(survey1<span class="sc">$</span>SIZELOG,<span class="at">breaks=</span><span class="dv">18</span>,<span class="at">main=</span><span class="st">&quot;SIZELOG&quot;</span>,<span class="at">xaxt=</span><span class="st">&quot;n&quot;</span>,<span class="at">yaxt=</span><span class="st">&quot;n&quot;</span>,<span class="at">xlab=</span><span class="st">&quot;&quot;</span>,<span class="at">ylab=</span><span class="st">&quot;&quot;</span>)</span>
<span id="cb58-8"><a href="interpretación-de-resultados-de-regresión.html#cb58-8" tabindex="-1"></a><span class="fu">hist</span>(survey1<span class="sc">$</span>INDCOST,<span class="at">breaks=</span><span class="dv">18</span>,<span class="at">main=</span><span class="st">&quot;INDCOST&quot;</span>,<span class="at">xaxt=</span><span class="st">&quot;n&quot;</span>,<span class="at">yaxt=</span><span class="st">&quot;n&quot;</span>,<span class="at">xlab=</span><span class="st">&quot;&quot;</span>,<span class="at">ylab=</span><span class="st">&quot;&quot;</span>)</span>
<span id="cb58-9"><a href="interpretación-de-resultados-de-regresión.html#cb58-9" tabindex="-1"></a><span class="fu">hist</span>(survey1<span class="sc">$</span>CENTRAL,<span class="at">breaks=</span><span class="dv">18</span>,<span class="at">main=</span><span class="st">&quot;CENTRAL&quot;</span>,<span class="at">xaxt=</span><span class="st">&quot;n&quot;</span>,<span class="at">yaxt=</span><span class="st">&quot;n&quot;</span>,<span class="at">xlab=</span><span class="st">&quot;&quot;</span>,<span class="at">ylab=</span><span class="st">&quot;&quot;</span>)</span>
<span id="cb58-10"><a href="interpretación-de-resultados-de-regresión.html#cb58-10" tabindex="-1"></a><span class="fu">hist</span>(survey1<span class="sc">$</span>SOPH,<span class="at">breaks=</span><span class="dv">18</span>,<span class="at">main=</span><span class="st">&quot;SOPH&quot;</span>,<span class="at">xaxt=</span><span class="st">&quot;n&quot;</span>,<span class="at">yaxt=</span><span class="st">&quot;n&quot;</span>,<span class="at">xlab=</span><span class="st">&quot;&quot;</span>,<span class="at">ylab=</span><span class="st">&quot;&quot;</span>)</span>
<span id="cb58-11"><a href="interpretación-de-resultados-de-regresión.html#cb58-11" tabindex="-1"></a><span class="fu">hist</span>(survey1<span class="sc">$</span>FIRMCOST,<span class="at">breaks=</span><span class="dv">18</span>,<span class="at">main=</span><span class="st">&quot;FIRMCOST&quot;</span>,<span class="at">xaxt=</span><span class="st">&quot;n&quot;</span>,<span class="at">yaxt=</span><span class="st">&quot;n&quot;</span>,<span class="at">xlab=</span><span class="st">&quot;&quot;</span>,<span class="at">ylab=</span><span class="st">&quot;&quot;</span>)</span>
<span id="cb58-12"><a href="interpretación-de-resultados-de-regresión.html#cb58-12" tabindex="-1"></a></span>
<span id="cb58-13"><a href="interpretación-de-resultados-de-regresión.html#cb58-13" tabindex="-1"></a><span class="fu">plot</span>(survey1<span class="sc">$</span>ASSUME,survey1<span class="sc">$</span>FIRMCOST,<span class="at">xaxt=</span><span class="st">&quot;n&quot;</span>,<span class="at">yaxt=</span><span class="st">&quot;n&quot;</span>,<span class="at">xlab=</span><span class="st">&quot;&quot;</span>,<span class="at">ylab=</span><span class="st">&quot;&quot;</span>)</span>
<span id="cb58-14"><a href="interpretación-de-resultados-de-regresión.html#cb58-14" tabindex="-1"></a><span class="fu">plot</span>(survey1<span class="sc">$</span>SIZELOG,survey1<span class="sc">$</span>FIRMCOST,<span class="at">xaxt=</span><span class="st">&quot;n&quot;</span>,<span class="at">yaxt=</span><span class="st">&quot;n&quot;</span>,<span class="at">xlab=</span><span class="st">&quot;&quot;</span>,<span class="at">ylab=</span><span class="st">&quot;&quot;</span>)</span>
<span id="cb58-15"><a href="interpretación-de-resultados-de-regresión.html#cb58-15" tabindex="-1"></a><span class="fu">plot</span>(survey1<span class="sc">$</span>INDCOST,survey1<span class="sc">$</span>FIRMCOST,<span class="at">xaxt=</span><span class="st">&quot;n&quot;</span>,<span class="at">yaxt=</span><span class="st">&quot;n&quot;</span>,<span class="at">xlab=</span><span class="st">&quot;&quot;</span>,<span class="at">ylab=</span><span class="st">&quot;&quot;</span>)</span>
<span id="cb58-16"><a href="interpretación-de-resultados-de-regresión.html#cb58-16" tabindex="-1"></a><span class="fu">plot</span>(survey1<span class="sc">$</span>CENTRAL,survey1<span class="sc">$</span>FIRMCOST,<span class="at">xaxt=</span><span class="st">&quot;n&quot;</span>,<span class="at">yaxt=</span><span class="st">&quot;n&quot;</span>,<span class="at">xlab=</span><span class="st">&quot;&quot;</span>,<span class="at">ylab=</span><span class="st">&quot;&quot;</span>)</span>
<span id="cb58-17"><a href="interpretación-de-resultados-de-regresión.html#cb58-17" tabindex="-1"></a><span class="fu">plot</span>(survey1<span class="sc">$</span>SOPH,survey1<span class="sc">$</span>FIRMCOST,<span class="at">xaxt=</span><span class="st">&quot;n&quot;</span>,<span class="at">yaxt=</span><span class="st">&quot;n&quot;</span>,<span class="at">xlab=</span><span class="st">&quot;&quot;</span>,<span class="at">ylab=</span><span class="st">&quot;&quot;</span>)</span></code></pre></div>
</div>
<p>Al examinar las relaciones entre pares de variables, en la Figura <a href="interpretación-de-resultados-de-regresión.html#fig:Fig66">6.6</a> observamos algunas de las relaciones que fueron evidentes en el ajuste preliminar de la regresión. Hay una relación inversa entre FIRMCOST y SIZELOG, y el gráfico de dispersión sugiere que esta relación podría ser no lineal. También hay una relación positiva leve entre FIRMCOST e INDCOST y no se observan relaciones aparentes entre FIRMCOST y ninguna de las otras variables explicativas. Estas observaciones se refuerzan con la tabla de correlaciones dada en la Tabla <a href="interpretación-de-resultados-de-regresión.html#tab:Tab64">6.4</a>. Nota que la tabla oculta una característica que es evidente en los gráficos de dispersión: el efecto de las observaciones inusualmente grandes.</p>
<table class=" lightable-classic table table-striped table-condensed" style="font-size: 12px; font-family: Cambria; width: auto !important; margin-left: auto; margin-right: auto; margin-left: auto; margin-right: auto;">
<caption style="font-size: initial !important;">
<span id="tab:Tab65">Tabla 6.5: </span><strong>Matriz de Correlaciones</strong>
</caption>
<thead>
<tr>
<th style="text-align:left;">
</th>
<th style="text-align:right;">
COSTLOG
</th>
<th style="text-align:right;">
FIRMCOST
</th>
<th style="text-align:right;">
ASSUME
</th>
<th style="text-align:right;">
CAP
</th>
<th style="text-align:right;">
SIZELOG
</th>
<th style="text-align:right;">
INDCOST
</th>
<th style="text-align:right;">
CENTRAL
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;width: 2.5cm; border-right:1px solid;">
FIRMCOST
</td>
<td style="text-align:right;width: 1.6cm; ">
0.713
</td>
<td style="text-align:right;width: 1.6cm; ">
</td>
<td style="text-align:right;width: 1.6cm; ">
</td>
<td style="text-align:right;">
</td>
<td style="text-align:right;">
</td>
<td style="text-align:right;">
</td>
<td style="text-align:right;">
</td>
</tr>
<tr>
<td style="text-align:left;width: 2.5cm; border-right:1px solid;">
ASSUME
</td>
<td style="text-align:right;width: 1.6cm; ">
0.165
</td>
<td style="text-align:right;width: 1.6cm; ">
0.039
</td>
<td style="text-align:right;width: 1.6cm; ">
</td>
<td style="text-align:right;">
</td>
<td style="text-align:right;">
</td>
<td style="text-align:right;">
</td>
<td style="text-align:right;">
</td>
</tr>
<tr>
<td style="text-align:left;width: 2.5cm; border-right:1px solid;">
CAP
</td>
<td style="text-align:right;width: 1.6cm; ">
-0.088
</td>
<td style="text-align:right;width: 1.6cm; ">
0.088
</td>
<td style="text-align:right;width: 1.6cm; ">
0.231
</td>
<td style="text-align:right;">
</td>
<td style="text-align:right;">
</td>
<td style="text-align:right;">
</td>
<td style="text-align:right;">
</td>
</tr>
<tr>
<td style="text-align:left;width: 2.5cm; border-right:1px solid;">
SIZELOG
</td>
<td style="text-align:right;width: 1.6cm; ">
-0.637
</td>
<td style="text-align:right;width: 1.6cm; ">
-0.366
</td>
<td style="text-align:right;width: 1.6cm; ">
-0.209
</td>
<td style="text-align:right;">
0.196
</td>
<td style="text-align:right;">
</td>
<td style="text-align:right;">
</td>
<td style="text-align:right;">
</td>
</tr>
<tr>
<td style="text-align:left;width: 2.5cm; border-right:1px solid;">
INDCOST
</td>
<td style="text-align:right;width: 1.6cm; ">
0.395
</td>
<td style="text-align:right;width: 1.6cm; ">
0.326
</td>
<td style="text-align:right;width: 1.6cm; ">
0.249
</td>
<td style="text-align:right;">
0.122
</td>
<td style="text-align:right;">
-0.102
</td>
<td style="text-align:right;">
</td>
<td style="text-align:right;">
</td>
</tr>
<tr>
<td style="text-align:left;width: 2.5cm; border-right:1px solid;">
CENTRAL
</td>
<td style="text-align:right;width: 1.6cm; ">
-0.054
</td>
<td style="text-align:right;width: 1.6cm; ">
0.014
</td>
<td style="text-align:right;width: 1.6cm; ">
-0.068
</td>
<td style="text-align:right;">
-0.004
</td>
<td style="text-align:right;">
-0.08
</td>
<td style="text-align:right;">
-0.085
</td>
<td style="text-align:right;">
</td>
</tr>
<tr>
<td style="text-align:left;width: 2.5cm; border-right:1px solid;">
SOPH
</td>
<td style="text-align:right;width: 1.6cm; ">
0.144
</td>
<td style="text-align:right;width: 1.6cm; ">
0.048
</td>
<td style="text-align:right;width: 1.6cm; ">
0.062
</td>
<td style="text-align:right;">
-0.087
</td>
<td style="text-align:right;">
-0.209
</td>
<td style="text-align:right;">
0.093
</td>
<td style="text-align:right;">
0.283
</td>
</tr>
</tbody>
</table>
<p>Debido al sesgo de la distribución y al efecto de las observaciones inusualmente grandes, una transformación de la variable de respuesta podría llevar a resultados más útiles. La Figura <a href="interpretación-de-resultados-de-regresión.html#fig:Fig67">6.7</a> muestra el histograma de COSTLOG, definido como el logaritmo de FIRMCOST. La distribución es mucho menos sesgada que la distribución de FIRMCOST. La variable COSTLOG también se incluyó en la matriz de correlaciones en la Tabla <a href="interpretación-de-resultados-de-regresión.html#tab:Tab64">6.4</a>. A partir de esta tabla, la relación entre SIZELOG parece ser más fuerte con COSTLOG que con FIRMCOST. La Figura <a href="interpretación-de-resultados-de-regresión.html#fig:Fig68">6.8</a> muestra varios gráficos de dispersión que ilustran la relación entre COSTLOG y las variables explicativas. La relación entre COSTLOG y SIZELOG parece ser lineal. Es más fácil interpretar estos gráficos de dispersión que los de la Figura <a href="interpretación-de-resultados-de-regresión.html#fig:Fig66">6.6</a> debido a la ausencia de los grandes valores inusuales de la variable dependiente.</p>

<div class="figure" style="text-align: center"><span style="display:block;" id="fig:Fig67"></span>
<img src="RegressionMarkdown_files/figure-html/Fig67-1.png" alt="Histograma de COSTLOG (el logaritmo natural de FIRMCOST). La distribución de COSTLOG es menos sesgada que la de FIRMCOST." width="60%" />
<p class="caption">
Figura 6.7: <strong>Histograma de COSTLOG (el logaritmo natural de FIRMCOST).</strong> La distribución de COSTLOG es menos sesgada que la de FIRMCOST.
</p>
</div>

<div class="figure" style="text-align: center"><span style="display:block;" id="fig:Fig68"></span>
<img src="RegressionMarkdown_files/figure-html/Fig68-1.png" alt="Gráficos de dispersión de COSTLOG versus varias variables explicativas. Hay una relación negativa entre COSTLOG y SIZELOG y una relación positiva leve entre COSTLOG e INDCOST." width="60%" />
<p class="caption">
Figura 6.8: <strong>Gráficos de dispersión de COSTLOG versus varias variables explicativas.</strong> Hay una relación negativa entre COSTLOG y SIZELOG y una relación positiva leve entre COSTLOG e INDCOST.
</p>
</div>
<h5 style="text-align: center;">
<a id="displayCode.Tab65.Hide" href="javascript:togglecode('toggleCode.Tab65.Hide','displayCode.Tab65.Hide');"><i><strong>Código R para producir la Tabla 6.5 y las Figuras 6.7 y 6.8</strong></i></a>
</h5>
<div id="toggleCode.Tab65.Hide" style="display: none">
<div class="sourceCode" id="cb59"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb59-1"><a href="interpretación-de-resultados-de-regresión.html#cb59-1" tabindex="-1"></a><span class="co"># Tabla 6.5</span></span>
<span id="cb59-2"><a href="interpretación-de-resultados-de-regresión.html#cb59-2" tabindex="-1"></a>survey2 <span class="ot">&lt;-</span> <span class="fu">cbind</span>(<span class="fu">log</span>(survey1[,<span class="dv">1</span>]), survey1)</span>
<span id="cb59-3"><a href="interpretación-de-resultados-de-regresión.html#cb59-3" tabindex="-1"></a><span class="fu">names</span>(survey2) <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="st">&quot;COSTLOG&quot;</span>, varSurvey)</span>
<span id="cb59-4"><a href="interpretación-de-resultados-de-regresión.html#cb59-4" tabindex="-1"></a>tableCor <span class="ot">&lt;-</span> <span class="fu">cor</span>(survey2)</span>
<span id="cb59-5"><a href="interpretación-de-resultados-de-regresión.html#cb59-5" tabindex="-1"></a>tableCor <span class="ot">&lt;-</span> <span class="fu">round</span>(tableCor, <span class="at">digits =</span> <span class="dv">3</span>)</span>
<span id="cb59-6"><a href="interpretación-de-resultados-de-regresión.html#cb59-6" tabindex="-1"></a>tableCor[<span class="fu">upper.tri</span>(tableCor, <span class="at">diag =</span> <span class="cn">TRUE</span>)] <span class="ot">&lt;-</span> <span class="st">&quot;&quot;</span></span>
<span id="cb59-7"><a href="interpretación-de-resultados-de-regresión.html#cb59-7" tabindex="-1"></a>tablePrint <span class="ot">&lt;-</span> tableCor[<span class="sc">-</span><span class="dv">1</span>,]</span>
<span id="cb59-8"><a href="interpretación-de-resultados-de-regresión.html#cb59-8" tabindex="-1"></a>tablePrint <span class="ot">&lt;-</span> tablePrint[,<span class="sc">-</span><span class="dv">8</span>]</span>
<span id="cb59-9"><a href="interpretación-de-resultados-de-regresión.html#cb59-9" tabindex="-1"></a><span class="fu">TableGen1</span>(<span class="at">TableData=</span>tablePrint, </span>
<span id="cb59-10"><a href="interpretación-de-resultados-de-regresión.html#cb59-10" tabindex="-1"></a>         <span class="at">TextTitle=</span><span class="st">&#39;Matriz de Correlaciones&#39;</span>, </span>
<span id="cb59-11"><a href="interpretación-de-resultados-de-regresión.html#cb59-11" tabindex="-1"></a>         <span class="at">Align=</span><span class="st">&#39;r&#39;</span>, <span class="at">Digits=</span><span class="dv">3</span>, <span class="at">ColumnSpec=</span><span class="dv">1</span><span class="sc">:</span><span class="dv">3</span>,</span>
<span id="cb59-12"><a href="interpretación-de-resultados-de-regresión.html#cb59-12" tabindex="-1"></a>         <span class="at">ColWidth =</span> ColWidth5)</span></code></pre></div>
<div class="sourceCode" id="cb60"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb60-1"><a href="interpretación-de-resultados-de-regresión.html#cb60-1" tabindex="-1"></a><span class="co">#  FIGURA 6.7</span></span>
<span id="cb60-2"><a href="interpretación-de-resultados-de-regresión.html#cb60-2" tabindex="-1"></a>COSTLOG <span class="ot">&lt;-</span> <span class="fu">log</span>(survey1<span class="sc">$</span>FIRMCOST)</span>
<span id="cb60-3"><a href="interpretación-de-resultados-de-regresión.html#cb60-3" tabindex="-1"></a></span>
<span id="cb60-4"><a href="interpretación-de-resultados-de-regresión.html#cb60-4" tabindex="-1"></a><span class="fu">par</span>(<span class="at">mar=</span><span class="fu">c</span>(<span class="dv">4</span>,<span class="fl">4.4</span>,.<span class="dv">2</span>,.<span class="dv">2</span>))</span>
<span id="cb60-5"><a href="interpretación-de-resultados-de-regresión.html#cb60-5" tabindex="-1"></a><span class="fu">hist</span>(COSTLOG, <span class="at">nclass=</span><span class="dv">16</span>, <span class="at">main=</span><span class="st">&quot;&quot;</span>, <span class="at">xlab=</span><span class="st">&quot;COSTLOG&quot;</span>,<span class="at">las=</span><span class="dv">1</span>,<span class="at">cex.lab=</span><span class="dv">2</span>)</span></code></pre></div>
<div class="sourceCode" id="cb61"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb61-1"><a href="interpretación-de-resultados-de-regresión.html#cb61-1" tabindex="-1"></a><span class="co">#  FIGURA 6.8</span></span>
<span id="cb61-2"><a href="interpretación-de-resultados-de-regresión.html#cb61-2" tabindex="-1"></a><span class="fu">layout</span>(<span class="fu">matrix</span>(<span class="fu">c</span>(<span class="dv">1</span>,<span class="dv">2</span>,<span class="dv">3</span>,<span class="dv">4</span>,<span class="dv">5</span>),<span class="at">byrow=</span><span class="cn">TRUE</span>,<span class="at">ncol=</span><span class="dv">5</span>))</span>
<span id="cb61-3"><a href="interpretación-de-resultados-de-regresión.html#cb61-3" tabindex="-1"></a><span class="fu">par</span>(<span class="st">&quot;oma&quot;</span><span class="ot">=</span><span class="fu">c</span>(<span class="dv">3</span>,<span class="dv">5</span>,<span class="dv">3</span>,<span class="dv">3</span>),<span class="st">&quot;mai&quot;</span><span class="ot">=</span><span class="fu">c</span>(<span class="dv">0</span>,<span class="dv">0</span>,<span class="fl">0.2</span>,<span class="dv">0</span>))</span>
<span id="cb61-4"><a href="interpretación-de-resultados-de-regresión.html#cb61-4" tabindex="-1"></a><span class="fu">plot</span>(survey1<span class="sc">$</span>ASSUME,COSTLOG,<span class="at">main=</span><span class="st">&quot;ASSUME&quot;</span>,  <span class="at">xaxt=</span><span class="st">&quot;n&quot;</span>,<span class="at">yaxt=</span><span class="st">&quot;n&quot;</span>,<span class="at">xlab=</span><span class="st">&quot;&quot;</span>,<span class="at">ylab=</span><span class="st">&quot;&quot;</span>,<span class="at">las=</span><span class="dv">1</span>)</span>
<span id="cb61-5"><a href="interpretación-de-resultados-de-regresión.html#cb61-5" tabindex="-1"></a><span class="fu">plot</span>(survey1<span class="sc">$</span>SIZELOG,COSTLOG,<span class="at">main=</span><span class="st">&quot;SIZELOG&quot;</span>,<span class="at">xaxt=</span><span class="st">&quot;n&quot;</span>,<span class="at">yaxt=</span><span class="st">&quot;n&quot;</span>,<span class="at">xlab=</span><span class="st">&quot;&quot;</span>,<span class="at">ylab=</span><span class="st">&quot;&quot;</span>)</span>
<span id="cb61-6"><a href="interpretación-de-resultados-de-regresión.html#cb61-6" tabindex="-1"></a><span class="fu">plot</span>(survey1<span class="sc">$</span>INDCOST,COSTLOG,<span class="at">main=</span><span class="st">&quot;INDCOST&quot;</span>,<span class="at">xaxt=</span><span class="st">&quot;n&quot;</span>,<span class="at">yaxt=</span><span class="st">&quot;n&quot;</span>,<span class="at">xlab=</span><span class="st">&quot;&quot;</span>,<span class="at">ylab=</span><span class="st">&quot;&quot;</span>)</span>
<span id="cb61-7"><a href="interpretación-de-resultados-de-regresión.html#cb61-7" tabindex="-1"></a><span class="fu">plot</span>(survey1<span class="sc">$</span>CENTRAL,COSTLOG,<span class="at">main=</span><span class="st">&quot;CENTRAL&quot;</span>,<span class="at">xaxt=</span><span class="st">&quot;n&quot;</span>,<span class="at">yaxt=</span><span class="st">&quot;n&quot;</span>,<span class="at">xlab=</span><span class="st">&quot;&quot;</span>,<span class="at">ylab=</span><span class="st">&quot;&quot;</span>)</span>
<span id="cb61-8"><a href="interpretación-de-resultados-de-regresión.html#cb61-8" tabindex="-1"></a><span class="fu">plot</span>(survey1<span class="sc">$</span>SOPH,COSTLOG,   <span class="at">main=</span><span class="st">&quot;SOPH&quot;</span>,   <span class="at">xaxt=</span><span class="st">&quot;n&quot;</span>,<span class="at">yaxt=</span><span class="st">&quot;n&quot;</span>,<span class="at">xlab=</span><span class="st">&quot;&quot;</span>,<span class="at">ylab=</span><span class="st">&quot;&quot;</span>)</span></code></pre></div>
</div>
</div>
<div id="algunos-modelos-nuevos" class="section level4 unnumbered hasAnchor">
<h4>Algunos Modelos Nuevos<a href="interpretación-de-resultados-de-regresión.html#algunos-modelos-nuevos" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>Ahora, exploramos el uso de COSTLOG como la variable dependiente. Este enfoque se basa en el trabajo de la subsección anterior y en los gráficos de residuos del ajuste preliminar de la regresión. Como primer paso, ajustamos un modelo con todas las variables explicativas. Por lo tanto, este modelo es el mismo que el ajuste preliminar de la regresión, excepto que usa COSTLOG en lugar de FIRMCOST como la variable dependiente. Este modelo sirve como un punto de referencia útil para nuestro trabajo posterior. La Tabla <a href="interpretación-de-resultados-de-regresión.html#tab:Tab66">6.6</a> resume el ajuste.</p>
<table class=" lightable-classic table table-striped table-condensed" style="font-size: 12px; font-family: Cambria; width: auto !important; margin-left: auto; margin-right: auto; margin-left: auto; margin-right: auto;">
<caption style="font-size: initial !important;">
<span id="tab:Tab66">Tabla 6.6: </span><strong>Resultados de la Regresión: COSTLOG como Variable Dependiente</strong>
</caption>
<thead>
<tr>
<th style="text-align:left;">
</th>
<th style="text-align:right;">
Coeficiente
</th>
<th style="text-align:right;">
Error Estándar
</th>
<th style="text-align:right;">
<span class="math inline">\(t\)</span>-Estadístico
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;width: 2.5cm; border-right:1px solid;">
(Intercept)
</td>
<td style="text-align:right;width: 3cm; ">
7.643
</td>
<td style="text-align:right;width: 3cm; ">
1.155
</td>
<td style="text-align:right;width: 3cm; ">
6.617
</td>
</tr>
<tr>
<td style="text-align:left;width: 2.5cm; border-right:1px solid;">
ASSUME
</td>
<td style="text-align:right;width: 3cm; ">
-0.008
</td>
<td style="text-align:right;width: 3cm; ">
0.013
</td>
<td style="text-align:right;width: 3cm; ">
-0.609
</td>
</tr>
<tr>
<td style="text-align:left;width: 2.5cm; border-right:1px solid;">
CAP
</td>
<td style="text-align:right;width: 3cm; ">
0.015
</td>
<td style="text-align:right;width: 3cm; ">
0.233
</td>
<td style="text-align:right;width: 3cm; ">
0.064
</td>
</tr>
<tr>
<td style="text-align:left;width: 2.5cm; border-right:1px solid;">
SIZELOG
</td>
<td style="text-align:right;width: 3cm; ">
-0.787
</td>
<td style="text-align:right;width: 3cm; ">
0.116
</td>
<td style="text-align:right;width: 3cm; ">
-6.752
</td>
</tr>
<tr>
<td style="text-align:left;width: 2.5cm; border-right:1px solid;">
INDCOST
</td>
<td style="text-align:right;width: 3cm; ">
1.905
</td>
<td style="text-align:right;width: 3cm; ">
0.503
</td>
<td style="text-align:right;width: 3cm; ">
3.787
</td>
</tr>
<tr>
<td style="text-align:left;width: 2.5cm; border-right:1px solid;">
CENTRAL
</td>
<td style="text-align:right;width: 3cm; ">
-0.080
</td>
<td style="text-align:right;width: 3cm; ">
0.087
</td>
<td style="text-align:right;width: 3cm; ">
-0.916
</td>
</tr>
<tr>
<td style="text-align:left;width: 2.5cm; border-right:1px solid;">
SOPH
</td>
<td style="text-align:right;width: 3cm; ">
0.002
</td>
<td style="text-align:right;width: 3cm; ">
0.021
</td>
<td style="text-align:right;width: 3cm; ">
0.116
</td>
</tr>
</tbody>
</table>
<p>Aquí, <span class="math inline">\(R_{a}^{2}=48\%\)</span>, <span class="math inline">\(F\)</span>-ratio <span class="math inline">\(=12.1\)</span> y <span class="math inline">\(s=0.882\)</span>. La Figura <a href="interpretación-de-resultados-de-regresión.html#fig:Fig69">6.9</a> muestra que la distribución de los residuos estandarizados es menos sesgada que la correspondiente en la Figura <a href="interpretación-de-resultados-de-regresión.html#fig:Fig65">6.5</a>. La distribución de los apalancamientos muestra que todavía hay observaciones altamente influyentes. (De hecho, la distribución de los apalancamientos parece ser la misma que en la Figura <a href="interpretación-de-resultados-de-regresión.html#fig:Fig65">6.5</a>. ¿Por qué?) Cuatro de las seis variables tienen <span class="math inline">\(t\)</span>-ratios menores que uno en valor absoluto, lo que sugiere que debemos continuar buscando un mejor modelo.</p>

<div class="figure" style="text-align: center"><span style="display:block;" id="fig:Fig69"></span>
<img src="RegressionMarkdown_files/figure-html/Fig69-1.png" alt="Histogramas de residuos estandarizados y apalancamientos utilizando COSTLOG como la variable dependiente." width="60%" />
<p class="caption">
Figura 6.9: <strong>Histogramas de residuos estandarizados y apalancamientos utilizando COSTLOG como la variable dependiente.</strong>
</p>
</div>
<p>Para continuar con la búsqueda, se realizó una regresión por pasos (aunque la salida no se reproduce aquí). La salida de esta técnica de búsqueda, así como el modelo de regresión ajustado arriba, sugiere usar las variables SIZELOG e INDCOST para explicar la variable dependiente COSTLOG.</p>
<p>Podemos realizar una regresión usando SIZELOG e INDCOST como variables explicativas. En la Figura <a href="interpretación-de-resultados-de-regresión.html#fig:Fig610">6.10</a>, vemos que el tamaño y la forma de la distribución de los residuos estandarizados son similares a los de la Figura <a href="interpretación-de-resultados-de-regresión.html#fig:Fig69">6.9</a>. Los apalancamientos son mucho menores, lo que refleja la eliminación de varias variables explicativas del modelo. Recuerda que el apalancamiento promedio es <span class="math inline">\(\bar{h} =(k+1)/n=3/73\approx 0.04\)</span>. Así, todavía tenemos tres puntos que superan tres veces el promedio y, por lo tanto, se consideran puntos de alto apalancamiento.</p>

<div class="figure" style="text-align: center"><span style="display:block;" id="fig:Fig610"></span>
<img src="RegressionMarkdown_files/figure-html/Fig610-1.png" alt="Histogramas de residuos estandarizados y apalancamientos usando SIZELOG e INDCOST como variables explicativas." width="60%" />
<p class="caption">
Figura 6.10: <strong>Histogramas de residuos estandarizados y apalancamientos usando SIZELOG e INDCOST como variables explicativas.</strong>
</p>
</div>
<h5 style="text-align: center;">
<a id="displayCode.Tab66.Hide" href="javascript:togglecode('toggleCode.Tab66.Hide','displayCode.Tab66.Hide');"><i><strong>Código R para producir la Tabla 6.6 y las Figuras 6.9 y 6.10</strong></i></a>
</h5>
<div id="toggleCode.Tab66.Hide" style="display: none">
<div class="sourceCode" id="cb62"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb62-1"><a href="interpretación-de-resultados-de-regresión.html#cb62-1" tabindex="-1"></a><span class="co">#  SEGUNDA REGRESIÓN</span></span>
<span id="cb62-2"><a href="interpretación-de-resultados-de-regresión.html#cb62-2" tabindex="-1"></a><span class="co">#  Tabla 6.6</span></span>
<span id="cb62-3"><a href="interpretación-de-resultados-de-regresión.html#cb62-3" tabindex="-1"></a>lmsurvey2 <span class="ot">&lt;-</span> <span class="fu">lm</span>(COSTLOG <span class="sc">~</span> ASSUME <span class="sc">+</span> CAP <span class="sc">+</span> SIZELOG <span class="sc">+</span> INDCOST <span class="sc">+</span> CENTRAL <span class="sc">+</span> SOPH, <span class="at">data=</span>survey2)</span>
<span id="cb62-4"><a href="interpretación-de-resultados-de-regresión.html#cb62-4" tabindex="-1"></a>sum2 <span class="ot">&lt;-</span> <span class="fu">summary</span>(lmsurvey2)</span>
<span id="cb62-5"><a href="interpretación-de-resultados-de-regresión.html#cb62-5" tabindex="-1"></a>tableout <span class="ot">&lt;-</span> sum2<span class="sc">$</span>coefficients[,<span class="dv">1</span><span class="sc">:</span><span class="dv">3</span>]</span>
<span id="cb62-6"><a href="interpretación-de-resultados-de-regresión.html#cb62-6" tabindex="-1"></a><span class="fu">colnames</span>(tableout) <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="st">&quot;Coeficiente&quot;</span>, <span class="st">&quot;Error Estándar&quot;</span>, <span class="st">&quot;$t$-Estadístico&quot;</span>)</span>
<span id="cb62-7"><a href="interpretación-de-resultados-de-regresión.html#cb62-7" tabindex="-1"></a><span class="fu">TableGen1</span>(<span class="at">TableData=</span>tableout, </span>
<span id="cb62-8"><a href="interpretación-de-resultados-de-regresión.html#cb62-8" tabindex="-1"></a>         <span class="at">TextTitle=</span><span class="st">&#39;Resultados de la Regresión: COSTLOG como Variable Dependiente&#39;</span>, </span>
<span id="cb62-9"><a href="interpretación-de-resultados-de-regresión.html#cb62-9" tabindex="-1"></a>         <span class="at">Align=</span><span class="st">&#39;r&#39;</span>, <span class="at">ColumnSpec=</span><span class="dv">1</span><span class="sc">:</span><span class="dv">3</span>, <span class="at">Digits=</span><span class="dv">3</span>,</span>
<span id="cb62-10"><a href="interpretación-de-resultados-de-regresión.html#cb62-10" tabindex="-1"></a>         <span class="at">ColWidth =</span> <span class="st">&quot;3cm&quot;</span>)</span></code></pre></div>
<div class="sourceCode" id="cb63"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb63-1"><a href="interpretación-de-resultados-de-regresión.html#cb63-1" tabindex="-1"></a><span class="co">#  FIGURA 6.9</span></span>
<span id="cb63-2"><a href="interpretación-de-resultados-de-regresión.html#cb63-2" tabindex="-1"></a>ri2 <span class="ot">&lt;-</span> <span class="fu">rstandard</span>(lmsurvey2)</span>
<span id="cb63-3"><a href="interpretación-de-resultados-de-regresión.html#cb63-3" tabindex="-1"></a>hii2 <span class="ot">&lt;-</span> <span class="fu">hatvalues</span>(lmsurvey2)</span>
<span id="cb63-4"><a href="interpretación-de-resultados-de-regresión.html#cb63-4" tabindex="-1"></a><span class="co">#  FIGURA 6.9</span></span>
<span id="cb63-5"><a href="interpretación-de-resultados-de-regresión.html#cb63-5" tabindex="-1"></a><span class="fu">par</span>(<span class="at">mfrow=</span><span class="fu">c</span>(<span class="dv">1</span>, <span class="dv">2</span>), <span class="at">mar=</span><span class="fu">c</span>(<span class="fl">4.1</span>, <span class="fl">4.5</span>, .<span class="dv">2</span>, .<span class="dv">2</span>))</span>
<span id="cb63-6"><a href="interpretación-de-resultados-de-regresión.html#cb63-6" tabindex="-1"></a><span class="fu">hist</span>(ri2, <span class="at">nclass=</span><span class="dv">16</span>, <span class="at">main=</span><span class="st">&quot;&quot;</span>, <span class="at">xlab=</span><span class="st">&quot;Residuos Estandarizados&quot;</span>, <span class="at">las=</span><span class="dv">1</span>, <span class="at">cex.lab=</span><span class="fl">1.5</span>)</span>
<span id="cb63-7"><a href="interpretación-de-resultados-de-regresión.html#cb63-7" tabindex="-1"></a><span class="fu">hist</span>(hii2, <span class="at">nclass=</span><span class="dv">16</span>, <span class="at">main=</span><span class="st">&quot;&quot;</span>, <span class="at">xlab=</span><span class="st">&quot;Apalancamientos&quot;</span>, <span class="at">las=</span><span class="dv">1</span>, <span class="at">cex.lab=</span><span class="fl">1.5</span>)</span></code></pre></div>
<div class="sourceCode" id="cb64"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb64-1"><a href="interpretación-de-resultados-de-regresión.html#cb64-1" tabindex="-1"></a><span class="co">#  FIGURA 6.10</span></span>
<span id="cb64-2"><a href="interpretación-de-resultados-de-regresión.html#cb64-2" tabindex="-1"></a>lmsurvey3 <span class="ot">&lt;-</span> <span class="fu">lm</span>(COSTLOG <span class="sc">~</span> SIZELOG <span class="sc">+</span> INDCOST, <span class="at">data=</span>survey2)</span>
<span id="cb64-3"><a href="interpretación-de-resultados-de-regresión.html#cb64-3" tabindex="-1"></a>ri3 <span class="ot">&lt;-</span> <span class="fu">rstandard</span>(lmsurvey3)</span>
<span id="cb64-4"><a href="interpretación-de-resultados-de-regresión.html#cb64-4" tabindex="-1"></a>hii3 <span class="ot">&lt;-</span> <span class="fu">hatvalues</span>(lmsurvey3)</span>
<span id="cb64-5"><a href="interpretación-de-resultados-de-regresión.html#cb64-5" tabindex="-1"></a></span>
<span id="cb64-6"><a href="interpretación-de-resultados-de-regresión.html#cb64-6" tabindex="-1"></a><span class="co">#  FIGURA 6.10</span></span>
<span id="cb64-7"><a href="interpretación-de-resultados-de-regresión.html#cb64-7" tabindex="-1"></a><span class="fu">par</span>(<span class="at">mfrow=</span><span class="fu">c</span>(<span class="dv">1</span>, <span class="dv">2</span>), <span class="at">mar=</span><span class="fu">c</span>(<span class="fl">4.1</span>, <span class="fl">4.5</span>, .<span class="dv">2</span>, .<span class="dv">2</span>))</span>
<span id="cb64-8"><a href="interpretación-de-resultados-de-regresión.html#cb64-8" tabindex="-1"></a><span class="fu">hist</span>(ri3, <span class="at">nclass=</span><span class="dv">16</span>, <span class="at">main=</span><span class="st">&quot;&quot;</span>, <span class="at">xlab=</span><span class="st">&quot;Residuos Estandarizados&quot;</span>, <span class="at">las=</span><span class="dv">1</span>, <span class="at">cex.lab=</span><span class="fl">1.5</span>)</span>
<span id="cb64-9"><a href="interpretación-de-resultados-de-regresión.html#cb64-9" tabindex="-1"></a><span class="fu">hist</span>(hii3, <span class="at">nclass=</span><span class="dv">16</span>, <span class="at">main=</span><span class="st">&quot;&quot;</span>, <span class="at">xlab=</span><span class="st">&quot;Apalancamientos&quot;</span>, <span class="at">las=</span><span class="dv">1</span>, <span class="at">cex.lab=</span><span class="fl">1.5</span>)</span></code></pre></div>
</div>
<table class=" lightable-classic table table-striped table-condensed" style="font-size: 12px; font-family: Cambria; width: auto !important; margin-left: auto; margin-right: auto; margin-left: auto; margin-right: auto;">
<caption style="font-size: initial !important;">
<span id="tab:Tab67">Tabla 6.7: </span><strong>Resultados de la Regresión con un Término Cuadrático en INDCOST</strong>
</caption>
<thead>
<tr>
<th style="text-align:left;">
</th>
<th style="text-align:right;">
Coeficiente
</th>
<th style="text-align:right;">
Error Estándar
</th>
<th style="text-align:right;">
<span class="math inline">\(t\)</span>-Estadístico
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;width: 2.5cm; border-right:1px solid;">
(Intercept)
</td>
<td style="text-align:right;width: 3cm; ">
6.353
</td>
<td style="text-align:right;width: 3cm; ">
0.953
</td>
<td style="text-align:right;width: 3cm; ">
6.666
</td>
</tr>
<tr>
<td style="text-align:left;width: 2.5cm; border-right:1px solid;">
SIZELOG
</td>
<td style="text-align:right;width: 3cm; ">
-0.773
</td>
<td style="text-align:right;width: 3cm; ">
0.101
</td>
<td style="text-align:right;width: 3cm; ">
-7.626
</td>
</tr>
<tr>
<td style="text-align:left;width: 2.5cm; border-right:1px solid;">
INDCOST
</td>
<td style="text-align:right;width: 3cm; ">
6.264
</td>
<td style="text-align:right;width: 3cm; ">
1.610
</td>
<td style="text-align:right;width: 3cm; ">
3.889
</td>
</tr>
<tr>
<td style="text-align:left;width: 2.5cm; border-right:1px solid;">
INDCOSTSQ
</td>
<td style="text-align:right;width: 3cm; ">
-3.585
</td>
<td style="text-align:right;width: 3cm; ">
1.265
</td>
<td style="text-align:right;width: 3cm; ">
-2.833
</td>
</tr>
</tbody>
</table>

<div class="figure" style="text-align: center"><span style="display:block;" id="fig:Fig611"></span>
<img src="RegressionMarkdown_files/figure-html/Fig611-1.png" alt="Gráfico de dispersión de residuos versus INDCOST. La curva ajustada suave (usando lowess) sugiere un término cuadrático en INDCOST." width="60%" />
<p class="caption">
Figura 6.11: <strong>Gráfico de dispersión de residuos versus INDCOST.</strong> La curva ajustada suave (usando lowess) sugiere un término cuadrático en INDCOST.
</p>
</div>
<h5 style="text-align: center;">
<a id="displayCode.Tab67.Hide" href="javascript:togglecode('toggleCode.Tab67.Hide','displayCode.Tab67.Hide');"><i><strong>Código R para producir la Tabla 6.7 y la Figura 6.11</strong></i></a>
</h5>
<div id="toggleCode.Tab67.Hide" style="display: none">
<div class="sourceCode" id="cb65"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb65-1"><a href="interpretación-de-resultados-de-regresión.html#cb65-1" tabindex="-1"></a><span class="co">#  TERCERA REGRESIÓN</span></span>
<span id="cb65-2"><a href="interpretación-de-resultados-de-regresión.html#cb65-2" tabindex="-1"></a><span class="co"># Tabla 6.7</span></span>
<span id="cb65-3"><a href="interpretación-de-resultados-de-regresión.html#cb65-3" tabindex="-1"></a>survey2<span class="sc">$</span>INDCOSTSQ <span class="ot">&lt;-</span> survey2<span class="sc">$</span>INDCOST <span class="sc">*</span> survey2<span class="sc">$</span>INDCOST</span>
<span id="cb65-4"><a href="interpretación-de-resultados-de-regresión.html#cb65-4" tabindex="-1"></a>lmsurvey4 <span class="ot">&lt;-</span> <span class="fu">lm</span>(COSTLOG <span class="sc">~</span> SIZELOG <span class="sc">+</span> INDCOST <span class="sc">+</span> INDCOSTSQ, <span class="at">data=</span>survey2)</span>
<span id="cb65-5"><a href="interpretación-de-resultados-de-regresión.html#cb65-5" tabindex="-1"></a>sum4 <span class="ot">&lt;-</span> <span class="fu">summary</span>(lmsurvey4)</span>
<span id="cb65-6"><a href="interpretación-de-resultados-de-regresión.html#cb65-6" tabindex="-1"></a>tableout <span class="ot">&lt;-</span> sum4<span class="sc">$</span>coefficients[,<span class="dv">1</span><span class="sc">:</span><span class="dv">3</span>]</span>
<span id="cb65-7"><a href="interpretación-de-resultados-de-regresión.html#cb65-7" tabindex="-1"></a><span class="fu">colnames</span>(tableout) <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="st">&quot;Coeficiente&quot;</span>, <span class="st">&quot;Error Estándar&quot;</span>, <span class="st">&quot;$t$-Estadístico&quot;</span>)</span>
<span id="cb65-8"><a href="interpretación-de-resultados-de-regresión.html#cb65-8" tabindex="-1"></a><span class="fu">TableGen1</span>(<span class="at">TableData=</span>tableout, </span>
<span id="cb65-9"><a href="interpretación-de-resultados-de-regresión.html#cb65-9" tabindex="-1"></a>         <span class="at">TextTitle=</span><span class="st">&#39;Resultados de la Regresión con un Término Cuadrático en INDCOST&#39;</span>, </span>
<span id="cb65-10"><a href="interpretación-de-resultados-de-regresión.html#cb65-10" tabindex="-1"></a>         <span class="at">Align=</span><span class="st">&#39;r&#39;</span>, <span class="at">ColumnSpec=</span><span class="dv">1</span><span class="sc">:</span><span class="dv">3</span>, <span class="at">Digits=</span><span class="dv">3</span>,</span>
<span id="cb65-11"><a href="interpretación-de-resultados-de-regresión.html#cb65-11" tabindex="-1"></a>         <span class="at">ColWidth =</span> <span class="st">&quot;3cm&quot;</span>)</span></code></pre></div>
<div class="sourceCode" id="cb66"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb66-1"><a href="interpretación-de-resultados-de-regresión.html#cb66-1" tabindex="-1"></a><span class="fu">par</span>(<span class="at">mar=</span><span class="fu">c</span>(<span class="fl">4.1</span>, <span class="fl">2.2</span>, <span class="fl">1.7</span>, .<span class="dv">2</span>), <span class="at">cex=</span><span class="fl">1.2</span>)</span>
<span id="cb66-2"><a href="interpretación-de-resultados-de-regresión.html#cb66-2" tabindex="-1"></a><span class="fu">plot</span>(survey2<span class="sc">$</span>INDCOST, lmsurvey4<span class="sc">$</span>residuals, <span class="at">xlab=</span><span class="st">&quot;INDCOST&quot;</span>, <span class="at">ylab=</span><span class="st">&quot;&quot;</span>, <span class="at">las=</span><span class="dv">1</span>)</span>
<span id="cb66-3"><a href="interpretación-de-resultados-de-regresión.html#cb66-3" tabindex="-1"></a><span class="fu">mtext</span>(<span class="st">&quot;RESIDUAL&quot;</span>, <span class="at">side=</span><span class="dv">2</span>, <span class="at">las=</span><span class="dv">1</span>, <span class="at">at=</span><span class="fl">3.3</span>, <span class="at">cex=</span><span class="fl">1.2</span>, <span class="at">adj=</span>.<span class="dv">4</span>)</span>
<span id="cb66-4"><a href="interpretación-de-resultados-de-regresión.html#cb66-4" tabindex="-1"></a><span class="fu">lines</span>(<span class="fu">lowess</span>(survey2<span class="sc">$</span>INDCOST, lmsurvey4<span class="sc">$</span>residuals, <span class="at">f=</span>.<span class="dv">8</span>))</span></code></pre></div>
</div>
<p>Los gráficos de residuos versus las variables explicativas revelan algunos patrones sutiles. El gráfico de dispersión de residuos versus INDCOST, en la Figura <a href="interpretación-de-resultados-de-regresión.html#fig:Fig611">6.11</a>, muestra una tendencia cuadrática leve en INDCOST. Para verificar si esta tendencia es importante, la variable INDCOST fue elevada al cuadrado y utilizada como una variable explicativa en un modelo de regresión. Los resultados de este ajuste están en la Tabla <a href="interpretación-de-resultados-de-regresión.html#tab:Tab66">6.6</a>.</p>
<p>A partir del <span class="math inline">\(t\)</span>-ratio asociado con <span class="math inline">\((INDCOST)^{2}\)</span>, vemos que la variable parece ser importante. El signo es razonable, indicando que la tasa de incremento de COSTLOG disminuye a medida que INDCOST aumenta. Es decir, el cambio esperado en COSTLOG por unidad de cambio en INDCOST es positivo y disminuye a medida que INDCOST aumenta.</p>
<p>Los chequeos diagnósticos adicionales del modelo no revelaron patrones adicionales. Por lo tanto, con los datos disponibles, no podemos afirmar ninguna de las cuatro hipótesis introducidas en la subsección de Introducción. Esto no significa que estas variables no sean importantes. Simplemente estamos diciendo que la variabilidad natural de los datos era lo suficientemente grande como para ocultar cualquier relación que pudiera existir. Sin embargo, hemos establecido la importancia del tamaño de la empresa y del riesgo industrial de la empresa.</p>
<p>La Figura <a href="interpretación-de-resultados-de-regresión.html#fig:Fig612">6.12</a> resume gráficamente las relaciones estimadas entre estas variables. En particular, en el panel inferior derecho, vemos que para la mayoría de las empresas en la muestra, FIRMCOST fue relativamente estable. Sin embargo, para las empresas pequeñas, medida por SIZELOG, el riesgo industrial, medido por INDCOST, fue particularmente importante. Para las empresas pequeñas, vemos que el FIRMCOST ajustado aumenta a medida que la variable INDCOST aumenta, con la tasa de incremento estabilizándose. Aunque el modelo predice teóricamente que FIRMCOST disminuye con un INDCOST grande <span class="math inline">\((&gt;1.2)\)</span>, no había empresas pequeñas en esta área de la región de datos.</p>

<div class="figure" style="text-align: center"><span style="display:block;" id="fig:Fig612"></span>
<img src="RegressionMarkdown_files/figure-html/Fig612-1.png" alt="Gráfico de cuatro modelos ajustados versus INDCOST y SIZELOG." width="100%" />
<p class="caption">
Figura 6.12: <strong>Gráfico de cuatro modelos ajustados versus INDCOST y SIZELOG.</strong>
</p>
</div>
</div>
</div>
<div id="Sec66" class="section level2 hasAnchor" number="6.6">
<h2><span class="header-section-number">6.6</span> Lecturas Adicionales y Referencias<a href="interpretación-de-resultados-de-regresión.html#Sec66" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Este capítulo concluye nuestra Parte I, una introducción a la regresión lineal. Para aprender más sobre la regresión lineal, en la Sección 1.7 proporcionamos referencias a libros de estadística alternativos que introducen el tema. También puedes estar interesado en una presentación más técnica, como el trabajo clásico de Seber (1977) o un trabajo más reciente de Abraham y Ledolter (2006). Para otros enfoques, textos como el de Wooldridge (2009) ofrecen una perspectiva econométrica donde se enfatiza la introducción de la regresión en el contexto de la teoría económica. Alternativamente, libros como el de Agresti y Finlay (2008) brindan una introducción desde una perspectiva más amplia de las ciencias sociales.</p>
<p>Existen muchas explicaciones de la regresión para lectores con diferentes perspectivas y niveles de formación cuantitativa; esto proporciona evidencia adicional de que este es un tema importante para que los actuarios y otros gestores de riesgos financieros lo comprendan. Otra forma de obtener una comprensión más profunda de la regresión lineal es ver cómo se aplica en un contexto de series temporales en la Parte II de este libro o en extensiones a la modelización no lineal en la Parte III.</p>
<p>Consulta Bollen (1989) para una introducción clásica a la modelización de ecuaciones estructurales.</p>
<p><strong>Referencias del Capítulo</strong></p>
<ul>
<li>Abraham, Bova and Johannes Ledolter (2006). <em>Introduction to Regression Modeling.</em> Thomson Higher Education, Belmont, CA.</li>
<li>Agresti, Alan and Barbara Finlay (2008). <em>Statistical Methods for the Social Sciences, Fourth Edition</em>. Prentice Hall, Upper Saddle, NJ.</li>
<li>Bollen, Kenneth A. (1989). <em>Structural Equations with Latent Variables</em>. New York: Wiley.</li>
<li>Box, George E. P. (1979). Robustness in the strategy of scientific model building. In R. Launer and G. Wilderson (editors), <em>Robustness in Statistics</em>, pages 201-236, Academic Press, New York.</li>
<li>Faraway, Julian J. (2005). <em>Linear Models with R</em>. Chapman &amp; Hall/CRC, Boca Raton, Florida.</li>
<li>Fienberg, S. E (1985). Insurance availability in Chicago. Chapter in <em>Data: A Collection of Problems from Many Fields for the Student and Research Worker</em>. Editors D.F. Andrews and A. M. Herzberg, Springer-Verlag, New York.</li>
<li>Goldberger, Arthur S. (1972). Structural equation methods in the social sciences. <em>Econometrica</em> 40, 979-1001.</li>
<li>Harrington, Scott E. and Greg Niehaus (1998). Race, redlining and automobile insurance prices. <em>Journal of Business</em> 71(3), 439-469.</li>
<li>Heckman, J. J. (1976). The common structure of statistical models of truncation, sample selection and limited dependent variables, and a simple estimator for such models. <em>Ann. Econ. Soc. Meas</em>. 5, 475-492.</li>
<li>Little, R. J. (1995). Modelling the drop-out mechanism in repeated-measures studies. <em>Journal of the American Statistical Association</em> 90, 1112-1121.</li>
<li>Little, R. J. and Rubin, D. B. (1987). <em>Statistical Analysis with Missing Data.</em> John Wiley, New York.</li>
<li>Roberts, Harry V. (1990). Business and economic statistics (with discussion). <em>Statistical Science</em> 4, 372-402.</li>
<li>Rubin, D. R. (1976). Inference and missing data. <em>Biometrika</em> 63, 581-592.</li>
<li>Schmit, Joan T. and K. Roth (1990). Cost effectiveness of risk management practices. <em>The Journal of Risk and Insurance</em> 57, No. 3, pages 455-470.</li>
<li>Seber, G. A. F. (1977). <em>Linear Regression Analysis.</em> John Wiley &amp; Sons, New York.</li>
<li>Wachter, K. W. and J. Trusell (1982). Estimating historical heights. <em>Journal of the American Statistical Association</em> 77, 279-301.</li>
<li>Wooldridge, Jeffrey (2009). <em>Introductory Econometrics: A Modern Approach, Fourth Edition.</em> South-Western Publishing, Mason, Ohio.</li>
</ul>
</div>
<div id="Sec67" class="section level2 hasAnchor" number="6.7">
<h2><span class="header-section-number">6.7</span> Ejercicios<a href="interpretación-de-resultados-de-regresión.html#Sec67" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>6.1 <strong>Segregación por Seguro.</strong> ¿Utilizan las compañías de seguros la raza como un factor determinante al ofrecer seguros? Fienberg (1985) recopiló datos de un informe emitido por la Comisión de Derechos Civiles de EE.UU. sobre el número de propietarios de viviendas y pólizas de seguro contra incendios residenciales emitidas en Chicago durante los meses de diciembre de 1977 a febrero de 1978. Las pólizas emitidas se clasificaron como parte del mercado voluntario estándar o del mercado involuntario subestándar. El mercado involuntario consiste en planes de “acceso justo a los seguros” (FAIR); estos son programas de seguros estatales a veces subsidiados por empresas privadas. Estos planes brindan seguros a personas que, de otro modo, serían rechazadas para asegurar su propiedad debido a problemas de alto riesgo. El objetivo principal es comprender la relación entre la actividad de seguros y la variable “raza”, el porcentaje de minorías. Los datos están disponibles para <span class="math inline">\(n=47\)</span> códigos postales en el área de Chicago. Estos datos también han sido analizados por Faraway (2005).</p>
<p>Para ayudar a controlar el tamaño de la pérdida esperada, Fienberg también recopiló datos de robos e incendios de los departamentos de policía y bomberos de Chicago. Otra variable que proporciona información sobre el tamaño de la pérdida es la antigüedad de la casa. El ingreso mediano, del Censo, proporciona información indirecta sobre el tamaño de la pérdida esperada así como sobre si el solicitante puede permitirse el seguro. La Tabla <a href="interpretación-de-resultados-de-regresión.html#tab:Tab68">6.8</a> proporciona más detalles sobre estas variables.</p>
<table class=" lightable-classic table table-striped table-condensed" style="font-size: 12px; font-family: Cambria; width: auto !important; margin-left: auto; margin-right: auto; margin-left: auto; margin-right: auto;">
<caption style="font-size: initial !important;">
<span id="tab:Tab68">Tabla 6.8: </span><strong>Disponibilidad de Seguros en Chicago</strong>
</caption>
<thead>
<tr>
<th style="text-align:left;">
Variable
</th>
<th style="text-align:left;">
Descripción
</th>
<th style="text-align:center;">
Promedio
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;width: 2.5cm; border-right:1px solid;border-right:1px solid;">
row.names
</td>
<td style="text-align:left;width: 2cm; width: 9cm; border-right:1px solid;">
Código postal
</td>
<td style="text-align:center;width: 2cm; ">
</td>
</tr>
<tr>
<td style="text-align:left;width: 2.5cm; border-right:1px solid;border-right:1px solid;">
race
</td>
<td style="text-align:left;width: 2cm; width: 9cm; border-right:1px solid;">
Composición racial en porcentaje de minorías
</td>
<td style="text-align:center;width: 2cm; ">
35
</td>
</tr>
<tr>
<td style="text-align:left;width: 2.5cm; border-right:1px solid;border-right:1px solid;">
fire
</td>
<td style="text-align:left;width: 2cm; width: 9cm; border-right:1px solid;">
Incendios por 1,000 unidades habitacionales
</td>
<td style="text-align:center;width: 2cm; ">
12.3
</td>
</tr>
<tr>
<td style="text-align:left;width: 2.5cm; border-right:1px solid;border-right:1px solid;">
theft
</td>
<td style="text-align:left;width: 2cm; width: 9cm; border-right:1px solid;">
Robos por 1,000 habitantes
</td>
<td style="text-align:center;width: 2cm; ">
32.4
</td>
</tr>
<tr>
<td style="text-align:left;width: 2.5cm; border-right:1px solid;border-right:1px solid;">
age
</td>
<td style="text-align:left;width: 2cm; width: 9cm; border-right:1px solid;">
Porcentaje de unidades habitacionales construidas en o antes de 1939
</td>
<td style="text-align:center;width: 2cm; ">
60.3
</td>
</tr>
<tr>
<td style="text-align:left;width: 2.5cm; border-right:1px solid;border-right:1px solid;">
volact
</td>
<td style="text-align:left;width: 2cm; width: 9cm; border-right:1px solid;">
Nuevas pólizas para propietarios más renovaciones, menos cancelaciones y no renovaciones por 100 unidades habitacionales
</td>
<td style="text-align:center;width: 2cm; ">
6.53
</td>
</tr>
<tr>
<td style="text-align:left;width: 2.5cm; border-right:1px solid;border-right:1px solid;">
involact
</td>
<td style="text-align:left;width: 2cm; width: 9cm; border-right:1px solid;">
Nuevas pólizas del plan FAIR y renovaciones por 100 unidades habitacionales
</td>
<td style="text-align:center;width: 2cm; ">
0.615
</td>
</tr>
<tr>
<td style="text-align:left;width: 2.5cm; border-right:1px solid;border-right:1px solid;">
income
</td>
<td style="text-align:left;width: 2cm; width: 9cm; border-right:1px solid;">
Ingreso familiar mediano
</td>
<td style="text-align:center;width: 2cm; ">
10696
</td>
</tr>
</tbody>
</table>
<ol style="list-style-type: lower-alpha">
<li>Produce estadísticas descriptivas de todas las variables, observando los patrones de asimetría para cada variable.</li>
<li>Crea una matriz de gráficos de dispersión de volact, involact y race. Comenta sobre las tres relaciones pares. ¿Son los patrones consistentes con una hipótesis de discriminación racial?</li>
<li>Para entender las relaciones entre las variables, produce una tabla de correlaciones.</li>
<li>Ajusta un modelo lineal usando volact como la variable dependiente y race, fire, theft, age e income como variables explicativas. <br>
d(i). Comenta sobre el signo y la significancia estadística del coeficiente asociado con race. <br>
d(ii). Dos códigos postales resultan tener alta influencia. Repite tu análisis después de eliminar estas dos observaciones. ¿Ha cambiado la significancia de la variable race? ¿Qué pasa con las otras variables explicativas? <br></li>
<li>Repite el análisis en la parte (d) usando involact como la variable dependiente.</li>
<li>Define proporción como involact/(volact+involact). Repite el análisis en la parte (d) usando proporción como la variable dependiente.</li>
<li>Los mismos dos códigos postales tienen alta influencia en las partes (d), (e) y (f). ¿Por qué ocurre esto?</li>
<li>Este análisis se realiza a nivel de código postal, no a nivel individual. Como enfatizan Harrington y Niehaus (1998), esto introduce un potencial sesgo por variables omitidas. ¿Qué variables se han omitido en el análisis que crees que podrían afectar la disponibilidad del seguro para propietarios y la raza?</li>
<li>Fienberg señala que la proximidad de un código postal a otro puede afectar la dependencia de las observaciones. Describe cómo podrías incorporar relaciones espaciales en un análisis de regresión.</li>
</ol>
<p>6.2 <strong>Equidad de Género en los Sueldos del Personal Académico.</strong> La Universidad de Wisconsin en Madison realizó un estudio titulado “Estudio de Equidad de Género en los Sueldos del Personal Académico”, fechado el 5 de junio de 1992. El propósito principal del estudio fue determinar si las mujeres son tratadas de manera injusta en la determinación de sueldos en una importante universidad de investigación en EE.UU. Para ello, el comité que emitió el informe estudió los sueldos de 1990 de 1,898 miembros de la facultad de la universidad. Es bien conocido que los hombres ganan más que las mujeres. De hecho, el sueldo promedio de 1990 para los 1,528 miembros masculinos de la facultad es 54,478, que es un 28% más alto que el sueldo promedio de 1990 para las miembros femeninas de la facultad, que es 43,315. Sin embargo, se argumenta que los miembros masculinos de la facultad son en general más experimentados (el promedio de años de experiencia es 18.8 años) que las miembros femeninas de la facultad (el promedio de años de experiencia es 11.9 años), y por lo tanto, merecen un sueldo más alto. Al comparar los sueldos de los profesores titulares (controlando así por años de experiencia), los miembros masculinos de la facultad ganaron aproximadamente un 13% más que sus contrapartes femeninas. Aun así, se acuerda en general que los campos en demanda deben ofrecer sueldos más altos para mantener una facultad de primer nivel. Por ejemplo, los sueldos en ingeniería son más altos que los sueldos en humanidades simplemente porque los académicos en ingeniería tienen muchas más oportunidades de empleo fuera de la academia que los académicos en humanidades. Por lo tanto, al considerar los sueldos, también se debe controlar por departamento.</p>
<p>Para controlar estas variables, un estudio de la facultad reporta un análisis de regresión usando el logaritmo del sueldo como la variable dependiente. Las variables explicativas incluyeron información sobre raza, género, rango (ya sea profesor asistente/instructor, profesor asociado o profesor titular), varias medidas de años de experiencia, 98 categorías diferentes de departamentos y una medida de la diferencia de sueldo por departamento. Hubo 109 variables explicativas en total (incluyendo 97 variables binarias departamentales), de las cuales 12 eran variables no departamentales. La Tabla <a href="interpretación-de-resultados-de-regresión.html#tab:Tab69">6.9</a> reporta las definiciones de variables, estimaciones de parámetros y <span class="math inline">\(t\)</span>-ratios para las 12 variables no departamentales. La Tabla de ANOVA <a href="interpretación-de-resultados-de-regresión.html#tab:Tab610">6.10</a> resume el ajuste de la regresión.</p>
<table class=" lightable-classic table table-striped table-condensed" style="font-size: 12px; font-family: Cambria; width: auto !important; margin-left: auto; margin-right: auto; margin-left: auto; margin-right: auto;">
<caption style="font-size: initial !important;">
<span id="tab:Tab69">Tabla 6.9: </span><strong>Variables No Departamentales y Estimaciones de Parámetros</strong>
</caption>
<thead>
<tr>
<th style="text-align:left;">
Variable Explicativa
</th>
<th style="text-align:left;">
Descripción de la Variable
</th>
<th style="text-align:center;">
Estimación del Parámetro
</th>
<th style="text-align:right;">
<span class="math inline">\(t\)</span>-Ratio
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;width: 2.5cm; border-right:1px solid;">
INTERCEPT
</td>
<td style="text-align:left;width: 2cm; width: 9cm; border-right:1px solid;">
</td>
<td style="text-align:center;width: 2cm; ">
10.746
</td>
<td style="text-align:right;">
261.1
</td>
</tr>
<tr>
<td style="text-align:left;width: 2.5cm; border-right:1px solid;">
GENDER
</td>
<td style="text-align:left;width: 2cm; width: 9cm; border-right:1px solid;">
= 1 si es hombre, 0 en caso contrario
</td>
<td style="text-align:center;width: 2cm; ">
0.016
</td>
<td style="text-align:right;">
1.86
</td>
</tr>
<tr>
<td style="text-align:left;width: 2.5cm; border-right:1px solid;">
RACE
</td>
<td style="text-align:left;width: 2cm; width: 9cm; border-right:1px solid;">
= 1 si es blanco, 0 en caso contrario
</td>
<td style="text-align:center;width: 2cm; ">
-0.029
</td>
<td style="text-align:right;">
-2.44
</td>
</tr>
<tr>
<td style="text-align:left;width: 2.5cm; border-right:1px solid;">
FULL
</td>
<td style="text-align:left;width: 2cm; width: 9cm; border-right:1px solid;">
= 1 si es profesor titular, 0 en caso contrario
</td>
<td style="text-align:center;width: 2cm; ">
0.186
</td>
<td style="text-align:right;">
16.42
</td>
</tr>
<tr>
<td style="text-align:left;width: 2.5cm; border-right:1px solid;">
ASSISTANT
</td>
<td style="text-align:left;width: 2cm; width: 9cm; border-right:1px solid;">
= 1 si es profesor asistente, 0 en caso contrario
</td>
<td style="text-align:center;width: 2cm; ">
-0.205
</td>
<td style="text-align:right;">
-15.93
</td>
</tr>
<tr>
<td style="text-align:left;width: 2.5cm; border-right:1px solid;">
ANYDOC
</td>
<td style="text-align:left;width: 2cm; width: 9cm; border-right:1px solid;">
= 1 si tiene un título terminal como un Ph.D. 
</td>
<td style="text-align:center;width: 2cm; ">
0.022
</td>
<td style="text-align:right;">
1.11
</td>
</tr>
<tr>
<td style="text-align:left;width: 2.5cm; border-right:1px solid;">
COHORT1
</td>
<td style="text-align:left;width: 2cm; width: 9cm; border-right:1px solid;">
= 1 si fue contratado antes de 1969, 0 en caso contrario
</td>
<td style="text-align:center;width: 2cm; ">
-0.102
</td>
<td style="text-align:right;">
-4.84
</td>
</tr>
<tr>
<td style="text-align:left;width: 2.5cm; border-right:1px solid;">
COHORT2
</td>
<td style="text-align:left;width: 2cm; width: 9cm; border-right:1px solid;">
= 1 si fue contratado entre 1969-1985, 0 en caso contrario
</td>
<td style="text-align:center;width: 2cm; ">
-0.046
</td>
<td style="text-align:right;">
-3.48
</td>
</tr>
<tr>
<td style="text-align:left;width: 2.5cm; border-right:1px solid;">
FULLYEARS
</td>
<td style="text-align:left;width: 2cm; width: 9cm; border-right:1px solid;">
Número de años como profesor titular en UW
</td>
<td style="text-align:center;width: 2cm; ">
0.012
</td>
<td style="text-align:right;">
12.84
</td>
</tr>
<tr>
<td style="text-align:left;width: 2.5cm; border-right:1px solid;">
ASSOCYEARS
</td>
<td style="text-align:left;width: 2cm; width: 9cm; border-right:1px solid;">
Número de años como profesor asociado en UW
</td>
<td style="text-align:center;width: 2cm; ">
-0.012
</td>
<td style="text-align:right;">
-8.65
</td>
</tr>
<tr>
<td style="text-align:left;width: 2.5cm; border-right:1px solid;">
ASSISYEARS
</td>
<td style="text-align:left;width: 2cm; width: 9cm; border-right:1px solid;">
Número de años como profesor asistente o instructor en UW
</td>
<td style="text-align:center;width: 2cm; ">
0.002
</td>
<td style="text-align:right;">
0.91
</td>
</tr>
<tr>
<td style="text-align:left;width: 2.5cm; border-right:1px solid;">
DIFYRS
</td>
<td style="text-align:left;width: 2cm; width: 9cm; border-right:1px solid;">
Número de años desde la obtención de un título terminal antes de llegar a UW
</td>
<td style="text-align:center;width: 2cm; ">
0.004
</td>
<td style="text-align:right;">
4.46
</td>
</tr>
<tr>
<td style="text-align:left;width: 2.5cm; border-right:1px solid;">
MRKTRATIO
</td>
<td style="text-align:left;width: 2cm; width: 9cm; border-right:1px solid;">
Logaritmo natural de una ‘razón de mercado’ definida como la razón del sueldo promedio en instituciones pares para una disciplina y rango dado
</td>
<td style="text-align:center;width: 2cm; ">
0.665
</td>
<td style="text-align:right;">
7.64
</td>
</tr>
</tbody>
</table>
<p><em>Fuente</em>: “Estudio de Equidad de Género en los Sueldos del Personal Académico”, 5 de junio de 1992, Universidad de Wisconsin en Madison.</p>
<table class=" lightable-classic table table-striped table-condensed" style="font-size: 12px; font-family: Cambria; width: auto !important; margin-left: auto; margin-right: auto; margin-left: auto; margin-right: auto;">
<caption style="font-size: initial !important;">
<span id="tab:Tab610">Tabla 6.10: </span><strong>Tabla ANOVA de Sueldos del Personal</strong>
</caption>
<thead>
<tr>
<th style="text-align:left;">
Fuente
</th>
<th style="text-align:right;">
Suma de Cuadrados
</th>
<th style="text-align:right;">
<span class="math inline">\(df\)</span>
</th>
<th style="text-align:right;">
Cuadrado Medio
</th>
<th style="text-align:right;">
<span class="math inline">\(F\)</span>-Ratio
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;width: 2.5cm; border-right:1px solid;border-right:1px solid;">
Regresión
</td>
<td style="text-align:right;width: 3cm; ">
114.048
</td>
<td style="text-align:right;width: 3cm; ">
109
</td>
<td style="text-align:right;width: 3cm; ">
1.0463
</td>
<td style="text-align:right;width: 3cm; ">
62.943
</td>
</tr>
<tr>
<td style="text-align:left;width: 2.5cm; border-right:1px solid;border-right:1px solid;">
Error
</td>
<td style="text-align:right;width: 3cm; ">
29.739
</td>
<td style="text-align:right;width: 3cm; ">
1789
</td>
<td style="text-align:right;width: 3cm; ">
0.0166
</td>
<td style="text-align:right;width: 3cm; ">
</td>
</tr>
<tr>
<td style="text-align:left;width: 2.5cm; border-right:1px solid;border-right:1px solid;">
Total
</td>
<td style="text-align:right;width: 3cm; ">
143.788
</td>
<td style="text-align:right;width: 3cm; ">
1898
</td>
<td style="text-align:right;width: 3cm; ">
</td>
<td style="text-align:right;width: 3cm; ">
</td>
</tr>
</tbody>
</table>
<ol style="list-style-type: lower-alpha">
<li>Suponga que una miembro femenina de la facultad en el departamento de química siente que su sueldo está por debajo de lo que debería ser. Describa brevemente cómo se puede utilizar este estudio como base para la evaluación del rendimiento.</li>
<li>Basado en este estudio, ¿cree que los sueldos de las mujeres son significativamente más bajos que los de los hombres? <br>
b(i). Cite argumentos estadísticos que apoyen el hecho de que los hombres no reciben un sueldo significativamente más alto que las mujeres. <br>
b(ii). Cite argumentos estadísticos que apoyen el hecho de que los hombres reciben un sueldo significativamente más alto que las mujeres. <br>
b(iii). Suponga que decide que las mujeres ganan menos que los hombres. Basado en este estudio, ¿cuánto aumentaría los sueldos de las miembros femeninas de la facultad para igualarlos con los de sus contrapartes masculinas?</li>
</ol>
</div>
<div id="Sec68" class="section level2 hasAnchor" number="6.8">
<h2><span class="header-section-number">6.8</span> Suplementos Técnicos para el Capítulo 6<a href="interpretación-de-resultados-de-regresión.html#Sec68" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<div id="Sec681" class="section level3 hasAnchor" number="6.8.1">
<h3><span class="header-section-number">6.8.1</span> Efectos de la Especificación Incorrecta del Modelo<a href="interpretación-de-resultados-de-regresión.html#Sec681" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p><strong>Notación.</strong> Particiona la matriz de variables explicativas <span class="math inline">\(\mathbf{X}\)</span> en dos submatrices, cada una con <span class="math inline">\(n\)</span> filas, de modo que <span class="math inline">\(\mathbf{X}=(\mathbf{X}_{1} : \mathbf{X}_{2})\)</span>. Para simplificar, supongamos que <span class="math inline">\(\mathbf{X}_{1}\)</span> es una matriz de <span class="math inline">\(n \times p\)</span>. De manera similar, particiona el vector de parámetros <span class="math inline">\(\boldsymbol \beta =\left( \boldsymbol \beta_{1}^{\prime }, \boldsymbol \beta_{2}^{\prime }\right) ^{\prime }\)</span> de manera que <span class="math inline">\(\mathbf{X \boldsymbol \beta }=\mathbf{X}_{1} \boldsymbol \beta_{1}+ \mathbf{X}_{2} \boldsymbol \beta_{2}\)</span>. Comparamos el modelo completo, o “largo”,</p>
<p><span class="math display">\[
\mathbf{y}=\mathbf{X \boldsymbol \beta }+\boldsymbol \varepsilon = \mathbf{X}_{1} \boldsymbol \beta_{1}+\mathbf{X}_{2} \boldsymbol \beta_{2}+\boldsymbol \varepsilon
\]</span></p>
<p>con el modelo reducido, o “corto”,</p>
<p><span class="math display">\[
\mathbf{y}=\mathbf{X}_{1} \boldsymbol \beta_{1}+\boldsymbol \varepsilon.
\]</span></p>
<p>Esto simplemente generaliza la configuración anterior para permitir la omisión de varias variables.</p>
<p><strong>Efecto del Subajuste.</strong> Supongamos que la representación verdadera es el modelo largo pero accidentalmente ejecutamos el modelo corto. Nuestras estimaciones de parámetros al ejecutar el modelo corto están dadas por <span class="math inline">\(\mathbf{b}_{1}=\mathbf{(X}_{1}^{\prime }\mathbf{X}_{1}\mathbf{)}^{-1}\mathbf{X}_{1}^{\prime }\mathbf{y}\)</span>. Estas estimaciones están sesgadas porque</p>
<p><span class="math display">\[
\begin{array}{ll}
\text{Sesgo} &amp;= \text{E }\mathbf{b}_{1}-\boldsymbol \beta_{1}
= \text{E}\mathbf{(X}_{1}^{\prime}\mathbf{X}_{1}\mathbf{)}^{-1}\mathbf{X}_{1}^{\prime }\mathbf{y} -\boldsymbol \beta_{1} \\
&amp;= \mathbf{(X}_{1}^{\prime }\mathbf{X}_{1}\mathbf{)}^{-1}\mathbf{X}_{1}^{\prime }\text{E }\mathbf{y}-\boldsymbol \beta_{1} \\
&amp;= \mathbf{(X}_{1}^{\prime }\mathbf{X}_{1}\mathbf{)}^{-1}\mathbf{X}_{1}^{\prime }\left( \mathbf{X}_{1}\boldsymbol \beta_{1}+\mathbf{X}_{2}\boldsymbol \beta_{2}\right) - \boldsymbol \beta_{1} \\
&amp;= \mathbf{(X}_{1}^{\prime}\mathbf{X}_{1}\mathbf{)}^{-1}\mathbf{X}_{1}^{\prime }\mathbf{X}_{2}\boldsymbol \beta_{2}
= \mathbf{A \boldsymbol \beta }_{2}.
\end{array}
\]</span></p>
<p>Aquí, <span class="math inline">\(\mathbf{A}=\mathbf{(X}_{1}^{\prime}\mathbf{X}_{1}\mathbf{)}^{-1}\mathbf{X}_{1}^{\prime }\mathbf{X}_{2}\)</span> se llama la <em>matriz de alias</em>, o matriz de sesgo. Al ejecutar el modelo corto, la varianza estimada es <span class="math inline">\(s_{1}^{2}=(\mathbf{y}^{\prime }\mathbf{y}-\mathbf{b}_{1}^{\prime }\mathbf{X}_{1}^{\prime }\mathbf{y})/(n-p)\)</span>. Se puede mostrar que</p>
<p><span class="math display" id="eq:eq63">\[\begin{equation}
\text{E }s_{1}^{2}=\sigma ^{2}+(n-p)^{-1}\boldsymbol \beta_{2}^{\prime }\left( \mathbf{X}_{2}^{\prime }\mathbf{X}_{2}-\mathbf{X}_{2}^{\prime }\mathbf{X}_{1}\mathbf{(X}_{1}^{\prime }\mathbf{X}_{1}\mathbf{)}^{-1}\mathbf{X}_{1}^{\prime }\mathbf{X}_{2}\right) \boldsymbol \beta_{2}.
\tag{6.3}
\end{equation}\]</span></p>
<p>Así, <span class="math inline">\(s_{1}^{2}\)</span> es una estimación “sobresesgada” de <span class="math inline">\(\sigma ^{2}\)</span>.</p>
<p>Sean <span class="math inline">\(\mathbf{x}_{1i}^{\prime }\)</span> y <span class="math inline">\(\mathbf{x}_{2i}^{\prime }\)</span> las <span class="math inline">\(i\)</span>-ésimas filas de <span class="math inline">\(\mathbf{X}_{1}\)</span> y <span class="math inline">\(\mathbf{X}_{2}\)</span>, respectivamente. Usando el modelo corto ajustado, el <span class="math inline">\(i\)</span>-ésimo valor ajustado es <span class="math inline">\(\hat{y}_{1i}=\mathbf{x}_{1i}^{\prime }\mathbf{b}_{1}\)</span>. La verdadera respuesta esperada <span class="math inline">\(i\)</span>-ésima es E <span class="math inline">\(\hat{y}_{1i}=\mathbf{x}_{1i}^{\prime } \boldsymbol \beta_{1} + \mathbf{x}_{2i}^{\prime } \boldsymbol \beta_{2}\)</span>. Así, el sesgo del <span class="math inline">\(i\)</span>-ésimo valor ajustado es</p>
<p><span class="math display">\[
\begin{array}{ll}
\text{Sesgo}(\hat{y}_{1i}) &amp;= \text{E }\hat{y}_{1i}-\text{E }y_{i}=\mathbf{x}_{1i}^{\prime }\text{E }\mathbf{b}_{1}-\left( \mathbf{x}_{1i}^{\prime }\boldsymbol \beta_{1}+\mathbf{x}_{2i}^{\prime } \boldsymbol \beta_{2}\right) \\
&amp; =\mathbf{x}_{1i}^{\prime }(\boldsymbol \beta_{1}+\mathbf{A \boldsymbol \beta }_{2})-\left( \mathbf{x}_{1i}^{\prime }\boldsymbol \beta_{1}+\mathbf{x}_{2i}^{\prime }\boldsymbol \beta_{2}\right) =(\mathbf{x}_{1i}^{\prime }\mathbf{A}-\mathbf{x}_{2i}^{\prime })\boldsymbol \beta_{2}.
\end{array}
\]</span></p>
<p>Usando esto y la ecuación <a href="interpretación-de-resultados-de-regresión.html#eq:eq63">(6.3)</a>, se muestra mediante álgebra directa que</p>
<p><span class="math display" id="eq:eq64">\[\begin{equation}
\text{E }s_{1}^{2}=\sigma ^{2}+(n-p)^{-1}\sum_{i=1}^{n}(\text{Sesgo}(\hat{y}_{1i}))^{2}.
\tag{6.4}
\end{equation}\]</span></p>
<p><strong>Efecto del Sobreajuste.</strong> Supongamos ahora que la representación verdadera es el modelo corto, pero accidentalmente usamos el modelo largo. Con la matriz de alias <span class="math inline">\(\mathbf{A}=\mathbf{(X}_{1}^{\prime }\mathbf{X}_{1}\mathbf{)}^{-1}\mathbf{X}_{1}^{\prime }\mathbf{X}_{2}\)</span>, podemos <em>reparametrizar</em> el modelo largo</p>
<p><span class="math display">\[
\begin{array}{ll}
\mathbf{y} &amp; =\mathbf{X}_{1}\boldsymbol \beta_{1}+\mathbf{X}_{2}\boldsymbol \beta_{2} + \boldsymbol \varepsilon = \mathbf{X}_{1}\left( \boldsymbol \beta_{1}+\mathbf{A \boldsymbol \beta }_{2}\right) + \mathbf{E}_{1}\boldsymbol \beta_{2} + \boldsymbol \varepsilon \\
&amp;= \mathbf{X}_{1}\boldsymbol \alpha_{1}+\mathbf{E}_{1}\boldsymbol \beta_{2} + \boldsymbol \varepsilon
\end{array}
\]</span></p>
<p>donde <span class="math inline">\(\mathbf{E}_{1}=\mathbf{X}_{2}-\mathbf{X}_{1}\mathbf{A}\)</span> y <span class="math inline">\(\boldsymbol \alpha_{1}=\boldsymbol \beta_{1}+\mathbf{A \boldsymbol \beta}_{2}\)</span>. La ventaja de esta nueva parametrización es que <span class="math inline">\(\mathbf{X}_{1}\)</span> es ortogonal a <span class="math inline">\(\mathbf{E}_{1}\)</span> porque <span class="math inline">\(\mathbf{X}_{1}^{\prime }\mathbf{E}_{1}=\mathbf{X}_{1}^{\prime }(\mathbf{X}_{2}-\mathbf{X}_{1}\mathbf{A})=\mathbf{0}\)</span>. Con <span class="math inline">\(\mathbf{X}^{\ast }=(\mathbf{X}_{1}: \mathbf{E}_{1})\)</span> y <span class="math inline">\(\boldsymbol \alpha =(\boldsymbol \alpha_{1}^{\prime }\boldsymbol \beta_{1}^{\prime })^{\prime }\)</span>, el vector de estimaciones de mínimos cuadrados es</p>
<p><span class="math display">\[
\begin{array}{ll}
\mathbf{a} &amp;=
\begin{bmatrix}
\mathbf{a}_{1} \\
\mathbf{b}_{1}
\end{bmatrix} = \left( \mathbf{X}^{\ast \prime }\mathbf{X}^{\ast }\right) ^{-1}\mathbf{X}^{\ast \prime }\mathbf{y} \\
&amp; = \begin{bmatrix}
\mathbf{(X}_{1}^{\prime }\mathbf{X}_{1}\mathbf{)}^{-1} &amp; 0 \\
0 &amp; \mathbf{(E}_{1}^{\prime }\mathbf{E}_{1}\mathbf{)}^{-1}
\end{bmatrix}
\begin{bmatrix}
\mathbf{X}_{1}^{\prime }\mathbf{y} \\
\mathbf{E}_{1}^{\prime }\mathbf{y}
\end{bmatrix} \\
&amp; = \begin{bmatrix}
\mathbf{(X}_{1}^{\prime }\mathbf{X}_{1}\mathbf{)}^{-1}\mathbf{X}_{1}^{\prime }\mathbf{y} \\
\mathbf{(E}_{1}^{\prime }\mathbf{E}_{1}\mathbf{)}^{-1}\mathbf{E}_{1}^{\prime }\mathbf{y}
\end{bmatrix}.
\end{array}
\]</span></p>
<p>Desde el modelo verdadero (corto), <span class="math inline">\(\mathrm{E}~\mathbf{y}=\mathbf{X}_{1}\boldsymbol \beta_{1}\)</span>, tenemos que</p>
<p><span class="math display">\[
\mathrm{E}~\mathbf{b}_{2}
=(\mathbf{E}_{1}^{\prime }\mathbf{E}_{1})^{-1}\mathbf{E}_{1}^{\prime }\mathrm{E}(\mathbf{y})
=(\mathbf{E}_{1}^{\prime }\mathbf{E}_{1})^{-1}\mathbf{E}_{1}^{\prime }\mathrm{E}~ (\mathbf{X}_{1}\mathbf{\beta}_{1})
=\mathbf{0},
\]</span></p>
<p>porque <span class="math inline">\(\mathbf{X}_{1}^{\prime }\mathbf{E}_{1}=\mathbf{0}\)</span>. La estimación de mínimos cuadrados de <span class="math inline">\(\boldsymbol \beta_{1}\)</span> es <span class="math inline">\(\mathbf{b}_{1}=\mathbf{a}_{1}-\mathbf{Ab}_{2}\)</span>. Debido a que</p>
<p><span class="math display">\[
\mathrm{E}~\mathbf{a}_{1}=\mathbf{(X}_{1}^{\prime }\mathbf{X}_{1}\mathbf{)}^{-1}\mathbf{X}_{1}^{\prime }\mathrm{E}~\mathbf{y}=\boldsymbol \beta_{1}
\]</span>
bajo el modelo corto, tenemos que <span class="math inline">\(\mathrm{E}~ \mathbf{b}_{1} = \mathrm{E}~ \mathbf{a}_{1}-\mathbf{A} \mathrm{E}~ \mathbf{b}_{2} = \boldsymbol \beta_{1}-\mathbf{0}=\boldsymbol \beta_{1}\)</span>. Así, aunque accidentalmente usemos el modelo largo, <span class="math inline">\(\mathbf{b}_{1}\)</span> sigue siendo un estimador no sesgado de <span class="math inline">\(\boldsymbol \beta_{1}\)</span> y <span class="math inline">\(\mathbf{b}_{2}\)</span> es un estimador no sesgado de <span class="math inline">\(\mathbf{0}\)</span>. Por lo tanto, no hay sesgo en el valor ajustado <span class="math inline">\(i\)</span>-ésimo porque</p>
<p><span class="math display">\[
\mathrm{E}~\hat{y}_{i}= \mathrm{E}~(\mathbf{x}_{1i}^{\prime }\mathbf{b}_{1}+\mathbf{x}_{2i}^{\prime }\mathbf{b}_{2})=\mathbf{x}_{1i}^{\prime }\boldsymbol \beta_{1}= \mathrm{E}~y_{i} .
\]</span></p>
<p><strong>Estadístico <span class="math inline">\(C_{p}\)</span>.</strong> Supongamos inicialmente que la representación verdadera es el modelo largo, pero usamos erróneamente el modelo corto. El valor ajustado <span class="math inline">\(i\)</span>-ésimo es <span class="math inline">\(\hat{y}_{1i}=\mathbf{x}_{1i}^{\prime }\mathbf{b}_{1}\)</span>, que tiene un error cuadrático medio (MSE)</p>
<p><span class="math display">\[
\text{MSE }\hat{y}_{1i} = \text{E}(\hat{y}_{1i} - \text{E }\hat{y}_{1i})^{2} = \text{Var }\hat{y}_{1i} + \left( \text{Bias }\hat{y}_{1i} \right)^{2}.
\]</span></p>
<p>Para la primera parte, tenemos que</p>
<p><span class="math display">\[
\begin{array}{ll}
\mathrm{Var}~\hat{y}_{1i}&amp;
=\mathrm{Var}\left( \mathbf{x}_{1i}^{\prime }\mathbf{b}_{1}\right)
= \text{Var} \left( \mathbf{x}_{1i}^{\prime } \mathbf{(X}_{1}^{\prime }\mathbf{X}_{1}\mathbf{)}^{-1}\mathbf{X}_{1}^{\prime }\mathbf{y}\right) \\
&amp; = \sigma^{2} \mathbf{x}_{1i} \mathbf{(X}_{1}^{\prime }\mathbf{X}_{1}\mathbf{)}^{-1} \mathbf{x}_{1i}^{\prime }.
\end{array}
\]</span></p>
<p>Podemos pensar en <span class="math inline">\(\mathbf{x}_{1i} \mathbf{(X}_{1}^{\prime }\mathbf{X}_{1}\mathbf{)}^{-1} \mathbf{x}_{1i}^{\prime }\)</span> como la palanca <span class="math inline">\(i\)</span>-ésima, como en la ecuación (5.3). Así, <span class="math inline">\(\sum_{i=1}^{n} \mathbf{x}_{1i} \mathbf{(X}_{1}^{\prime }\mathbf{X}_{1}\mathbf{)}^{-1} \mathbf{x}_{1i}^{\prime } = p\)</span>, el número de columnas de <span class="math inline">\(\mathbf{X}_{1}\)</span>. Con esto, podemos definir el <em>error total estandarizado</em></p>
<p><span class="math display">\[
\begin{array}{ll}
\frac{\sum_{i=1}^{n} \text{MSE }\hat{y}_{1i}}{\sigma^{2}}
&amp; = \frac{\sum_{i=1}^{n} \left( \text{Var }\hat{y}_{1i} + \left( \text{Bias }\hat{y}_{1i} \right)^{2} \right)}{\sigma^{2}} \\
&amp; = \frac{\sigma^{2} \sum_{i=1}^{n} \left( \mathbf{x}_{1i} \mathbf{(X}_{1}^{\prime }\mathbf{X}_{1}\mathbf{)}^{-1} \mathbf{x}_{1i}^{\prime } + \left( \text{Bias }\hat{y}_{1i} \right)^{2} \right)}{\sigma^{2}} \\
&amp;= p + \sigma^{-2} \sum_{i=1}^{n} \left( \text{Bias }\hat{y}_{1i} \right)^{2}.
\end{array}
\]</span></p>
<p>Ahora, si <span class="math inline">\(\sigma^{2}\)</span> es conocido, a partir de la ecuación <a href="interpretación-de-resultados-de-regresión.html#eq:eq64">(6.4)</a>, una estimación no sesgada del error total estandarizado es <span class="math inline">\(p + \frac{(n-p)(s_{1}^{2} - \sigma^{2})}{\sigma^{2}}\)</span>. Como <span class="math inline">\(\sigma^{2}\)</span> es desconocido, debe estimarse. Si no estamos seguros de si el modelo largo o el corto es la representación apropiada, una opción conservadora es usar <span class="math inline">\(s^{2}\)</span> del modelo largo, o completo. Incluso si el modelo corto es el verdadero, <span class="math inline">\(s^{2}\)</span> del modelo largo sigue siendo una estimación no sesgada de <span class="math inline">\(\sigma^{2}\)</span>. Así, definimos</p>
<p><span class="math display">\[
C_{p} = p + \frac{(n-p)(s_{1}^{2} - s^{2})}{s^{2}}.
\]</span></p>
<p>Si el modelo corto es correcto, entonces <span class="math inline">\(\mathrm{E}~s_{1}^{2} = \mathrm{E}~s^{2} = \sigma^{2}\)</span> y <span class="math inline">\(\mathrm{E}~C_{p} \approx p\)</span>. Si el modelo largo es verdadero, entonces <span class="math inline">\(\mathrm{E}~s_{1}^{2} &gt; \sigma^{2}\)</span> y <span class="math inline">\(\mathrm{E}~C_{p} &gt; p\)</span>.</p>

<!-- # Chap 1 -->
<!-- # Chap 2 -->
<!-- # Chap 3 -->
<!-- # Chap 4 -->
<!-- # Chap 5 -->
<!-- # Chap 6 -->
</div>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="C5VarSelect.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="C7Trends.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": null,
"search": {
"engine": "fuse",
"options": null
},
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/latest.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
