<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapter 3 Multiple Linear Regression - I | Regression Modeling with Actuarial and Financial Applications</title>
  <meta name="description" content="Development of a research monograph that provides quantitative tools to assess the relevance of dependence in insurance risk management." />
  <meta name="generator" content="bookdown 0.39 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapter 3 Multiple Linear Regression - I | Regression Modeling with Actuarial and Financial Applications" />
  <meta property="og:type" content="book" />
  
  <meta property="og:description" content="Development of a research monograph that provides quantitative tools to assess the relevance of dependence in insurance risk management." />
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 3 Multiple Linear Regression - I | Regression Modeling with Actuarial and Financial Applications" />
  
  <meta name="twitter:description" content="Development of a research monograph that provides quantitative tools to assess the relevance of dependence in insurance risk management." />
  

<meta name="author" content="Edward (Jed) Frees, University of Wisconsin - Madison, Australian National University" />



  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="basic-regression.html"/>
<link rel="next" href="bibliography.html"/>
<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/anchor-sections-1.1.0/anchor-sections.css" rel="stylesheet" />
<link href="libs/anchor-sections-1.1.0/anchor-sections-hash.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.1.0/anchor-sections.js"></script>
<script src="libs/kePrint-0.0.1/kePrint.js"></script>
<link href="libs/lightable-0.0.1/lightable.css" rel="stylesheet" />
<link href="libs/bsTable-3.3.7/bootstrapTable.min.css" rel="stylesheet" />
<script src="libs/bsTable-3.3.7/bootstrapTable.js"></script>

<!-- Mathjax Version 2-->
<script type='text/x-mathjax-config'>
		MathJax.Hub.Config({
			extensions: ['tex2jax.js'],
			jax: ['input/TeX', 'output/HTML-CSS'],
			tex2jax: {
				inlineMath: [ ['$','$'], ['\\(','\\)'] ],
				displayMath: [ ['$$','$$'], ['\\[','\\]'] ],
				processEscapes: true
			},
			'HTML-CSS': { availableFonts: ['TeX'] }
		});
</script>

<script type="text/javascript"  src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/MathJax.js?config=TeX-AMS_HTML"> </script>

<script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
<script type="text/javascript" src="https://unpkg.com/survey-jquery/survey.jquery.min.js"></script>
<link href="https://unpkg.com/survey-jquery/modern.min.css" type="text/css" rel="stylesheet">
<script src="https://unpkg.com/showdown/dist/showdown.min.js"></script>


<!-- Various toggle functions used throughout --> 
<script language="javascript">
function toggle(id1,id2) {
	var ele = document.getElementById(id1); var text = document.getElementById(id2);
	if (ele.style.display == "block") {ele.style.display = "none"; text.innerHTML = "Show Solution";}
		else {ele.style.display = "block"; text.innerHTML = "Hide Solution";}}
function togglecode(id1,id2) {
   var ele = document.getElementById(id1); var text = document.getElementById(id2);
   if (ele.style.display == "block") {ele.style.display = "none"; text.innerHTML = "Show R Code";}
      else {ele.style.display = "block"; text.innerHTML = "Hide R Code";}}
function toggleEX(id1,id2) {
   var ele = document.getElementById(id1); var text = document.getElementById(id2);
   if (ele.style.display == "block") {ele.style.display = "none"; text.innerHTML = "Show Example";}
      else {ele.style.display = "block"; text.innerHTML = "Hide Example";}}
function toggleTheory(id1,id2) {
   var ele = document.getElementById(id1); var text = document.getElementById(id2);
   if (ele.style.display == "block") {ele.style.display = "none"; text.innerHTML = "Show Theory";}
      else {ele.style.display = "block"; text.innerHTML = "Hide Theory";}}
function toggleSolution(id1,id2) {
   var ele = document.getElementById(id1); var text = document.getElementById(id2);
   if (ele.style.display == "block") {ele.style.display = "none"; text.innerHTML = "Show Solution";}
      else {ele.style.display = "block"; text.innerHTML = "Hide Solution";}}      
function toggleQuiz(id1,id2) {
   var ele = document.getElementById(id1); var text = document.getElementById(id2);
   if (ele.style.display == "block") {ele.style.display = "none"; text.innerHTML = "Show Quiz Solution";}
      else {ele.style.display = "block"; text.innerHTML = "Hide Quiz Solution";}}      
</script>

<!-- A few functions for revealing definitions -->
<script language="javascript">
<!--   $( function() {
    $("#tabs").tabs();
  } ); -->

$(document).ready(function(){
    $('[data-toggle="tooltip"]').tooltip();
});

$(document).ready(function(){
    $('[data-toggle="popover"]').popover(); 
});
</script>

<script language="javascript">
function openTab(evt, tabName) {
    var i, tabcontent, tablinks;
    tabcontent = document.getElementsByClassName("tabcontent");
    for (i = 0; i < tabcontent.length; i++) {
        tabcontent[i].style.display = "none";
    }
    tablinks = document.getElementsByClassName("tablinks");
    for (i = 0; i < tablinks.length; i++) {
        tablinks[i].className = tablinks[i].className.replace(" active", "");
    }
    document.getElementById(tabName).style.display = "block";
    evt.currentTarget.className += " active";
}

// Get the element with id="defaultOpen" and click on it
document.getElementById("defaultOpen").click();
</script>



<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { color: #008000; } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { color: #008000; font-weight: bold; } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<style type="text/css">
  
  div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Regression Modeling With Actuarial and Financial Applications</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="it-takes-a-team.html"><a href="it-takes-a-team.html"><i class="fa fa-check"></i>It Takes a Team</a></li>
<li class="chapter" data-level="" data-path="preface.html"><a href="preface.html"><i class="fa fa-check"></i>Preface</a>
<ul>
<li class="chapter" data-level="" data-path="preface.html"><a href="preface.html#dedication"><i class="fa fa-check"></i>Dedication</a></li>
<li class="chapter" data-level="" data-path="preface.html"><a href="preface.html#forward"><i class="fa fa-check"></i>Forward</a>
<ul>
<li class="chapter" data-level="" data-path="preface.html"><a href="preface.html#who-is-this-book-for"><i class="fa fa-check"></i>Who Is This Book For?</a></li>
<li class="chapter" data-level="" data-path="preface.html"><a href="preface.html#what-is-this-book-about"><i class="fa fa-check"></i>What Is This Book About?</a></li>
<li class="chapter" data-level="" data-path="preface.html"><a href="preface.html#how-does-this-book-deliver-its-message"><i class="fa fa-check"></i>How Does This Book Deliver Its Message?</a></li>
<li class="chapter" data-level="" data-path="preface.html"><a href="preface.html#acknowledgements"><i class="fa fa-check"></i>Acknowledgements</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="1" data-path="regression-and-the-normal-distribution.html"><a href="regression-and-the-normal-distribution.html"><i class="fa fa-check"></i><b>1</b> Regression and the Normal Distribution</a>
<ul>
<li class="chapter" data-level="1.1" data-path="regression-and-the-normal-distribution.html"><a href="regression-and-the-normal-distribution.html#S1:Intro"><i class="fa fa-check"></i><b>1.1</b> What is Regression Analysis?</a></li>
<li class="chapter" data-level="1.2" data-path="regression-and-the-normal-distribution.html"><a href="regression-and-the-normal-distribution.html#fitting-data-to-a-normal-distribution"><i class="fa fa-check"></i><b>1.2</b> Fitting Data to a Normal Distribution</a></li>
<li class="chapter" data-level="1.3" data-path="regression-and-the-normal-distribution.html"><a href="regression-and-the-normal-distribution.html#S1:PowerTransforms"><i class="fa fa-check"></i><b>1.3</b> Power Transforms</a></li>
<li class="chapter" data-level="1.4" data-path="regression-and-the-normal-distribution.html"><a href="regression-and-the-normal-distribution.html#sampling-and-the-role-of-normality"><i class="fa fa-check"></i><b>1.4</b> Sampling and the Role of Normality</a></li>
<li class="chapter" data-level="1.5" data-path="regression-and-the-normal-distribution.html"><a href="regression-and-the-normal-distribution.html#regression-and-sampling-designs"><i class="fa fa-check"></i><b>1.5</b> Regression and Sampling Designs</a></li>
<li class="chapter" data-level="1.6" data-path="regression-and-the-normal-distribution.html"><a href="regression-and-the-normal-distribution.html#actuarial-applications-of-regression"><i class="fa fa-check"></i><b>1.6</b> Actuarial Applications of Regression</a></li>
<li class="chapter" data-level="1.7" data-path="regression-and-the-normal-distribution.html"><a href="regression-and-the-normal-distribution.html#further-reading-and-references"><i class="fa fa-check"></i><b>1.7</b> Further Reading and References</a></li>
<li class="chapter" data-level="1.8" data-path="regression-and-the-normal-distribution.html"><a href="regression-and-the-normal-distribution.html#exercises"><i class="fa fa-check"></i><b>1.8</b> Exercises</a></li>
<li class="chapter" data-level="1.9" data-path="regression-and-the-normal-distribution.html"><a href="regression-and-the-normal-distribution.html#S1:TechSupp"><i class="fa fa-check"></i><b>1.9</b> Technical Supplement - Central Limit Theorem</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="basic-regression.html"><a href="basic-regression.html"><i class="fa fa-check"></i><b>2</b> Basic Regression</a></li>
<li class="chapter" data-level="3" data-path="multiple-linear-regression---i.html"><a href="multiple-linear-regression---i.html"><i class="fa fa-check"></i><b>3</b> Multiple Linear Regression - I</a>
<ul>
<li class="chapter" data-level="3.1" data-path="multiple-linear-regression---i.html"><a href="multiple-linear-regression---i.html#S3:LSMethod"><i class="fa fa-check"></i><b>3.1</b> Method of Least Squares</a>
<ul>
<li class="chapter" data-level="" data-path="multiple-linear-regression---i.html"><a href="multiple-linear-regression---i.html#summarizing-the-data"><i class="fa fa-check"></i>Summarizing the Data</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="" data-path="bibliography.html"><a href="bibliography.html"><i class="fa fa-check"></i>Bibliography</a></li>
<li class="divider"></li>
<li><a href="https://github.com/OpenActTextDev/RegressionSpanish/" target="blank">Spanish Regression on GitHub</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Regression Modeling with Actuarial and Financial Applications</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="multiple-linear-regression---i" class="section level1 hasAnchor" number="3">
<h1><span class="header-section-number">Chapter 3</span> Multiple Linear Regression - I<a href="multiple-linear-regression---i.html#multiple-linear-regression---i" class="anchor-section" aria-label="Anchor link to header"></a></h1>
<p><em>Chapter Preview</em>. This chapter introduces linear
regression in the case of several explanatory variables, known as
. Many basic linear regression
concepts extend directly, including goodness of fit measures such as
<span class="math inline">\(R^2\)</span> and inference using <span class="math inline">\(t\)</span>-statistics. Multiple linear regression
models provide a framework for summarizing highly complex,
multivariate data. Because this framework requires only linearity in
the parameters, we are able to fit models that are nonlinear
functions of the explanatory variables, thus providing a wide scope
of potential applications.</p>
<div id="S3:LSMethod" class="section level2 hasAnchor" number="3.1">
<h2><span class="header-section-number">3.1</span> Method of Least Squares<a href="multiple-linear-regression---i.html#S3:LSMethod" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p></p>
<p>Chapter 2 dealt with the problem of a response depending on a single
explanatory variable. We now extend the focus of that chapter and study how
a response may depend on several explanatory variables.</p>
<p>
</p>
<p><strong>Example: Term Life Insurance.</strong>} Like all firms, life insurance companies continually seek new ways to deliver products to the market. Those involved in
product development wish to know ``who buys insurance and how much
do they buy?’’ In economics, this is known as side of
a market for products. Analysts can readily get information on
characteristics of current customers through company databases.
Potential customers, those that do not have insurance with the
company, are often the main focus for expanding market share.</p>
<p>In this example, we examine the Survey of Consumer Finances (SCF), a
nationally representative sample that contains extensive information
on assets, liabilities, income, and demographic characteristics of
those sampled (potential U.S. customers). We study a random sample
of 500 households with positive incomes that were interviewed in the
2004 survey. We initially consider the subset of <span class="math inline">\(n=275\)</span> families
that purchased term life insurance. We wish to address the second
portion of the demand question and determine family characteristics
that influence the amount of insurance purchased. Chapter 11 will
consider the first portion, whether or not a household purchases
insurance, through models where the response is a binary random
variable.</p>
<p>For term life insurance, the quantity of insurance is measured by
the policy FACE, the amount that the company will pay in the event
of the death of the named insured. Characteristics that will turn
out to be important include annual INCOME, the number of years of
EDUCATION of the survey respondent and the number of household
members, NUMHH.</p>
<p></p>
<p>In general, we will consider data sets where there are <span class="math inline">\(k\)</span>
explanatory variables and one response variable in a sample of size
<span class="math inline">\(n\)</span>. That is, the data consist of:</p>
<p>The <span class="math inline">\(i\)</span>th observation corresponds to the <span class="math inline">\(i\)</span>th row,
consisting of <span class="math inline">\((x_{i1},x_{i2},\ldots,x_{ik},y_i)\)</span>. For this general
case, we take <span class="math inline">\(k+1\)</span> measurements on each entity. For the insurance
demand example, <span class="math inline">\(k=3\)</span> and the data
consists of <span class="math inline">\((x_{11},x_{12},x_{13}, y_1)\)</span>, , <span class="math inline">\(% (x_{275,1},x_{275,2},x_{275,3},y_{275})\)</span>. That is, we use four
measurements from each of the <span class="math inline">\(n=275\)</span> households.</p>
<div id="summarizing-the-data" class="section level3 unnumbered hasAnchor">
<h3>Summarizing the Data<a href="multiple-linear-regression---i.html#summarizing-the-data" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>We begin the data analysis by examining each variable in isolation
of the others. Table <span class="math inline">\(\ref{T3:FaceSumStats}\)</span> provides basic summary
statistics of the four variables. For FACE and INCOME, we see that
the mean is much greater than the median, suggesting that the
distribution is skewed to the right. Histograms (not reported here)
show that this is the case. It will turn out to be useful to also
consider their logarithmic transforms, LNFACE and LNINCOME,
respectively, that are also reported in Table <span class="math inline">\(\ref{T3:FaceSumStats}\)</span>.</p>
<p>The next step is to measure the relationship between each <span class="math inline">\(x\)</span> on
<span class="math inline">\(y\)</span>, beginning with the scatter plots in Figure
<span class="math inline">\(\ref{F3:TermLifeTwoPlots}\)</span>. The left-hand panel is a plot of FACE
versus INCOME; with this panel, we see a large clustering in the
lower left-hand corner corresponding to households that have both
small incomes and face amounts of insurance. Both variables have
skewed distributions and their joint effect is highly nonlinear. The
right-hand panel presents the same variables but using logarithmic
transforms. Here, we see a relationship that can be more readily
approximated with a line.</p>
<p>The Term Life data are in the sense that several
measurements are taken on each household. It is difficult to produce
a graph of observations in three or more dimensions on a
two-dimensional platform, such as a piece of paper, that is not
confusing, misleading or both. To summarize graphically multivariate
data in regression applications, consider using a such as in Figure <span class="math inline">\(\ref{F3:TermLifeSMatrix}\)</span>. Each square of
this figure represents a simple plot of one variable versus another.
For each square, the row variable gives the units of the vertical
axis and the column variable gives the units of the horizontal axis.
The matrix is sometimes called a
because only the lower left-hand elements are presented.</p>
<p></p>
<p>The scatterplot matrix can be numerically summarized using a
correlation matrix. Each correlation in Table <span class="math inline">\(\ref{T3:Corr}\)</span>
corresponds to a square of the scatterplot matrix in Figure
<span class="math inline">\(\ref{F3:TermLifeSMatrix}\)</span>. Analysts often present tables of
correlations because they are easy to interpret. However, remember
that a correlation coefficient merely measures the extent of linear
relationships. Thus, a table of correlations provides a sense of
linear relationships but may miss a nonlinear relationship that can
be revealed in a scatterplot matrix.</p>
<p>The scatterplot matrix and corresponding correlation matrix are
useful devices for summarizing multivariate data. They are easy to
produce and to interpret. Still, each device captures only
relationships between pairs of variables and cannot quantify
relationships among several variables.</p>
<p>Consider the question: ``Can knowledge of education, household size
and income help us understand the demand for insurance?’’ The
correlations in Table <span class="math inline">\(\ref{T3:Corr}\)</span> and the graphs in Figures
<span class="math inline">\(\ref{F3:TermLifeTwoPlots}\)</span> and <span class="math inline">\(\ref{F3:TermLifeSMatrix}\)</span> suggest that
each variable, EDUCATION, NUMHH and LNINCOME, may be a useful
explanatory variable of LNFACE when taken individually. It seems
reasonable to investigate the effect of these variables
on a response.</p>
<p>The geometric concept of a is used to explore the
linear relationship between a response and several explanatory
variables. Recall that a plane extends the concept of a line to more
than two dimensions. A plane may be defined through an algebraic
equation such as
<span class="math display">\[\begin{equation*}
y = b_0 + b_1 x_1 + \ldots + b_k x_k.
\end{equation*}\]</span>
This equation defines a plane in <span class="math inline">\(k+1\)</span> dimensions. Figure
<span class="math inline">\(\ref{F3:3DPlane}\)</span> shows a plane in three dimensions. For this figure,
there is one response variable, LNFACE, and two explanatory
variables, EDUCATION and LNINCOME (NUMHH is held fixed). It is
difficult to graph more than three dimensions in a meaningful way.</p>
<p>We need a way to determine a plane based on the data. The difficulty
is that in most regression analysis applications, the number of
observations, <span class="math inline">\(n\)</span>, far exceeds the number of observations required
to fit a plane, <span class="math inline">\(k+1\)</span>. Thus, it is generally not possible to find a
single plane that passes through all <span class="math inline">\(n\)</span> observations. As in Chapter
2, we use the to determine a plane
from the data.</p>
<p>The method of least squares is based on determining the values of $
b_0<sup>{},b_1</sup>{},,b_k^{}$ that minimize the quantity
<span class="math display">\[\begin{equation}\label{E3:SSBasic}
SS(b_0^{\ast},b_1^{\ast},\ldots,b_k^{\ast})=\sum_{i=1}^{n}\left(
y_i-\left(
b_0^{\ast}+b_1^{\ast}x_{i1}+\ldots+b_k^{\ast}x_{ik}\right) \right)
^2.
\end{equation}\]</span>
We drop the asterisk, or star, notation and use <span class="math inline">\(b_0, b_1, \ldots, b_k\)</span> to denote the best values, known as the . With the least squares estimates, define the as
<span class="math display">\[\begin{equation*}
\widehat{y} = b_0 + b_1 x_1 + \ldots + b_k x_k.
\end{equation*}\]</span></p>
<p>The least squares estimates are determined by minimizing
<span class="math inline">\(SS(b_0^{\ast},b_1^{\ast},\ldots,b_k^{\ast})\)</span>. It is difficult to
write down the resulting least squares estimators using a simple
formula unless one resorts to matrix notation. Because of their
importance in applied statistical models, an explicit formula for
the estimators is provided below. However, these formulas have been
programmed into a wide variety of statistical and spreadsheet
software packages. The fact that these packages are readily
available allows data analysts to concentrate on the ideas of the
estimation procedure instead of focusing on the details of the
calculation procedures.</p>
<p>As an example, a regression plane was fit to the Term Life data
where three explanatory variables, <span class="math inline">\(x_1\)</span> for EDUCATION, <span class="math inline">\(x_2\)</span> for
NUMHH and <span class="math inline">\(x_3\)</span> for LNINCOME, were used. The resulting fitted
regression plane is</p>
<p><span class="math display">\[\begin{equation}\label{E3:TermRegression}
\widehat{y} = 2.584 + 0.206 x_1 + 0.306 x_2 + 0.494 x_3.
\end{equation}\]</span></p>
<p></p>
<p>Assume that the data are of the form
<span class="math inline">\((x_{i0},x_{i1},\ldots,x_{ik},y_i)\)</span>, where <span class="math inline">\(i = 1, \ldots, n\)</span>. Here,
the variable <span class="math inline">\(x_{i0}\)</span> is associated with the ``intercept’’ term. That
is, in most applications, we assume that <span class="math inline">\(x_{i0}\)</span> is identically
equal to 1 and thus need not be explicitly represented. However,
there are important applications where this is not the case and
thus, to express the model in general notation, it is included here.
The data are represented in matrix notation using</p>
<p><span class="math display">\[\begin{equation*}
\mathbf{y}=\left(
\begin{array}{l}
y_1 \\
y_2 \\
\multicolumn{1}{c}{\vdots} \\
y_n%
\end{array}%
\right) ~~~\mathrm{and}~~~\mathbf{X}=\left(
\begin{array}{cccc}
x_{10} &amp; x_{11} &amp; \cdots &amp; x_{1k} \\
x_{20} &amp; x_{21} &amp; \cdots &amp; x_{2k} \\
\vdots &amp; \vdots &amp; \ddots &amp; \vdots \\
x_{n0} &amp; x_{n1} &amp; \cdots &amp; x_{nk}%
\end{array}%
\right) .
\end{equation*}\]</span>%
Here, is the <span class="math inline">\(n\times 1\)</span> vector of responses and
is the <span class="math inline">\(n\times (k+1)\)</span> matrix of explanatory variables.
We use the matrix algebra convention that lower and upper case bold
letters represent vectors and matrices, respectively. (If you need
to brush up on matrices, review Section 2.11.)</p>
<p> Recall that <span class="math inline">\(y\)</span>
represents the logarithmic face, <span class="math inline">\(x_1\)</span> for years of education, <span class="math inline">\(x_2\)</span>
for number of household members and <span class="math inline">\(x_3\)</span> for logarithmic income.
Thus, there are <span class="math inline">\(k=3\)</span> explanatory variables and <span class="math inline">\(n=275\)</span> households.
The vector of responses and the matrix of explanatory variables are:</p>
<p><span class="math display">\[\begin{equation*}
\mathbf{y}=\left(
\begin{array}{l}
y_1 \\
y_2 \\
\multicolumn{1}{c}{\vdots} \\
y_{275}%
\end{array}%
\right) =\left(
\begin{array}{c}
9.904 \\
11.775 \\
\vdots \\
9.210
\end{array}%
\right) ~~~\mathrm{and}~~~\mathbf{X}=\left(
\begin{array}{cccc}
1 &amp; x_{11} &amp; x_{12} &amp; x_{13} \\
1 &amp; x_{21} &amp; x_{22} &amp; x_{23}\\
\vdots &amp; \vdots &amp; \vdots &amp;\vdots\\
1 &amp; x_{275,1} &amp; x_{275,2} &amp; x_{275,3}%
\end{array}%
\right) =\left(
\begin{array}{cccc}
1 &amp; 16 &amp; 3  &amp; 10.669\\
1 &amp; 9 &amp; 3 &amp; 9.393\\
\vdots &amp; \vdots &amp; \vdots &amp;\vdots\\
1 &amp; 12 &amp; 1 &amp; 10.545%
\end{array}%
\right) .
\end{equation*}\]</span>
</p>
<p>For example, for the first observation in the data set,
the dependent variable is <span class="math inline">\(y_1\)</span>=9.904 (corresponding to
<span class="math inline">\(\textrm{exp}(9.904)= \$ 20,000\)</span>), for a survey respondent with 16
years of education living in a household with 3 people with
logarithmic income of 10.669 (<span class="math inline">\(\exp (10.669)= \$ 43,000)\)</span>.</p>
<p>Under the least squares estimation principle, our goal is to choose
the coefficients <span class="math inline">\(b_0^{\ast},b_1^{\ast},\ldots,b_k^{\ast}\)</span> to
minimize the sum of squares function
<span class="math inline">\(SS(b_0^{\ast},b_1^{\ast},\ldots,b_k^{\ast})\)</span>. Using calculus, we
return to equation (<span class="math inline">\(\ref{E3:SSBasic}\)</span>), take partial derivatives with
respect to each coefficient and set these quantities equal to zero:
<span class="math display">\[\begin{equation*}
\frac{\partial }{\partial
b_j^{\ast}}SS(b_0^{\ast},b_1^{\ast},\ldots,b_k^{\ast})=\sum_{i=1}^{n}\left(
-2x_{ij}\right) \left( y_i-\left(
b_0^{\ast}+b_1^{\ast}x_{i1}+\ldots+b_k^{\ast}x_{ik}\right) \right)
=0,~~~\mathrm{for}~~j=0,1,\ldots .,k.
\end{equation*}\]</span>
This is a system of <span class="math inline">\(k+1\)</span> equations and <span class="math inline">\(k+1\)</span> unknowns that can be readily
solved using matrix notation, as follows.</p>
<p>We may express the vector of parameters to be minimized as
<span class="math inline">\(\mathbf{b}^{\ast}=(b_0^{\ast},b_1^{\ast},\ldots,b_k^{\ast})^{\prime}\)</span>.
Using this,
the sum of squares can be written as <span class="math inline">\(SS(\mathbf{b}^{\ast})=(\mathbf{y-Xb}% ^{\ast})^{\prime}(\mathbf{y-Xb}^{\ast}).\)</span> Thus, in matrix form, the
solution to the minimization problem can be expressed as <span class="math inline">\((\partial /\partial \mathbf{b}^{\ast})SS(\mathbf{b}^{\ast})=\mathbf{0}\)</span>. This
solution satisfies the
<span class="math display">\[\begin{equation}\label{E3:NormalEquations}
\mathbf{X^{\prime}Xb}=\mathbf{X}^{\prime}\mathbf{y}.
\end{equation}\]</span>
Here, the asterisk notation (*) has been dropped to denote the fact that <span class="math inline">\(% \mathbf{b}=(b_0,b_1,\ldots,b_k)^{\prime}\)</span> represents the best vector
of values in the
sense of minimizing <span class="math inline">\(SS(\mathbf{b}^{\ast})\)</span> over all choices of <span class="math inline">\(\mathbf{b}% ^{\ast}\)</span>.</p>
<p>The least squares estimator <span class="math inline">\(\mathbf{b}\)</span> need not be unique.
However, assuming that the explanatory variables are not linear
combinations of one another, we have that <span class="math inline">\(\mathbf{X^{\prime}X}\)</span> is
invertible. In this case, we can write the unique solution as
<span class="math display">\[\begin{equation}\label{E3:LSEstimates}
\mathbf{b}=\left( \mathbf{X^{\prime}X}\right) ^{-1}\mathbf{X}^{\prime}%
\mathbf{y}.
\end{equation}\]</span></p>
<p>To illustrate, for the Term Life example, equation
(<span class="math inline">\(\ref{E3:TermRegression}\)</span>) yields
<span class="math display">\[\begin{equation*}
\mathbf{b} = \left(
\begin{array}{c}
b_0 \\ b_1 \\ b_2 \\ b_3 \\
\end{array}
\right) = \left(
\begin{array}{c}
2.584 \\ 0.206 \\ 0.306 \\ 0.494 \\
\end{array}
\right).
\end{equation*}\]</span></p>
<p>In the previous section, we learned how to use the method of least
squares to fit a regression plane with a data set. This section
describes the assumptions underpinning the regression model and some
of the resulting properties of the regression coefficient
estimators. With the model and the fitted data, we will be able to
draw inferences about the sample data set to a larger population.
Moreover, we will later use these regression model assumptions to
help us improve the model specification in Chapter 5.</p>
<p>Most of the assumptions of the multiple linear regression model will
carry over directly from the basic linear regression model
assumptions introduced in Section 2.2. The primary difference is
that we now summarize the relationship between the response and the
explanatory variables through the </p>
<p><span class="math display">\[\begin{equation}\label{E3:MLRegressionFct}
\mathrm{E~}y=\beta_0 x_0+\beta_1 x_1+\ldots+\beta_k x_k,
\end{equation}\]</span>%
that is linear in the parameters <span class="math inline">\(\beta_0,\ldots ,\beta_k\)</span>.
Henceforth, we will use <span class="math inline">\(x_0=1\)</span> for the variable associated with the
parameter <span class="math inline">\(\beta_0;\)</span> this is the default in most statistical
packages and most applications of regression include the intercept
term <span class="math inline">\(\beta_0\)</span>. The intercept is the expected value of <span class="math inline">\(y\)</span> when all
of the explanatory variables are equal to zero. Although rarely of
interest, the term <span class="math inline">\(\beta_0\)</span> serves to set the height of the fitted
regression plane.</p>
<p></p>
<p>In contrast, the other betas are typically important parameters from
a regression study. To help interpret them, we initially assume that
<span class="math inline">\(x_j\)</span> varies continuously and is not related to the other
explanatory variables. Then, we can interpret <span class="math inline">\(\beta_j\)</span> as the
expected change in <span class="math inline">\(y\)</span> per unit change in <span class="math inline">\(x_j\)</span> . That is, from calculus,
you will recognize that <span class="math inline">\(\beta_j\)</span> can be interpreted as a partial
derivative. Specifically, using equation (<span class="math inline">\(\ref{E3:MLRegressionFct}\)</span>),
we have that
<span class="math display">\[\begin{equation*}
\beta_j=\frac{\partial }{\partial x_j}\mathrm{E}~y.
\end{equation*}\]</span></p>
<p></p>
<p>Let us examine the regression coefficient estimates from the Term
Life Insurance example and focus initially on the of the
coefficients. For example, from equation (<span class="math inline">\(\ref{E3:TermRegression}\)</span>),
the coefficient associated with NUMHH is <span class="math inline">\(b_2 = 0.306&gt;0\)</span>. If we
consider two households that have the same income and the same level
of education, then the larger household (in terms of NUMHH) is
expected to demand term life insurance under the
regression model. This is a sensible interpretation, larger
households have more dependents for which term life insurance can
provide needed financial assets in the event of the untimely death
of a breadwinner. The positive coefficient associated with income
(<span class="math inline">\(b_3 = 0.494\)</span>) is also plausible; households with larger incomes
have more disposable dollars to purchase insurance. The positive
sign associated with EDUCATION (<span class="math inline">\(b_1 = 0.206)\)</span> is also reasonable,
more education suggests that respondents are more aware of their
insurance needs, other things being equal.</p>
You will also need to interpret the of the regression
coefficient. Consider first the EDUCATION coefficient. Using
equation (<span class="math inline">\(\ref{E3:TermRegression}\)</span>), fitted values of
<span class="math inline">\(\widehat{LNFACE}\)</span> were calculated by allowing EDUCATION to vary and
keeping NUMHH and LNINCOME fixed at the sample averages. The results
are:
<p>As EDUCATION increases, <span class="math inline">\(\widehat{LNFACE}\)</span> increases.
Further, the amount of <span class="math inline">\(\widehat{LNFACE}\)</span> increase is a constant
0.0206. This comes directly from equation (<span class="math inline">\(\ref{E3:TermRegression}\)</span>);
as EDUCATION increases by 0.1 years, we expect the demand for
insurance to increase by 0.0206 logarithmic dollars, holding NUMHH
and LNINCOME fixed. This interpretation is correct but most product
development directors are not overly fond of logarithmic dollars. To
return to dollars, fitted face values can be calculated through
exponentiation as $ =()$.
Moreover, the percentage change can be computed; for example,
$100*(147,817/144,803 - 1) % $. This provides another
interpretation of the regression coefficient; as EDUCATION increases
by 0.1 years, we expect the demand for insurance to increase by
2.08%. This is a simple consequence of calculus using $
~y /
x = (y / x ) / y$; that is, a
small change in the logarithmic value of <span class="math inline">\(y\)</span> equals a small change
in <span class="math inline">\(y\)</span> as a proportion of <span class="math inline">\(y\)</span>. It is because of this calculus result
that we use natural logs instead of common logs in regression
analysis. Because this table uses a discrete change in EDUCATION,
the 2.08% differs slightly from the continuous result <span class="math inline">\(0.206 \times (\mathrm{change~in~EDUCATION}) = 2.06\%\)</span>. However, this proximity is
usually regarded as suitable for interpretation purposes.</p>
<p>Continuing this logic, consider small changes in logarithmic income.</p>
<p></p>
<p>We can use the same logic to interpret the LNINCOME
coefficient in equation (<span class="math inline">\(\ref{E3:TermRegression}\)</span>). As logarithmic
income increases by 0.1 units, we expect the demand for insurance to
increase by 5.06%. This takes care of logarithmic units in the <span class="math inline">\(y\)</span>
but not the <span class="math inline">\(x\)</span>. We can use the same logic to say that as
logarithmic income increases by 0.1 units, INCOME increases by
10.52%. Thus, a 10.52% change in INCOME corresponds to a 5.06%
change in FACE. Summarizing, we say that, holding NUMHH and
EDUCATION fixed, we expect that a 1% increase in INCOME is
associated with a 0.482% increase in <span class="math inline">\(\widehat{FACE}\)</span> (as before,
this is close to the parameter estimate <span class="math inline">\(b_3 = 0.494\)</span>). The
coefficient associated with income is known as an
in economics. In economics, elasticity is the ratio of the percent
change in one variable to the percent change in another variable.
Mathematically, we summarize this as
<span class="math display">\[\begin{equation*}
\frac{\partial \textrm{ln} ~y}{\partial \textrm{ln} ~x} =
\left(\frac{\partial ~y}{y}\right)/\left(\frac{\partial
~x}{x}\right).
\end{equation*}\]</span></p>

</div>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="basic-regression.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="bibliography.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": null,
"search": {
"engine": "fuse",
"options": null
},
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/latest.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
