<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapter 11 Variables Dependientes Categóricas | Modelado de Regresión con Aplicaciones Actuariales y Financieras</title>
  <meta name="description" content="Spanish Translation of ‘Regression Modeling with Actuarial and Financial Applications’" />
  <meta name="generator" content="bookdown 0.39 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapter 11 Variables Dependientes Categóricas | Modelado de Regresión con Aplicaciones Actuariales y Financieras" />
  <meta property="og:type" content="book" />
  
  <meta property="og:description" content="Spanish Translation of ‘Regression Modeling with Actuarial and Financial Applications’" />
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 11 Variables Dependientes Categóricas | Modelado de Regresión con Aplicaciones Actuariales y Financieras" />
  
  <meta name="twitter:description" content="Spanish Translation of ‘Regression Modeling with Actuarial and Financial Applications’" />
  

<meta name="author" content="Edward (Jed) Frees, University of Wisconsin - Madison, Australian National University" />



  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="chap-10.html"/>
<link rel="next" href="C12Count.html"/>
<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/anchor-sections-1.1.0/anchor-sections.css" rel="stylesheet" />
<link href="libs/anchor-sections-1.1.0/anchor-sections-hash.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.1.0/anchor-sections.js"></script>
<script src="libs/kePrint-0.0.1/kePrint.js"></script>
<link href="libs/lightable-0.0.1/lightable.css" rel="stylesheet" />

<!-- Mathjax Version 2-->
<script type='text/x-mathjax-config'>
		MathJax.Hub.Config({
			extensions: ['tex2jax.js'],
			jax: ['input/TeX', 'output/HTML-CSS'],
			tex2jax: {
				inlineMath: [ ['$','$'], ['\\(','\\)'] ],
				displayMath: [ ['$$','$$'], ['\\[','\\]'] ],
				processEscapes: true
			},
			'HTML-CSS': { availableFonts: ['TeX'] }
		});
</script>

<script type="text/javascript"  src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/MathJax.js?config=TeX-AMS_HTML"> </script>

<script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
<script type="text/javascript" src="https://unpkg.com/survey-jquery/survey.jquery.min.js"></script>
<link href="https://unpkg.com/survey-jquery/modern.min.css" type="text/css" rel="stylesheet">
<script src="https://unpkg.com/showdown/dist/showdown.min.js"></script>


<!-- Various toggle functions used throughout --> 
<script language="javascript">
function toggle(id1,id2) {
	var ele = document.getElementById(id1); var text = document.getElementById(id2);
	if (ele.style.display == "block") {ele.style.display = "none"; text.innerHTML = "Show Solution";}
		else {ele.style.display = "block"; text.innerHTML = "Hide Solution";}}
function togglecode(id1,id2) {
   var ele = document.getElementById(id1); var text = document.getElementById(id2);
   if (ele.style.display == "block") {ele.style.display = "none"; text.innerHTML = "Show R Code";}
      else {ele.style.display = "block"; text.innerHTML = "Hide R Code";}}
function toggleEX(id1,id2) {
   var ele = document.getElementById(id1); var text = document.getElementById(id2);
   if (ele.style.display == "block") {ele.style.display = "none"; text.innerHTML = "Show Example";}
      else {ele.style.display = "block"; text.innerHTML = "Hide Example";}}
function toggleTheory(id1,id2) {
   var ele = document.getElementById(id1); var text = document.getElementById(id2);
   if (ele.style.display == "block") {ele.style.display = "none"; text.innerHTML = "Show Theory";}
      else {ele.style.display = "block"; text.innerHTML = "Hide Theory";}}
function toggleSolution(id1,id2) {
   var ele = document.getElementById(id1); var text = document.getElementById(id2);
   if (ele.style.display == "block") {ele.style.display = "none"; text.innerHTML = "Show Solution";}
      else {ele.style.display = "block"; text.innerHTML = "Hide Solution";}}      
function toggleQuiz(id1,id2) {
   var ele = document.getElementById(id1); var text = document.getElementById(id2);
   if (ele.style.display == "block") {ele.style.display = "none"; text.innerHTML = "Show Quiz Solution";}
      else {ele.style.display = "block"; text.innerHTML = "Hide Quiz Solution";}}      
</script>

<!-- A few functions for revealing definitions -->
<script language="javascript">
<!--   $( function() {
    $("#tabs").tabs();
  } ); -->

$(document).ready(function(){
    $('[data-toggle="tooltip"]').tooltip();
});

$(document).ready(function(){
    $('[data-toggle="popover"]').popover(); 
});
</script>

<script language="javascript">
function openTab(evt, tabName) {
    var i, tabcontent, tablinks;
    tabcontent = document.getElementsByClassName("tabcontent");
    for (i = 0; i < tabcontent.length; i++) {
        tabcontent[i].style.display = "none";
    }
    tablinks = document.getElementsByClassName("tablinks");
    for (i = 0; i < tablinks.length; i++) {
        tablinks[i].className = tablinks[i].className.replace(" active", "");
    }
    document.getElementById(tabName).style.display = "block";
    evt.currentTarget.className += " active";
}

// Get the element with id="defaultOpen" and click on it
document.getElementById("defaultOpen").click();
</script>



<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { color: #008000; } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { color: #008000; font-weight: bold; } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<style type="text/css">
  
  div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Regression Modeling With Actuarial and Financial Applications</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Prefacio</a>
<ul>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#prólogo"><i class="fa fa-check"></i>Prólogo</a>
<ul>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#para-quién-es-este-libro"><i class="fa fa-check"></i>¿Para Quién Es Este Libro?</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#de-qué-trata-este-libro"><i class="fa fa-check"></i>¿De Qué Trata Este Libro?</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#cómo-transmite-este-libro-su-mensaje"><i class="fa fa-check"></i>¿Cómo Transmite Este Libro Su Mensaje?</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#agradecimientos"><i class="fa fa-check"></i>Agradecimientos</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#dedicación"><i class="fa fa-check"></i>Dedicación</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="translation.html"><a href="translation.html"><i class="fa fa-check"></i>Translation</a></li>
<li class="chapter" data-level="1" data-path="regresión-y-la-distribución-normal.html"><a href="regresión-y-la-distribución-normal.html"><i class="fa fa-check"></i><b>1</b> Regresión y la Distribución Normal</a>
<ul>
<li class="chapter" data-level="1.1" data-path="regresión-y-la-distribución-normal.html"><a href="regresión-y-la-distribución-normal.html#Sec11"><i class="fa fa-check"></i><b>1.1</b> ¿Qué es el Análisis de Regresión?</a></li>
<li class="chapter" data-level="1.2" data-path="regresión-y-la-distribución-normal.html"><a href="regresión-y-la-distribución-normal.html#Sec12"><i class="fa fa-check"></i><b>1.2</b> Ajuste de Datos a una Distribución Normal</a></li>
<li class="chapter" data-level="1.3" data-path="regresión-y-la-distribución-normal.html"><a href="regresión-y-la-distribución-normal.html#Sec13"><i class="fa fa-check"></i><b>1.3</b> Transformaciones de Potencia</a></li>
<li class="chapter" data-level="1.4" data-path="regresión-y-la-distribución-normal.html"><a href="regresión-y-la-distribución-normal.html#Sec14"><i class="fa fa-check"></i><b>1.4</b> Muestreo y el Papel de la Normalidad</a></li>
<li class="chapter" data-level="1.5" data-path="regresión-y-la-distribución-normal.html"><a href="regresión-y-la-distribución-normal.html#Sec15"><i class="fa fa-check"></i><b>1.5</b> Regresión y Diseños de Muestreo</a></li>
<li class="chapter" data-level="1.6" data-path="regresión-y-la-distribución-normal.html"><a href="regresión-y-la-distribución-normal.html#Sec16"><i class="fa fa-check"></i><b>1.6</b> Aplicaciones Actuariales de la Regresión</a></li>
<li class="chapter" data-level="1.7" data-path="regresión-y-la-distribución-normal.html"><a href="regresión-y-la-distribución-normal.html#Sec17"><i class="fa fa-check"></i><b>1.7</b> Lecturas Adicionales y Referencias</a></li>
<li class="chapter" data-level="1.8" data-path="regresión-y-la-distribución-normal.html"><a href="regresión-y-la-distribución-normal.html#Sec18"><i class="fa fa-check"></i><b>1.8</b> Ejercicios</a></li>
<li class="chapter" data-level="1.9" data-path="regresión-y-la-distribución-normal.html"><a href="regresión-y-la-distribución-normal.html#Sec19"><i class="fa fa-check"></i><b>1.9</b> Suplemento Técnico - Teorema del Límite Central</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="C2BasicLR.html"><a href="C2BasicLR.html"><i class="fa fa-check"></i><b>2</b> Regresión Lineal Básica</a>
<ul>
<li class="chapter" data-level="2.1" data-path="C2BasicLR.html"><a href="C2BasicLR.html#Sec21"><i class="fa fa-check"></i><b>2.1</b> Correlaciones y Mínimos Cuadrados</a></li>
<li class="chapter" data-level="2.2" data-path="C2BasicLR.html"><a href="C2BasicLR.html#Sec22"><i class="fa fa-check"></i><b>2.2</b> Modelo Básico de Regresión Lineal</a></li>
<li class="chapter" data-level="2.3" data-path="C2BasicLR.html"><a href="C2BasicLR.html#Sec23"><i class="fa fa-check"></i><b>2.3</b> ¿Es Útil el Modelo? Algunas Medidas de Resumen Básicas</a>
<ul>
<li class="chapter" data-level="2.3.1" data-path="C2BasicLR.html"><a href="C2BasicLR.html#Sec231"><i class="fa fa-check"></i><b>2.3.1</b> Particionando la Variabilidad</a></li>
<li class="chapter" data-level="2.3.2" data-path="C2BasicLR.html"><a href="C2BasicLR.html#Sec232"><i class="fa fa-check"></i><b>2.3.2</b> El Tamaño de una Desviación Típica: <em>s</em></a></li>
</ul></li>
<li class="chapter" data-level="2.4" data-path="C2BasicLR.html"><a href="C2BasicLR.html#Sec24"><i class="fa fa-check"></i><b>2.4</b> Propiedades de los Estimadores del Coeficiente de Regresión</a></li>
<li class="chapter" data-level="2.5" data-path="C2BasicLR.html"><a href="C2BasicLR.html#Sec25"><i class="fa fa-check"></i><b>2.5</b> Inferencia Estadística</a>
<ul>
<li class="chapter" data-level="2.5.1" data-path="C2BasicLR.html"><a href="C2BasicLR.html#Sec251"><i class="fa fa-check"></i><b>2.5.1</b> ¿Es Importante la Variable Explicativa?: La Prueba <em>t</em></a></li>
<li class="chapter" data-level="2.5.2" data-path="C2BasicLR.html"><a href="C2BasicLR.html#Sec252"><i class="fa fa-check"></i><b>2.5.2</b> Intervalos de Confianza</a></li>
<li class="chapter" data-level="2.5.3" data-path="C2BasicLR.html"><a href="C2BasicLR.html#Sec253"><i class="fa fa-check"></i><b>2.5.3</b> Intervalos de Predicción</a></li>
</ul></li>
<li class="chapter" data-level="2.6" data-path="C2BasicLR.html"><a href="C2BasicLR.html#Sec26"><i class="fa fa-check"></i><b>2.6</b> Construyendo un Mejor Modelo: Análisis de Residuos</a></li>
<li class="chapter" data-level="2.7" data-path="C2BasicLR.html"><a href="C2BasicLR.html#Sec27"><i class="fa fa-check"></i><b>2.7</b> Aplicación: Modelo de Valoración de Activos Financieros</a></li>
<li class="chapter" data-level="2.8" data-path="C2BasicLR.html"><a href="C2BasicLR.html#Sec28"><i class="fa fa-check"></i><b>2.8</b> Salida Computacional Ilustrativa de Regresión</a></li>
<li class="chapter" data-level="2.9" data-path="C2BasicLR.html"><a href="C2BasicLR.html#Sec29"><i class="fa fa-check"></i><b>2.9</b> Lecturas Adicionales y Referencias</a></li>
<li class="chapter" data-level="2.10" data-path="C2BasicLR.html"><a href="C2BasicLR.html#Sec210"><i class="fa fa-check"></i><b>2.10</b> Ejercicios</a></li>
<li class="chapter" data-level="2.11" data-path="C2BasicLR.html"><a href="C2BasicLR.html#Sec211"><i class="fa fa-check"></i><b>2.11</b> Suplemento Técnico - Elementos del Álgebra de Matrices</a>
<ul>
<li class="chapter" data-level="2.11.1" data-path="C2BasicLR.html"><a href="C2BasicLR.html#Sec2111"><i class="fa fa-check"></i><b>2.11.1</b> Definiciones Básicas</a></li>
<li class="chapter" data-level="2.11.2" data-path="C2BasicLR.html"><a href="C2BasicLR.html#Sec2112"><i class="fa fa-check"></i><b>2.11.2</b> Algunas Matrices Especiales</a></li>
<li class="chapter" data-level="2.11.3" data-path="C2BasicLR.html"><a href="C2BasicLR.html#Sec2113"><i class="fa fa-check"></i><b>2.11.3</b> Operaciones Básicas</a></li>
<li class="chapter" data-level="2.11.4" data-path="C2BasicLR.html"><a href="C2BasicLR.html#Sec2114"><i class="fa fa-check"></i><b>2.11.4</b> Matrices Aleatorias</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="3" data-path="C3BasicMLR.html"><a href="C3BasicMLR.html"><i class="fa fa-check"></i><b>3</b> Regresión Lineal Múltiple - I</a>
<ul>
<li class="chapter" data-level="3.1" data-path="C3BasicMLR.html"><a href="C3BasicMLR.html#Sec31"><i class="fa fa-check"></i><b>3.1</b> Método de Mínimos Cuadrados</a></li>
<li class="chapter" data-level="3.2" data-path="C3BasicMLR.html"><a href="C3BasicMLR.html#Sec32"><i class="fa fa-check"></i><b>3.2</b> Modelo de Regresión Lineal y Propiedades de los Estimadores</a>
<ul>
<li class="chapter" data-level="3.2.1" data-path="C3BasicMLR.html"><a href="C3BasicMLR.html#Sec321"><i class="fa fa-check"></i><b>3.2.1</b> Función de Regresión</a></li>
<li class="chapter" data-level="3.2.2" data-path="C3BasicMLR.html"><a href="C3BasicMLR.html#Sec322"><i class="fa fa-check"></i><b>3.2.2</b> Interpretación del Coeficiente de Regresión</a></li>
<li class="chapter" data-level="3.2.3" data-path="C3BasicMLR.html"><a href="C3BasicMLR.html#Sec323"><i class="fa fa-check"></i><b>3.2.3</b> Suposiciones del Modelo</a></li>
<li class="chapter" data-level="3.2.4" data-path="C3BasicMLR.html"><a href="C3BasicMLR.html#Sec324"><i class="fa fa-check"></i><b>3.2.4</b> Propiedades de los Estimadores de los Coeficientes de Regresión</a></li>
</ul></li>
<li class="chapter" data-level="3.3" data-path="C3BasicMLR.html"><a href="C3BasicMLR.html#Sec33"><i class="fa fa-check"></i><b>3.3</b> Estimación y Bondad de Ajuste</a></li>
<li class="chapter" data-level="3.4" data-path="C3BasicMLR.html"><a href="C3BasicMLR.html#Sec34"><i class="fa fa-check"></i><b>3.4</b> Inferencia Estadística para un Coeficiente Único</a>
<ul>
<li class="chapter" data-level="3.4.1" data-path="C3BasicMLR.html"><a href="C3BasicMLR.html#Sec341"><i class="fa fa-check"></i><b>3.4.1</b> La Prueba <em>t</em></a></li>
<li class="chapter" data-level="3.4.2" data-path="C3BasicMLR.html"><a href="C3BasicMLR.html#Sec342"><i class="fa fa-check"></i><b>3.4.2</b> Intervalos de Confianza</a></li>
<li class="chapter" data-level="3.4.3" data-path="C3BasicMLR.html"><a href="C3BasicMLR.html#Sec343"><i class="fa fa-check"></i><b>3.4.3</b> Gráficos de Variables Añadidas</a></li>
<li class="chapter" data-level="3.4.4" data-path="C3BasicMLR.html"><a href="C3BasicMLR.html#Sec344"><i class="fa fa-check"></i><b>3.4.4</b> Coeficientes de Correlación Parcial</a></li>
</ul></li>
<li class="chapter" data-level="3.5" data-path="C3BasicMLR.html"><a href="C3BasicMLR.html#Sec35"><i class="fa fa-check"></i><b>3.5</b> Algunas Variables Explicativas Especiales</a>
<ul>
<li class="chapter" data-level="3.5.1" data-path="C3BasicMLR.html"><a href="C3BasicMLR.html#Sec351"><i class="fa fa-check"></i><b>3.5.1</b> Variables Binarias</a></li>
<li class="chapter" data-level="3.5.2" data-path="C3BasicMLR.html"><a href="C3BasicMLR.html#Sec352"><i class="fa fa-check"></i><b>3.5.2</b> Transformación de Variables Explicativas</a></li>
<li class="chapter" data-level="3.5.3" data-path="C3BasicMLR.html"><a href="C3BasicMLR.html#Sec353"><i class="fa fa-check"></i><b>3.5.3</b> Términos de Interacción</a></li>
</ul></li>
<li class="chapter" data-level="3.6" data-path="C3BasicMLR.html"><a href="C3BasicMLR.html#Sec36"><i class="fa fa-check"></i><b>3.6</b> Lectura Adicional y Referencias</a></li>
<li class="chapter" data-level="3.7" data-path="C3BasicMLR.html"><a href="C3BasicMLR.html#Sec37"><i class="fa fa-check"></i><b>3.7</b> Ejercicios</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="C4MLRANOVA.html"><a href="C4MLRANOVA.html"><i class="fa fa-check"></i><b>4</b> Regresión Lineal Múltiple - II</a>
<ul>
<li class="chapter" data-level="4.1" data-path="C4MLRANOVA.html"><a href="C4MLRANOVA.html#Sec41"><i class="fa fa-check"></i><b>4.1</b> El Papel de las Variables Binarias</a></li>
<li class="chapter" data-level="4.2" data-path="C4MLRANOVA.html"><a href="C4MLRANOVA.html#Sec42"><i class="fa fa-check"></i><b>4.2</b> Inferencia Estadística para Varios Coeficientes</a>
<ul>
<li class="chapter" data-level="4.2.1" data-path="C4MLRANOVA.html"><a href="C4MLRANOVA.html#Sec421"><i class="fa fa-check"></i><b>4.2.1</b> Conjuntos de Coeficientes de Regresión</a></li>
<li class="chapter" data-level="4.2.2" data-path="C4MLRANOVA.html"><a href="C4MLRANOVA.html#Sec422"><i class="fa fa-check"></i><b>4.2.2</b> La Hipótesis Lineal General</a></li>
<li class="chapter" data-level="4.2.3" data-path="C4MLRANOVA.html"><a href="C4MLRANOVA.html#Sec423"><i class="fa fa-check"></i><b>4.2.3</b> Estimando y Prediciendo Varios Coeficientes</a></li>
</ul></li>
<li class="chapter" data-level="4.3" data-path="C4MLRANOVA.html"><a href="C4MLRANOVA.html#Sec43"><i class="fa fa-check"></i><b>4.3</b> Modelo ANOVA de Un Factor</a></li>
<li class="chapter" data-level="4.4" data-path="C4MLRANOVA.html"><a href="C4MLRANOVA.html#Sec44"><i class="fa fa-check"></i><b>4.4</b> Combinando Variables Explicativas Categóricas y Continuas</a></li>
<li class="chapter" data-level="4.5" data-path="C4MLRANOVA.html"><a href="C4MLRANOVA.html#Sec45"><i class="fa fa-check"></i><b>4.5</b> Lecturas Adicionales y Referencias</a></li>
<li class="chapter" data-level="4.6" data-path="C4MLRANOVA.html"><a href="C4MLRANOVA.html#Sec46"><i class="fa fa-check"></i><b>4.6</b> Ejercicios</a></li>
<li class="chapter" data-level="4.7" data-path="C4MLRANOVA.html"><a href="C4MLRANOVA.html#Sec47"><i class="fa fa-check"></i><b>4.7</b> Suplemento Técnico - Expresiones Matriciales</a>
<ul>
<li class="chapter" data-level="4.7.1" data-path="C4MLRANOVA.html"><a href="C4MLRANOVA.html#Sec471"><i class="fa fa-check"></i><b>4.7.1</b> Expresión de Modelos con Variables Categóricas en Forma Matricial</a></li>
<li class="chapter" data-level="4.7.2" data-path="C4MLRANOVA.html"><a href="C4MLRANOVA.html#Sec472"><i class="fa fa-check"></i><b>4.7.2</b> Cálculo Recursivo de Mínimos Cuadrados</a></li>
<li class="chapter" data-level="4.7.3" data-path="C4MLRANOVA.html"><a href="C4MLRANOVA.html#Sec473"><i class="fa fa-check"></i><b>4.7.3</b> Modelo Lineal General</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="5" data-path="C5VarSelect.html"><a href="C5VarSelect.html"><i class="fa fa-check"></i><b>5</b> Selección de Variables</a>
<ul>
<li class="chapter" data-level="5.1" data-path="C5VarSelect.html"><a href="C5VarSelect.html#Sec51"><i class="fa fa-check"></i><b>5.1</b> Un Enfoque Iterativo para el Análisis de Datos y Modelado</a></li>
<li class="chapter" data-level="5.2" data-path="C5VarSelect.html"><a href="C5VarSelect.html#Sec52"><i class="fa fa-check"></i><b>5.2</b> Procedimientos Automáticos de Selección de Variables</a></li>
<li class="chapter" data-level="5.3" data-path="C5VarSelect.html"><a href="C5VarSelect.html#Sec53"><i class="fa fa-check"></i><b>5.3</b> Análisis de Residuales</a>
<ul>
<li class="chapter" data-level="5.3.1" data-path="C5VarSelect.html"><a href="C5VarSelect.html#Sec531"><i class="fa fa-check"></i><b>5.3.1</b> Residuales</a></li>
<li class="chapter" data-level="5.3.2" data-path="C5VarSelect.html"><a href="C5VarSelect.html#Sec532"><i class="fa fa-check"></i><b>5.3.2</b> Uso de los Residuales para Identificar Valores Atípicos</a></li>
<li class="chapter" data-level="5.3.3" data-path="C5VarSelect.html"><a href="C5VarSelect.html#Sec533"><i class="fa fa-check"></i><b>5.3.3</b> Uso de los Residuales para Seleccionar Variables Explicativas</a></li>
</ul></li>
<li class="chapter" data-level="5.4" data-path="C5VarSelect.html"><a href="C5VarSelect.html#Sec54"><i class="fa fa-check"></i><b>5.4</b> Puntos Influyentes</a>
<ul>
<li class="chapter" data-level="5.4.1" data-path="C5VarSelect.html"><a href="C5VarSelect.html#Sec541"><i class="fa fa-check"></i><b>5.4.1</b> Apalancamiento</a></li>
<li class="chapter" data-level="5.4.2" data-path="C5VarSelect.html"><a href="C5VarSelect.html#Sec542"><i class="fa fa-check"></i><b>5.4.2</b> Distancia de Cook</a></li>
</ul></li>
<li class="chapter" data-level="5.5" data-path="C5VarSelect.html"><a href="C5VarSelect.html#Sec55"><i class="fa fa-check"></i><b>5.5</b> Colinealidad</a>
<ul>
<li class="chapter" data-level="5.5.1" data-path="C5VarSelect.html"><a href="C5VarSelect.html#Sec551"><i class="fa fa-check"></i><b>5.5.1</b> ¿Qué es la Colinealidad?</a></li>
<li class="chapter" data-level="5.5.2" data-path="C5VarSelect.html"><a href="C5VarSelect.html#Sec552"><i class="fa fa-check"></i><b>5.5.2</b> Factores de Inflación de Varianza</a></li>
<li class="chapter" data-level="5.5.3" data-path="C5VarSelect.html"><a href="C5VarSelect.html#Sec553"><i class="fa fa-check"></i><b>5.5.3</b> Colinealidad e Influencia</a></li>
<li class="chapter" data-level="5.5.4" data-path="C5VarSelect.html"><a href="C5VarSelect.html#Sec554"><i class="fa fa-check"></i><b>5.5.4</b> Variables Suprensoras</a></li>
<li class="chapter" data-level="5.5.5" data-path="C5VarSelect.html"><a href="C5VarSelect.html#Sec555"><i class="fa fa-check"></i><b>5.5.5</b> Variables Ortogonales</a></li>
</ul></li>
<li class="chapter" data-level="5.6" data-path="C5VarSelect.html"><a href="C5VarSelect.html#Sec56"><i class="fa fa-check"></i><b>5.6</b> Criterios de Selección</a>
<ul>
<li class="chapter" data-level="5.6.1" data-path="C5VarSelect.html"><a href="C5VarSelect.html#Sec561"><i class="fa fa-check"></i><b>5.6.1</b> Bondad de Ajuste</a></li>
<li class="chapter" data-level="5.6.2" data-path="C5VarSelect.html"><a href="C5VarSelect.html#Sec562"><i class="fa fa-check"></i><b>5.6.2</b> Validación del Modelo</a></li>
<li class="chapter" data-level="5.6.3" data-path="C5VarSelect.html"><a href="C5VarSelect.html#Sec563"><i class="fa fa-check"></i><b>5.6.3</b> Validación Cruzada</a></li>
</ul></li>
<li class="chapter" data-level="5.7" data-path="C5VarSelect.html"><a href="C5VarSelect.html#Sec57"><i class="fa fa-check"></i><b>5.7</b> Heterocedasticidad</a>
<ul>
<li class="chapter" data-level="5.7.1" data-path="C5VarSelect.html"><a href="C5VarSelect.html#Sec571"><i class="fa fa-check"></i><b>5.7.1</b> Detección de Heterocedasticidad</a></li>
<li class="chapter" data-level="5.7.2" data-path="C5VarSelect.html"><a href="C5VarSelect.html#Sec572"><i class="fa fa-check"></i><b>5.7.2</b> Errores Estándar Consistentes con Heterocedasticidad</a></li>
<li class="chapter" data-level="5.7.3" data-path="C5VarSelect.html"><a href="C5VarSelect.html#Sec573"><i class="fa fa-check"></i><b>5.7.3</b> Mínimos Cuadrados Ponderados</a></li>
<li class="chapter" data-level="5.7.4" data-path="C5VarSelect.html"><a href="C5VarSelect.html#Sec574"><i class="fa fa-check"></i><b>5.7.4</b> Transformaciones</a></li>
</ul></li>
<li class="chapter" data-level="5.8" data-path="C5VarSelect.html"><a href="C5VarSelect.html#Sec58"><i class="fa fa-check"></i><b>5.8</b> Lectura Adicional y Referencias</a></li>
<li class="chapter" data-level="5.9" data-path="C5VarSelect.html"><a href="C5VarSelect.html#Sec59"><i class="fa fa-check"></i><b>5.9</b> Ejercicios</a></li>
<li class="chapter" data-level="5.10" data-path="C5VarSelect.html"><a href="C5VarSelect.html#Sec510"><i class="fa fa-check"></i><b>5.10</b> Suplementos Técnicos para el Capítulo 5</a>
<ul>
<li class="chapter" data-level="5.10.1" data-path="C5VarSelect.html"><a href="C5VarSelect.html#Sec5101"><i class="fa fa-check"></i><b>5.10.1</b> Matriz de Proyección</a></li>
<li class="chapter" data-level="5.10.2" data-path="C5VarSelect.html"><a href="C5VarSelect.html#Sec5102"><i class="fa fa-check"></i><b>5.10.2</b> Estadísticas Leave-One-Out</a></li>
<li class="chapter" data-level="5.10.3" data-path="C5VarSelect.html"><a href="C5VarSelect.html#Sec5103"><i class="fa fa-check"></i><b>5.10.3</b> Omisión de Variables</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="6" data-path="interpretación-de-resultados-de-regresión.html"><a href="interpretación-de-resultados-de-regresión.html"><i class="fa fa-check"></i><b>6</b> Interpretación de Resultados de Regresión</a>
<ul>
<li class="chapter" data-level="6.1" data-path="interpretación-de-resultados-de-regresión.html"><a href="interpretación-de-resultados-de-regresión.html#Sec61"><i class="fa fa-check"></i><b>6.1</b> Lo que nos dice el proceso de modelado</a>
<ul>
<li class="chapter" data-level="6.1.1" data-path="interpretación-de-resultados-de-regresión.html"><a href="interpretación-de-resultados-de-regresión.html#Sec611"><i class="fa fa-check"></i><b>6.1.1</b> Interpretación de efectos individuales</a></li>
<li class="chapter" data-level="6.1.2" data-path="interpretación-de-resultados-de-regresión.html"><a href="interpretación-de-resultados-de-regresión.html#Sec612"><i class="fa fa-check"></i><b>6.1.2</b> Otras Interpretaciones</a></li>
</ul></li>
<li class="chapter" data-level="6.2" data-path="interpretación-de-resultados-de-regresión.html"><a href="interpretación-de-resultados-de-regresión.html#Sec62"><i class="fa fa-check"></i><b>6.2</b> La Importancia de la Selección de Variables</a>
<ul>
<li class="chapter" data-level="6.2.1" data-path="interpretación-de-resultados-de-regresión.html"><a href="interpretación-de-resultados-de-regresión.html#Sec621"><i class="fa fa-check"></i><b>6.2.1</b> Sobreajuste del Modelo</a></li>
<li class="chapter" data-level="6.2.2" data-path="interpretación-de-resultados-de-regresión.html"><a href="interpretación-de-resultados-de-regresión.html#Sec622"><i class="fa fa-check"></i><b>6.2.2</b> Subajuste del Modelo</a></li>
</ul></li>
<li class="chapter" data-level="6.3" data-path="interpretación-de-resultados-de-regresión.html"><a href="interpretación-de-resultados-de-regresión.html#Sec63"><i class="fa fa-check"></i><b>6.3</b> La Importancia de la Recolección de Datos</a>
<ul>
<li class="chapter" data-level="6.3.1" data-path="interpretación-de-resultados-de-regresión.html"><a href="interpretación-de-resultados-de-regresión.html#Sec631"><i class="fa fa-check"></i><b>6.3.1</b> Error en el Marco Muestral y Selección Adversa</a></li>
<li class="chapter" data-level="6.3.2" data-path="interpretación-de-resultados-de-regresión.html"><a href="interpretación-de-resultados-de-regresión.html#Sec632"><i class="fa fa-check"></i><b>6.3.2</b> Regiones de Muestreo Limitadas</a></li>
<li class="chapter" data-level="6.3.3" data-path="interpretación-de-resultados-de-regresión.html"><a href="interpretación-de-resultados-de-regresión.html#Sec633"><i class="fa fa-check"></i><b>6.3.3</b> Variables Dependientes Limitadas, Censura y Truncamiento</a></li>
<li class="chapter" data-level="6.3.4" data-path="interpretación-de-resultados-de-regresión.html"><a href="interpretación-de-resultados-de-regresión.html#Sec634"><i class="fa fa-check"></i><b>6.3.4</b> Variables Omitidas y Endógenas</a></li>
<li class="chapter" data-level="6.3.5" data-path="interpretación-de-resultados-de-regresión.html"><a href="interpretación-de-resultados-de-regresión.html#Sec635"><i class="fa fa-check"></i><b>6.3.5</b> Datos Faltantes</a></li>
</ul></li>
<li class="chapter" data-level="6.4" data-path="interpretación-de-resultados-de-regresión.html"><a href="interpretación-de-resultados-de-regresión.html#Sec64"><i class="fa fa-check"></i><b>6.4</b> Modelos de Datos Faltantes</a>
<ul>
<li class="chapter" data-level="6.4.1" data-path="interpretación-de-resultados-de-regresión.html"><a href="interpretación-de-resultados-de-regresión.html#Sec641"><i class="fa fa-check"></i><b>6.4.1</b> Faltante al Azar</a></li>
<li class="chapter" data-level="6.4.2" data-path="interpretación-de-resultados-de-regresión.html"><a href="interpretación-de-resultados-de-regresión.html#Sec642"><i class="fa fa-check"></i><b>6.4.2</b> Datos Faltantes No Ignorables</a></li>
</ul></li>
<li class="chapter" data-level="6.5" data-path="interpretación-de-resultados-de-regresión.html"><a href="interpretación-de-resultados-de-regresión.html#Sec65"><i class="fa fa-check"></i><b>6.5</b> Aplicación: Eficiencia en el Costo de los Gestores de Riesgos</a></li>
<li class="chapter" data-level="6.6" data-path="interpretación-de-resultados-de-regresión.html"><a href="interpretación-de-resultados-de-regresión.html#Sec66"><i class="fa fa-check"></i><b>6.6</b> Lecturas Adicionales y Referencias</a></li>
<li class="chapter" data-level="6.7" data-path="interpretación-de-resultados-de-regresión.html"><a href="interpretación-de-resultados-de-regresión.html#Sec67"><i class="fa fa-check"></i><b>6.7</b> Ejercicios</a></li>
<li class="chapter" data-level="6.8" data-path="interpretación-de-resultados-de-regresión.html"><a href="interpretación-de-resultados-de-regresión.html#Sec68"><i class="fa fa-check"></i><b>6.8</b> Suplementos Técnicos para el Capítulo 6</a>
<ul>
<li class="chapter" data-level="6.8.1" data-path="interpretación-de-resultados-de-regresión.html"><a href="interpretación-de-resultados-de-regresión.html#Sec681"><i class="fa fa-check"></i><b>6.8.1</b> Efectos de la Especificación Incorrecta del Modelo</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="7" data-path="chap-7.html"><a href="chap-7.html"><i class="fa fa-check"></i><b>7</b> Chap 7</a></li>
<li class="chapter" data-level="8" data-path="chap-8.html"><a href="chap-8.html"><i class="fa fa-check"></i><b>8</b> Chap 8</a></li>
<li class="chapter" data-level="9" data-path="chap-9.html"><a href="chap-9.html"><i class="fa fa-check"></i><b>9</b> Chap 9</a></li>
<li class="chapter" data-level="10" data-path="chap-10.html"><a href="chap-10.html"><i class="fa fa-check"></i><b>10</b> Chap 10</a></li>
<li class="chapter" data-level="11" data-path="C11Binary.html"><a href="C11Binary.html"><i class="fa fa-check"></i><b>11</b> Variables Dependientes Categóricas</a>
<ul>
<li class="chapter" data-level="11.1" data-path="C11Binary.html"><a href="C11Binary.html#S:Sec111"><i class="fa fa-check"></i><b>11.1</b> Variables Dependientes Binarias</a></li>
<li class="chapter" data-level="11.2" data-path="C11Binary.html"><a href="C11Binary.html#S:Sec112"><i class="fa fa-check"></i><b>11.2</b> Modelos de Regresión Logística y Probit</a>
<ul>
<li class="chapter" data-level="11.2.1" data-path="C11Binary.html"><a href="C11Binary.html#S:Sec1121"><i class="fa fa-check"></i><b>11.2.1</b> Uso de Funciones No Lineales de Variables Explicativas</a></li>
<li class="chapter" data-level="11.2.2" data-path="C11Binary.html"><a href="C11Binary.html#S:Sec1122"><i class="fa fa-check"></i><b>11.2.2</b> Interpretación del Umbral</a></li>
<li class="chapter" data-level="11.2.3" data-path="C11Binary.html"><a href="C11Binary.html#S:Sec1123"><i class="fa fa-check"></i><b>11.2.3</b> Interpretación de Utilidad Aleatoria</a></li>
<li class="chapter" data-level="11.2.4" data-path="C11Binary.html"><a href="C11Binary.html#S:Sec1124"><i class="fa fa-check"></i><b>11.2.4</b> Regresión Logística</a></li>
</ul></li>
<li class="chapter" data-level="11.3" data-path="C11Binary.html"><a href="C11Binary.html#S:Sec113"><i class="fa fa-check"></i><b>11.3</b> Inferencia para Modelos de Regresión Logística y Probit</a>
<ul>
<li class="chapter" data-level="11.3.1" data-path="C11Binary.html"><a href="C11Binary.html#estimación-de-parámetros"><i class="fa fa-check"></i><b>11.3.1</b> Estimación de Parámetros</a></li>
<li class="chapter" data-level="11.3.2" data-path="C11Binary.html"><a href="C11Binary.html#inferencia-adicional"><i class="fa fa-check"></i><b>11.3.2</b> Inferencia Adicional</a></li>
</ul></li>
<li class="chapter" data-level="11.4" data-path="C11Binary.html"><a href="C11Binary.html#S:Sec114"><i class="fa fa-check"></i><b>11.4</b> Aplicación: Gastos Médicos</a></li>
<li class="chapter" data-level="11.5" data-path="C11Binary.html"><a href="C11Binary.html#S:Sec115"><i class="fa fa-check"></i><b>11.5</b> Variables Dependientes Nominales</a>
<ul>
<li class="chapter" data-level="11.5.1" data-path="C11Binary.html"><a href="C11Binary.html#S:Sec1151"><i class="fa fa-check"></i><b>11.5.1</b> Logit Generalizado</a></li>
<li class="chapter" data-level="11.5.2" data-path="C11Binary.html"><a href="C11Binary.html#S:Sec1152"><i class="fa fa-check"></i><b>11.5.2</b> Logit Multinomial</a></li>
<li class="chapter" data-level="11.5.3" data-path="C11Binary.html"><a href="C11Binary.html#S:Sec1153"><i class="fa fa-check"></i><b>11.5.3</b> Logit Anidado</a></li>
</ul></li>
<li class="chapter" data-level="11.6" data-path="C11Binary.html"><a href="C11Binary.html#S:Sec116"><i class="fa fa-check"></i><b>11.6</b> Variables Dependientes Ordinales</a>
<ul>
<li class="chapter" data-level="11.6.1" data-path="C11Binary.html"><a href="C11Binary.html#logit-acumulativo"><i class="fa fa-check"></i><b>11.6.1</b> Logit Acumulativo</a></li>
<li class="chapter" data-level="11.6.2" data-path="C11Binary.html"><a href="C11Binary.html#probit-acumulativo"><i class="fa fa-check"></i><b>11.6.2</b> Probit Acumulativo</a></li>
</ul></li>
<li class="chapter" data-level="11.7" data-path="C11Binary.html"><a href="C11Binary.html#S:Sec117"><i class="fa fa-check"></i><b>11.7</b> Lecturas Adicionales y Referencias</a></li>
<li class="chapter" data-level="11.8" data-path="C11Binary.html"><a href="C11Binary.html#S:Sec118"><i class="fa fa-check"></i><b>11.8</b> Ejercicios</a></li>
<li class="chapter" data-level="11.9" data-path="C11Binary.html"><a href="C11Binary.html#S:Sec119"><i class="fa fa-check"></i><b>11.9</b> Suplementos Técnicos - Inferencia Basada en Verosimilitud</a>
<ul>
<li class="chapter" data-level="11.9.1" data-path="C11Binary.html"><a href="C11Binary.html#S:Sec1191"><i class="fa fa-check"></i><b>11.9.1</b> Propiedades de las Funciones de Verosimilitud</a></li>
<li class="chapter" data-level="11.9.2" data-path="C11Binary.html"><a href="C11Binary.html#S:Sec1192"><i class="fa fa-check"></i><b>11.9.2</b> Estimadores de Máxima Verosimilitud</a></li>
<li class="chapter" data-level="11.9.3" data-path="C11Binary.html"><a href="C11Binary.html#S:Sec1193"><i class="fa fa-check"></i><b>11.9.3</b> Pruebas de Hipótesis</a></li>
<li class="chapter" data-level="11.9.4" data-path="C11Binary.html"><a href="C11Binary.html#S:Sec1194"><i class="fa fa-check"></i><b>11.9.4</b> Criterios de Información</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="12" data-path="C12Count.html"><a href="C12Count.html"><i class="fa fa-check"></i><b>12</b> Variables Dependientes de Conteo</a>
<ul>
<li class="chapter" data-level="12.1" data-path="C12Count.html"><a href="C12Count.html#S:Sec121"><i class="fa fa-check"></i><b>12.1</b> Regresión de Poisson</a>
<ul>
<li class="chapter" data-level="12.1.1" data-path="C12Count.html"><a href="C12Count.html#S:Sec1211"><i class="fa fa-check"></i><b>12.1.1</b> Distribución de Poisson</a></li>
<li class="chapter" data-level="12.1.2" data-path="C12Count.html"><a href="C12Count.html#S:Sec1212"><i class="fa fa-check"></i><b>12.1.2</b> Modelo de Regresión</a></li>
<li class="chapter" data-level="12.1.3" data-path="C12Count.html"><a href="C12Count.html#S:Sec1213"><i class="fa fa-check"></i><b>12.1.3</b> Estimación</a></li>
<li class="chapter" data-level="12.1.4" data-path="C12Count.html"><a href="C12Count.html#S:Sec1214"><i class="fa fa-check"></i><b>12.1.4</b> Inferencia Adicional</a></li>
</ul></li>
<li class="chapter" data-level="12.2" data-path="C12Count.html"><a href="C12Count.html#S:Sec122"><i class="fa fa-check"></i><b>12.2</b> Aplicación: Seguro de Automóviles en Singapur</a></li>
<li class="chapter" data-level="12.3" data-path="C12Count.html"><a href="C12Count.html#S:Sec123"><i class="fa fa-check"></i><b>12.3</b> Sobre dispersión y Modelos Binomiales Negativos</a></li>
<li class="chapter" data-level="12.4" data-path="C12Count.html"><a href="C12Count.html#S:Sec124"><i class="fa fa-check"></i><b>12.4</b> Otros Modelos de Conteo</a>
<ul>
<li class="chapter" data-level="12.4.1" data-path="C12Count.html"><a href="C12Count.html#modelos-inflados-en-ceros"><i class="fa fa-check"></i><b>12.4.1</b> Modelos Inflados en Ceros</a></li>
<li class="chapter" data-level="12.4.2" data-path="C12Count.html"><a href="C12Count.html#modelos-hurdle"><i class="fa fa-check"></i><b>12.4.2</b> Modelos Hurdle</a></li>
<li class="chapter" data-level="12.4.3" data-path="C12Count.html"><a href="C12Count.html#modelos-de-heterogeneidad"><i class="fa fa-check"></i><b>12.4.3</b> Modelos de Heterogeneidad</a></li>
<li class="chapter" data-level="12.4.4" data-path="C12Count.html"><a href="C12Count.html#modelos-de-clases-latentes"><i class="fa fa-check"></i><b>12.4.4</b> Modelos de Clases Latentes</a></li>
</ul></li>
<li class="chapter" data-level="12.5" data-path="C12Count.html"><a href="C12Count.html#S:Sec125"><i class="fa fa-check"></i><b>12.5</b> Lecturas Adicionales y Referencias</a></li>
<li class="chapter" data-level="12.6" data-path="C12Count.html"><a href="C12Count.html#S:Sec126"><i class="fa fa-check"></i><b>12.6</b> Ejercicios</a></li>
</ul></li>
<li class="chapter" data-level="13" data-path="C13GLM.html"><a href="C13GLM.html"><i class="fa fa-check"></i><b>13</b> Modelos Lineales Generalizados</a>
<ul>
<li class="chapter" data-level="13.1" data-path="C13GLM.html"><a href="C13GLM.html#S:Sec131"><i class="fa fa-check"></i><b>13.1</b> Introducción</a></li>
<li class="chapter" data-level="13.2" data-path="C13GLM.html"><a href="C13GLM.html#S:Sec132"><i class="fa fa-check"></i><b>13.2</b> Modelo GLM</a>
<ul>
<li class="chapter" data-level="13.2.1" data-path="C13GLM.html"><a href="C13GLM.html#S:Sec1321"><i class="fa fa-check"></i><b>13.2.1</b> Familia Exponencial Lineal de Distribuciones</a></li>
<li class="chapter" data-level="13.2.2" data-path="C13GLM.html"><a href="C13GLM.html#S:Sec1322"><i class="fa fa-check"></i><b>13.2.2</b> Funciones de Enlace</a></li>
</ul></li>
<li class="chapter" data-level="13.3" data-path="C13GLM.html"><a href="C13GLM.html#S:Sec133"><i class="fa fa-check"></i><b>13.3</b> Estimación</a>
<ul>
<li class="chapter" data-level="13.3.1" data-path="C13GLM.html"><a href="C13GLM.html#S:Sec1331"><i class="fa fa-check"></i><b>13.3.1</b> Estimación de Máxima Verosimilitud para Enlaces Canónicos</a></li>
<li class="chapter" data-level="13.3.2" data-path="C13GLM.html"><a href="C13GLM.html#sobredispersión"><i class="fa fa-check"></i><b>13.3.2</b> Sobredispersión</a></li>
<li class="chapter" data-level="13.3.3" data-path="C13GLM.html"><a href="C13GLM.html#S:Sec1333"><i class="fa fa-check"></i><b>13.3.3</b> Estadísticas de Bondad de Ajuste</a></li>
</ul></li>
<li class="chapter" data-level="13.4" data-path="C13GLM.html"><a href="C13GLM.html#S:Sec134"><i class="fa fa-check"></i><b>13.4</b> Aplicación: Gastos Médicos</a></li>
<li class="chapter" data-level="13.5" data-path="C13GLM.html"><a href="C13GLM.html#S:Sec135"><i class="fa fa-check"></i><b>13.5</b> Residuales</a></li>
<li class="chapter" data-level="13.6" data-path="C13GLM.html"><a href="C13GLM.html#S:Sec136"><i class="fa fa-check"></i><b>13.6</b> Distribución de Tweedie</a></li>
<li class="chapter" data-level="13.7" data-path="C13GLM.html"><a href="C13GLM.html#S:Sec137"><i class="fa fa-check"></i><b>13.7</b> Lecturas adicionales y referencias</a></li>
<li class="chapter" data-level="13.8" data-path="C13GLM.html"><a href="C13GLM.html#S:Sec138"><i class="fa fa-check"></i><b>13.8</b> Ejercicios</a></li>
<li class="chapter" data-level="13.9" data-path="C13GLM.html"><a href="C13GLM.html#S:Sec139"><i class="fa fa-check"></i><b>13.9</b> Suplementos Técnicos - Familia Exponencial</a>
<ul>
<li class="chapter" data-level="13.9.1" data-path="C13GLM.html"><a href="C13GLM.html#S:Sec1391"><i class="fa fa-check"></i><b>13.9.1</b> Familia Exponencial Lineal de Distribuciones</a></li>
<li class="chapter" data-level="13.9.2" data-path="C13GLM.html"><a href="C13GLM.html#S:Sec1392"><i class="fa fa-check"></i><b>13.9.2</b> Momentos</a></li>
<li class="chapter" data-level="13.9.3" data-path="C13GLM.html"><a href="C13GLM.html#S:Sec1393"><i class="fa fa-check"></i><b>13.9.3</b> Estimación de Máxima Verosimilitud para Enlaces Generales</a></li>
<li class="chapter" data-level="13.9.4" data-path="C13GLM.html"><a href="C13GLM.html#S:Sec1394"><i class="fa fa-check"></i><b>13.9.4</b> Mínimos Cuadrados Reponderados Iterativos</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="14" data-path="apéndices.html"><a href="apéndices.html"><i class="fa fa-check"></i><b>14</b> Apéndices</a>
<ul>
<li class="chapter" data-level="" data-path="apéndices.html"><a href="apéndices.html#apéndice-a1.-inferencia-estadística-básica"><i class="fa fa-check"></i>Apéndice A1. Inferencia Estadística Básica</a>
<ul>
<li class="chapter" data-level="" data-path="apéndices.html"><a href="apéndices.html#distribuciones-de-funciones-de-variables-aleatorias"><i class="fa fa-check"></i>Distribuciones de Funciones de Variables Aleatorias</a></li>
<li class="chapter" data-level="" data-path="apéndices.html"><a href="apéndices.html#estimación-y-predicción"><i class="fa fa-check"></i>Estimación y Predicción</a></li>
<li class="chapter" data-level="" data-path="apéndices.html"><a href="apéndices.html#pruebas-de-hipótesis"><i class="fa fa-check"></i>Pruebas de Hipótesis</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="apéndices.html"><a href="apéndices.html#apéndice-a2.-álgebra-de-matrices"><i class="fa fa-check"></i>Apéndice A2. Álgebra de Matrices</a>
<ul>
<li class="chapter" data-level="" data-path="apéndices.html"><a href="apéndices.html#definiciones-básicas"><i class="fa fa-check"></i>Definiciones Básicas</a></li>
<li class="chapter" data-level="" data-path="apéndices.html"><a href="apéndices.html#revisión-de-operaciones-básicas"><i class="fa fa-check"></i>Revisión de Operaciones Básicas</a></li>
<li class="chapter" data-level="" data-path="apéndices.html"><a href="apéndices.html#definiciones-adicionales"><i class="fa fa-check"></i>Definiciones Adicionales</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="apéndices.html"><a href="apéndices.html#apéndice-a3.-tablas-de-probabilidad"><i class="fa fa-check"></i>Apéndice A3. Tablas de Probabilidad</a>
<ul>
<li class="chapter" data-level="" data-path="apéndices.html"><a href="apéndices.html#distribución-normal"><i class="fa fa-check"></i>Distribución Normal</a></li>
<li class="chapter" data-level="" data-path="apéndices.html"><a href="apéndices.html#distribución-chi-cuadrado"><i class="fa fa-check"></i>Distribución Chi-Cuadrado</a></li>
<li class="chapter" data-level="" data-path="apéndices.html"><a href="apéndices.html#distribución-t"><i class="fa fa-check"></i>Distribución <em>t</em></a></li>
<li class="chapter" data-level="" data-path="apéndices.html"><a href="apéndices.html#distribución-f"><i class="fa fa-check"></i>Distribución <em>F</em></a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="" data-path="bibliography.html"><a href="bibliography.html"><i class="fa fa-check"></i>Bibliography</a></li>
<li class="divider"></li>
<li><a href="https://github.com/OpenActTextDev/RegressionSpanish/" target="blank">Spanish Regression on GitHub</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Modelado de Regresión con Aplicaciones Actuariales y Financieras</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="C11Binary" class="section level1 hasAnchor" number="11">
<h1><span class="header-section-number">Chapter 11</span> Variables Dependientes Categóricas<a href="C11Binary.html#C11Binary" class="anchor-section" aria-label="Anchor link to header"></a></h1>
<p><em>Vista Previa del Capítulo</em>. Un modelo con una variable dependiente
categórica permite predecir si una observación pertenece a un grupo o
categoría distinta. Las variables binarias representan un caso especial importante;
pueden indicar si un evento de interés ha ocurrido o no. En aplicaciones actuariales
y financieras, el evento puede ser si ocurre un siniestro, si una persona compra un
seguro, si una persona se jubila o si una empresa se vuelve insolvente. Este capítulo
introduce los modelos de regresión logística y probit para variables dependientes binarias.
Las variables categóricas también pueden representar más de dos grupos, conocidos como
resultados <em>multicategoría</em>. Las variables multicategoría pueden estar desordenadas o ordenadas,
dependiendo de si tiene sentido clasificar los resultados de la variable. Para los resultados
desordenados, conocidos como variables <em>nominales</em>, el capítulo introduce los modelos
de logits generalizados y logit multinomial. Para los resultados ordenados, conocidos como
variables <em>ordinales</em>, el capítulo introduce los modelos de logit acumulativo y probit.</p>
<div id="S:Sec111" class="section level2 hasAnchor" number="11.1">
<h2><span class="header-section-number">11.1</span> Variables Dependientes Binarias<a href="C11Binary.html#S:Sec111" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Ya hemos introducido las variables binarias como un tipo especial de
variable discreta que puede utilizarse para indicar si un sujeto tiene
una característica de interés, como el sexo de una persona o la propiedad
de una empresa de seguros cautiva por parte de una firma. Las variables
binarias también describen si ha ocurrido o no un evento de interés,
como un accidente. Un modelo con una variable dependiente binaria permite
predecir si ha ocurrido un evento o si un sujeto tiene una característica de interés.</p>
<hr />
<p><strong>Ejemplo: Gastos MEPS.</strong> La Sección <a href="C11Binary.html#S:Sec114">11.4</a> describirá una extensa base de datos de la Encuesta del Panel de Gastos Médicos (MEPS, por sus siglas en inglés) sobre la utilización y los gastos de hospitalización. Para estos datos, consideraremos
<span class="math display">\[
y_i = \left\{
\begin{array}{ll}
1 &amp; \text{la i-ésima persona fue hospitalizada durante el período de la muestra} \\
0 &amp; \text{de lo contrario}
\end{array}
\right. .
\]</span>
Hay <span class="math inline">\(n=2,000\)</span> personas en esta muestra, distribuidas de la siguiente manera:</p>
<table class=" lightable-classic table table-striped table-condensed" style="font-size: 12px; font-family: Cambria; width: auto !important; margin-left: auto; margin-right: auto; margin-left: auto; margin-right: auto;">
<caption style="font-size: initial !important;">
<span id="tab:Tab111">Tabla 11.1: </span><strong>Hospitalización por Sexo</strong>
</caption>
<thead>
<tr>
<th style="text-align:left;">
</th>
<th style="text-align:center;">
</th>
<th style="text-align:center;">
Hombres
</th>
<th style="text-align:center;">
Mujeres
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;width: 2.5cm; border-right:1px solid;width: 4cm; ">
No hospitalizado
</td>
<td style="text-align:center;width: 3cm; ">
<span class="math inline">\(y=0\)</span>
</td>
<td style="text-align:center;width: 3cm; ">
902 (95.3%)
</td>
<td style="text-align:center;width: 3cm; ">
941 (89.3%)
</td>
</tr>
<tr>
<td style="text-align:left;width: 2.5cm; border-right:1px solid;width: 4cm; ">
Hospitalizado
</td>
<td style="text-align:center;width: 3cm; ">
<span class="math inline">\(y=1\)</span>
</td>
<td style="text-align:center;width: 3cm; ">
44 (4.7%)
</td>
<td style="text-align:center;width: 3cm; ">
113 (10.7%)
</td>
</tr>
<tr>
<td style="text-align:left;width: 2.5cm; border-right:1px solid;width: 4cm; ">
Total
</td>
<td style="text-align:center;width: 3cm; ">
</td>
<td style="text-align:center;width: 3cm; ">
946
</td>
<td style="text-align:center;width: 3cm; ">
1,054
</td>
</tr>
</tbody>
</table>
<h5 style="text-align: center;">
<a id="displayCode.Tab111.Hide" href="javascript:togglecode('toggleCode.Tab111.Hide','displayCode.Tab111.Hide');"><i><strong>Código R para Generar la Tabla 11.1</strong></i></a>
</h5>
<div id="toggleCode.Tab111.Hide" style="display: none">
<div class="sourceCode" id="cb67"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb67-1"><a href="C11Binary.html#cb67-1" tabindex="-1"></a>Hexpend <span class="ot">&lt;-</span> <span class="fu">read.csv</span>(<span class="st">&quot;CSVData/HealthExpend.csv&quot;</span>, <span class="at">header=</span><span class="cn">TRUE</span>)</span>
<span id="cb67-2"><a href="C11Binary.html#cb67-2" tabindex="-1"></a><span class="co">#  Tabla 11.1</span></span>
<span id="cb67-3"><a href="C11Binary.html#cb67-3" tabindex="-1"></a>POSEXP <span class="ot">=</span> <span class="dv">1</span><span class="sc">*</span>(Hexpend<span class="sc">$</span>EXPENDIP<span class="sc">&gt;</span><span class="dv">0</span>)</span>
<span id="cb67-4"><a href="C11Binary.html#cb67-4" tabindex="-1"></a><span class="co">#table(POSEXP)</span></span>
<span id="cb67-5"><a href="C11Binary.html#cb67-5" tabindex="-1"></a><span class="co">#table(Hexpend$GENDER)</span></span>
<span id="cb67-6"><a href="C11Binary.html#cb67-6" tabindex="-1"></a><span class="co">#Hmisc::summarize(POSEXP, Hexpend$GENDER, mean)</span></span>
<span id="cb67-7"><a href="C11Binary.html#cb67-7" tabindex="-1"></a></span>
<span id="cb67-8"><a href="C11Binary.html#cb67-8" tabindex="-1"></a>row1 <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="st">&quot;No hospitalizado&quot;</span> , <span class="st">&quot;$y=0$&quot;</span> , <span class="st">&quot;902 (95.3%)&quot;</span> , <span class="st">&quot;941 (89.3%)&quot;</span> )</span>
<span id="cb67-9"><a href="C11Binary.html#cb67-9" tabindex="-1"></a>row2 <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="st">&quot;Hospitalizado&quot;</span> , <span class="st">&quot;$y=1$ &quot;</span>,  <span class="st">&quot;44 (4.7%)&quot;</span>  , <span class="st">&quot;113 (10.7%)&quot;</span> )</span>
<span id="cb67-10"><a href="C11Binary.html#cb67-10" tabindex="-1"></a>row3 <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="st">&quot;Total&quot;</span> ,  <span class="st">&quot;&quot;</span>, <span class="st">&quot;946&quot;</span>  , <span class="st">&quot;1,054&quot;</span> )</span>
<span id="cb67-11"><a href="C11Binary.html#cb67-11" tabindex="-1"></a>tableout <span class="ot">&lt;-</span> <span class="fu">rbind</span>(row1, row2, row3)</span>
<span id="cb67-12"><a href="C11Binary.html#cb67-12" tabindex="-1"></a><span class="fu">row.names</span>(tableout) <span class="ot">&lt;-</span> <span class="cn">NULL</span></span>
<span id="cb67-13"><a href="C11Binary.html#cb67-13" tabindex="-1"></a><span class="fu">colnames</span>(tableout) <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="st">&quot;&quot;</span>, <span class="st">&quot;&quot;</span>, <span class="st">&quot;Hombres&quot;</span>, <span class="st">&quot;Mujeres&quot;</span>)</span>
<span id="cb67-14"><a href="C11Binary.html#cb67-14" tabindex="-1"></a><span class="fu">TableGen1</span>(<span class="at">TableData=</span>tableout, </span>
<span id="cb67-15"><a href="C11Binary.html#cb67-15" tabindex="-1"></a>         <span class="at">TextTitle=</span><span class="st">&#39;Hospitalización por Sexo&#39;</span>, </span>
<span id="cb67-16"><a href="C11Binary.html#cb67-16" tabindex="-1"></a>         <span class="at">Align=</span><span class="st">&#39;lccc&#39;</span>, <span class="at">ColumnSpec=</span><span class="dv">1</span><span class="sc">:</span><span class="dv">3</span>,</span>
<span id="cb67-17"><a href="C11Binary.html#cb67-17" tabindex="-1"></a>         <span class="at">ColWidth =</span> <span class="st">&quot;3cm&quot;</span>)  <span class="sc">%&gt;%</span> </span>
<span id="cb67-18"><a href="C11Binary.html#cb67-18" tabindex="-1"></a>     kableExtra<span class="sc">::</span><span class="fu">column_spec</span>(<span class="dv">1</span>, <span class="at">width =</span>  <span class="st">&quot;4cm&quot;</span>)</span></code></pre></div>
</div>
<p>La Tabla <a href="C11Binary.html#tab:Tab111">11.1</a> sugiere que el sexo tiene una influencia importante sobre si una persona se hospitaliza.</p>
<hr />
<p>Al igual que con las técnicas de regresión lineal introducidas en capítulos anteriores, estamos interesados en usar las características de una persona, como su edad, sexo, educación, ingresos y estado de salud previo, para ayudar a explicar la variable dependiente <span class="math inline">\(y\)</span>. A diferencia de los capítulos anteriores, ahora la variable dependiente es discreta y no sigue una distribución normal, ni siquiera de manera aproximada. En circunstancias limitadas, la regresión lineal puede usarse con variables dependientes binarias; esta aplicación se conoce como un <em>modelo de probabilidad lineal</em>.</p>
<div id="modelos-de-probabilidad-lineal" class="section level4 unnumbered hasAnchor">
<h4>Modelos de Probabilidad Lineal<a href="C11Binary.html#modelos-de-probabilidad-lineal" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>Para introducir algunas de las complejidades que se encuentran con variables dependientes binarias, denotemos la probabilidad de que la respuesta sea igual a 1 como <span class="math inline">\(\pi_i= \mathrm{Pr}(y_i=1)\)</span>. Una variable aleatoria binaria tiene una <em>distribución de Bernoulli</em>. Por lo tanto, podemos interpretar la respuesta media como la probabilidad de que la respuesta sea uno, es decir, <span class="math inline">\(\mathrm{E~}y_i=0\times \mathrm{Pr}(y_i=0) + 1 \times \mathrm{Pr}(y_i=1) = \pi_i\)</span>. Además, la varianza está relacionada con la media a través de la expresión <span class="math inline">\(\mathrm{Var}~y_i = \pi_i(1-\pi_i)\)</span>.</p>
<p>Comenzamos considerando un modelo lineal de la forma
<span class="math display">\[
y_i = \mathbf{x}_i^{\mathbf{\prime}} \boldsymbol \beta +
\varepsilon_i,
\]</span></p>
<p>conocido como modelo de probabilidad lineal. Asumiendo
<span class="math inline">\(\mathrm{E~}\varepsilon_i=0\)</span>, tenemos que
<span class="math inline">\(\mathrm{E~}y_i=\mathbf{x}_i^{\mathbf{\prime }} \boldsymbol \beta =\pi_i\)</span>. Dado que <span class="math inline">\(y_i\)</span> tiene una distribución de Bernoulli,
<span class="math inline">\(\mathrm{Var}~y_i=\mathbf{x}_i^{\mathbf{\prime}} \boldsymbol \beta(1-\mathbf{x}_i^{\mathbf{\prime}}\boldsymbol \beta)\)</span>. Los modelos de probabilidad lineal se utilizan debido a la facilidad de interpretación de los parámetros. Para conjuntos de datos grandes, la simplicidad computacional de los estimadores de mínimos cuadrados ordinarios es atractiva en comparación con algunos modelos no lineales más complejos que se introducen más adelante en este capítulo. Como se describió en el Capítulo 3, los estimadores de mínimos cuadrados ordinarios para <span class="math inline">\(\boldsymbol \beta\)</span> tienen propiedades deseables. Es sencillo comprobar que los estimadores son consistentes y asintóticamente normales bajo condiciones moderadas sobre las variables explicativas {<span class="math inline">\(\mathbf{x}_i\)</span>}. Sin embargo, los modelos de probabilidad lineal tienen varios inconvenientes que son graves en muchas aplicaciones.</p>
<div class="blackbox">
<p><em>Desventajas del Modelo de Probabilidad Lineal</em></p>
<ul>
<li><p><em>Los valores ajustados pueden ser inadecuados.</em> La respuesta esperada es una probabilidad y, por lo tanto, debe variar entre 0 y 1. Sin embargo, la combinación lineal, <span class="math inline">\(\mathbf{x}_i^{\mathbf{\prime}} \boldsymbol \beta\)</span>, puede variar entre infinito negativo y positivo. Esta desproporción implica, por ejemplo, que los valores ajustados pueden ser poco razonables.</p></li>
<li><p><em>Heterocedasticidad.</em> Los modelos lineales suponen homocedasticidad (varianza constante), pero la varianza de la respuesta depende de la media, que varía entre las observaciones. El problema de la variabilidad cambiante se conoce como heterocedasticidad.</p></li>
<li><p><em>El análisis de los residuos no tiene sentido.</em> La respuesta debe ser 0 o 1, aunque los modelos de regresión generalmente consideran la distribución del término de error como continua. Esta desproporción implica, por ejemplo, que el análisis usual de los residuos en los modelos de regresión no tiene sentido.</p></li>
</ul>
</div>
<p>Para manejar el problema de la heterocedasticidad, es posible un procedimiento de mínimos cuadrados ponderados (en dos etapas). En la primera etapa, se usan mínimos cuadrados ordinarios para calcular estimaciones de <span class="math inline">\(\boldsymbol \beta\)</span>. Con esta estimación, se puede calcular una varianza estimada para cada sujeto utilizando la relación <span class="math inline">\(\mathrm{Var}~y_i=\mathbf{x}_i^{\mathbf{\prime}}\boldsymbol \beta (1-\mathbf{x}_i^{\mathbf{\prime}}\boldsymbol \beta)\)</span>. En la segunda etapa, se realiza un ajuste de mínimos cuadrados ponderados utilizando el inverso de las varianzas estimadas como ponderaciones para obtener nuevas estimaciones de <span class="math inline">\(\boldsymbol \beta\)</span>. Es posible iterar este procedimiento, aunque estudios han demostrado que tiene pocas ventajas hacerlo (ver Carroll y Ruppert, 1988). Alternativamente, se pueden usar estimadores de mínimos cuadrados ordinarios de <span class="math inline">\(\boldsymbol \beta\)</span> con errores estándar robustos a la heterocedasticidad (ver Sección 5.7.2).</p>
</div>
</div>
<div id="S:Sec112" class="section level2 hasAnchor" number="11.2">
<h2><span class="header-section-number">11.2</span> Modelos de Regresión Logística y Probit<a href="C11Binary.html#S:Sec112" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<div id="S:Sec1121" class="section level3 hasAnchor" number="11.2.1">
<h3><span class="header-section-number">11.2.1</span> Uso de Funciones No Lineales de Variables Explicativas<a href="C11Binary.html#S:Sec1121" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Para evitar las desventajas de los modelos de probabilidad lineal, consideramos modelos alternativos en los que expresamos la expectativa de la respuesta como una función de las variables explicativas,
<span class="math inline">\(\pi_i=\mathrm{\pi }(\mathbf{x}_i^{\mathbf{\prime}}\boldsymbol \beta)\)</span> <span class="math inline">\(=\Pr (y_i=1|\mathbf{x}_i)\)</span>. Nos centramos en dos casos especiales de la función <span class="math inline">\(\mathrm{\pi }(\cdot)\)</span>:</p>
<ul>
<li><p><span class="math inline">\(\mathrm{\pi }(z)=\frac{1}{1+\exp (-z)}=\frac{e^{z}}{1+e^{z}}\)</span>, el caso logit, y</p></li>
<li><p><span class="math inline">\(\mathrm{\pi }(z)=\mathrm{\Phi }(z)\)</span>, el caso probit.</p></li>
</ul>
<p>Aquí, <span class="math inline">\(\mathrm{\Phi }(\cdot)\)</span> es la función de distribución normal estándar. La elección de la función identidad (un tipo especial de función lineal), <span class="math inline">\(\mathrm{\pi }(z)=z\)</span>, da lugar al modelo de probabilidad lineal. En cambio, <span class="math inline">\(\mathrm{\pi}\)</span> es no lineal tanto en el caso logit como en el probit. Estas dos funciones son similares en el sentido de que están casi linealmente relacionadas en el intervalo <span class="math inline">\(0.1 \le p \le 0.9\)</span>. Así que, en gran medida, la elección de la función depende de las preferencias del analista. La Figura <a href="C11Binary.html#fig:Fig111">11.1</a> compara las funciones logit y probit, mostrando que será difícil distinguir entre las dos especificaciones en la mayoría de los conjuntos de datos.</p>
<p>La inversa de la función, <span class="math inline">\(\mathrm{\pi }^{-1}\)</span>, especifica la forma de la probabilidad que es lineal en las variables explicativas, es decir, <span class="math inline">\(\mathrm{\pi }^{-1}(\pi_i)= \mathbf{x}_i^{\mathbf{\prime}}\boldsymbol \beta\)</span>. En el Capítulo 13, nos referimos a esta inversa como la <em>función de enlace</em>.</p>

<div class="figure" style="text-align: center"><span style="display:block;" id="fig:Fig111"></span>
<img src="RegressionMarkdown_files/figure-html/Fig111-1.png" alt="Comparación de la Distribución Logit y Probit (Normal Estándar)" width="60%" />
<p class="caption">
Figura 11.1: <strong>Comparación de la Distribución Logit y Probit (Normal Estándar)</strong>
</p>
</div>
<hr />
<p><strong>Ejemplo: Puntuación de Crédito.</strong> Los bancos, las agencias de crédito y otras instituciones financieras desarrollan “puntuaciones de crédito” para individuos que se utilizan para predecir la probabilidad de que el prestatario reembolse sus deudas actuales y futuras. Se dice que las personas que no cumplen con los plazos de pago estipulados en un acuerdo de préstamo están en “incumplimiento”. Una puntuación de crédito es entonces una probabilidad predicha de estar en incumplimiento, utilizando la información de la solicitud de crédito como variables explicativas para desarrollar la puntuación. La elección de las variables explicativas depende del propósito de la solicitud; la puntuación de crédito se usa tanto para emitir tarjetas de crédito para pequeñas compras de consumo como para solicitudes de hipotecas de casas multimillonarias. En la <a href="C11Binary.html#Tab112">Tabla 11.2</a>, Hand y Henley (1997) proporcionan una lista de características típicas que se utilizan en la puntuación de crédito.</p>
<p><a id=Tab112></a></p>
<p><span id="Tab112">Tabla 11.2</span>. <strong>Características Utilizadas en Algunos Procedimientos de Puntuación de Crédito</strong></p>
<p><span class="math display">\[
\small{
\begin{array}{ll}
   \hline
\textbf{Características} &amp; \textbf{Valores Potenciales} \\
\hline
\text{Tiempo en la dirección actual} &amp; \text{0-1, 1-2, 3-4, 5+ años}\\
\text{Estado de la vivienda} &amp; \text{Propietario, inquilino, otro }\\
\text{Código postal} &amp; \text{Rango A, B, C, D, E} \\
\text{Teléfono} &amp; \text{Sí, no} \\
\text{Ingresos anuales del solicitante} &amp;  \text{£ (0-10000),}  \text{£ (10,000-20,000)}  \text{£ (20,000+)} \\
\text{Tarjeta de crédito} &amp; \text{Sí, no} \\
\text{Tipo de cuenta bancaria} &amp; \text{Corriente y/o ahorro, ninguna} \\
\text{Edad }&amp; \text{18-25, 26-40, 41-55, 55+ años} \\
\text{Juicios del Tribunal del Condado} &amp; \text{Número} \\
\text{Tipo de ocupación} &amp; \text{Codificado} \\
\text{Propósito del préstamo} &amp; \text{Codificado} \\
\text{Estado civil} &amp; \text{Casado, divorciado, soltero, viudo, otro} \\
\text{Tiempo con el banco} &amp; \text{Años} \\
\text{Tiempo con el empleador} &amp; \text{Años }\\
\hline
\textit{Fuente}: \text{Hand y Henley (1997)} \\
\end{array}
}
\]</span></p>
<p>Con la información de la solicitud de crédito y la experiencia de incumplimiento, se puede utilizar un modelo de regresión logística para ajustar la probabilidad de incumplimiento con puntuaciones de crédito derivadas de los valores ajustados. Wiginton (1980) proporciona una de las primeras aplicaciones de la regresión logística a la puntuación de crédito de consumidores. En ese momento, otros métodos estadísticos conocidos como análisis discriminante estaban a la vanguardia de las metodologías de puntuación cuantitativa. En su artículo de revisión, Hand y Henley (1997) discuten otros competidores de la regresión logística, incluidos los sistemas de aprendizaje automático y las redes neuronales. Como señalan Hand y Henley, no existe un “mejor” método de manera uniforme. Las técnicas de regresión son importantes por sí mismas debido a su uso generalizado y porque pueden proporcionar una plataforma para aprender sobre métodos más nuevos.</p>
<p>Las puntuaciones de crédito estiman la probabilidad de incumplimiento en préstamos, pero los emisores de crédito también están interesados en la cantidad y el momento del pago de la deuda. Por ejemplo, un “buen” riesgo puede pagar un saldo de crédito tan rápidamente que el prestamista obtiene pocas ganancias. Además, un mal riesgo hipotecario puede incumplir un préstamo tan tarde en el contrato que el prestamista ya ha ganado suficiente ganancia. Véase Gourieroux y Jasiak (2007) para una discusión amplia sobre cómo el modelado de crédito puede usarse para evaluar el riesgo y la rentabilidad de los préstamos.</p>
</div>
<div id="S:Sec1122" class="section level3 hasAnchor" number="11.2.2">
<h3><span class="header-section-number">11.2.2</span> Interpretación del Umbral<a href="C11Binary.html#S:Sec1122" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Tanto el caso logit como el probit se pueden interpretar de la siguiente manera.
Supongamos que existe un modelo lineal <em>subyacente</em>,
<span class="math inline">\(y_i^{\ast} = \mathbf{x}_i^{\mathbf{\prime}}\boldsymbol \beta + \varepsilon_i^{\ast}\)</span>. Aquí, no observamos la respuesta
<span class="math inline">\(y_i^{\ast}\)</span>, pero la interpretamos como la “propensión” a poseer
una característica. Por ejemplo, podríamos pensar en la fortaleza financiera de una empresa de seguros como una medida de su propensión a volverse insolvente (incapaz de cumplir con sus obligaciones financieras). Bajo la interpretación del umbral, no observamos la propensión, pero sí observamos cuando la propensión cruza un umbral. Es habitual asumir que este umbral es 0, por simplicidad. Así, observamos
<span class="math display">\[
y_i=\left\{
\begin{array}{ll}
0 &amp; y_i^{\ast} \le 0 \\
1 &amp; y_i^{\ast}&gt;0
\end{array}
\right. .
\]</span>
Para ver cómo se deriva el caso logit a partir del modelo del umbral,
supongamos una función de distribución logística para las perturbaciones, de modo que
<span class="math display">\[
\mathrm{\Pr }(\varepsilon_i^{\ast} \le a)=\frac{1}{1+\exp (-a)}.
\]</span>
Al igual que la distribución normal, se puede verificar calculando la densidad que la distribución logística es simétrica alrededor de cero. Así, <span class="math inline">\(-\varepsilon_i^{\ast}\)</span> tiene la misma distribución que <span class="math inline">\(\varepsilon_i^{\ast}\)</span> y entonces
<span class="math display">\[
\pi_i
=\Pr (y_i=1|\mathbf{x}_i)=\mathrm{\Pr }(y_i^{\ast}&gt;0)
=\mathrm{ \Pr }(\varepsilon_i^{\ast} \le \mathbf{x}_i^{\mathbf{\prime}}\mathbf{\beta })
=\frac{1}{1+\exp (-\mathbf{x}_i^{\mathbf{\prime}}\boldsymbol \beta)}
=\mathrm{\pi }(\mathbf{x}_i^{\mathbf{\prime}}\boldsymbol \beta).
\]</span>
Esto establece la interpretación del umbral para el caso logit.
El desarrollo para el caso probit es similar y se omite.</p>
</div>
<div id="S:Sec1123" class="section level3 hasAnchor" number="11.2.3">
<h3><span class="header-section-number">11.2.3</span> Interpretación de Utilidad Aleatoria<a href="C11Binary.html#S:Sec1123" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Tanto el caso logit como el probit también se justifican apelando a la siguiente interpretación de “utilidad aleatoria” del modelo. En algunas aplicaciones económicas, los individuos seleccionan una de dos opciones.
Aquí, las preferencias entre opciones están indexadas por una función de utilidad no observada; los individuos seleccionan la opción que les brinda mayor utilidad.</p>
<p>Para el sujeto <span class="math inline">\(i\)</span>, utilizamos la notación <span class="math inline">\(u_i\)</span> para esta función de utilidad.
Modelamos la utilidad (<span class="math inline">\(U\)</span>) como una función de un valor subyacente (<span class="math inline">\(V\)</span>) más un ruido aleatorio (<span class="math inline">\(\varepsilon\)</span>), es decir, <span class="math inline">\(U_{ij}=u_i(V_{ij}+\varepsilon_{ij})\)</span>, donde <span class="math inline">\(j\)</span> puede ser 1 o 2, correspondiente a la elección. Para ilustrar, asumimos que el individuo elige la categoría correspondiente a <span class="math inline">\(j=1\)</span> si
<span class="math inline">\(U_{i1}&gt;U_{i2}\)</span> y denotamos esta elección como <span class="math inline">\(y_i=1\)</span>. Asumiendo que
<span class="math inline">\(u_i\)</span> es una función estrictamente creciente, tenemos
<span class="math display">\[\begin{eqnarray*}
\Pr (y_i &amp;=&amp;1)=\mathrm{\Pr }(U_{i2}&lt;U_{i1})=\mathrm{\Pr }\left(
u_i(V_{i2}+\varepsilon_{i2})&lt;u_i(V_{i1}+\varepsilon_{i1})\right) \\
&amp;=&amp;\mathrm{\Pr }(\varepsilon_{i2}-\varepsilon_{i1}&lt;V_{i1}-V_{i2}).
\end{eqnarray*}\]</span></p>
<p>Para parametrizar el problema, asumimos que el valor <span class="math inline">\(V\)</span> es una combinación lineal desconocida de las variables explicativas. Específicamente, tomamos
<span class="math inline">\(V_{i2}=0\)</span> y <span class="math inline">\(V_{i1}=\mathbf{x}_i^{\mathbf{\prime}}\boldsymbol \beta\)</span>. Podemos asumir que la diferencia en los errores,
<span class="math inline">\(\varepsilon_{i2}-\varepsilon_{i1}\)</span>, sigue una distribución normal o logística,
correspondiente a los casos probit y logit, respectivamente. La distribución logística se cumple si asumimos que los errores tienen una distribución de <em>valor extremo</em>, o <em>Gumbel</em> (ver, por ejemplo, Amemiya, 1985).</p>
</div>
<div id="S:Sec1124" class="section level3 hasAnchor" number="11.2.4">
<h3><span class="header-section-number">11.2.4</span> Regresión Logística<a href="C11Binary.html#S:Sec1124" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Una ventaja del caso logit es que permite expresiones en forma cerrada,
a diferencia de la función de distribución normal. <em>Regresión logística</em> es otra frase utilizada para describir el caso logit.</p>
<p>Usando <span class="math inline">\(p=\mathrm{\pi }(z)= \left( 1+ \mathrm{e}^{-z}\right)^{-1}\)</span>,
la inversa de <span class="math inline">\(\mathrm{\pi }\)</span> se calcula como <span class="math inline">\(z=\mathrm{\pi }^{-1}(p)=\ln(p/(1-p))\)</span>. Para simplificar presentaciones futuras, definimos
<span class="math display">\[
\mathrm{logit}(p)=\ln \left( \frac{p}{1-p}\right)
\]</span>
como la <em>función logit</em>. Con un modelo de regresión logística,
representamos la combinación lineal de variables explicativas como el
logit de la probabilidad de éxito, es decir,
<span class="math inline">\(\mathbf{x}_i^{\mathbf{\prime}}\boldsymbol \beta=\mathrm{logit}(\pi_i)\)</span>.</p>
<div id="interpretación-de-los-odds" class="section level4 unnumbered hasAnchor">
<h4>Interpretación de los Odds<a href="C11Binary.html#interpretación-de-los-odds" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>Cuando la respuesta <span class="math inline">\(y\)</span> es binaria, conocer solo <span class="math inline">\(p=\Pr(y=1)\)</span>
resume toda la distribución. En algunas aplicaciones, una simple transformación de <span class="math inline">\(p\)</span> tiene una interpretación importante. El ejemplo más común de esto son los <em>odds</em>, dados por <span class="math inline">\(p/(1-p)\)</span>. Por ejemplo,
supongamos que <span class="math inline">\(y\)</span> indica si un caballo gana una carrera y
<span class="math inline">\(p\)</span> es la probabilidad de que el caballo gane. Si <span class="math inline">\(p=0.25\)</span>, entonces los odds de que el caballo gane son <span class="math inline">\(0.25/(1.00-0.25)=0.3333\)</span>. Podríamos decir que los odds de ganar son 0.3333
a 1, o de uno a tres. De manera equivalente, decimos que la probabilidad de no
ganar es <span class="math inline">\(1-p=0.75\)</span>, de modo que los odds de que el caballo no gane son <span class="math inline">\(0.75/(1-0.75)=3\)</span> y los odds en contra del caballo son tres a uno.</p>
<p>Los odds tienen una interpretación útil desde el punto de vista de las apuestas. Supongamos que estamos jugando un juego justo y que hacemos una apuesta de 1 con odds de uno a tres. Si el caballo gana, entonces recuperamos nuestro 1 más una ganancia de 3. Si el caballo pierde, perdemos nuestra apuesta de 1. Es un juego justo en el sentido de que el valor esperado del juego es cero porque ganamos 3 con probabilidad <span class="math inline">\(p=0.25\)</span> y perdemos 1 con probabilidad <span class="math inline">\(1-p=0.75\)</span>. Desde el punto de vista económico, los odds proporcionan los números importantes (apuesta de 1 y ganancia de 3), no las probabilidades. Por supuesto, si conocemos <span class="math inline">\(p\)</span>, siempre podemos calcular los odds. Del mismo modo, si conocemos los odds, siempre podemos calcular la probabilidad <span class="math inline">\(p\)</span>.</p>
<p>El logit es la función logarítmica de los odds, también conocida como <em>log-odds</em>.</p>
</div>
<div id="interpretación-de-la-razón-de-momios" class="section level4 unnumbered hasAnchor">
<h4>Interpretación de la Razón de Momios<a href="C11Binary.html#interpretación-de-la-razón-de-momios" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>Para interpretar los coeficientes de regresión en el modelo de regresión logística, <span class="math inline">\(\boldsymbol \beta=(\beta_0,\ldots ,\beta_{k})^{\prime}\)</span>, comenzamos asumiendo que la <span class="math inline">\(j\)</span>-ésima variable explicativa, <span class="math inline">\(x_{ij}\)</span>, es 0 o 1. Entonces, con la notación <span class="math inline">\(\mathbf{x}_i=(x_{i0},...,x_{ij},\ldots ,x_{ik})^{\prime}\)</span>, podemos interpretar</p>
<p><span class="math display">\[\begin{eqnarray*}
\beta_j &amp;=&amp;(x_{i0},...,1,\ldots ,x_{ik})^{\prime}\boldsymbol \beta
-(x_{i0},...,0,\ldots ,x_{ik})^{\prime}\boldsymbol \beta \\
&amp;=&amp;\ln \left( \frac{\Pr (y_i=1|x_{ij}=1)}{1-\Pr (y_i=1|x_{ij}=1)}\right) -\ln \left( \frac{\Pr (y_i=1|x_{ij}=0)}{1-\Pr (y_i=1|x_{ij}=0)}\right)
\end{eqnarray*}\]</span></p>
<p>Así,</p>
<p><span class="math display">\[
e^{\beta_j}=\frac{\Pr (y_i=1|x_{ij}=1)/\left( 1-\Pr (y_i=1|x_{ij}=1)\right) }{\Pr (y_i=1|x_{ij}=0)/\left( 1-\Pr (y_i=1|x_{ij}=0)\right) }.
\]</span>
Esto muestra que <span class="math inline">\(e^{\beta_j}\)</span> puede expresarse como la razón de dos momios, conocida como la <em>razón de momios</em>. Es decir, el numerador de esta expresión es el momio cuando <span class="math inline">\(x_{ij}=1\)</span>, mientras que el denominador es el momio cuando <span class="math inline">\(x_{ij}=0\)</span>. Así, podemos decir que el momio cuando <span class="math inline">\(x_{ij}=1\)</span> es <span class="math inline">\(\exp (\beta_j)\)</span> veces mayor que el momio cuando <span class="math inline">\(x_{ij}=0\)</span>. Para ilustrar, supongamos que <span class="math inline">\(\beta_j=0.693\)</span>, de modo que <span class="math inline">\(\exp (\beta _j)=2\)</span>. A partir de esto, decimos que los momios (para <span class="math inline">\(y=1\)</span>) son el doble para <span class="math inline">\(x_{ij}=1\)</span> que para <span class="math inline">\(x_{ij}=0\)</span>.</p>
<p>De manera similar, suponiendo que la <span class="math inline">\(j\)</span>-ésima variable explicativa es continua (diferenciable), tenemos
<span class="math display" id="eq:eq111">\[\begin{eqnarray}
\beta_j &amp;=&amp;\frac{\partial }{\partial x_{ij}}\mathbf{x}_i^{\prime}
\boldsymbol \beta =\frac{\partial }{\partial x_{ij}}\ln \left(
\frac{\Pr (y_i=1|x_{ij})}{1-\Pr (y_i=1|x_{ij})}\right)   \nonumber \\
&amp;=&amp;\frac{\frac{\partial }{\partial x_{ij}}\Pr (y_i=1|x_{ij})/\left(
1-\Pr (y_i=1|x_{ij})\right) }{\Pr (y_i=1|x_{ij})/\left( 1-\Pr
(y_i=1|x_{ij})\right) }.
\tag{11.1}
\end{eqnarray}\]</span>
Así, podemos interpretar <span class="math inline">\(\beta_j\)</span> como el cambio proporcional en la
razón de momios, conocido como <em>elasticidad</em> en economía.</p>
<hr />
<p><strong>Ejemplo: Gastos MEPS - Continuación.</strong> La Tabla
<a href="C11Binary.html#tab:Tab111">11.1</a> muestra que el porcentaje de mujeres que
fueron hospitalizadas es del <span class="math inline">\(10.7\%\)</span>; alternativamente, el momio de que una mujer sea hospitalizada es <span class="math inline">\(0.107/(1-0.107)=0.120\)</span>. Para los hombres, el porcentaje es del <span class="math inline">\(4.7\%\)</span>, de modo que el momio es <span class="math inline">\(0.0493\)</span>. La razón de momios es <span class="math inline">\(0.120/0.0493=2.434\)</span>; las mujeres tienen más del doble de probabilidad de ser hospitalizadas que los hombres.</p>
<p>A partir de un ajuste de regresión logística (descrito en la Sección
<a href="C11Binary.html#S:Sec114">11.4</a>), el coeficiente asociado al sexo es <span class="math inline">\(0.733\)</span>.
Con base en este modelo, decimos que las mujeres tienen
<span class="math inline">\(\exp (0.733)=2.081\)</span> veces más probabilidad que los hombres de ser hospitalizadas. La estimación de regresión de la razón de momios controla por variables adicionales (como edad y educación) en comparación con el cálculo básico basado en frecuencias crudas.</p>
</div>
</div>
</div>
<div id="S:Sec113" class="section level2 hasAnchor" number="11.3">
<h2><span class="header-section-number">11.3</span> Inferencia para Modelos de Regresión Logística y Probit<a href="C11Binary.html#S:Sec113" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<div id="estimación-de-parámetros" class="section level3 hasAnchor" number="11.3.1">
<h3><span class="header-section-number">11.3.1</span> Estimación de Parámetros<a href="C11Binary.html#estimación-de-parámetros" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>El método habitual de estimación para modelos logísticos y probit es el <em>máxima verosimilitud</em>, descrito con más detalle en la Sección
<a href="C11Binary.html#S:Sec119">11.9</a>. Para proporcionar una intuición, describimos
las ideas en el contexto de los modelos de regresión con variables dependientes binarias.</p>
<p>La <em>verosimilitud</em> es el valor observado de la función de probabilidad.
Para una sola observación, la verosimilitud es
<span class="math display">\[
\left\{
\begin{array}{ll}
1-\pi_i &amp; \mathrm{si}\ y_i=0 \\
\pi_i &amp; \mathrm{si}\ y_i=1
\end{array}
\right. .
\]</span>
El objetivo de la estimación de máxima verosimilitud es encontrar los valores
de los parámetros que producen la mayor verosimilitud. Encontrar el
máximo de la función logarítmica produce la misma solución que
encontrar el máximo de la función correspondiente. Debido a que
generalmente es más sencillo computacionalmente, consideramos la verosimilitud logarítmica (o log-verosimilitud), escrita como
<span class="math display" id="eq:eq112">\[\begin{equation}
\left\{
\begin{array}{ll}
\ln \left( 1-\pi_i\right) &amp; \mathrm{si}\ y_i=0 \\
\ln \pi_i &amp; \mathrm{si}\ y_i=1
\end{array}
\right. .
\tag{11.2}
\end{equation}\]</span>
De manera más compacta, la log-verosimilitud de una sola observación es
<span class="math display">\[
y_i\ln \mathrm{\pi }(\mathbf{x}_i^{\mathbf{\prime}}\boldsymbol
\beta) + (1-y_i) \ln \left( 1-\mathrm{\pi }(\mathbf{x}_i^{\mathbf{\prime}}
\boldsymbol \beta)\right) ,
\]</span>
donde <span class="math inline">\(\pi_i=\mathrm{\pi }(\mathbf{x}_i^{\mathbf{\prime}}\boldsymbol \beta)\)</span>. Asumiendo independencia entre las observaciones, la verosimilitud del conjunto de datos
es un producto de las verosimilitudes de cada observación. Tomando logaritmos, la
log-verosimilitud del conjunto de datos es la suma de las log-verosimilitudes de cada observación.</p>
<div class="blackbox">
<p>La log-verosimilitud del conjunto de datos es
<span class="math display" id="eq:eq113">\[\begin{equation}
L(\boldsymbol \beta)=\sum\limits_{i=1}^{n}\left\{ y_i\ln \mathrm{\pi
}( \mathbf{x}_i^{\mathbf{\prime}}\boldsymbol \beta) + (1-y_i) \ln
\left( 1- \mathrm{\pi }(\mathbf{x}_i^{\mathbf{\prime}}\boldsymbol
\beta)\right) \right\} .
\tag{11.3}
\end{equation}\]</span>
La log-verosimilitud se considera como una función de los parámetros, con los
datos fijos. En contraste, la función de probabilidad conjunta
se considera como una función de los datos realizados, con los
parámetros fijos.</p>
</div>
<p>El <em>método de máxima verosimilitud</em> consiste en encontrar los valores
de <span class="math inline">\(\boldsymbol \beta\)</span> que maximizan la log-verosimilitud. El
método habitual para encontrar el máximo es tomar las derivadas parciales
con respecto a los parámetros de interés y encontrar las raíces de las ecuaciones resultantes. En este caso, al tomar las derivadas parciales
con respecto a <span class="math inline">\(\boldsymbol \beta\)</span> se obtienen las
<em>ecuaciones de puntaje</em>:</p>
<p><span class="math display" id="eq:eq114">\[\begin{equation}
\frac{\partial }{\partial \boldsymbol \beta}L(\boldsymbol \beta
)=\sum\limits_{i=1}^{n}\mathbf{x}_i\left( y_i-\mathrm{\pi
}(\mathbf{x}_i^{\mathbf{\prime}}\boldsymbol \beta)\right)
\frac{\mathrm{\pi }^{\prime}(
\mathbf{x}_i^{\mathbf{\prime}}\boldsymbol \beta)}{\mathrm{\pi
}(\mathbf{x}_i^{\mathbf{\prime}}\boldsymbol \beta)(1-\mathrm{\pi
}(\mathbf{x}_i^{ \mathbf{\prime}}\boldsymbol \beta))}=\mathbf{0},
\tag{11.4}
\end{equation}\]</span>
donde <span class="math inline">\(\pi^{\prime}\)</span> es la derivada de <span class="math inline">\(\pi\)</span>. La solución de estas ecuaciones, denotada como <span class="math inline">\(\mathbf{b}_{MLE}\)</span>, es el estimador de máxima verosimilitud. Para la función logit, las ecuaciones de puntaje se reducen a</p>
<p><span class="math display" id="eq:eq115">\[\begin{equation}
\frac{\partial }{\partial \boldsymbol \beta}L(\boldsymbol \beta
)=\sum\limits_{i=1}^{n}\mathbf{x}_i\left( y_i-\mathrm{\pi }(\mathbf{x}
_i^{\mathbf{\prime}}\boldsymbol \beta)\right) =\mathbf{0},
\tag{11.5}
\end{equation}\]</span>
donde <span class="math inline">\(\mathrm{\pi }(z)=1/(1+\exp (-z))\)</span>.</p>
</div>
<div id="inferencia-adicional" class="section level3 hasAnchor" number="11.3.2">
<h3><span class="header-section-number">11.3.2</span> Inferencia Adicional<a href="C11Binary.html#inferencia-adicional" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Un estimador de la varianza muestral grande de <span class="math inline">\(\boldsymbol \beta\)</span> puede
calcularse tomando las derivadas parciales de las ecuaciones de puntaje.
Específicamente, el término
<span class="math display">\[
\mathbf{I}(\boldsymbol \beta) = - \mathrm{E} \left( \frac{\partial^2}
{\partial \boldsymbol \beta ~ \partial \boldsymbol \beta
^{\prime}}L(\boldsymbol \beta) \right)
\]</span>
es la <em>matriz de información</em>. Como caso especial, usando la función logit
y la ecuación <a href="C11Binary.html#eq:eq115">(11.5)</a>, cálculos sencillos muestran que la matriz de información es
<span class="math display">\[
\mathbf{I}(\boldsymbol \beta) = \sum\limits_{i=1}^{n} \sigma_i^2
\mathbf{x}_i \mathbf{x}_i^{\prime}
\]</span>
donde <span class="math inline">\(\sigma_i^2 = \mathrm{\pi} (\mathbf{x}_i^{\prime} \boldsymbol \beta) (1 - \mathrm{\pi}(\mathbf{x}_i^{\prime} \boldsymbol \beta))\)</span>.
La raíz cuadrada del <span class="math inline">\((j+1)\)</span>-ésimo elemento diagonal de esta matriz,
evaluado en <span class="math inline">\(\boldsymbol \beta = \mathbf{b}_{MLE}\)</span>, proporciona el
error estándar de <span class="math inline">\(b_{j,MLE}\)</span>, denotado como <span class="math inline">\(se(b_{j,MLE})\)</span>.</p>
<p>Para evaluar el ajuste general del modelo, es habitual citar
<em>estadísticos de prueba de razón de verosimilitud</em> en modelos de regresión no lineales. Para probar la adecuación general del modelo <span class="math inline">\(H_0:\boldsymbol \beta=\mathbf{0}\)</span>, utilizamos el estadístico
<span class="math display">\[
LRT=2\times (L(\mathbf{b}_{MLE})-L_0),
\]</span>
donde <span class="math inline">\(L_0\)</span> es la log-verosimilitud maximizada solo con el término de intercepto.
Bajo la hipótesis nula <span class="math inline">\(H_0\)</span>, este estadístico tiene una
distribución chi-cuadrado con <span class="math inline">\(k\)</span> grados de libertad. La Sección
<a href="C11Binary.html#S:Sec1193">11.9.3</a> describe los estadísticos de prueba de razón de verosimilitud con
mayor detalle técnico.</p>
<p>Como se describe en la Sección <a href="C11Binary.html#S:Sec119">11.9</a>, las medidas de
bondad de ajuste pueden ser difíciles de interpretar en modelos no lineales.
Una medida es el llamado <span class="math inline">\(max-scaled~R^2\)</span>, definido como
<span class="math inline">\(R_{ms}^2=R^2/R_{max}^2\)</span>, donde
<span class="math display">\[
R^2=1-\left( \frac{\exp (L_0/n)}{\exp
(L(\mathbf{b}_{MLE})/n)}\right)
\]</span>
y <span class="math inline">\(R_{max }^2 = 1 - \exp(L_0/n)^2\)</span>. Aquí, <span class="math inline">\(L_0/n\)</span> representa el
valor promedio de esta log-verosimilitud.</p>
<p>Otra medida es un “<em>pseudo-</em><span class="math inline">\(R^2\)</span>”
<span class="math display">\[
\frac{L( \mathbf{b}_{MLE}) - L_0}{L_{max}-L_0},
\]</span>
donde <span class="math inline">\(L_0\)</span> y <span class="math inline">\(L_{max }\)</span> son la log-verosimilitud basada solo en un
intercepto y en el máximo alcanzable, respectivamente. Al igual que
el coeficiente de determinación, el pseudo-<span class="math inline">\(R^2\)</span> toma valores
entre cero y uno, con valores mayores que indican un mejor ajuste a
los datos. Otras versiones del pseudo-<span class="math inline">\(R^2\)</span> están disponibles en la
literatura, véase, por ejemplo, Cameron y Trivedi (1998). Una
ventaja de esta medida de pseudo-<span class="math inline">\(R^2\)</span> es su relación con las pruebas de
hipótesis de los coeficientes de regresión.</p>
<hr />
<p><strong>Ejemplo: Seguridad Laboral.</strong> Valletta (1999) estudió la disminución de la seguridad laboral utilizando la base de datos de la Encuesta Panel de Dinámicas de Ingresos (PSID). Aquí consideramos uno de los modelos de regresión presentados por Valletta, basado en una muestra de jefes de hogar masculinos que consta de <span class="math inline">\(n=24,168\)</span> observaciones durante los años 1976-1992, inclusive. La encuesta PSID registra las razones por las cuales los hombres dejaron su empleo más reciente, incluyendo cierres de planta, “renuncia” y cambios de trabajo por otras razones. Sin embargo, Valletta se centró en los despidos (“lay off” o “despedido”) porque las separaciones involuntarias están asociadas con la inseguridad laboral.</p>
<p><a href="C11Binary.html#Tab113">Tabla 11.3</a> presenta un modelo de regresión probit
realizado por Valletta (1999), utilizando los despidos como variable dependiente. Además de las variables explicativas enumeradas en <a href="C11Binary.html#Tab113">Tabla 11.3</a>, otras variables controladas incluyeron educación, estado civil, número de hijos, raza, años de experiencia laboral a tiempo completo y su cuadrado, afiliación sindical, empleo en el gobierno, salario logarítmico, la tasa de empleo en EE.UU. y ubicación según el área estadística metropolitana de residencia. En la <a href="C11Binary.html#Tab113">Tabla 11.3</a>, la antigüedad representa los años trabajados en la empresa actual. Además, el empleo en el sector fue medido examinando el empleo según la Encuesta de Precios al Consumidor en 387 sectores de la economía, basada en 43 categorías industriales y nueve regiones del país.</p>
<p>Por un lado, el coeficiente de antigüedad revela que los trabajadores con más experiencia tienen menos probabilidades de ser despedidos. Por otro lado, el coeficiente asociado a la interacción entre antigüedad y la tendencia temporal revela una tasa creciente de despidos para los trabajadores con más experiencia.</p>
<p>La interpretación de los coeficientes de empleo por sector también es de interés. Con una antigüedad promedio de aproximadamente 7.8 años en la muestra, vemos que los hombres con poca antigüedad no se ven muy afectados por los cambios en el empleo por sector. Sin embargo, para los hombres con más experiencia, hay una probabilidad creciente de despido asociada con los sectores de la economía donde el crecimiento disminuye.</p>
<p><a id=Tab113></a></p>
<p><span id="Tab113">Tabla 11.3</span>. <strong>Estimaciones de Regresión Probit para Despidos</strong></p>
<p><span class="math display">\[
\small{
\begin{array}{lrr}
\hline
\textbf{Variable} &amp; \textbf{Estimación del} &amp; \textbf{Error} \\
&amp; \textbf{Parámetro} &amp; \textbf{Estándar} \\
\hline
\text{Antigüedad} &amp; -0.084 &amp; 0.010 \\
\text{Tendencia Temporal} &amp; -0.002 &amp; 0.005 \\
\text{Antigüedad*(Tendencia Temporal)} &amp; 0.003 &amp; 0.001 \\
\text{Cambio en el Empleo Logarítmico por Sector} &amp; 0.094 &amp; 0.057 \\
\text{Antigüedad*(Cambio en el Empleo Logarítmico por Sector)} &amp; -0.020  &amp; 0.009 \\ \hline
\text{-2 Log Verosimilitud} &amp; 7,027.8 &amp;  \\
\text{Pseudo}-R^2 &amp; 0.097 &amp;  \\ \hline
\end{array}
}
\]</span></p>
</div>
</div>
<div id="S:Sec114" class="section level2 hasAnchor" number="11.4">
<h2><span class="header-section-number">11.4</span> Aplicación: Gastos Médicos<a href="C11Binary.html#S:Sec114" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Esta sección considera datos de la Encuesta del Panel de Gastos Médicos (MEPS), realizada por la Agencia de Investigación y Calidad de la Salud de EE. UU. MEPS es una encuesta probabilística que proporciona estimaciones representativas a nivel nacional sobre el uso de atención médica, los gastos, las fuentes de pago y la cobertura de seguros para la población civil de EE. UU. Esta encuesta recoge información detallada sobre las personas y cada episodio de atención médica, por tipo de servicios, incluyendo visitas al consultorio del médico, visitas a la sala de emergencias del hospital, visitas ambulatorias al hospital, estancias hospitalarias, visitas a otros proveedores médicos y uso de medicamentos recetados. Esta información detallada permite desarrollar modelos de utilización de atención médica para predecir gastos futuros. Consideramos datos de MEPS del primer panel de 2003 y tomamos una muestra aleatoria de <span class="math inline">\(n=2,000\)</span> individuos entre 18 y 65 años.</p>
<div id="variable-dependiente" class="section level4 unnumbered hasAnchor">
<h4>Variable Dependiente<a href="C11Binary.html#variable-dependiente" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>Nuestra variable dependiente es un indicador de gastos positivos por admisiones hospitalarias. En MEPS, las admisiones hospitalarias incluyen personas que fueron admitidas en un hospital y pasaron la noche. En contraste, los eventos ambulatorios incluyen visitas al departamento ambulatorio del hospital, visitas a proveedores en consultorios y visitas a la sala de emergencias, excluyendo servicios dentales. (Los servicios dentales, en comparación con otros tipos de atención médica, son más predecibles y ocurren de manera más regular). Las estancias hospitalarias con la misma fecha de ingreso y alta, conocidas como “estancias de cero noches”, se incluyeron en los recuentos y gastos ambulatorios. Los pagos asociados con visitas a la sala de emergencias que precedieron inmediatamente a una estancia hospitalaria se incluyeron en los gastos hospitalarios. Los medicamentos recetados vinculados a admisiones hospitalarias se incluyeron en los gastos hospitalarios (no en la utilización ambulatoria).</p>
</div>
<div id="variables-explicativas" class="section level4 unnumbered hasAnchor">
<h4>Variables Explicativas<a href="C11Binary.html#variables-explicativas" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>Las variables explicativas que pueden ayudar a explicar la utilización de atención médica se categorizan en factores demográficos, geográficos, de salud, educación y económicos. Los factores demográficos incluyen edad, sexo y etnia. A medida que las personas envejecen, la tasa a la que su salud se deteriora aumenta con la edad; como resultado, la edad tiene un impacto creciente en la demanda de atención médica. El sexo y la etnia pueden tratarse como aproximaciones de la herencia de salud y los hábitos sociales en el mantenimiento de la salud. Para un factor geográfico, usamos la región como una aproximación de la accesibilidad a los servicios de salud y del impacto económico o regional general en el comportamiento de atención médica de los residentes.</p>
<p>Se piensa que la demanda de servicios médicos está influenciada por el estado de salud y la educación de las personas. En MEPS, la salud física y mental autoevaluada, y cualquier limitación funcional o relacionada con la actividad durante el período de la muestra, se utilizan como aproximaciones del estado de salud. La educación tiende a tener un impacto ambiguo en la demanda de servicios de atención médica. Una teoría es que las personas más educadas son más conscientes de los riesgos para la salud, por lo tanto, son más activas en el mantenimiento de su salud; como resultado, las personas educadas pueden ser menos propensas a enfermedades graves que conduzcan a hospitalizaciones. Otra teoría es que las personas con menos educación tienen mayor exposición a riesgos para la salud y, a través de esta exposición, desarrollan una mayor tolerancia a ciertos tipos de riesgos. En MEPS, la educación se aproxima por los títulos recibidos y se clasifica en tres niveles diferentes: menos que secundaria, secundaria, y universidad o superior.</p>
<p>Las covariables económicas incluyen ingresos y cobertura de seguro. Una medida de ingresos en MEPS es el ingreso relativo al nivel de pobreza. Este enfoque es adecuado porque resume los efectos de los diferentes niveles de ingresos en la utilización de atención médica en dólares constantes. La cobertura de seguro también es una variable importante para explicar la utilización de atención médica. Un problema con la cobertura de seguro de salud es que reduce los precios pagados por los asegurados, lo que induce un riesgo moral. La investigación asociada con el Experimento de Seguro de Salud de Rand sugirió empíricamente que los efectos del costo compartido derivados de la cobertura de seguro afectarán principalmente el número de contactos médicos más que la intensidad de cada contacto. Esto motivó nuestra introducción de una variable binaria que toma el valor de 1 si una persona tuvo algún seguro público o privado durante al menos un mes, y 0 de lo contrario.</p>
</div>
<div id="estadísticas-descriptivas" class="section level4 unnumbered hasAnchor">
<h4>Estadísticas Descriptivas<a href="C11Binary.html#estadísticas-descriptivas" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p><a href="C11Binary.html#Tab114">Tabla 11.4</a> describe estas variables explicativas
y proporciona estadísticas descriptivas que sugieren sus efectos sobre la
probabilidad de gastos hospitalarios positivos. Por ejemplo, vemos
que las mujeres tuvieron una mayor utilización general que los hombres.
Específicamente, el 10.7% de las mujeres tuvo un gasto positivo durante
el año en comparación con solo el 4.7% de los hombres. De manera similar, la utilización
varía según otras covariables, lo que sugiere su importancia como predictores
de los gastos.</p>
<p><a id=Tab114></a></p>
<p><span id="Tab114">Tabla 11.4</span>. <strong>Porcentaje de Gastos Positivos por Variable Explicativa</strong></p>
<p><span class="math display">\[
\scriptsize{
\begin{array}{lllrr}
\hline
&amp;  &amp;   &amp; \textbf{Por-} &amp; \textbf{Porcentaje} \\
\textbf{Categoría} &amp; \textbf{Variable} &amp;  \textbf{Descripción} &amp; \textbf{centaje} &amp; \textbf{Gastos} \\
&amp;  &amp;  &amp; \textbf{de datos} &amp; \textbf{Positivos} \\ \hline
\text{Demografía} &amp; AGE &amp; \text{Edad en años entre} \\
&amp;  &amp; \text{    18 a 65 (media: 39.0)} \\
&amp; GENDER &amp; 1 \text{si mujer} &amp; 52.7 &amp; 10.7  \\
&amp;  &amp; \text{0 si hombre} &amp; 47.3  &amp;  4.7\\
\text{Etnia} &amp; ASIAN &amp; \text{1 si asiático} &amp; 4.3 &amp; 4.7  \\
&amp; BLACK &amp; \text{1 si negro} &amp; 14.8 &amp; 10.5 \\
&amp; NATIVE &amp; \text{1 si nativo} &amp; 1.1 &amp; 13.6  \\
&amp; WHITE &amp; \text{Nivel de referencia} &amp; 79.9  &amp;  7.5  \\
\text{Región} &amp; NORTHEAST &amp; 1 \text{si noreste} &amp; 14.3 &amp; 10.1 \\
&amp; MIDWEST &amp; 1 \text{si medio oeste} &amp; 19.7 &amp;  8.7 \\
&amp; SOUTH &amp; 1 \text{si sur} &amp; 38.2  &amp;  8.4 \\
&amp; WEST &amp; \text{Nivel de referencia} &amp;27.9  &amp;  5.4 \\
\hline \text{Educación} &amp; \text{COLLEGE} &amp; 1 \text{si universidad o grado superior} &amp; 27.2  &amp; 6.8 \\
&amp; HIGHSCHOOL &amp; 1 \text{si grado de secundaria} &amp; 43.3   &amp; 7.9\\
&amp; \text{Nivel de referencia } &amp; &amp; 29.5 &amp; 8.8\\  
&amp; \text{     es menor que grado} &amp;  &amp; \\
&amp; \text{    de secundaria} &amp;  &amp; \\
\hline
\text{Salud } &amp; POOR &amp; \text{1 si pobre} &amp; 3.8 &amp; 36.0 \\
\ \ \text{autoevaluada} &amp; FAIR &amp; \text{1 si regular} &amp; 9.9 &amp; 8.1 \\
\ \ \text{física} &amp; GOOD &amp; \text{1 si buena} &amp; 29.9  &amp;  8.2 \\
\ \ \text{salud}&amp; VGOOD &amp; \text{1 si muy buena} &amp; 31.1  &amp;  6.3 \\
&amp;  \text{Nivel de referencia} &amp; &amp; 25.4  &amp;  5.1 \\
&amp;  ~~~\text{   es excelente salud} &amp;   &amp; \\
\text{Salud mental} &amp; MNHPOOR &amp; \text{1 si pobre o regular} &amp; 7.5 &amp; 16.8  \\
\ \ \text{autoevaluada} &amp;  &amp; \text{0 si buena a excelente salud mental} &amp; 92.6 &amp;  7.1 \\
\text{Cualquier} &amp; ANYLIMIT &amp; \text{1 si cualquier limitación}&amp;
22.3  &amp; 14.6  \\
\ \ \ \text{ limitación} &amp;  &amp; \ \ \ \text{funcional/actividad}&amp;   &amp;  \\
\ \ \text{en la actividad} &amp;  &amp; \text{0 si no hay limitación} &amp; 77.7 &amp; 5.9
\\
\hline \text{Ingresos} &amp; HINCOME  &amp; \text{1 si ingresos altos} &amp; 31.6 &amp; 5.4 \\
\ \ \text{comparado con} &amp; MINCOME &amp; \text{1 si ingresos medios} &amp; 29.9
&amp; 7.0 \\
\ \ \text{nivel de pobreza} &amp; LINCOME &amp; \text{1 si ingresos bajos} &amp; 15.8 &amp; 8.3 \\
&amp; NPOOR &amp; \text{1 si casi pobre} &amp; 5.8 &amp; 9.5
\\
&amp; \text{Nivel de referencia} &amp; 17.0 &amp; 13.0 \\
&amp; ~~~\text{  es pobre/negativo} &amp;  &amp; \\ \hline  
\text{Seguro} &amp; INSURE &amp; \text{1 si cubierto por seguro } &amp; 77.8 &amp;  9.2 \\
\ \ \text{de salud} &amp;  &amp; \ \ \text{público/privado en } &amp;  &amp;   \\
                   &amp;  &amp; \ \ \text{cualquier mes de 2003} &amp;  &amp;  \\
&amp;  &amp; \text{0 si no tiene seguro de salud en 2003} &amp; 22.3 &amp; 3.1
\\ \hline
Total &amp;  &amp;  &amp; 100.0 &amp; 7.9 \\ \hline
\end{array}
}
\]</span></p>
<h5 style="text-align: center;">
<a id="displayCode.Tab114.Hide" href="javascript:togglecode('toggleCode.Tab114.Hide','displayCode.Tab114.Hide');"><i><strong>Código R para Generar la Tabla 11.4</strong></i></a>
</h5>
<div id="toggleCode.Tab114.Hide" style="display: none">
<div class="sourceCode" id="cb68"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb68-1"><a href="C11Binary.html#cb68-1" tabindex="-1"></a><span class="co">#  CREAR UNA FUNCIÓN CORTA PARA AHORRAR TRABAJO</span></span>
<span id="cb68-2"><a href="C11Binary.html#cb68-2" tabindex="-1"></a>fun1 <span class="ot">&lt;-</span> <span class="cf">function</span>(y){</span>
<span id="cb68-3"><a href="C11Binary.html#cb68-3" tabindex="-1"></a>  <span class="fu">options</span>(<span class="at">digits=</span><span class="dv">3</span>)</span>
<span id="cb68-4"><a href="C11Binary.html#cb68-4" tabindex="-1"></a>  temp0 <span class="ot">&lt;-</span> <span class="fu">cbind</span>(<span class="fu">table</span>(y)<span class="sc">/</span><span class="fu">length</span>(y),<span class="fu">summarize</span>(POSEXP, y, mean)) </span>
<span id="cb68-5"><a href="C11Binary.html#cb68-5" tabindex="-1"></a>  temp <span class="ot">&lt;-</span> temp0[<span class="fu">c</span>(<span class="dv">2</span>,<span class="dv">1</span>),] </span>
<span id="cb68-6"><a href="C11Binary.html#cb68-6" tabindex="-1"></a>  temp[,<span class="fu">c</span>(<span class="dv">2</span>,<span class="dv">4</span>)] <span class="ot">&lt;-</span> <span class="fu">round</span>(temp[,<span class="fu">c</span>(<span class="dv">2</span>,<span class="dv">4</span>)], <span class="at">digits=</span><span class="dv">3</span>)</span>
<span id="cb68-7"><a href="C11Binary.html#cb68-7" tabindex="-1"></a><span class="fu">return</span>(<span class="fu">cbind</span>(temp[,<span class="dv">3</span>],temp[,<span class="dv">2</span>],temp[,<span class="dv">4</span>]))}</span>
<span id="cb68-8"><a href="C11Binary.html#cb68-8" tabindex="-1"></a></span>
<span id="cb68-9"><a href="C11Binary.html#cb68-9" tabindex="-1"></a>var1 <span class="ot">&lt;-</span> <span class="fu">fun1</span>(Hexpend<span class="sc">$</span>GENDER)</span>
<span id="cb68-10"><a href="C11Binary.html#cb68-10" tabindex="-1"></a>var2 <span class="ot">&lt;-</span> <span class="fu">fun1</span>(Hexpend<span class="sc">$</span>RACE)</span>
<span id="cb68-11"><a href="C11Binary.html#cb68-11" tabindex="-1"></a>var3 <span class="ot">&lt;-</span> <span class="fu">fun1</span>(Hexpend<span class="sc">$</span>REGION)</span>
<span id="cb68-12"><a href="C11Binary.html#cb68-12" tabindex="-1"></a>var4 <span class="ot">&lt;-</span> <span class="fu">fun1</span>(Hexpend<span class="sc">$</span>EDUC)</span>
<span id="cb68-13"><a href="C11Binary.html#cb68-13" tabindex="-1"></a>var5 <span class="ot">&lt;-</span> <span class="fu">fun1</span>(Hexpend<span class="sc">$</span>PHSTAT)</span>
<span id="cb68-14"><a href="C11Binary.html#cb68-14" tabindex="-1"></a><span class="co">#var6 &lt;- fun1(Hexpend$MPOOR)</span></span>
<span id="cb68-15"><a href="C11Binary.html#cb68-15" tabindex="-1"></a>var7 <span class="ot">&lt;-</span> <span class="fu">fun1</span>(Hexpend<span class="sc">$</span>ANYLIMIT)</span>
<span id="cb68-16"><a href="C11Binary.html#cb68-16" tabindex="-1"></a>var8 <span class="ot">&lt;-</span> <span class="fu">fun1</span>(Hexpend<span class="sc">$</span>INCOME)</span>
<span id="cb68-17"><a href="C11Binary.html#cb68-17" tabindex="-1"></a>var9 <span class="ot">&lt;-</span> <span class="fu">fun1</span>(Hexpend<span class="sc">$</span>insure)</span>
<span id="cb68-18"><a href="C11Binary.html#cb68-18" tabindex="-1"></a></span>
<span id="cb68-19"><a href="C11Binary.html#cb68-19" tabindex="-1"></a>tableout <span class="ot">&lt;-</span> <span class="fu">rbind</span>(var1, var2, var3, var4,</span>
<span id="cb68-20"><a href="C11Binary.html#cb68-20" tabindex="-1"></a>                  var5, var7, var8, var9)</span>
<span id="cb68-21"><a href="C11Binary.html#cb68-21" tabindex="-1"></a><span class="co">#tableout</span></span></code></pre></div>
</div>
<p>La <a href="C11Binary.html#Tab115">Tabla 11.5</a> resume el ajuste de varios modelos de regresión binaria. Los ajustes se informan en la columna “Modelo Completo” para todas las variables utilizando la función logit. Los <span class="math inline">\(t\)</span>-ratios para muchas de las variables explicativas superan dos en valor absoluto, lo que sugiere que son predictores útiles. A partir de una inspección de estos <span class="math inline">\(t\)</span>-ratios, uno podría considerar un modelo más parsimonioso eliminando las variables estadísticamente insignificantes. La <a href="C11Binary.html#Tab115">Tabla 11.5</a> muestra un “Modelo Reducido,” en el cual las variables de edad y estado de salud mental han sido eliminadas. Para evaluar su significancia conjunta, podemos calcular un estadístico de prueba de razón de verosimilitud como el doble del cambio en la log-verosimilitud. Esto resulta ser solo <span class="math inline">\(2\times \left( -488.78-(-488.69)\right) =0.36.\)</span> Comparando esto con una distribución chi-cuadrado con <span class="math inline">\(df=2\)</span> grados de libertad, obtenemos un valor-<span class="math inline">\(p=0.835\)</span>, lo que indica que los parámetros adicionales para la edad y el estado de salud mental no son estadísticamente significativos. La <a href="C11Binary.html#Tab115">Tabla 11.5</a> también proporciona los ajustes del modelo probit. Aquí, vemos que los resultados son similares a los del modelo logit, según el signo de los coeficientes y su significancia, lo que sugiere que para esta aplicación hay poca diferencia entre las dos especificaciones.</p>
<h5 style="text-align: center;">
<a id="displayCode.Table11.1Silly" href="javascript:togglecode('toggleCode.Table11.1Silly','displayCode.Table11.1Silly');"><i><strong></strong></i></a>
</h5>
<div id="toggleCode.Table11.1Silly" style="display: none">
<div class="sourceCode" id="cb69"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb69-1"><a href="C11Binary.html#cb69-1" tabindex="-1"></a>knitr<span class="sc">::</span><span class="fu">kable</span>(<span class="dv">2</span>, <span class="at">caption =</span> <span class="st">&quot;Tonto. Crear una tabla solo para actualizar el contador...&quot;</span>)</span></code></pre></div>
<table>
<caption><span id="tab:unnamed-chunk-79">Tabla 11.2: </span>Tonto. Crear una tabla solo para actualizar el contador…</caption>
<thead>
<tr class="header">
<th align="right">x</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="right">2</td>
</tr>
</tbody>
</table>
<div class="sourceCode" id="cb70"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb70-1"><a href="C11Binary.html#cb70-1" tabindex="-1"></a>knitr<span class="sc">::</span><span class="fu">kable</span>(<span class="dv">2</span>, <span class="at">caption =</span> <span class="st">&quot;Tonto.&quot;</span>)</span></code></pre></div>
<table>
<caption><span id="tab:unnamed-chunk-80">Tabla 11.3: </span>Tonto.</caption>
<thead>
<tr class="header">
<th align="right">x</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="right">2</td>
</tr>
</tbody>
</table>
<div class="sourceCode" id="cb71"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb71-1"><a href="C11Binary.html#cb71-1" tabindex="-1"></a>knitr<span class="sc">::</span><span class="fu">kable</span>(<span class="dv">2</span>, <span class="at">caption =</span> <span class="st">&quot;Tonto. &quot;</span>)</span></code></pre></div>
<table>
<caption><span id="tab:unnamed-chunk-81">Tabla 11.4: </span>Tonto.</caption>
<thead>
<tr class="header">
<th align="right">x</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="right">2</td>
</tr>
</tbody>
</table>
</div>
<p><a id=Tab115></a></p>
<p><span id="Tab115">Tabla 11.5</span>. <strong>Comparación de Modelos de Regresión Binaria</strong></p>
<p><span class="math display">\[
\scriptsize{
\begin{array}{l|rr|rr|rr}
\hline &amp; \text{Logistic} &amp; &amp; \text{Logistic} &amp;&amp;\text{Probit} \\
\hline &amp; \text{Full Model} &amp; &amp;\text{Reduced Model} &amp;&amp; \text{Reduced Model} \\
&amp; \text{Parameter} &amp;  &amp; \text{Parameter} &amp;  &amp; \text{Parameter} &amp;  \\
\text{Effect} &amp; \text{Estimate} &amp; t\text{-ratio}o &amp; \text{Estimate} &amp; t\text{-rati}o &amp;
\text{Estimate} &amp; t\text{-ratio} \\ \hline
Intercept &amp;     -4.239 &amp;     -8.982 &amp;     -4.278 &amp;    -10.094 &amp;     -2.281 &amp;    -11.432 \\
       AGE &amp;     -0.001 &amp;     -0.180 &amp;            &amp;            &amp;            &amp;            \\
    GENDER &amp;      0.733 &amp;      3.812 &amp;      0.732 &amp;      3.806 &amp;      0.395 &amp;      4.178 \\
     ASIAN &amp;     -0.219 &amp;     -0.411 &amp;     -0.219 &amp;     -0.412 &amp;     -0.108 &amp;     -0.427 \\
     BLACK &amp;     -0.001 &amp;     -0.003 &amp;      0.004 &amp;      0.019 &amp;      0.009 &amp;      0.073 \\
    NATIVE &amp;      0.610 &amp;      0.926 &amp;      0.612 &amp;      0.930 &amp;      0.285 &amp;      0.780 \\
NORTHEAST &amp;      0.609 &amp;      2.112 &amp;      0.604 &amp;      2.098 &amp;      0.281 &amp;      1.950 \\
   MIDWEST &amp;      0.524 &amp;      1.904 &amp;      0.517 &amp;      1.883 &amp;      0.237 &amp;      1.754 \\
     SOUTH &amp;      0.339 &amp;      1.376 &amp;      0.328 &amp;      1.342 &amp;      0.130 &amp;      1.085 \\ \hline
   COLLEGE &amp;      0.068 &amp;      0.255 &amp;      0.070 &amp;      0.263 &amp;      0.049 &amp;      0.362 \\
HIGHSCHOOL &amp;      0.004 &amp;      0.017 &amp;      0.009 &amp;      0.041 &amp;
0.003 &amp;      0.030 \\ \hline
      POOR &amp;      1.712 &amp;      4.385 &amp;      1.652 &amp;      4.575 &amp;      0.939 &amp;      4.805 \\
      FAIR &amp;      0.136 &amp;      0.375 &amp;      0.109 &amp;      0.306 &amp;      0.079 &amp;      0.450 \\
      GOOD &amp;      0.376 &amp;      1.429 &amp;      0.368 &amp;      1.405 &amp;      0.182 &amp;      1.412 \\
     VGOOD &amp;      0.178 &amp;      0.667 &amp;      0.174 &amp;      0.655 &amp;      0.094 &amp;      0.728 \\
   MNHPOOR &amp;     -0.113 &amp;     -0.369 &amp;            &amp;            &amp;            &amp;            \\
  ANYLIMIT &amp;      0.564 &amp;      2.680 &amp;      0.545 &amp;      2.704 &amp;      0.311 &amp;      3.022 \\ \hline
   HINCOME &amp;     -0.921 &amp;     -3.101 &amp;     -0.919 &amp;     -3.162 &amp;     -0.470 &amp;     -3.224 \\
   MINCOME &amp;     -0.609 &amp;     -2.315 &amp;     -0.604 &amp;     -2.317 &amp;     -0.314 &amp;     -2.345 \\
   LINCOME &amp;     -0.411 &amp;     -1.453 &amp;     -0.408 &amp;     -1.449 &amp;     -0.241 &amp;     -1.633 \\
     NPOOR &amp;     -0.201 &amp;     -0.528 &amp;     -0.204 &amp;     -0.534 &amp;     -0.146 &amp;     -0.721 \\
    INSURE &amp;      1.234 &amp;      4.047 &amp;      1.227 &amp;      4.031 &amp;      0.579 &amp;      4.147 \\
\hline Log-Likelihood &amp;  -488.69 &amp;&amp; -488.78 &amp;&amp; -486.98 \\
\textit{AIC} &amp;  1,021.38 &amp;&amp; 1,017.56 &amp;&amp; 1,013.96 \\
\hline
\end{array}
}
\]</span></p>
<h5 style="text-align: center;">
<a id="displayCode.Tab115.Hide" href="javascript:togglecode('toggleCode.Tab115.Hide','displayCode.Tab115.Hide');"><i><strong>Código R para Generar la Tabla 11.5</strong></i></a>
</h5>
<div id="toggleCode.Tab115.Hide" style="display: none">
<div class="sourceCode" id="cb72"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb72-1"><a href="C11Binary.html#cb72-1" tabindex="-1"></a><span class="co">#Hexpend &lt;- read.csv(&quot;CSVData/HealthExpend.csv&quot;, header=TRUE)</span></span>
<span id="cb72-2"><a href="C11Binary.html#cb72-2" tabindex="-1"></a><span class="co">#  Tabla 11.5</span></span>
<span id="cb72-3"><a href="C11Binary.html#cb72-3" tabindex="-1"></a>Hexpend<span class="sc">$</span>POSEXP <span class="ot">=</span> <span class="dv">1</span><span class="sc">*</span>(Hexpend<span class="sc">$</span>EXPENDIP<span class="sc">&gt;</span><span class="dv">0</span>)</span>
<span id="cb72-4"><a href="C11Binary.html#cb72-4" tabindex="-1"></a></span>
<span id="cb72-5"><a href="C11Binary.html#cb72-5" tabindex="-1"></a><span class="co"># CAMBIAR NIVELES DE REFERENCIA PARA COINCIDIR CON EL LIBRO (HECHO EN SAS)</span></span>
<span id="cb72-6"><a href="C11Binary.html#cb72-6" tabindex="-1"></a><span class="fu">attach</span>(Hexpend)</span>
<span id="cb72-7"><a href="C11Binary.html#cb72-7" tabindex="-1"></a>RACE <span class="ot">=</span> <span class="fu">relevel</span>(<span class="fu">factor</span>(RACE),<span class="at">ref=</span><span class="st">&quot;WHITE&quot;</span>)</span>
<span id="cb72-8"><a href="C11Binary.html#cb72-8" tabindex="-1"></a>REGION <span class="ot">=</span> <span class="fu">relevel</span>(<span class="fu">factor</span>(REGION),<span class="at">ref=</span><span class="st">&quot;WEST&quot;</span>)</span>
<span id="cb72-9"><a href="C11Binary.html#cb72-9" tabindex="-1"></a>EDUC <span class="ot">=</span> <span class="fu">relevel</span>(<span class="fu">factor</span>(EDUC),<span class="at">ref=</span><span class="st">&quot;LHIGHSC&quot;</span>)</span>
<span id="cb72-10"><a href="C11Binary.html#cb72-10" tabindex="-1"></a>PHSTAT <span class="ot">=</span> <span class="fu">relevel</span>(<span class="fu">factor</span>(PHSTAT),<span class="at">ref=</span><span class="st">&quot;EXCE&quot;</span>)</span>
<span id="cb72-11"><a href="C11Binary.html#cb72-11" tabindex="-1"></a>INCOME <span class="ot">=</span> <span class="fu">relevel</span>(<span class="fu">factor</span>(INCOME),<span class="at">ref=</span><span class="st">&quot;POOR&quot;</span>)</span>
<span id="cb72-12"><a href="C11Binary.html#cb72-12" tabindex="-1"></a></span>
<span id="cb72-13"><a href="C11Binary.html#cb72-13" tabindex="-1"></a><span class="co"># MODELO LOGIT COMPLETO;</span></span>
<span id="cb72-14"><a href="C11Binary.html#cb72-14" tabindex="-1"></a>PosExpglmFull <span class="ot">=</span> <span class="fu">glm</span>(POSEXP<span class="sc">~</span>AGE<span class="sc">+</span>GENDER</span>
<span id="cb72-15"><a href="C11Binary.html#cb72-15" tabindex="-1"></a> <span class="sc">+</span><span class="fu">factor</span>(RACE)<span class="sc">+</span> <span class="fu">factor</span>(REGION)<span class="sc">+</span><span class="fu">factor</span>(EDUC)</span>
<span id="cb72-16"><a href="C11Binary.html#cb72-16" tabindex="-1"></a> <span class="sc">+</span><span class="fu">factor</span>(PHSTAT)<span class="sc">+</span>ANYLIMIT<span class="sc">+</span><span class="fu">factor</span>(INCOME)</span>
<span id="cb72-17"><a href="C11Binary.html#cb72-17" tabindex="-1"></a> <span class="sc">+</span>insure, <span class="at">family=</span><span class="fu">binomial</span>(<span class="at">link=</span>logit))</span>
<span id="cb72-18"><a href="C11Binary.html#cb72-18" tabindex="-1"></a><span class="co">#summary(PosExpglmFull)</span></span>
<span id="cb72-19"><a href="C11Binary.html#cb72-19" tabindex="-1"></a>Table1 <span class="ot">&lt;-</span> <span class="fu">summary</span>(PosExpglmFull)</span>
<span id="cb72-20"><a href="C11Binary.html#cb72-20" tabindex="-1"></a>Table1Red <span class="ot">&lt;-</span> <span class="fu">round</span>(Table1<span class="sc">$</span>coefficients[,<span class="fu">c</span>(<span class="dv">1</span>,<span class="dv">3</span>)], <span class="at">digits=</span><span class="dv">3</span>)</span>
<span id="cb72-21"><a href="C11Binary.html#cb72-21" tabindex="-1"></a></span>
<span id="cb72-22"><a href="C11Binary.html#cb72-22" tabindex="-1"></a><span class="co"># MODELO LOGIT REDUCIDO;</span></span>
<span id="cb72-23"><a href="C11Binary.html#cb72-23" tabindex="-1"></a>PosExpglmRed <span class="ot">=</span> <span class="fu">glm</span>(POSEXP<span class="sc">~</span>GENDER <span class="sc">+</span> <span class="fu">factor</span>(RACE) <span class="sc">+</span> </span>
<span id="cb72-24"><a href="C11Binary.html#cb72-24" tabindex="-1"></a>        <span class="sc">+</span><span class="fu">factor</span>(REGION)<span class="sc">+</span><span class="fu">factor</span>(EDUC)</span>
<span id="cb72-25"><a href="C11Binary.html#cb72-25" tabindex="-1"></a> <span class="sc">+</span><span class="fu">factor</span>(PHSTAT)<span class="sc">+</span>ANYLIMIT<span class="sc">+</span><span class="fu">factor</span>(INCOME)</span>
<span id="cb72-26"><a href="C11Binary.html#cb72-26" tabindex="-1"></a> <span class="sc">+</span>insure, <span class="at">family=</span><span class="fu">binomial</span>(<span class="at">link=</span>logit))</span>
<span id="cb72-27"><a href="C11Binary.html#cb72-27" tabindex="-1"></a><span class="co">#summary(PosExpglmRed)</span></span>
<span id="cb72-28"><a href="C11Binary.html#cb72-28" tabindex="-1"></a>Table2 <span class="ot">&lt;-</span> <span class="fu">summary</span>(PosExpglmRed)</span>
<span id="cb72-29"><a href="C11Binary.html#cb72-29" tabindex="-1"></a>Table2Red <span class="ot">&lt;-</span> <span class="fu">round</span>(Table2<span class="sc">$</span>coefficients[,<span class="fu">c</span>(<span class="dv">1</span>,<span class="dv">3</span>)], <span class="at">digits =</span> <span class="dv">3</span>) </span>
<span id="cb72-30"><a href="C11Binary.html#cb72-30" tabindex="-1"></a><span class="co">#anova(PosExpglmRed,PosExpglmFull, test=&quot;Chisq&quot;)</span></span>
<span id="cb72-31"><a href="C11Binary.html#cb72-31" tabindex="-1"></a></span>
<span id="cb72-32"><a href="C11Binary.html#cb72-32" tabindex="-1"></a><span class="co"># MODELO PROBIT REDUCIDO;</span></span>
<span id="cb72-33"><a href="C11Binary.html#cb72-33" tabindex="-1"></a>PosExpglmRedProbit <span class="ot">=</span> <span class="fu">glm</span>(POSEXP<span class="sc">~</span>GENDER<span class="sc">+</span> <span class="fu">factor</span>(RACE)<span class="sc">+</span></span>
<span id="cb72-34"><a href="C11Binary.html#cb72-34" tabindex="-1"></a>        <span class="sc">+</span><span class="fu">factor</span>(REGION)<span class="sc">+</span><span class="fu">factor</span>(EDUC)</span>
<span id="cb72-35"><a href="C11Binary.html#cb72-35" tabindex="-1"></a> <span class="sc">+</span><span class="fu">factor</span>(PHSTAT)<span class="sc">+</span><span class="fu">factor</span>(ANYLIMIT)<span class="sc">+</span><span class="fu">factor</span>(INCOME)</span>
<span id="cb72-36"><a href="C11Binary.html#cb72-36" tabindex="-1"></a> <span class="sc">+</span><span class="fu">factor</span>(insure), <span class="fu">binomial</span>(<span class="at">link=</span>probit))</span>
<span id="cb72-37"><a href="C11Binary.html#cb72-37" tabindex="-1"></a><span class="co">#summary(PosExpglmRedProbit)</span></span>
<span id="cb72-38"><a href="C11Binary.html#cb72-38" tabindex="-1"></a>Table3 <span class="ot">&lt;-</span> <span class="fu">summary</span>(PosExpglmRedProbit)</span>
<span id="cb72-39"><a href="C11Binary.html#cb72-39" tabindex="-1"></a>Table3Red <span class="ot">&lt;-</span> <span class="fu">round</span>(Table3<span class="sc">$</span>coefficients[,<span class="fu">c</span>(<span class="dv">1</span>,<span class="dv">3</span>)], <span class="at">digits =</span> <span class="dv">3</span>)</span>
<span id="cb72-40"><a href="C11Binary.html#cb72-40" tabindex="-1"></a><span class="fu">detach</span>(Hexpend)</span>
<span id="cb72-41"><a href="C11Binary.html#cb72-41" tabindex="-1"></a><span class="fu">row.names</span>(Table2Red) <span class="ot">&lt;-</span> <span class="cn">NULL</span></span>
<span id="cb72-42"><a href="C11Binary.html#cb72-42" tabindex="-1"></a><span class="fu">row.names</span>(Table3Red) <span class="ot">&lt;-</span> <span class="cn">NULL</span></span>
<span id="cb72-43"><a href="C11Binary.html#cb72-43" tabindex="-1"></a>Table23Join <span class="ot">&lt;-</span> <span class="fu">cbind</span>(Table2Red,Table3Red)</span>
<span id="cb72-44"><a href="C11Binary.html#cb72-44" tabindex="-1"></a>Table23JoinA <span class="ot">&lt;-</span> <span class="fu">rbind</span>(Table23Join[<span class="dv">1</span>,], <span class="fu">c</span>(<span class="st">&quot;&quot;</span>,<span class="st">&quot;&quot;</span>,<span class="st">&quot;&quot;</span>,<span class="st">&quot;&quot;</span>),</span>
<span id="cb72-45"><a href="C11Binary.html#cb72-45" tabindex="-1"></a>                      Table23Join[<span class="dv">2</span><span class="sc">:</span><span class="dv">14</span>,], <span class="fu">c</span>(<span class="st">&quot;&quot;</span>,<span class="st">&quot;&quot;</span>,<span class="st">&quot;&quot;</span>,<span class="st">&quot;&quot;</span>),</span>
<span id="cb72-46"><a href="C11Binary.html#cb72-46" tabindex="-1"></a>                      Table23Join[<span class="dv">15</span><span class="sc">:</span><span class="dv">20</span>,])</span>
<span id="cb72-47"><a href="C11Binary.html#cb72-47" tabindex="-1"></a>Table123 <span class="ot">&lt;-</span> <span class="fu">cbind</span>(Table1Red, Table23JoinA)</span>
<span id="cb72-48"><a href="C11Binary.html#cb72-48" tabindex="-1"></a>rowLogLik <span class="ot">&lt;-</span> <span class="fu">round</span>(<span class="fu">c</span>(<span class="fu">logLik</span>(PosExpglmFull) , <span class="fu">logLik</span>(PosExpglmRed) , <span class="fu">logLik</span>(PosExpglmRedProbit) ), <span class="at">digits =</span> <span class="dv">2</span>)</span>
<span id="cb72-49"><a href="C11Binary.html#cb72-49" tabindex="-1"></a>rowAIC <span class="ot">&lt;-</span> <span class="fu">round</span>(<span class="fu">c</span>(<span class="fu">AIC</span>(PosExpglmFull) , <span class="fu">AIC</span>(PosExpglmRed) , <span class="fu">AIC</span>(PosExpglmRedProbit) ), <span class="at">digits =</span> <span class="dv">2</span>)</span>
<span id="cb72-50"><a href="C11Binary.html#cb72-50" tabindex="-1"></a>rowSumStats <span class="ot">&lt;-</span> <span class="fu">rbind</span>(<span class="fu">c</span>(rowLogLik[<span class="dv">1</span>], <span class="st">&quot;&quot;</span>,rowLogLik[<span class="dv">2</span>], <span class="st">&quot;&quot;</span>,rowLogLik[<span class="dv">3</span>], <span class="st">&quot;&quot;</span>),</span>
<span id="cb72-51"><a href="C11Binary.html#cb72-51" tabindex="-1"></a>                     <span class="fu">c</span>(rowAIC[<span class="dv">1</span>], <span class="st">&quot;&quot;</span>,rowAIC[<span class="dv">2</span>], <span class="st">&quot;&quot;</span>,rowAIC[<span class="dv">3</span>], <span class="st">&quot;&quot;</span>) )</span>
<span id="cb72-52"><a href="C11Binary.html#cb72-52" tabindex="-1"></a><span class="fu">row.names</span>(rowSumStats) <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="st">&quot;Log-Verosimilitud&quot;</span>, <span class="st">&quot;$AIC$&quot;</span>)</span>
<span id="cb72-53"><a href="C11Binary.html#cb72-53" tabindex="-1"></a>Table123A <span class="ot">&lt;-</span> <span class="fu">rbind</span>(Table123, rowSumStats)</span>
<span id="cb72-54"><a href="C11Binary.html#cb72-54" tabindex="-1"></a><span class="fu">colnames</span>(Table123A) <span class="ot">&lt;-</span> <span class="fu">rep</span>(<span class="fu">c</span>(<span class="st">&quot;Estimaciones de Parámetro&quot;</span>, <span class="st">&quot;$t$-Ratio&quot;</span>),<span class="dv">3</span>)</span>
<span id="cb72-55"><a href="C11Binary.html#cb72-55" tabindex="-1"></a>  </span>
<span id="cb72-56"><a href="C11Binary.html#cb72-56" tabindex="-1"></a><span class="fu">TableGen1</span>(<span class="at">TableData=</span>Table123A, </span>
<span id="cb72-57"><a href="C11Binary.html#cb72-57" tabindex="-1"></a>         <span class="at">TextTitle=</span><span class="st">&#39;Comparación de Modelos de Regresión Binaria&#39;</span>, </span>
<span id="cb72-58"><a href="C11Binary.html#cb72-58" tabindex="-1"></a>         <span class="at">Align=</span><span class="st">&#39;r&#39;</span>, <span class="at">ColumnSpec=</span><span class="dv">1</span><span class="sc">:</span><span class="dv">6</span>,</span>
<span id="cb72-59"><a href="C11Binary.html#cb72-59" tabindex="-1"></a>         <span class="at">ColWidth =</span> ColWidth6)  <span class="sc">%&gt;%</span> </span>
<span id="cb72-60"><a href="C11Binary.html#cb72-60" tabindex="-1"></a>  <span class="fu">add_header_above</span>(<span class="fu">c</span>(<span class="st">&quot; &quot;</span><span class="ot">=</span><span class="dv">1</span>, <span class="st">&quot;Modelo Logístico Completo&quot;</span> <span class="ot">=</span> <span class="dv">2</span>, <span class="st">&quot;Modelo Logístico Reducido&quot;</span> <span class="ot">=</span> <span class="dv">2</span>, <span class="st">&quot;Modelo Probit Reducido&quot;</span><span class="ot">=</span><span class="dv">2</span>))</span></code></pre></div>
<table class=" lightable-classic table table-striped table-condensed" style="font-size: 12px; font-family: Cambria; width: auto !important; margin-left: auto; margin-right: auto; margin-left: auto; margin-right: auto;">
<caption style="font-size: initial !important;">
<span id="tab:Tab115">Tabla 11.5: </span><strong>Comparación de Modelos de Regresión Binaria</strong>
</caption>
<thead>
<tr>
<th style="empty-cells: hide;" colspan="1">
</th>
<th style="padding-bottom:0; padding-left:3px;padding-right:3px;text-align: center; " colspan="2">
<div style="border-bottom: 1px solid #111111; margin-bottom: -1px; ">
Modelo Logístico Completo
</div>
</th>
<th style="padding-bottom:0; padding-left:3px;padding-right:3px;text-align: center; " colspan="2">
<div style="border-bottom: 1px solid #111111; margin-bottom: -1px; ">
Modelo Logístico Reducido
</div>
</th>
<th style="padding-bottom:0; padding-left:3px;padding-right:3px;text-align: center; " colspan="2">
<div style="border-bottom: 1px solid #111111; margin-bottom: -1px; ">
Modelo Probit Reducido
</div>
</th>
</tr>
<tr>
<th style="text-align:left;">
</th>
<th style="text-align:right;">
Estimaciones de Parámetro
</th>
<th style="text-align:right;">
<span class="math inline">\(t\)</span>-Ratio
</th>
<th style="text-align:right;">
Estimaciones de Parámetro
</th>
<th style="text-align:right;">
<span class="math inline">\(t\)</span>-Ratio
</th>
<th style="text-align:right;">
Estimaciones de Parámetro
</th>
<th style="text-align:right;">
<span class="math inline">\(t\)</span>-Ratio
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;width: 2.5cm; border-right:1px solid;">
(Intercept)
</td>
<td style="text-align:right;width: 1.4cm; ">
-4.239
</td>
<td style="text-align:right;width: 1.4cm; ">
-8.981
</td>
<td style="text-align:right;width: 1.4cm; ">
-4.274
</td>
<td style="text-align:right;width: 1.4cm; ">
-10.082
</td>
<td style="text-align:right;width: 1.4cm; ">
-2.279
</td>
<td style="text-align:right;width: 1.4cm; ">
-11.346
</td>
</tr>
<tr>
<td style="text-align:left;width: 2.5cm; border-right:1px solid;">
AGE
</td>
<td style="text-align:right;width: 1.4cm; ">
-0.001
</td>
<td style="text-align:right;width: 1.4cm; ">
-0.17
</td>
<td style="text-align:right;width: 1.4cm; ">
</td>
<td style="text-align:right;width: 1.4cm; ">
</td>
<td style="text-align:right;width: 1.4cm; ">
</td>
<td style="text-align:right;width: 1.4cm; ">
</td>
</tr>
<tr>
<td style="text-align:left;width: 2.5cm; border-right:1px solid;">
GENDER
</td>
<td style="text-align:right;width: 1.4cm; ">
0.734
</td>
<td style="text-align:right;width: 1.4cm; ">
3.815
</td>
<td style="text-align:right;width: 1.4cm; ">
0.735
</td>
<td style="text-align:right;width: 1.4cm; ">
3.817
</td>
<td style="text-align:right;width: 1.4cm; ">
0.395
</td>
<td style="text-align:right;width: 1.4cm; ">
4.197
</td>
</tr>
<tr>
<td style="text-align:left;width: 2.5cm; border-right:1px solid;">
factor(RACE)ASIAN
</td>
<td style="text-align:right;width: 1.4cm; ">
-0.222
</td>
<td style="text-align:right;width: 1.4cm; ">
-0.417
</td>
<td style="text-align:right;width: 1.4cm; ">
-0.223
</td>
<td style="text-align:right;width: 1.4cm; ">
-0.418
</td>
<td style="text-align:right;width: 1.4cm; ">
-0.108
</td>
<td style="text-align:right;width: 1.4cm; ">
-0.432
</td>
</tr>
<tr>
<td style="text-align:left;width: 2.5cm; border-right:1px solid;">
factor(RACE)BLACK
</td>
<td style="text-align:right;width: 1.4cm; ">
-0.004
</td>
<td style="text-align:right;width: 1.4cm; ">
-0.017
</td>
<td style="text-align:right;width: 1.4cm; ">
-0.002
</td>
<td style="text-align:right;width: 1.4cm; ">
-0.008
</td>
<td style="text-align:right;width: 1.4cm; ">
0.008
</td>
<td style="text-align:right;width: 1.4cm; ">
0.062
</td>
</tr>
<tr>
<td style="text-align:left;width: 2.5cm; border-right:1px solid;">
factor(RACE)NATIV
</td>
<td style="text-align:right;width: 1.4cm; ">
0.602
</td>
<td style="text-align:right;width: 1.4cm; ">
0.913
</td>
<td style="text-align:right;width: 1.4cm; ">
0.607
</td>
<td style="text-align:right;width: 1.4cm; ">
0.92
</td>
<td style="text-align:right;width: 1.4cm; ">
0.283
</td>
<td style="text-align:right;width: 1.4cm; ">
0.781
</td>
</tr>
<tr>
<td style="text-align:left;width: 2.5cm; border-right:1px solid;">
factor(RACE)OTHER
</td>
<td style="text-align:right;width: 1.4cm; ">
-0.215
</td>
<td style="text-align:right;width: 1.4cm; ">
-0.32
</td>
<td style="text-align:right;width: 1.4cm; ">
-0.214
</td>
<td style="text-align:right;width: 1.4cm; ">
-0.319
</td>
<td style="text-align:right;width: 1.4cm; ">
-0.05
</td>
<td style="text-align:right;width: 1.4cm; ">
-0.148
</td>
</tr>
<tr>
<td style="text-align:left;width: 2.5cm; border-right:1px solid;">
factor(REGION)MIDWEST
</td>
<td style="text-align:right;width: 1.4cm; ">
0.518
</td>
<td style="text-align:right;width: 1.4cm; ">
1.887
</td>
<td style="text-align:right;width: 1.4cm; ">
0.517
</td>
<td style="text-align:right;width: 1.4cm; ">
1.882
</td>
<td style="text-align:right;width: 1.4cm; ">
0.236
</td>
<td style="text-align:right;width: 1.4cm; ">
1.747
</td>
</tr>
<tr>
<td style="text-align:left;width: 2.5cm; border-right:1px solid;">
factor(REGION)NORTHEAST
</td>
<td style="text-align:right;width: 1.4cm; ">
0.605
</td>
<td style="text-align:right;width: 1.4cm; ">
2.099
</td>
<td style="text-align:right;width: 1.4cm; ">
0.603
</td>
<td style="text-align:right;width: 1.4cm; ">
2.092
</td>
<td style="text-align:right;width: 1.4cm; ">
0.28
</td>
<td style="text-align:right;width: 1.4cm; ">
1.941
</td>
</tr>
<tr>
<td style="text-align:left;width: 2.5cm; border-right:1px solid;">
factor(REGION)SOUTH
</td>
<td style="text-align:right;width: 1.4cm; ">
0.332
</td>
<td style="text-align:right;width: 1.4cm; ">
1.355
</td>
<td style="text-align:right;width: 1.4cm; ">
0.33
</td>
<td style="text-align:right;width: 1.4cm; ">
1.348
</td>
<td style="text-align:right;width: 1.4cm; ">
0.13
</td>
<td style="text-align:right;width: 1.4cm; ">
1.081
</td>
</tr>
<tr>
<td style="text-align:left;width: 2.5cm; border-right:1px solid;">
factor(EDUC)COLLEGE
</td>
<td style="text-align:right;width: 1.4cm; ">
0.068
</td>
<td style="text-align:right;width: 1.4cm; ">
0.255
</td>
<td style="text-align:right;width: 1.4cm; ">
0.068
</td>
<td style="text-align:right;width: 1.4cm; ">
0.253
</td>
<td style="text-align:right;width: 1.4cm; ">
0.048
</td>
<td style="text-align:right;width: 1.4cm; ">
0.357
</td>
</tr>
<tr>
<td style="text-align:left;width: 2.5cm; border-right:1px solid;">
factor(EDUC)HIGHSCH
</td>
<td style="text-align:right;width: 1.4cm; ">
0.005
</td>
<td style="text-align:right;width: 1.4cm; ">
0.025
</td>
<td style="text-align:right;width: 1.4cm; ">
0.005
</td>
<td style="text-align:right;width: 1.4cm; ">
0.024
</td>
<td style="text-align:right;width: 1.4cm; ">
0.003
</td>
<td style="text-align:right;width: 1.4cm; ">
0.024
</td>
</tr>
<tr>
<td style="text-align:left;width: 2.5cm; border-right:1px solid;">
factor(PHSTAT)FAIR
</td>
<td style="text-align:right;width: 1.4cm; ">
0.115
</td>
<td style="text-align:right;width: 1.4cm; ">
0.321
</td>
<td style="text-align:right;width: 1.4cm; ">
0.108
</td>
<td style="text-align:right;width: 1.4cm; ">
0.303
</td>
<td style="text-align:right;width: 1.4cm; ">
0.078
</td>
<td style="text-align:right;width: 1.4cm; ">
0.445
</td>
</tr>
<tr>
<td style="text-align:left;width: 2.5cm; border-right:1px solid;">
factor(PHSTAT)GOOD
</td>
<td style="text-align:right;width: 1.4cm; ">
0.371
</td>
<td style="text-align:right;width: 1.4cm; ">
1.409
</td>
<td style="text-align:right;width: 1.4cm; ">
0.366
</td>
<td style="text-align:right;width: 1.4cm; ">
1.399
</td>
<td style="text-align:right;width: 1.4cm; ">
0.181
</td>
<td style="text-align:right;width: 1.4cm; ">
1.409
</td>
</tr>
<tr>
<td style="text-align:left;width: 2.5cm; border-right:1px solid;">
factor(PHSTAT)POOR
</td>
<td style="text-align:right;width: 1.4cm; ">
1.668
</td>
<td style="text-align:right;width: 1.4cm; ">
4.524
</td>
<td style="text-align:right;width: 1.4cm; ">
1.656
</td>
<td style="text-align:right;width: 1.4cm; ">
4.583
</td>
<td style="text-align:right;width: 1.4cm; ">
0.939
</td>
<td style="text-align:right;width: 1.4cm; ">
4.739
</td>
</tr>
<tr>
<td style="text-align:left;width: 2.5cm; border-right:1px solid;">
factor(PHSTAT)VGOO
</td>
<td style="text-align:right;width: 1.4cm; ">
0.175
</td>
<td style="text-align:right;width: 1.4cm; ">
0.654
</td>
<td style="text-align:right;width: 1.4cm; ">
</td>
<td style="text-align:right;width: 1.4cm; ">
</td>
<td style="text-align:right;width: 1.4cm; ">
</td>
<td style="text-align:right;width: 1.4cm; ">
</td>
</tr>
<tr>
<td style="text-align:left;width: 2.5cm; border-right:1px solid;">
ANYLIMIT
</td>
<td style="text-align:right;width: 1.4cm; ">
0.554
</td>
<td style="text-align:right;width: 1.4cm; ">
2.651
</td>
<td style="text-align:right;width: 1.4cm; ">
0.171
</td>
<td style="text-align:right;width: 1.4cm; ">
0.644
</td>
<td style="text-align:right;width: 1.4cm; ">
0.093
</td>
<td style="text-align:right;width: 1.4cm; ">
0.723
</td>
</tr>
<tr>
<td style="text-align:left;width: 2.5cm; border-right:1px solid;">
factor(INCOME)HINCOME
</td>
<td style="text-align:right;width: 1.4cm; ">
-0.911
</td>
<td style="text-align:right;width: 1.4cm; ">
-3.082
</td>
<td style="text-align:right;width: 1.4cm; ">
0.545
</td>
<td style="text-align:right;width: 1.4cm; ">
2.702
</td>
<td style="text-align:right;width: 1.4cm; ">
0.311
</td>
<td style="text-align:right;width: 1.4cm; ">
3.008
</td>
</tr>
<tr>
<td style="text-align:left;width: 2.5cm; border-right:1px solid;">
factor(INCOME)LINCOME
</td>
<td style="text-align:right;width: 1.4cm; ">
-0.404
</td>
<td style="text-align:right;width: 1.4cm; ">
-1.431
</td>
<td style="text-align:right;width: 1.4cm; ">
-0.92
</td>
<td style="text-align:right;width: 1.4cm; ">
-3.165
</td>
<td style="text-align:right;width: 1.4cm; ">
-0.471
</td>
<td style="text-align:right;width: 1.4cm; ">
-3.187
</td>
</tr>
<tr>
<td style="text-align:left;width: 2.5cm; border-right:1px solid;">
factor(INCOME)MINCOME
</td>
<td style="text-align:right;width: 1.4cm; ">
-0.6
</td>
<td style="text-align:right;width: 1.4cm; ">
-2.288
</td>
<td style="text-align:right;width: 1.4cm; ">
-0.408
</td>
<td style="text-align:right;width: 1.4cm; ">
-1.448
</td>
<td style="text-align:right;width: 1.4cm; ">
-0.241
</td>
<td style="text-align:right;width: 1.4cm; ">
-1.635
</td>
</tr>
<tr>
<td style="text-align:left;width: 2.5cm; border-right:1px solid;">
factor(INCOME)NPOOR
</td>
<td style="text-align:right;width: 1.4cm; ">
-0.199
</td>
<td style="text-align:right;width: 1.4cm; ">
-0.522
</td>
<td style="text-align:right;width: 1.4cm; ">
-0.604
</td>
<td style="text-align:right;width: 1.4cm; ">
-2.317
</td>
<td style="text-align:right;width: 1.4cm; ">
-0.315
</td>
<td style="text-align:right;width: 1.4cm; ">
-2.326
</td>
</tr>
<tr>
<td style="text-align:left;width: 2.5cm; border-right:1px solid;">
insure
</td>
<td style="text-align:right;width: 1.4cm; ">
1.232
</td>
<td style="text-align:right;width: 1.4cm; ">
4.041
</td>
<td style="text-align:right;width: 1.4cm; ">
-0.199
</td>
<td style="text-align:right;width: 1.4cm; ">
-0.522
</td>
<td style="text-align:right;width: 1.4cm; ">
-0.146
</td>
<td style="text-align:right;width: 1.4cm; ">
-0.722
</td>
</tr>
<tr>
<td style="text-align:left;width: 2.5cm; border-right:1px solid;">
Log-Verosimilitud
</td>
<td style="text-align:right;width: 1.4cm; ">
-488.71
</td>
<td style="text-align:right;width: 1.4cm; ">
</td>
<td style="text-align:right;width: 1.4cm; ">
-488.72
</td>
<td style="text-align:right;width: 1.4cm; ">
</td>
<td style="text-align:right;width: 1.4cm; ">
-486.97
</td>
<td style="text-align:right;width: 1.4cm; ">
</td>
</tr>
<tr>
<td style="text-align:left;width: 2.5cm; border-right:1px solid;">
<span class="math inline">\(AIC\)</span>
</td>
<td style="text-align:right;width: 1.4cm; ">
1021.42
</td>
<td style="text-align:right;width: 1.4cm; ">
</td>
<td style="text-align:right;width: 1.4cm; ">
1019.45
</td>
<td style="text-align:right;width: 1.4cm; ">
</td>
<td style="text-align:right;width: 1.4cm; ">
1015.94
</td>
<td style="text-align:right;width: 1.4cm; ">
</td>
</tr>
</tbody>
</table>
</div>
</div>
</div>
<div id="S:Sec115" class="section level2 hasAnchor" number="11.5">
<h2><span class="header-section-number">11.5</span> Variables Dependientes Nominales<a href="C11Binary.html#S:Sec115" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Ahora consideramos una respuesta que es una variable categórica no ordenada, también conocida como variable dependiente <em>nominal</em>. Suponemos que la variable dependiente <span class="math inline">\(y\)</span> puede tomar los valores <span class="math inline">\(1, 2, \ldots , c,\)</span> correspondientes a <span class="math inline">\(c\)</span> categorías. Cuando <span class="math inline">\(c&gt;2\)</span>, nos referimos a los datos como “multicategoría”, también conocidos como <em>policótomos</em> o <em>policitomos</em>.</p>
<p>En muchas aplicaciones, las categorías de respuesta corresponden a un atributo poseído o a elecciones hechas por individuos, hogares o empresas. Algunas aplicaciones incluyen:</p>
<ul>
<li>Elección de empleo, como en Valletta (1999)</li>
<li>Modo de transporte, como en el trabajo clásico de McFadden (1978)</li>
<li>Tipo de seguro de salud, como en Browne y Frees (2007).</li>
</ul>
<p>Para una observación del sujeto <span class="math inline">\(i\)</span>, denotamos la probabilidad de elegir la categoría <span class="math inline">\(j\)</span> como <span class="math inline">\(\pi_{ij}= \mathrm{Pr}(y_i = j)\)</span>, de modo que <span class="math inline">\(\pi_{i1}+\cdots+\pi_{ic}=1\)</span>. En general, modelaremos estas probabilidades como una función (conocida) de parámetros y utilizaremos la estimación de máxima verosimilitud para la inferencia estadística. Sea <span class="math inline">\(y_{ij}\)</span> una variable binaria que es 1 si <span class="math inline">\(y_i=j\)</span>. Extendiendo la ecuación <a href="C11Binary.html#eq:eq112">(11.2)</a> a <span class="math inline">\(c\)</span> categorías, la verosimilitud para el sujeto <span class="math inline">\(i\)</span> es:</p>
<p><span class="math display">\[
\prod_{j=1}^c \left( \pi_{i,j} \right)^{y_{i,j}} =\left\{
\begin{array}{cc}
\pi_{i,1} &amp; \mathrm {if}~ y_i = 1 \\
\pi_{i,2} &amp; \mathrm {if}~ y_i = 2 \\
\vdots &amp; \vdots \\
\pi_{i,c} &amp; \mathrm {if}~ y_i = c \\
\end{array}
\right. .
\]</span>
Por lo tanto, suponiendo independencia entre las observaciones, la verosimilitud total es</p>
<p><span class="math display">\[
L = \sum_{i=1}^n \sum_{j=1}^c y_{i,j}~ \mathrm{ln}~ \pi_{i,j} .
\]</span>
Con este marco, la estimación estándar de máxima verosimilitud está disponible (Sección <a href="C11Binary.html#S:Sec119">11.9</a>). Por lo tanto, nuestra tarea principal es especificar una forma apropiada para <span class="math inline">\(\pi\)</span>.</p>
<div id="S:Sec1151" class="section level3 hasAnchor" number="11.5.1">
<h3><span class="header-section-number">11.5.1</span> Logit Generalizado<a href="C11Binary.html#S:Sec1151" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Al igual que la regresión lineal estándar, los modelos de logit generalizado emplean combinaciones lineales de variables explicativas de la forma:
<span class="math display" id="eq:eq116">\[\begin{equation}
V_{i,j} = \mathbf{x}_i^{\prime} \boldsymbol \beta_j .
\tag{11.6}
\end{equation}\]</span>
Debido a que las variables dependientes no son numéricas, no podemos modelar la respuesta <span class="math inline">\(y\)</span> como una combinación lineal de variables explicativas más un error. En su lugar, utilizamos las probabilidades
<span class="math display" id="eq:eq117">\[\begin{equation}
\mathrm{Pr} \left(y_i = j \right) = \pi_{i,j} = \frac {\exp
(V_{i,j})}{\sum_{k=1}^c \exp(V_{i,k})} .
\tag{11.7}
\end{equation}\]</span>
Tenga en cuenta aquí que <span class="math inline">\(\boldsymbol \beta_j\)</span> es el vector correspondiente de parámetros que puede depender de la alternativa <span class="math inline">\(j\)</span>, mientras que las variables explicativas <span class="math inline">\(\mathbf{x}_i\)</span> no. Para que las probabilidades sumen uno, una normalización conveniente para este modelo es <span class="math inline">\(\boldsymbol \beta_c =\mathbf{0}\)</span>. Con esta normalización y el caso especial de <span class="math inline">\(c = 2\)</span>, el logit generalizado se reduce al modelo de logit introducido en la Sección <a href="C11Binary.html#S:Sec112">11.2</a>.</p>
<div id="interpretaciones-de-parámetros" class="section level4 unnumbered hasAnchor">
<h4>Interpretaciones de Parámetros<a href="C11Binary.html#interpretaciones-de-parámetros" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>Ahora describimos una interpretación de los coeficientes en los modelos de logit generalizado, similar al modelo logístico. De las ecuaciones <a href="C11Binary.html#eq:eq116">(11.6)</a> y <a href="C11Binary.html#eq:eq117">(11.7)</a>, tenemos
<span class="math display">\[
\mathrm{ln}~ \frac{\mathrm{Pr} \left(y_i = j \right)} {\mathrm{Pr}
\left(y_i = c \right)} = V_{i,j} - V_{i,c} =\mathbf{x}_i^{\prime}
\boldsymbol \beta_j .
\]</span>
El lado izquierdo de esta ecuación se interpreta como el logaritmo de las probabilidades de elegir la opción <span class="math inline">\(j\)</span> en comparación con la opción <span class="math inline">\(c\)</span>. Por lo tanto, podemos interpretar <span class="math inline">\(\boldsymbol \beta_j\)</span> como el cambio proporcional en la razón de probabilidad.</p>
<p>Los logits generalizados tienen una interesante estructura <em>anidada</em> que exploraremos brevemente en la Sección <a href="C11Binary.html#S:Sec1153">11.5.3</a>. Es decir, es fácil comprobar que, condicional a no elegir la primera categoría, la forma de Pr(<span class="math inline">\(y_i = j| y_i \neq 1\)</span>) tiene una forma de logit generalizado en la ecuación <a href="C11Binary.html#eq:eq117">(11.7)</a>. Además, si <span class="math inline">\(j\)</span> y <span class="math inline">\(h\)</span> son alternativas diferentes, observamos que</p>
<p><span class="math display">\[\begin{eqnarray*}
\mathrm{Pr}(y_i = j| y_i=j ~\mathrm{or}~ y_i=h)
&amp;=&amp;\frac{\mathrm{Pr}(y_i = j)}{\mathrm{Pr}(y_i = j)+\mathrm{Pr}(y_i
= h)}
=\frac{\mathrm{exp}(V_{i,j})}{\mathrm{exp}(V_{i,j})+\mathrm{exp}(V_{i,h})}
\\
&amp;=&amp;\frac{1}{1+\mathrm{exp}(\mathbf{x}_i^{\prime}(\boldsymbol \beta
_h - \boldsymbol \beta_j))} . \end{eqnarray*}\]</span></p>
<p>Esto tiene una forma de logit que se introdujo en la Sección
<a href="C11Binary.html#S:Sec112">11.2</a>.</p>
<p><strong>Caso Especial - Modelo con solo intercepto.</strong> Para desarrollar intuición, ahora consideramos el modelo con solo interceptos. Así, sea <span class="math inline">\(\mathbf{x}_i = 1\)</span> y <span class="math inline">\(\boldsymbol \beta_j = \beta_{0,j} = \alpha_j\)</span>. Con la convención de que <span class="math inline">\(\alpha_c=0\)</span>, tenemos
<span class="math display">\[
\mathrm{Pr} \left(y_i = j \right) = \pi_{i,j} = \frac
{e^{\alpha_j}}{e^{\alpha_1}+e^{\alpha_2}+\cdots+e^{\alpha_{c-1}}+1}
\]</span>
y
<span class="math display">\[
\mathrm{ln}~ \frac{\mathrm{Pr} \left(y_i = j \right)} {\mathrm{Pr}
\left(y_i = c \right)} = \alpha_j.
\]</span>
A partir de la segunda relación, podemos interpretar el <span class="math inline">\(j\)</span>-ésimo intercepto <span class="math inline">\(\alpha_j\)</span> como las probabilidades logarítmicas de elegir la alternativa <span class="math inline">\(j\)</span> en comparación con la alternativa <span class="math inline">\(c\)</span>.</p>
<hr />
<p><strong>Ejemplo: Seguridad Laboral - Continuación.</strong> Esta es una continuación del ejemplo de la Sección <a href="C11Binary.html#S:Sec112">11.2</a> sobre los determinantes de la rotación laboral, basado en el trabajo de Valletta (1999). El primer análisis de estos datos consideró solo la variable dependiente binaria de despido, ya que este resultado es la principal fuente de inseguridad laboral. Valletta (1999) también presentó resultados de un modelo logit generalizado, su principal motivación fue que la teoría económica que describe la rotación laboral implica que otras razones para dejar un trabajo pueden afectar las probabilidades de despido.</p>
<p>Para el modelo logit generalizado, la variable de respuesta tiene <span class="math inline">\(c = 5\)</span> categorías: despido, dejó el trabajo debido al cierre de plantas, “renunció”, cambió de trabajo por otras razones y no hubo cambio en el empleo. La categoría de “no hubo cambio en el empleo” es la omitida en <a href="C11Binary.html#Tab116">Tabla 11.6</a>. Las variables explicativas del logit generalizado son las mismas que en la regresión probit; las estimaciones resumidas en la Tabla <a href="C11Binary.html#tab:Tab111">11.1</a> se reproducen aquí para mayor conveniencia.</p>
<p><a href="C11Binary.html#Tab116">Tabla 11.6</a> muestra que la rotación disminuye a medida que aumenta la antigüedad. Para ilustrar, considere a un hombre típico en la muestra de 1992 donde tenemos tiempo = 16 y nos enfocamos en las probabilidades de despido. Para este valor de tiempo, el coeficiente asociado con la antigüedad para el despido es -0.221 + 16 (0.008) = -0.093 (debido al término de interacción). A partir de esto, interpretamos que un año adicional de antigüedad implica que la probabilidad de despido es exp(-0.093) = 91% de lo que sería de otra manera, lo que representa una disminución del 9%.</p>
<p><a href="C11Binary.html#Tab116">Tabla 11.6</a> también muestra que los coeficientes generalizados asociados con el despido son similares a los ajustes del modelo probit.</p>
<p>Los errores estándar también son cualitativamente similares, aunque más altos para los logit generalizados en comparación con el modelo probit. En particular, nuevamente vemos que el coeficiente asociado con la interacción entre la antigüedad y la tendencia del tiempo revela una tasa de despido en aumento para los trabajadores con experiencia. Lo mismo ocurre con la tasa de renuncia.</p>
<p><a id=Tab116></a></p>
<p><span id="Tab116">Tabla 11.6</span>. <strong>Estimaciones de Regresión Logit Generalizado y Probit para la Rotación Laboral</strong></p>
<p><span class="math display">\[
\small{
\begin{array}{lcrrrr}
\hline
&amp; \textbf{Probit} &amp; &amp;\textbf{Logit} &amp;\textbf{Generalizado} &amp;\textbf{Modelo} \\
&amp; \text{Regresión} &amp; &amp; \text{Cierre de} &amp; \text{Otras} &amp; \\
\text{Variable} &amp; \text{Modelo} &amp; \text{Despido} &amp; \text{Plantas} &amp; \text{razones} &amp; \text{Renuncia} \\
&amp; \text{(Despido)}\\
\hline
\text{Antigüedad} &amp; -0.084  &amp;  -0.221  &amp;  -0.086   &amp; -0.068  &amp;  -0.127 \\
   &amp;     (0.010)  &amp; (0.025)  &amp; (0.019)  &amp; (0.020)  &amp; (0.012) \\
\text{Tendencia Temporal} &amp;  -0.002  &amp;  -0.008  &amp;  -0.024  &amp;  0.011  &amp;   -0.022 \\
            &amp;  (0.005)  &amp; (0.011)  &amp; (0.016)  &amp; (0.013) &amp;  (0.007)\\
\text{Antigüedad (Tendencia Temporal)} &amp;    0.003  &amp;   0.008   &amp;  0.004  &amp;   -0.005 &amp; 0.006 \\
  &amp;    (0.001)  &amp; (0.002) &amp;  (0.001) &amp;  (0.002) &amp;  (0.001) \\
\text{Cambio en Logaritmo}   &amp;  0.094  &amp;   0.286   &amp; 0.459  &amp; -0.022  &amp; 0.333 \\
~~\text{de Empleo en el Sector}    &amp;  (0.057)  &amp; (0.123)  &amp; (0.189)  &amp; (0.158)  &amp; (0.082) \\
\text{Antigüedad (Cambio en Logaritmo} &amp; -0.020 &amp; -0.061 &amp;  -0.053  &amp;  -0.005   &amp; -0.027 \\
~~\text{de Empleo en el Sector)} &amp;    (0.009)  &amp;  (0.023)  &amp;  (0.025)  &amp; (0.025)  &amp; (0.012) \\
\hline
\end{array}
}
\]</span></p>
<p><em>Notas</em>: <em>Errores estándar en paréntesis. La categoría omitida es la de no cambio en el empleo para el logit generalizado. Otras variables controladas incluyen educación, estado civil, número de hijos, raza, años de experiencia laboral a tiempo completo y su cuadrado, membresía sindical, empleo en el gobierno, salario logarítmico, la tasa de empleo en EE.UU. y ubicación.</em></p>
</div>
</div>
<div id="S:Sec1152" class="section level3 hasAnchor" number="11.5.2">
<h3><span class="header-section-number">11.5.2</span> Logit Multinomial<a href="C11Binary.html#S:Sec1152" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Similar al ecuación <a href="C11Binary.html#eq:eq116">(11.6)</a>, una combinación lineal alternativa de las variables explicativas es
<span class="math display" id="eq:eq118">\[\begin{equation}
V_{i,j} = \mathbf{x}_{i,j}^{\prime} \boldsymbol \beta,
\tag{11.8}
\end{equation}\]</span>
donde <span class="math inline">\(\mathbf{x}_{i,j}\)</span> es un vector de variables explicativas que depende de la <span class="math inline">\(j\)</span>-ésima alternativa mientras que los parámetros <span class="math inline">\(\boldsymbol \beta\)</span> no. Utilizando las expresiones en las ecuaciones <a href="C11Binary.html#eq:eq117">(11.7)</a> y <a href="C11Binary.html#eq:eq118">(11.8)</a> se forma la base del modelo <em>logit multinomial</em>, también conocido como el modelo <em>logit condicional</em> (McFadden, 1974). Con esta especificación, la log-verosimilitud total es
<span class="math display">\[
L = \sum_{i=1}^n \sum_{j=1}^c y_{i,j}~ \mathrm{ln}~ \pi_{i,j} =
\sum_{i=1}^n \left[ \sum_{j=1}^c y_{i,j} \mathbf{x}_{i,j}^{\prime}
\boldsymbol \beta \ - \mathrm{ln} \left(\sum_{k=1}^c
\mathrm{exp}(\mathbf{x}_{i,k}^{\prime} \boldsymbol \beta)  \right)
\right].
\]</span>
Esta expresión directa para la verosimilitud permite realizar fácilmente la inferencia por máxima verosimilitud.</p>
<p>El modelo logit generalizado es un caso especial del modelo logit multinomial. Para ver esto, considere las variables explicativas <span class="math inline">\(\mathbf{x}_i\)</span> y los parámetros <span class="math inline">\(\boldsymbol \beta_j\)</span>, cada uno de dimensión <span class="math inline">\(k\times 1\)</span>. Defina
<span class="math display">\[
\mathbf{x}_{i,j} = \left(
\begin{array}{c}
\mathbf{0} \\ \vdots \\ \mathbf{0} \\ \mathbf{x}_i \\ \mathbf{0} \\
\vdots \\ \mathbf{0} \\
\end{array}\right) ~~~ \mathrm{y}~~~
\boldsymbol \beta = \left(
\begin{array}{c}
\boldsymbol \beta_1 \\ \boldsymbol \beta_2 \\
\vdots \\
\boldsymbol \beta_c \\
\end{array} \right).
\]</span>
Específicamente, <span class="math inline">\(\mathbf{x}_{i,j}\)</span> se define como <span class="math inline">\(j-1\)</span> vectores nulos (cada uno de dimensión <span class="math inline">\(k\times 1\)</span>), seguido por <span class="math inline">\(\mathbf{x}_i\)</span> y luego seguido por <span class="math inline">\(c-j\)</span> vectores nulos. Con esta especificación, tenemos <span class="math inline">\(\mathbf{x}_{i,j}^{\prime} \boldsymbol \beta =\mathbf{x}_i^{\prime} \boldsymbol \beta_j\)</span>. Así, un paquete estadístico que realiza estimaciones logit multinomiales también puede realizar estimaciones logit generalizadas mediante la codificación apropiada de variables explicativas y parámetros. Otra consecuencia de esta conexión es que algunos autores usan el término logit multinomial cuando se refieren al modelo logit generalizado.</p>
<p>Además, mediante esquemas de codificación similares, los modelos logit multinomiales también pueden manejar combinaciones lineales de la forma:
<span class="math display">\[
V_i = \mathbf{x}_{i,1,j}^{\prime} \boldsymbol \beta +
\mathbf{x}_{i,2}^{\prime} \boldsymbol \beta_j .
\]</span>
Aquí, <span class="math inline">\(\mathbf{x}_{i,1,j}\)</span> son variables explicativas que dependen de la alternativa, mientras que <span class="math inline">\(\mathbf{x}_{i,2}\)</span> no. De manera similar, <span class="math inline">\(\boldsymbol \beta_j\)</span> son parámetros que dependen de la alternativa, mientras que <span class="math inline">\(\boldsymbol \beta\)</span> no. Este tipo de combinación lineal es la base de un <em>modelo logit mixto</em>. Al igual que con los logits condicionales, es común elegir un conjunto de parámetros como base y especificar <span class="math inline">\(\boldsymbol \beta_c = \mathbf{0}\)</span> para evitar redundancias.</p>
<p>Para interpretar los parámetros del modelo logit multinomial, podemos comparar las alternativas <span class="math inline">\(h\)</span> y <span class="math inline">\(k\)</span> usando las ecuaciones <a href="C11Binary.html#eq:eq117">(11.7)</a> y <a href="C11Binary.html#eq:eq118">(11.8)</a>, obteniendo
<span class="math display">\[
\mathrm{ln}~ \frac{\mathrm{Pr} \left(y_i = h \right)} {\mathrm{Pr}
\left(y_i = k \right)} = (\mathbf{x}_{i,h}-\mathbf{x}_{i,k})
^{\prime} \boldsymbol \beta  .
\]</span>
Así, podemos interpretar <span class="math inline">\(\beta_j\)</span> como el cambio proporcional en la razón de probabilidades, donde el cambio es el valor de la <span class="math inline">\(j\)</span>-ésima variable explicativa, pasando de la alternativa <span class="math inline">\(k\)</span> a la <span class="math inline">\(h\)</span>.</p>
<p>Con la ecuación <a href="C11Binary.html#eq:eq117">(11.7)</a>, note que <span class="math inline">\(\pi_{i,1} / \pi_{i,2} = \mathrm{exp}(V_{i,1}) /\mathrm{exp}(V_{i,2})\)</span>. Esta razón no depende de los valores subyacentes de las otras alternativas, <span class="math inline">\(V_{i,j}\)</span>, para <span class="math inline">\(j=3, \ldots, c\)</span>. Esta característica, llamada <em>independencia de alternativas irrelevantes</em>, puede ser una desventaja del modelo logit multinomial para algunas aplicaciones.</p>
<hr />
<p><strong>Ejemplo: Elección de Seguro de Salud.</strong> Para ilustrar, Browne y Frees (2007) examinaron <span class="math inline">\(c=4\)</span> opciones de seguro de salud, que consistían en:</p>
<ul>
<li><span class="math inline">\(y=1\)</span> - un individuo cubierto por seguro grupal,</li>
<li><span class="math inline">\(y=2\)</span> - un individuo cubierto por seguro privado, no grupal,</li>
<li><span class="math inline">\(y=3\)</span> - un individuo cubierto por seguro gubernamental, pero no privado, o</li>
<li><span class="math inline">\(y=4\)</span> - un individuo no cubierto por seguro de salud.</li>
</ul>
<p>Sus datos sobre cobertura de seguro de salud provinieron del suplemento de marzo de la Encuesta de Población Actual (CPS, por sus siglas en inglés), realizada por la Oficina de Estadísticas Laborales. Browne y Frees (2007) analizaron aproximadamente 10,800 hogares de personas solteras por año, cubriendo de 1988 a 1995, lo que dio un total de <span class="math inline">\(n=86,475\)</span> observaciones. Examinaron si las restricciones de suscripción, leyes aprobadas para prohibir que los aseguradores discriminen, facilitan o desalientan el consumo de seguros de salud. Se centraron en las leyes de discapacidad que prohibían a los aseguradores utilizar la discapacidad física como criterio de suscripción.</p>
<p>La Tabla <a href="C11Binary.html#tab:Tab117">11.7</a> sugiere que las leyes de discapacidad tienen poco efecto en el comportamiento promedio de compra de seguro de salud. Para ilustrar, para los individuos encuestados con las leyes de discapacidad en vigor, el 57.6% compró seguro de salud grupal en comparación con el 59.3% de aquellos donde las restricciones no estaban en vigor. De manera similar, el 19.9% no tenía seguro cuando las restricciones de discapacidad estaban en vigor en comparación con el 20.1% cuando no lo estaban. En términos de probabilidades, cuando las restricciones de discapacidad estaban en vigor, las probabilidades de comprar un seguro de salud grupal en comparación con quedar sin seguro son 57.6/19.9 = 2.895. Cuando las restricciones de discapacidad no estaban en vigor, las probabilidades son 2.946. La razón de probabilidades, 2.895/2.946 = 0.983, indica que hay poco cambio en las probabilidades cuando se compara si las restricciones de discapacidad estaban en vigor o no.</p>
<h5 style="text-align: center;">
<a id="displayCode.Table11.2Silly" href="javascript:togglecode('toggleCode.Table11.2Silly','displayCode.Table11.2Silly');"><i><strong></strong></i></a>
</h5>
<div id="toggleCode.Table11.2Silly" style="display: none">
<div class="sourceCode" id="cb73"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb73-1"><a href="C11Binary.html#cb73-1" tabindex="-1"></a>knitr<span class="sc">::</span><span class="fu">kable</span>(<span class="dv">2</span>, <span class="at">caption =</span> <span class="st">&quot;Silly. Create a table just to update the counter...&quot;</span>)</span></code></pre></div>
<table>
<caption><span id="tab:unnamed-chunk-82">Tabla 11.6: </span>Silly. Create a table just to update the counter…</caption>
<thead>
<tr class="header">
<th align="right">x</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="right">2</td>
</tr>
</tbody>
</table>
</div>
<table class=" lightable-classic table table-striped table-condensed" style="font-size: 12px; font-family: Cambria; width: auto !important; margin-left: auto; margin-right: auto; margin-left: auto; margin-right: auto;">
<caption style="font-size: initial !important;">
<span id="tab:Tab117">Tabla 11.7: </span><strong>Porcentajes de Cobertura de Salud por Variable de Ley</strong>
</caption>
<thead>
<tr>
<th style="text-align:left;">
Ley de Discapacidad en Vigor
</th>
<th style="text-align:center;">
Número
</th>
<th style="text-align:center;">
Sin Seguro
</th>
<th style="text-align:center;">
No Grupal
</th>
<th style="text-align:left;">
Gubernamental
</th>
<th style="text-align:center;">
Grupal
</th>
<th style="text-align:center;">
Prob. Comparativa Grupal vs. Sin Seguro
</th>
<th style="text-align:center;">
Razón de Probabilidades
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;width: 2.5cm; border-right:1px solid;">
No
</td>
<td style="text-align:center;width: 1.3cm; ">
82246
</td>
<td style="text-align:center;width: 1.3cm; ">
20.1
</td>
<td style="text-align:center;width: 1.3cm; ">
12.2
</td>
<td style="text-align:left;width: 1.3cm; ">
8.4
</td>
<td style="text-align:center;width: 1.3cm; ">
59.3
</td>
<td style="text-align:center;width: 1.3cm; ">
2.946
</td>
<td style="text-align:center;width: 1.3cm; ">
</td>
</tr>
<tr>
<td style="text-align:left;width: 2.5cm; border-right:1px solid;">
Sí
</td>
<td style="text-align:center;width: 1.3cm; ">
4229
</td>
<td style="text-align:center;width: 1.3cm; ">
19.9
</td>
<td style="text-align:center;width: 1.3cm; ">
10.1
</td>
<td style="text-align:left;width: 1.3cm; ">
12.5
</td>
<td style="text-align:center;width: 1.3cm; ">
57.6
</td>
<td style="text-align:center;width: 1.3cm; ">
2.895
</td>
<td style="text-align:center;width: 1.3cm; ">
0.983
</td>
</tr>
<tr>
<td style="text-align:left;width: 2.5cm; border-right:1px solid;">
Total
</td>
<td style="text-align:center;width: 1.3cm; ">
86475
</td>
<td style="text-align:center;width: 1.3cm; ">
20.1
</td>
<td style="text-align:center;width: 1.3cm; ">
12.1
</td>
<td style="text-align:left;width: 1.3cm; ">
8.6
</td>
<td style="text-align:center;width: 1.3cm; ">
59.2
</td>
<td style="text-align:center;width: 1.3cm; ">
</td>
<td style="text-align:center;width: 1.3cm; ">
</td>
</tr>
</tbody>
</table>
<p>En contraste, la Tabla <a href="C11Binary.html#tab:Tab118">11.8</a> sugiere que las leyes de discapacidad
pueden tener efectos importantes en el comportamiento promedio de compra de seguro de salud
de subgrupos seleccionados de la muestra. La Tabla <a href="C11Binary.html#tab:Tab118">11.8</a> muestra el porcentaje de personas sin seguro y las probabilidades
de adquirir un seguro grupal (comparado con estar sin seguro) para
subgrupos seleccionados. Para ilustrar, para personas con discapacidad, las
probabilidades de adquirir un seguro grupal son 1.329 veces más altas cuando
las restricciones de discapacidad están en vigor. La Tabla <a href="C11Binary.html#tab:Tab117">11.7</a> sugiere que las restricciones de discapacidad no
tienen efecto; esto puede ser cierto al observar toda la muestra.
Sin embargo, al examinar subgrupos, la Tabla <a href="C11Binary.html#tab:Tab118">11.8</a>
muestra que podemos ver efectos importantes asociados con las restricciones legales
de suscripción que no son evidentes al observar los promedios en toda la muestra.</p>
<table class=" lightable-classic table table-striped table-condensed" style="font-size: 12px; font-family: Cambria; width: auto !important; margin-left: auto; margin-right: auto; margin-left: auto; margin-right: auto;">
<caption style="font-size: initial !important;">
<span id="tab:Tab118">Tabla 11.8: </span><strong>Probabilidades de Cobertura de Salud por Ley y Discapacidad Física</strong>
</caption>
<thead>
<tr>
<th style="text-align:left;">
Subgrupos Seleccionados
</th>
<th style="text-align:right;">
Ley de Discapacidad en Vigor
</th>
<th style="text-align:right;">
Número
</th>
<th style="text-align:right;">
Porcentaje Grupal
</th>
<th style="text-align:right;">
Porcentaje Sin Seguro
</th>
<th style="text-align:right;">
Prob. Comparativa Grupal vs. Sin Seguro
</th>
<th style="text-align:right;">
Razón de Probabilidades
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;width: 2.5cm; border-right:1px solid;">
Sin Discapacidad
</td>
<td style="text-align:right;width: 1.4cm; ">
No
</td>
<td style="text-align:right;width: 1.4cm; ">
72150
</td>
<td style="text-align:right;width: 1.4cm; ">
64.2
</td>
<td style="text-align:right;width: 1.4cm; ">
20.5
</td>
<td style="text-align:right;width: 1.4cm; ">
3.134
</td>
<td style="text-align:right;width: 1.4cm; ">
</td>
</tr>
<tr>
<td style="text-align:left;width: 2.5cm; border-right:1px solid;">
Sin Discapacidad
</td>
<td style="text-align:right;width: 1.4cm; ">
Sí
</td>
<td style="text-align:right;width: 1.4cm; ">
3649
</td>
<td style="text-align:right;width: 1.4cm; ">
63.4
</td>
<td style="text-align:right;width: 1.4cm; ">
21.2
</td>
<td style="text-align:right;width: 1.4cm; ">
2.985
</td>
<td style="text-align:right;width: 1.4cm; ">
0.952
</td>
</tr>
<tr>
<td style="text-align:left;width: 2.5cm; border-right:1px solid;">
Con Discapacidad
</td>
<td style="text-align:right;width: 1.4cm; ">
No
</td>
<td style="text-align:right;width: 1.4cm; ">
10096
</td>
<td style="text-align:right;width: 1.4cm; ">
24.5
</td>
<td style="text-align:right;width: 1.4cm; ">
17.6
</td>
<td style="text-align:right;width: 1.4cm; ">
1.391
</td>
<td style="text-align:right;width: 1.4cm; ">
</td>
</tr>
<tr>
<td style="text-align:left;width: 2.5cm; border-right:1px solid;">
Con Discapacidad
</td>
<td style="text-align:right;width: 1.4cm; ">
Sí
</td>
<td style="text-align:right;width: 1.4cm; ">
580
</td>
<td style="text-align:right;width: 1.4cm; ">
21
</td>
<td style="text-align:right;width: 1.4cm; ">
11.4
</td>
<td style="text-align:right;width: 1.4cm; ">
1.848
</td>
<td style="text-align:right;width: 1.4cm; ">
1.329
</td>
</tr>
</tbody>
</table>
<p>Hay muchas formas de seleccionar subgrupos de interés. Con un gran
conjunto de datos de <span class="math inline">\(n=86,475\)</span> observaciones, probablemente se podrían elegir
subgrupos para confirmar casi cualquier hipótesis. Además, existe la
preocupación de que los datos de la CPS pueden no proporcionar una muestra representativa de
las poblaciones estatales. Por lo tanto, es habitual utilizar técnicas de regresión
para “controlar” las variables explicativas, como
la discapacidad física.</p>
<p>La Tabla <a href="C11Binary.html#tab:Tab119">11.9</a> presenta los principales resultados de un
modelo logit multinomial con muchas variables de control incluidas. Se
incluyó una variable dummy para cada uno de los 50 estados (el Distrito de
Columbia es un “estado” en este conjunto de datos, por lo que necesitamos <span class="math inline">\(51-1=50\)</span> variables dummy). Estas variables fueron sugeridas en la literatura y son
descritas con más detalle en Browne y Frees (2007). Incluyen el
género del individuo, estado civil, raza, nivel educativo, si es
trabajador independiente o no y si el individuo trabajó a tiempo completo, a tiempo parcial
o no trabajó.</p>
<p>En la Tabla <a href="C11Binary.html#tab:Tab119">11.9</a>, “Ley” se refiere a la variable binaria
que es 1 si una restricción legal estaba en vigor y
“Discapacidad” es una variable binaria que es 1 si un
individuo tiene una discapacidad física. Por lo tanto, la interacción
“Ley*Discapacidad” informa sobre el efecto de una
restricción legal en una persona con discapacidad física. La interpretación es similar a la de la
Tabla <a href="C11Binary.html#tab:Tab118">11.8</a>. Específicamente, interpretamos el
coeficiente 1.419 como que las personas con discapacidad son un 41.9% más
propensas a adquirir un seguro de salud grupal comparado con no adquirir
ningún seguro, cuando la restricción de suscripción por discapacidad está en
vigor. De manera similar, las personas sin discapacidad son un 21.2% (<span class="math inline">\(=1/0.825 - 1\)</span>) menos propensas a adquirir un seguro de salud grupal comparado con
no adquirir ningún seguro, cuando la restricción de suscripción por discapacidad
está en vigor. Este resultado sugiere que las personas sin discapacidad
son más propensas a quedar sin seguro como resultado de las prohibiciones sobre el
uso del estado de discapacidad como criterio de suscripción. En general, los
resultados son estadísticamente significativos, confirmando que esta restricción
legal tiene un impacto en el consumo de seguros de
salud.</p>
<table class=" lightable-classic table table-striped table-condensed" style="font-size: 12px; font-family: Cambria; width: auto !important; margin-left: auto; margin-right: auto; margin-left: auto; margin-right: auto;">
<caption style="font-size: initial !important;">
<span id="tab:Tab119">Tabla 11.9: </span><strong>Razones de Probabilidades del Modelo de Regresión Logit Multinomial</strong>
</caption>
<thead>
<tr>
<th style="text-align:left;">
</th>
<th style="text-align:right;">
Grupal vs. Sin Seguro
</th>
<th style="text-align:right;">
No Grupal vs. Sin Seguro
</th>
<th style="text-align:right;">
Gubernamental vs. Sin Seguro
</th>
<th style="text-align:right;">
Grupal vs. No Grupal
</th>
<th style="text-align:right;">
Grupal vs. Gubernamental
</th>
<th style="text-align:right;">
No Grupal vs. Gubernamental
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;width: 2.5cm; border-right:1px solid;width: 3.5cm; ">
Ley <span class="math inline">\(\times\)</span> Sin Discapacidad
</td>
<td style="text-align:right;width: 1.4cm; ">
0.825
</td>
<td style="text-align:right;width: 1.4cm; ">
1.053
</td>
<td style="text-align:right;width: 1.4cm; ">
1.010
</td>
<td style="text-align:right;width: 1.4cm; ">
0.784
</td>
<td style="text-align:right;width: 1.4cm; ">
0.818
</td>
<td style="text-align:right;width: 1.4cm; ">
1.043
</td>
</tr>
<tr>
<td style="text-align:left;width: 2.5cm; border-right:1px solid;width: 3.5cm; ">
<span class="math inline">\(p\)</span>-Valor
</td>
<td style="text-align:right;width: 1.4cm; ">
0.001
</td>
<td style="text-align:right;width: 1.4cm; ">
0.452
</td>
<td style="text-align:right;width: 1.4cm; ">
0.900
</td>
<td style="text-align:right;width: 1.4cm; ">
0.001
</td>
<td style="text-align:right;width: 1.4cm; ">
0.023
</td>
<td style="text-align:right;width: 1.4cm; ">
0.677
</td>
</tr>
<tr>
<td style="text-align:left;width: 2.5cm; border-right:1px solid;width: 3.5cm; ">
Ley <span class="math inline">\(\times\)</span> Con Discapacidad
</td>
<td style="text-align:right;width: 1.4cm; ">
1.419
</td>
<td style="text-align:right;width: 1.4cm; ">
0.953
</td>
<td style="text-align:right;width: 1.4cm; ">
1.664
</td>
<td style="text-align:right;width: 1.4cm; ">
1.490
</td>
<td style="text-align:right;width: 1.4cm; ">
0.854
</td>
<td style="text-align:right;width: 1.4cm; ">
0.573
</td>
</tr>
<tr>
<td style="text-align:left;width: 2.5cm; border-right:1px solid;width: 3.5cm; ">
<span class="math inline">\(p\)</span>-Valor
</td>
<td style="text-align:right;width: 1.4cm; ">
0.062
</td>
<td style="text-align:right;width: 1.4cm; ">
0.789
</td>
<td style="text-align:right;width: 1.4cm; ">
0.001
</td>
<td style="text-align:right;width: 1.4cm; ">
0.079
</td>
<td style="text-align:right;width: 1.4cm; ">
0.441
</td>
<td style="text-align:right;width: 1.4cm; ">
0.001
</td>
</tr>
</tbody>
</table>
<p><em>Notas: La regresión incluye 150 (<span class="math inline">\(=50 \times 3\)</span>) efectos específicos por estado, varias variables continuas (edad, educación e ingresos, así como términos de orden superior) y variables categóricas (como raza y año).</em></p>
</div>
<div id="S:Sec1153" class="section level3 hasAnchor" number="11.5.3">
<h3><span class="header-section-number">11.5.3</span> Logit Anidado<a href="C11Binary.html#S:Sec1153" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Para mitigar el problema de la independencia de alternativas irrelevantes
en los logits multinomiales, ahora introducimos un tipo de modelo jerárquico
conocido como un <em>logit anidado</em>. Para interpretar el modelo logit
anidado, en la primera etapa se elige una alternativa (digamos la primera
alternativa) con probabilidad
<span class="math display" id="eq:eq119">\[\begin{equation}
\pi_{i,1} = \mathrm{Pr}(y_i = 1) =
\frac{\mathrm{exp}(V_{i,1})}{\mathrm{exp}(V_{i,1})+ \left[
\sum_{k=2}^c \mathrm{exp}(V_{i,k}/ \rho) \right]^{\rho}}  .
\tag{11.9}
\end{equation}\]</span>
Luego, condicionado a no elegir la primera alternativa, la
probabilidad de elegir cualquiera de las otras alternativas sigue un
modelo logit multinomial con probabilidades
<span class="math display" id="eq:eq1110">\[\begin{equation}
\frac{\pi_{i,j}}{1-\pi_{i,1}} = \mathrm{Pr}(y_i = j | y_i \neq 1) =
\frac{\mathrm{exp}(V_{i,j}/ \rho)}{\sum_{k=2}^c
\mathrm{exp}(V_{i,k}/ \rho) }, ~~~j=2, \ldots, c .
\tag{11.10}
\end{equation}\]</span>
En las ecuaciones <a href="C11Binary.html#eq:eq119">(11.9)</a> y <a href="C11Binary.html#eq:eq1110">(11.10)</a>,
el parámetro <span class="math inline">\(\rho\)</span> mide la asociación entre las elecciones <span class="math inline">\(j = 2, \ldots, c\)</span>. El valor de <span class="math inline">\(\rho=1\)</span> se reduce al modelo logit multinomial, lo que interpretamos como independencia de alternativas irrelevantes. También interpretamos Prob(<span class="math inline">\(y_i = 1\)</span>) como un promedio
ponderado de los valores de la primera elección y las otras. Condicionado a no elegir la primera categoría, la forma de <span class="math inline">\(\mathrm{Pr}(y_i = j| y_i \neq 1)\)</span> en la ecuación <a href="C11Binary.html#eq:eq1110">(11.10)</a> tiene la misma
forma que el logit multinomial.</p>
<p>La ventaja del logit anidado es que generaliza el
modelo logit multinomial de manera que ya no tenemos el
problema de la independencia de alternativas irrelevantes. Una desventaja,
señalada por McFadden (1981), es que solo se observa una elección;
por lo tanto, no sabemos qué categoría pertenece a la primera etapa de
la anidación sin una teoría adicional sobre el comportamiento de elección.
No obstante, el logit anidado generaliza el logit multinomial al
permitir estructuras de “dependencia” alternativas. Es decir, se puede
ver el logit anidado como una alternativa robusta al logit
multinomial y examinar cada una de las categorías en la primera etapa de
la anidación.</p>
</div>
</div>
<div id="S:Sec116" class="section level2 hasAnchor" number="11.6">
<h2><span class="header-section-number">11.6</span> Variables Dependientes Ordinales<a href="C11Binary.html#S:Sec116" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Ahora consideramos una respuesta que es una variable categórica ordenada,
también conocida como una variable dependiente <em>ordinal</em>. Para ilustrar,
cualquier tipo de respuesta de encuesta en la que se califique la impresión en una
escala de siete puntos que va desde “muy insatisfecho” hasta “muy
satisfecho” es un ejemplo de una variable ordinal.</p>
<hr />
<p><strong>Ejemplo: Elección de Plan de Salud.</strong> Pauly y Herring (2007) examinaron <span class="math inline">\(c=4\)</span> opciones de tipos de planes de salud, que consistían en:</p>
<ul>
<li><span class="math inline">\(y=1\)</span> - una organización para el mantenimiento de la salud (HMO),</li>
<li><span class="math inline">\(y=2\)</span> - un plan de punto de servicio (POS),</li>
<li><span class="math inline">\(y=3\)</span> - una organización de proveedores preferidos (PPO) o</li>
<li><span class="math inline">\(y=4\)</span> - un plan de pago por servicio (FFS).</li>
</ul>
<p>Un plan FFS es el menos restrictivo, permitiendo a los afiliados ver
a los proveedores de atención médica (como médicos de atención primaria) por una tarifa
que refleja el costo de los servicios prestados. El plan PPO es el siguiente
menos restrictivo; este plan generalmente utiliza pagos FFS pero
los afiliados generalmente deben elegir de una lista de “proveedores
preferidos”. Pauly y Herring (2007) consideraron los planes POS y HMO como
el tercer y cuarto menos restrictivo, respectivamente. Un HMO a menudo
utiliza la capitación (una tarifa fija por persona) para reembolsar a los proveedores,
restringiendo a los afiliados a una red de proveedores. En contraste, un plan POS
da a los afiliados la opción de ver a proveedores fuera de la red de HMO
(por una tarifa adicional).</p>
<div id="logit-acumulativo" class="section level3 hasAnchor" number="11.6.1">
<h3><span class="header-section-number">11.6.1</span> Logit Acumulativo<a href="C11Binary.html#logit-acumulativo" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Los modelos de variables dependientes ordinales se basan en probabilidades
acumulativas de la forma
<span class="math display">\[
\mathrm{Pr} ( y \le j ) = \pi_1 + \cdots + \pi_j, ~ ~ j=1, \ldots,
c .
\]</span>
En esta sección, usamos <em>logits acumulativos</em>
<span class="math display" id="eq:eq1111">\[\begin{equation}
\mathrm{logit}\left(\mathrm{Pr} ( y \le j ) \right) = \mathrm{ln}
\left(\frac{\Pr ( y \le j )}{1-\Pr ( y \le j )}
\right)
= \mathrm{ln} \left(\frac{\pi_1 + \cdots + \pi_j}{\pi_{j+1} + \cdots
+ \pi_c}
\right) .
\tag{11.11}
\end{equation}\]</span></p>
<p>El modelo de logit acumulativo más simple es
<span class="math display">\[
\mathrm{logit}\left(\Pr ( y \le j ) \right) = \alpha_j
\]</span>
que no utiliza ninguna variable explicativa. Los parámetros de “punto de corte” <span class="math inline">\(\alpha_j\)</span> son no decrecientes, de modo que <span class="math inline">\(\alpha_1 \le \alpha_2 \le \ldots \le \alpha_c,\)</span> reflejando la naturaleza acumulativa de la función de distribución <span class="math inline">\(\mathrm{Pr} ( y \le j )\)</span>.</p>
<p>El <em>modelo de razones proporcionales</em> incorpora variables explicativas. Con este modelo, los logits acumulativos se expresan como
<span class="math display" id="eq:eq1112">\[\begin{equation}
\mathrm{logit}\left(\Pr ( y \le j ) \right)  = \alpha_j +
\mathbf{x}_i^{\prime} \boldsymbol \beta .
\tag{11.12}
\end{equation}\]</span>
Este modelo proporciona interpretaciones de los parámetros similares a las descritas para la regresión logística en la Sección <a href="C11Binary.html#S:Sec114">11.4</a>. Por ejemplo, si la variable <span class="math inline">\(x_1\)</span> es continua, entonces como en la ecuación <a href="C11Binary.html#eq:eq111">(11.1)</a> tenemos
<span class="math display">\[
\beta_1 = \frac{\partial }{\partial x_{i1}}\left( \alpha_j +
\mathbf{x}_i^{\prime}\boldsymbol \beta \right) =
\frac{\frac{\partial }{\partial x_{i1}}\Pr (y_i \le
j|\mathbf{x}_i)/\left( 1-\Pr (y_ile j|\mathbf{x}_i)\right) }{\Pr
(y_ile j|\mathbf{x}_i)/\left( 1-\Pr (y_ile
j|\mathbf{x}_i)\right) }.
\]</span>
Por lo tanto, podemos interpretar <span class="math inline">\(\beta_1\)</span> como el cambio proporcional en la razón de probabilidades acumulativas.</p>
<hr />
<p><strong>Ejemplo: Elección de Plan de Salud - Continuación.</strong> Pauly y Herring
utilizaron datos de las Encuestas del Estudio de Seguimiento Comunitario de Hogares (CTS-HS) de 1996-1997 y 1998-1999 para estudiar la demanda de seguros de salud. Esta es una encuesta representativa a nivel nacional que contiene más de 60,000 individuos por período. Como una medida de la demanda, Pauly y Herring examinaron la elección de plan de salud, razonando que los individuos que eligieron (a través de empleo o membresía en una asociación) planes menos restrictivos buscaban una mayor protección para la atención médica. (También analizaron otras medidas, incluyendo el número de restricciones impuestas a los planes y la cantidad de compartición de costos.)
<a href="C11Binary.html#Tab1110">Tabla 11.10</a> proporciona los determinantes de la elección de plan de salud
basado en <span class="math inline">\(n=34,486\)</span> individuos que tenían seguro de salud grupal, de entre 18 y 64 años sin seguro público. Pauly y Herring también compararon estos resultados con aquellos que tenían seguro de salud individual para
entender las diferencias en los determinantes entre estos dos mercados.</p>
<p><a id=Tab1110></a></p>
<p><span id="Tab1110">Tabla 11.10</span>. <strong>Modelo de Logit Acumulativo para la Elección de Plan de Salud</strong></p>
<p><span class="math display">\[
\small{
\begin{array}{llll}
\hline \textbf{Variable}  &amp; \textbf{Razón de Probabilidades} &amp; \textbf{Variable}  &amp; \textbf{Razón de Probabilidades} \\
\hline \text{Edad} &amp; 0.992^{***} &amp; \text{Hispano} &amp; 1.735^{***} \\
\text{Mujer} &amp; 1.064^{***} &amp; \text{Tomador de riesgos} &amp; 0.967 \\
\text{Tamaño de la familia} &amp; 0.985 &amp; \text{Fumador} &amp; 1.055^{***} \\
\text{Ingresos familiares} &amp; 0.963^{***} &amp; \text{Salud regular/mala} &amp; 1.056 \\
\text{Educación} &amp; 1.006 &amp; \alpha_1 &amp; 0.769^{***} \\
\text{Asiático} &amp; 1.180^{***} &amp; \alpha_2 &amp; 1.406^{***} \\
\text{Afroamericano} &amp; 1.643^{***} &amp; \alpha_3 &amp; 12.089^{***} \\
\text{R^2 Máximo Rescalado} &amp; 0.102 &amp; \\
\hline
\end{array}
}
\]</span>
<em>Notas: Fuente: Pauly y Herring (2007).</em> <span class="math inline">\(^{***}\)</span> <em>indica que los <span class="math inline">\(p\)</span>-valores asociados son menores a 0.01. Para la raza, Caucásico es la variable omitida.</em></p>
<p>Para interpretar las razones de probabilidades en <a href="C11Binary.html#Tab1110">Tabla 11.10</a>, primero notamos que las estimaciones de los puntos de corte, correspondientes a <span class="math inline">\(\alpha_1,\)</span> <span class="math inline">\(\alpha_2\)</span> y <span class="math inline">\(\alpha_3\)</span>,
aumentan a medida que las opciones se vuelven menos restrictivas, como se anticipaba. Para el género, vemos que
las probabilidades estimadas para las mujeres son 1.064 veces las de los hombres en la
dirección de elegir un plan de salud menos restrictivo. Controlando
por otras variables, las mujeres tienen más probabilidades de elegir planes
menos restrictivos que los hombres. De manera similar, los más jóvenes, menos adinerados,
no caucásicos y fumadores tienen más probabilidades de elegir planes menos restrictivos. Los coeficientes asociados con el tamaño de la familia, educación, toma de riesgos y salud auto-reportada no fueron estadísticamente significativos
en este modelo ajustado.</p>
</div>
<div id="probit-acumulativo" class="section level3 hasAnchor" number="11.6.2">
<h3><span class="header-section-number">11.6.2</span> Probit Acumulativo<a href="C11Binary.html#probit-acumulativo" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Como en la Sección <a href="C11Binary.html#S:Sec1122">11.2.2</a> para la regresión logística,
los modelos de logit acumulativo tienen una interpretación de umbral.
Específicamente, sea <span class="math inline">\(y_i^{\ast}\)</span> una variable latente, no observada, aleatoria
sobre la cual basamos la variable dependiente observada como
<span class="math display">\[
y_i=\left\{
\begin{array}{cc}
1 &amp; y_i^{\ast} \le \alpha_1 \\
2 &amp; \alpha_1 &lt; y_i^{\ast} \le \alpha_2 \\
\vdots &amp; \vdots \\
c-1 &amp; \alpha_{c-2} &lt; y_i^{\ast} \le \alpha_{c-1} \\
c &amp; \alpha_{c-1} &lt; y_i^{\ast}\\
\end{array}
\right. .
\]</span>
Si <span class="math inline">\(y_i^{\ast} - \mathbf{x}_i^{\prime}\boldsymbol \beta\)</span> tiene una
distribución logística, entonces
<span class="math display">\[
\Pr(y_i^{\ast} - \mathbf{x}_i^{\prime}\boldsymbol \beta \le
a)=\frac{1}{1+\exp (-a)}
\]</span>
y por lo tanto
<span class="math display">\[
\Pr(y_i \le j ) = \Pr(y_i^{\ast} \le \alpha_j) =\frac{1}{1+\exp
\left( -(\alpha_j - \mathbf{x}_i^{\prime}\boldsymbol \beta)
\right)}.
\]</span>
Aplicando la transformación logit a ambos lados se obtiene la ecuación
<a href="C11Binary.html#eq:eq1112">(11.12)</a>.</p>
<p>Alternativamente, asumamos que <span class="math inline">\(y_i^{\ast} - \mathbf{x}_i^{prime}\boldsymbol \beta\)</span> tiene una distribución normal estándar. Entonces,
<span class="math display">\[
\Pr(y_i \le j ) = \Pr(y_i^{\ast} \le \alpha_j) =\Phi \left(
\alpha_j - \mathbf{x}_i^{\prime}\boldsymbol \beta \right).
\]</span>
Este es el modelo de <em>probit acumulativo</em>. Al igual que en los modelos de variables binarias,
el probit acumulativo da resultados que son similares al
modelo logit acumulativo.</p>
</div>
</div>
<div id="S:Sec117" class="section level2 hasAnchor" number="11.7">
<h2><span class="header-section-number">11.7</span> Lecturas Adicionales y Referencias<a href="C11Binary.html#S:Sec117" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Los modelos de regresión de variables binarias se utilizan ampliamente. Para introducciones más
detalladas, consulte Hosmer y Lemshow (1989) o Agresti
(1996). También puede examinar tratamientos más rigurosos como los de Agresti (1990) y Cameron y Trivedi (1998). El trabajo
de Agresti (1990, 1996) discute variables dependientes multicategoría,
al igual que el tratamiento avanzado de econometría en Amemiya (1985).</p>
<p><strong>Referencias del Capítulo</strong></p>
<ul>
<li>Agresti, Alan (1990). <em>Categorical Data Analysis</em>. Wiley, New York.</li>
<li>Agresti, Alan (1996). <em>An Introduction to Categorical Data Analysis</em>. Wiley, New York.</li>
<li>Amemiya, Takeshi (1985). <em>Advanced Econometrics</em>. Harvard University Press, Cambridge, Massachusetts.</li>
<li>Browne, Mark J. and Edward W. Frees (2007). Prohibitions on health insurance underwriting. Working paper.</li>
<li>Cameron, A. Colin and Pravin K. Trivedi (1998). <em>Regression Analysis of Count Data</em>. Cambridge University Press, Cambridge.</li>
<li>Carroll, Raymond J. and David Ruppert (1988). <em>Transformation and Weighting in Regression</em>. Chapman-Hall.</li>
<li>Gourieroux, Christian and Joann Jasiak (2007). <em>The Econometrics of Individual Risk</em>. Princeton University Press, Princeton.</li>
<li>Hand, D.J. and W. E. Henley (1997). Statistical classification methods in consumer credit scoring: A review. <em>Journal of the Royal Statistical Society A</em>, 160(3), 523-541.</li>
<li>Hosmer, David W. and Stanley Lemeshow (1989). <em>Applied Logistic Regression</em>. Wiley, New York.</li>
<li>Pauly, Mark V. and Bradley Herring (2007). The demand for health insurance in the group setting: Can you always get what you want? <em>Journal of Risk and Insurance</em> 74, 115-140.</li>
<li>Smith, Richard M. and Phyllis Schumacher (2006). Academic attributes of college freshmen that lead to success in actuarial studies in a business college. <em>Journal of Education for Business</em> 81(5), 256-260.</li>
<li>Valletta, R. G. (1999). Declining job security. <em>Journal of Labor Economics</em> 17, S170-S197.</li>
<li>Wiginton, John C. (1980). A note on the comparison of logit and discriminant models of consumer credit behavior. <em>Journal of Financial and Quantitative Analysis</em> 15(3), 757-770.</li>
</ul>
</div>
<div id="S:Sec118" class="section level2 hasAnchor" number="11.8">
<h2><span class="header-section-number">11.8</span> Ejercicios<a href="C11Binary.html#S:Sec118" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>11.1 <strong>Similitud entre Logit y Probit</strong>. Suponga que la variable
aleatoria <span class="math inline">\(y^{\ast}\)</span> tiene una función de distribución logit, <span class="math inline">\(\Pr(y^{\ast} le y) = \mathrm{F}(y) = e^y/(1+e^y).\)</span></p>
<ol style="list-style-type: lower-alpha">
<li><p>Calcule la correspondiente función de densidad de probabilidad.</p></li>
<li><p>Utilice la función de densidad de probabilidad para calcular la media
(<span class="math inline">\(\mu_y\)</span>).</p></li>
<li><p>Calcule la desviación estándar correspondiente (<span class="math inline">\(\sigma_y\)</span>).</p></li>
<li><p>Defina la variable aleatoria reescalada <span class="math inline">\(y^{\ast \ast} =\frac{y^{\ast}-\mu_y}{\sigma_y}.\)</span> Determine la función de densidad de probabilidad para <span class="math inline">\(y^{\ast \ast}\)</span>.</p></li>
<li><p>Trace la función de densidad de probabilidad en la parte (d). Superponga este
gráfico con uno de una función de densidad de probabilidad normal estándar.
(Esto proporciona una versión de la función de densidad de las gráficas de la función
de distribución en la Figura 11.1.)</p></li>
</ol>
<p>11.2 <strong>Interpretación de umbral del modelo de regresión probit</strong>.
Considere un modelo lineal subyacente, <span class="math inline">\(y_i^{\ast }=\mathbf{x}_i^{\mathbf{ \prime }}\boldsymbol \beta+\epsilon_i^{\ast }\)</span>, donde
<span class="math inline">\(\epsilon_i^{\ast }\)</span> está distribuido normalmente con media cero y varianza
<span class="math inline">\(\sigma ^{2}\)</span>. Defina <span class="math inline">\(y_i=\mathrm{I}(y_i^{\ast }&gt;0),\)</span> donde I(<span class="math inline">\(\cdot\)</span>) es
la función indicadora. Muestre que <span class="math inline">\(\pi_i=\Pr (y_i=1|\mathbf{x}_i)\)</span>
<span class="math inline">\(=\mathrm{\Phi }(\mathbf{x}_i^{\mathbf{\prime }}\mathbf{\beta /\sigma })\)</span>, donde
<span class="math inline">\(\mathrm{\Phi }(\cdot)\)</span> es la función de distribución normal estándar.</p>
<p>11.3 <strong>Interpretación de utilidad aleatoria del modelo de regresión logística</strong>.
Bajo la interpretación de utilidad aleatoria, un individuo con utilidad $
U_{ij}=u_i(V_{ij}+_{ij})$, donde <span class="math inline">\(j\)</span> puede ser 1 o 2, selecciona
la categoría correspondiente a <span class="math inline">\(j=1\)</span> con probabilidad
<span class="math display">\[\begin{eqnarray*}
\pi_i &amp;=&amp; \Pr (y_i =1)=\mathrm{\Pr }(U_{i2}&lt;U_{i1}) \\
&amp;=&amp;\mathrm{\Pr }(\epsilon _{i2}-\epsilon _{i1}&lt;V_{i1}-V_{i2}).
\end{eqnarray*}\]</span>
Como en la Sección 11.2.3, tomamos <span class="math inline">\(V_{i2}=0\)</span> y
<span class="math inline">\(V_{i1}=\mathbf{x}_i^{\mathbf{\prime}}\boldsymbol \beta\)</span>. Supongamos además
que los errores provienen de una distribución de valor extremo de
la forma
<span class="math display">\[
\Pr (\epsilon_{ij}&lt;a)=\exp (-e^{-a}).
\]</span>
Muestre que la probabilidad de elección <span class="math inline">\(\pi_i\)</span> tiene una forma logit. Es decir,
muestre que
<span class="math display">\[
\pi_i=\frac{1}{1+\exp (-\mathbf{x}_i^{\mathbf{\prime }}\boldsymbol
\beta)}.
\]</span></p>
<p>11.4 <strong>Dos Poblaciones.</strong></p>
<ol style="list-style-type: lower-alpha">
<li><p>Comience con una población y suponga que <span class="math inline">\(y_1, \ldots, y_n\)</span> es
una muestra i.i.d. de una distribución Bernoulli con media <span class="math inline">\(\pi\)</span>. Muestre
que el estimador de máxima verosimilitud de <span class="math inline">\(\pi\)</span> es <span class="math inline">\(\overline{y}\)</span>.</p></li>
<li><p>Ahora considere dos poblaciones. Suponga que <span class="math inline">\(y_1, \ldots, y_{n_1}\)</span>
es una muestra i.i.d. de una distribución Bernoulli con media <span class="math inline">\(\pi_1\)</span>
y que <span class="math inline">\(y_{n_1+1}, \ldots, y_{n_1+n_2}\)</span> es una muestra i.i.d. de una
distribución Bernoulli con media <span class="math inline">\(\pi_2\)</span>, donde las muestras son
independientes entre sí.</p>
<p>b(i). Muestre que el estimador de máxima verosimilitud de <span class="math inline">\(\pi_2 - \pi_1\)</span>
es <span class="math inline">\(\overline{y}_2 - \overline{y}_1\)</span>.</p>
<p>b(ii). Determine la varianza del estimador en la parte b(i).</p></li>
<li><p>Ahora exprese el problema de las dos poblaciones en un contexto de regresión
usando una variable explicativa. Específicamente, suponga que <span class="math inline">\(x_i\)</span>
solo toma los valores 0 y 1. De las <span class="math inline">\(n\)</span> observaciones, <span class="math inline">\(n_1\)</span>
toman el valor <span class="math inline">\(x=0\)</span>. Estas <span class="math inline">\(n_1\)</span> observaciones tienen un valor promedio
de <span class="math inline">\(y\)</span> de <span class="math inline">\(\overline{y}_1\)</span>. Las restantes <span class="math inline">\(n_2 =n-n_1\)</span>
observaciones tienen el valor <span class="math inline">\(x=1\)</span> y un valor promedio de <span class="math inline">\(y\)</span>
de <span class="math inline">\(\overline{y}_2\)</span>. Usando el caso logit, sea <span class="math inline">\(b_{0,MLE}\)</span> y
<span class="math inline">\(b_{1,MLE}\)</span> representen los estimadores de máxima verosimilitud de <span class="math inline">\(\beta_0\)</span>
y <span class="math inline">\(\beta_1\)</span>, respectivamente.</p>
<p>c(i). Muestre que los estimadores de máxima verosimilitud satisfacen las
ecuaciones
<span class="math display">\[
\overline{y}_1 = \mathrm{\pi}\left(b_{0,MLE}\right)
\]</span>
y
<span class="math display">\[
\overline{y}_2 = \mathrm{\pi}\left(b_{0,MLE}+b_{1,MLE}\right).
\]</span></p>
<p>c(ii). Use la parte c(i) para mostrar que el estimador de máxima verosimilitud
para <span class="math inline">\(\beta_1\)</span> es
<span class="math inline">\(\mathrm{\pi}^{-1}(\overline{y}_2)-\mathrm{\pi}^{-1}(\overline{y}_1)\)</span>.</p>
<p>c(iii). Con la notación <span class="math inline">\(\pi_1 = \mathrm{\pi}(\beta_0)\)</span> y <span class="math inline">\(\pi_2 = \mathrm{\pi}(\beta_0 +\beta_1)\)</span>, confirme que la matriz de información
se puede expresar como
<span class="math display">\[
\mathbf{I}(\beta_0, \beta_1)  = n_1  \pi_1 (1-\pi_1) \left(
  \begin{array}{cc}
1 &amp; 0 \\
0 &amp; 0 \\
  \end{array}
\right) + n_2 \pi_2 (1-\pi_2) \left(
  \begin{array}{cc}
1 &amp; 1 \\
1 &amp; 1 \\
  \end{array}
\right).
\]</span></p>
<p>c(iv). Utilice la matriz de información para determinar la varianza en muestras grandes
del estimador de máxima verosimilitud para <span class="math inline">\(\beta_1\)</span>.</p></li>
</ol>
<p>11.5 <strong>Valores Ajustados</strong>. Sea <span class="math inline">\(\widehat{y}_i = \mathrm{\pi }\left( \mathbf{x}_i^{\prime} \mathbf{b}_{MLE})\right)\)</span> el <span class="math inline">\(i\)</span>-ésimo valor ajustado para la
función logit. Suponga que se utiliza un intercepto en el modelo, de modo
que una de las variables explicativas <span class="math inline">\(x\)</span> es una constante igual a
uno. Muestre que la respuesta promedio es igual al valor ajustado
promedio, es decir, muestre que
<span class="math inline">\(\overline{y} = n^{-1} \sum_{i=1}^n \widehat{y}_i\)</span>.</p>
<p>11.6 Comenzando con las ecuaciones de puntaje <a href="C11Binary.html#eq:eq114">(11.4)</a>, verifique la expresión para el caso logit en la ecuación <a href="C11Binary.html#eq:eq115">(11.5)</a>.</p>
<p>11.7 <strong>Matriz de Información</strong></p>
<ol style="list-style-type: lower-alpha">
<li><p>Comenzando con la función de puntaje para el caso logit en la ecuación
<a href="C11Binary.html#eq:eq115">(11.5)</a>, muestre que la matriz de información puede ser
expresada como
<span class="math display">\[
\mathbf{I}(\boldsymbol \beta) = \sum\limits_{i=1}^{n}
\sigma_i^2 \mathbf{x}_i\mathbf{x}_i^{\mathbf{\prime }},
\]</span>
donde <span class="math inline">\(\sigma_i^2 = \mathrm{\pi}(\mathbf{x}_i^{\prime} \boldsymbol \beta)(1-\mathrm{\pi}(\mathbf{x}_i^{\prime}\boldsymbol \beta))\)</span>.</p></li>
<li><p>Comenzando con la función de puntaje general en la ecuación
<a href="C11Binary.html#eq:eq114">(11.4)</a>, determine la matriz de información.</p></li>
</ol>
<p>11.8 <strong>Reclamaciones de seguro por lesiones en automóviles.</strong> Refiérase a la descripción en
el Ejercicio 1.5.</p>
<p>Consideramos <span class="math inline">\(n=1,340\)</span> reclamaciones por responsabilidad civil por lesiones corporales de un solo
estado utilizando una encuesta de 2002 realizada por el Consejo de Investigación de Seguros (IRC). El IRC es una división del Instituto Americano de Chartered Property Casualty Underwriters y el Instituto de Seguros
de América. La encuesta solicitó a las empresas participantes que informaran sobre
reclamaciones cerradas con pago durante un período de dos semanas designado. En
esta asignación, nos interesa entender las
características de los demandantes que eligen ser representados por un
abogado al resolver su reclamo. Las descripciones de las variables se dan en la Tabla <a href="C11Binary.html#tab:Tab1111">11.11</a>.</p>
<h5 style="text-align: center;">
<a id="displayCode.Table11.11Silly" href="javascript:togglecode('toggleCode.Table11.11Silly','displayCode.Table11.11Silly');"><i><strong></strong></i></a>
</h5>
<div id="toggleCode.Table11.11Silly" style="display: none">
<div class="sourceCode" id="cb74"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb74-1"><a href="C11Binary.html#cb74-1" tabindex="-1"></a>knitr<span class="sc">::</span><span class="fu">kable</span>(<span class="dv">2</span>, <span class="at">caption =</span> <span class="st">&quot;Silly. Create a table just to update the counter...&quot;</span>)</span></code></pre></div>
<table>
<caption><span id="tab:unnamed-chunk-83">Tabla 11.10: </span>Silly. Create a table just to update the counter…</caption>
<thead>
<tr class="header">
<th align="right">x</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="right">2</td>
</tr>
</tbody>
</table>
</div>
<table class=" lightable-classic table table-striped table-condensed" style="font-size: 12px; font-family: Cambria; width: auto !important; margin-left: auto; margin-right: auto; margin-left: auto; margin-right: auto;">
<caption style="font-size: initial !important;">
<span id="tab:Tab1111">Tabla 11.11: </span><strong>Reclamaciones por Lesiones Corporales</strong>
</caption>
<thead>
<tr>
<th style="text-align:left;">
<strong>Variable</strong>
</th>
<th style="text-align:left;">
<span class="math inline">\(\textbf{Descripción}\)</span>
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;width: 2.5cm; border-right:1px solid;">
ATTORNEY
</td>
<td style="text-align:left;width: 1.8cm; width: 10cm; ">
si el reclamante está representado por un abogado (=1 si sí y =2 si no)
</td>
</tr>
<tr>
<td style="text-align:left;width: 2.5cm; border-right:1px solid;">
CLMAGE
</td>
<td style="text-align:left;width: 1.8cm; width: 10cm; ">
edad del reclamante
</td>
</tr>
<tr>
<td style="text-align:left;width: 2.5cm; border-right:1px solid;">
CLMSEX
</td>
<td style="text-align:left;width: 1.8cm; width: 10cm; ">
género del reclamante (=1 si masculino y =2 si femenino)
</td>
</tr>
<tr>
<td style="text-align:left;width: 2.5cm; border-right:1px solid;">
MARITAL
</td>
<td style="text-align:left;width: 1.8cm; width: 10cm; ">
estado civil del reclamante (=1 si casado, =2 si soltero, =3 si viudo, y =4 si divorciado/separado)
</td>
</tr>
<tr>
<td style="text-align:left;width: 2.5cm; border-right:1px solid;">
SEATBELT
</td>
<td style="text-align:left;width: 1.8cm; width: 10cm; ">
si el reclamante estaba usando un cinturón de seguridad/restricción infantil (=1 si sí, =2 si no, y =3 si no aplicable)
</td>
</tr>
<tr>
<td style="text-align:left;width: 2.5cm; border-right:1px solid;">
CLMINSUR
</td>
<td style="text-align:left;width: 1.8cm; width: 10cm; ">
si el conductor del vehículo del reclamante estaba sin seguro (=1 si sí, =2 si no, y =3 si no aplicable)
</td>
</tr>
<tr>
<td style="text-align:left;width: 2.5cm; border-right:1px solid;">
LOSS
</td>
<td style="text-align:left;width: 1.8cm; width: 10cm; ">
pérdida económica total del reclamante (en miles).
</td>
</tr>
</tbody>
</table>
<ol style="list-style-type: lower-alpha">
<li><p><em>Estadísticas Resumidas</em>.</p>
<ol style="list-style-type: lower-roman">
<li><p>Calcule histogramas y estadísticas resumidas de las variables explicativas continuas CLMAGE y LOSS. Basado en estos resultados, cree una versión logarítmica de LOSS, llamada lnLOSS.</p></li>
<li><p>Examine las medias de CLMAGE, LOSS y lnLOSS por nivel de ATTORNEY. ¿Sugieren estas estadísticas que las variables continuas difieren según ATTORNEY?</p></li>
<li><p>Cree tablas de conteo (o porcentajes) de ATTORNEY por nivel de CLMSEX, MARITAL, SEATBELT y CLMINSUR. ¿Sugieren estas estadísticas que las variables categóricas difieren según ATTORNEY?</p></li>
<li><p>Identifique el número de valores faltantes para cada variable explicativa.</p></li>
</ol></li>
<li><p><em>Modelos de Regresión Logística.</em></p>
<ol style="list-style-type: lower-roman">
<li><p>Ejecute un modelo de regresión logística utilizando solo la variable explicativa CLMSEX. ¿Es un factor importante para determinar el uso de
un abogado? Proporcione una interpretación en términos de las probabilidades de usar
un abogado.</p></li>
<li><p>Ejecute un modelo de regresión logística utilizando las variables explicativas
CLMAGE, CLMSEX, MARITAL, SEATBELT y CLMINSUR. ¿Qué variables
parecen ser estadísticamente significativas?</p></li>
<li><p>Para el modelo en la parte (ii), ¿quién usa más abogados, hombres o
mujeres? Proporcione una interpretación en términos de las probabilidades de usar un
abogado para la variable CLMSEX.</p></li>
<li><p>Ejecute un modelo de regresión logística utilizando las variables explicativas
CLMAGE, CLMSEX, MARITAL, SEATBELT, CLMINSUR, LOSS y lnLOSS. Decida
cuál de las dos medidas de pérdida es más importante y vuelva a ejecutar el
modelo utilizando solo una de estas variables. En este modelo, ¿es la
medida de las pérdidas una variable estadísticamente significativa?</p></li>
<li><p>Ejecute su modelo en la parte (iv) pero omitiendo la variable CLMAGE.
Describa las diferencias entre este ajuste de modelo y el de la parte (iv),
enfocándose en las variables estadísticamente significativas y en el número de
observaciones utilizadas en el ajuste del modelo.</p></li>
<li><p>Considere un reclamante masculino soltero de 32 años de edad. Suponga que el
reclamante estaba usando un cinturón de seguridad, que el conductor estaba asegurado y
la pérdida económica total es de $5,000. Para el modelo en la parte (iv), ¿cuál
es la estimación de la probabilidad de usar un abogado?</p></li>
</ol></li>
<li><p><em>Regresión Probit.</em> Repita la parte b(v) utilizando modelos de regresión probit, pero interprete solo el signo de los coeficientes de regresión.</p></li>
</ol>
<p>11.9 <strong>Carreras de Caballos en Hong Kong.</strong>
El hipódromo es un ejemplo fascinante de la dinámica de los mercados financieros
en acción. Vamos a la pista y hagamos una apuesta. Supongamos que, de un
campo de 10 caballos, simplemente queremos elegir un ganador. En el
contexto de la regresión, dejaremos que <span class="math inline">\(y\)</span> sea la variable de respuesta
que indica si un caballo gana (<span class="math inline">\(y\)</span> = 1) o no (<span class="math inline">\(y\)</span> = 0). De los formularios
de carreras, periódicos, y otras fuentes, hay muchas variables explicativas
que están disponibles públicamente y que podrían ayudarnos a predecir el
resultado para <span class="math inline">\(y\)</span>. Algunas variables candidatas pueden incluir la edad del
caballo, el rendimiento reciente del caballo y el jinete, el pedigrí del
caballo, y así sucesivamente. Estas variables son evaluadas por los inversores
presentes en la carrera, la multitud apostadora. Al igual que en muchos mercados financieros,
resulta que una de las variables explicativas más útiles es la
evaluación general de la multitud sobre las habilidades del caballo. Estas
evaluaciones no se hacen basadas en una encuesta de la multitud, sino más bien
en función de las apuestas realizadas. La información sobre las apuestas de la multitud está
disponible en un gran cartel en la carrera llamado el <em>tote
board</em> (tablero de apuestas). El tote board muestra las probabilidades de que cada caballo gane una
carrera. <a href="C11Binary.html#Tab1112">Tabla 11.12</a> es un tote board hipotético para una
carrera de 10 caballos.</p>
<p><a id=Tab1112></a></p>
<p><span id="Tab1112">Tabla 11.12</span>. <strong>Tote Board Hipotético</strong></p>
<p><span class="math display">\[
\scriptsize{
\begin{array}{l|cccccccccc}
\hline
\text{Caballo} &amp; 1 &amp; 2 &amp; 3 &amp; 4 &amp; 5 &amp; 6 &amp; 7 &amp; 8 &amp; 9 &amp; 10 \\
\text{Probabilidades Publicadas} &amp; 1-1 &amp; 79-1 &amp; 7-1 &amp; 3-1 &amp; 15-1 &amp; 7-1 &amp; 49-1 &amp; 49-1 &amp; 19-1 &amp; 79-1 \\
\hline
\end{array}
}
\]</span></p>
<p>Las probabilidades que aparecen en el tote board han sido ajustadas para proporcionar
una “tasa de la pista.” Es decir, por cada dólar apostado,
$<span class="math inline">\(T\)</span> va a la pista por patrocinar la carrera y $(1-<span class="math inline">\(T\)</span>) va
a los apostadores ganadores. Las tasas típicas de la pista están en el orden
del veinte por ciento, o <span class="math inline">\(T\)</span>=0.20.</p>
<p>Podemos convertir fácilmente las probabilidades en el tote board en la
evaluación de la multitud de las probabilidades de ganar. Para ilustrar esto,
<a href="C11Binary.html#Tab1113">Tabla 11.13</a> muestra apuestas hipotéticas para ganar que
resultaron en la información mostrada en el tote board hipotético en la
<a href="C11Binary.html#Tab1112">Tabla 11.12</a>.</p>
<p><a id=Tab1113></a></p>
<p><span id="Tab1113">Tabla 11.13</span>. <strong>Apuestas Hipotéticas</strong></p>
<p><span class="math display">\[
\scriptsize{
\begin{array}{l|cccccccccc}
\hline \text{Caballo} &amp; 1 &amp; 2 &amp; 3 &amp; 4 &amp; 5 &amp; 6 &amp; 7 &amp; 8 &amp; 9 &amp; 10 &amp; Total\\
\hline \text{Apuestas} para Ganar &amp; 8,000 &amp; 200 &amp; 2,000 &amp; 4,000 &amp; 1,000 &amp; 3,000 &amp; 400 &amp; 400 &amp; 800 &amp; 200 &amp; 20,000 \\
\text{Probabilidad} &amp; 0.40 &amp; 0.01 &amp; 0.10 &amp; 0.20 &amp; 0.05 &amp; 0.15 &amp; 0.02 &amp; 0.02 &amp; 0.04 &amp; 0.02 &amp; 1.000 \\
\text{Probabilidades Publicadas} &amp; 1-1 &amp; 79-1 &amp; 7-1 &amp; 3-1 &amp; 15-1 &amp; 7-1 &amp; 49-1 &amp; 49-1 &amp; 19-1 &amp; 79-1 \\
\hline
\end{array}
}
\]</span></p>
<p>Para esta carrera hipotética, se apostaron 20,000 para ganar. Debido a que 8,000
de estos 20,000 se apostaron en el primer caballo, interprete la relación
8000/20000 = 0.40 como la evaluación de la multitud de la probabilidad de
ganar. Las probabilidades teóricas se calculan como 0.4/(1-0.4) = 2/3, o una
apuesta de 0.67 gana 1. Sin embargo, las probabilidades teóricas asumen un juego justo
sin tasa de la pista. Para ajustar al hecho de que solo (1-<span class="math inline">\(T\)</span>) están
disponibles para el ganador, las probabilidades publicadas para este caballo serían
0.4/(1-<span class="math inline">\(T\)</span>-0.4) = 1, si <span class="math inline">\(T\)</span>=0.20. En este caso, ahora se requiere una apuesta de 1
para ganar 1. Entonces tenemos la relación <span class="math inline">\(probabilidades~ajustadas = x/(1-T-x)\)</span>, donde <span class="math inline">\(x\)</span> es la evaluación de la multitud de la probabilidad
de ganar.</p>
<p>Antes del inicio de la carrera, el tote board nos proporciona
probabilidades ajustadas que pueden convertirse fácilmente en <span class="math inline">\(x\)</span>, la
evaluación de la multitud sobre ganar. Usamos esta medida para ayudarnos a predecir
<span class="math inline">\(y\)</span>, el evento de que el caballo realmente gane la carrera.</p>
<p>Consideramos datos de 925 carreras realizadas en Hong Kong desde septiembre de
1981 hasta septiembre de 1989. En cada carrera, había diez caballos,
uno de los cuales fue seleccionado aleatoriamente para estar en la muestra. En los datos,
use FINISH = <span class="math inline">\(y\)</span> como el indicador de que un caballo gane una carrera y
WIN = <span class="math inline">\(x\)</span> como la evaluación a priori de la multitud de la
probabilidad de que un caballo gane una carrera.</p>
<ol style="list-style-type: lower-alpha">
<li><p>Un colega estadísticamente ingenuo quisiera duplicar el tamaño de la muestra
eligiendo dos caballos de cada carrera en lugar de seleccionar aleatoriamente un
caballo de un campo de 10.</p>
<ol style="list-style-type: lower-roman">
<li><p>Describa la relación entre las variables dependientes de los
dos caballos seleccionados.</p></li>
<li><p>Explique cómo esto viola las suposiciones del modelo de regresión.</p></li>
</ol></li>
<li><p>Calcule la media de FINISH y las estadísticas resumidas de WIN. Note
que la desviación estándar de FINISH es mayor que la de WIN,
aunque las medias de las muestras sean aproximadamente las mismas. Para la variable
FINISH, ¿cuál es la relación entre la media muestral y
la desviación estándar?</p></li>
<li><p>Calcule las estadísticas resumidas de WIN por nivel de FINISH. Note que
la media muestral es mayor para los caballos que ganaron (FINISH = 1) que para
aquellos que perdieron (FINISH = 0). Interprete este resultado.</p></li>
<li><p>Estime un modelo de probabilidad lineal, utilizando WIN para predecir FINISH.</p>
<ol style="list-style-type: lower-roman">
<li><p>¿Es WIN un predictor estadísticamente significativo de FINISH?</p></li>
<li><p>¿Qué tan bien se ajusta este modelo a los datos utilizando la estadística de bondad
de ajuste habitual?</p></li>
<li><p>Para este modelo estimado, ¿es posible que los valores ajustados
se encuentren fuera del intervalo [0, 1]? Note que, por definición, la
variable x WIN debe estar dentro del intervalo [0, 1].</p></li>
</ol></li>
<li><p>Estime un modelo de regresión logística, utilizando WIN para predecir
FINISH. ¿Es WIN un predictor estadísticamente significativo de FINISH?</p></li>
<li><p>Compare los valores ajustados de los modelos en las partes (d) y (e)</p>
<ol style="list-style-type: lower-roman">
<li><p>Para cada modelo, proporcione valores ajustados en WIN = 0, 0.01, 0.05,
0.10 y 1.0.</p></li>
<li><p>Trace un gráfico de los valores ajustados del modelo de probabilidad lineal versus
los valores ajustados del modelo de regresión logística.</p></li>
</ol></li>
<li><p>Interprete WIN como la evaluación a priori de la multitud de la
probabilidad de que un caballo gane una carrera. Los valores ajustados, FINISH, es
su nueva estimación de la probabilidad de que un caballo gane una carrera,
basada en la evaluación de la multitud.</p>
<ol style="list-style-type: lower-roman">
<li><p>Trace el gráfico de la diferencia FINISH - WIN versus WIN.</p></li>
<li><p>Discuta una estrategia de apuestas que podría emplear basada en la
diferencia, FINISH - WIN.</p></li>
</ol></li>
</ol>
<p>11.10 <strong>Demanda de Seguro de Vida a Término.</strong> Continuamos nuestro estudio de la Demanda de Seguro de Vida a Término de los Capítulos 3 y 4. Específicamente, examinamos la Encuesta de Finanzas del Consumidor (SCF) de 2004, una muestra representativa a nivel nacional que contiene información extensa sobre activos, pasivos, ingresos y características demográficas de los encuestados (potenciales clientes de EE. UU.). Ahora volvemos a la muestra original de <span class="math inline">\(n=500\)</span> familias con ingresos positivos y estudiamos si una familia compra o no seguro de vida a término. De nuestra muestra, resulta que 225 no compraron (FACEPOS=0), mientras que 275 sí compraron seguro de vida a término (FACEPOS=1).</p>
<ol style="list-style-type: lower-alpha">
<li><p>Estadísticas Resumidas. Proporcione una tabla de medias de las variables explicativas por nivel de la variable dependiente FACEPOS. Interprete lo que aprendemos de esta tabla.</p></li>
<li><p>Modelo de Probabilidad Lineal. Ajuste un modelo de probabilidad lineal usando FACEPOS como la variable dependiente y LINCOME, EDUCATION, AGE y GENDER como variables explicativas continuas, junto con el factor MARSTAT.</p>
<p>b(i). Defina brevemente un modelo de probabilidad lineal.</p>
<p>b(ii). Comente sobre la calidad del modelo ajustado.</p>
<p>b(iii). ¿Cuáles son los tres principales inconvenientes del modelo de probabilidad lineal?</p></li>
<li><p>Modelo de Regresión Logística. Ajuste un modelo de regresión logística utilizando el mismo conjunto de variables explicativas.</p>
<p>c(i). Identifique qué variables parecen ser estadísticamente significativas. En su identificación, describa la base para sus conclusiones.</p>
<p>c(ii). ¿Qué medida resume la bondad de ajuste?</p></li>
<li><p>Modelo de Regresión Logística Reducido. Defina MARSTAT1 como una variable binaria que indica MARSTAT=1. Ajuste un segundo modelo de regresión logística utilizando LINCOME, EDUCATION y MARSTAT1.</p>
<p>d(i). Compare estos dos modelos, utilizando una prueba de razón de verosimilitud. Establezca sus hipótesis nula y alternativa, criterio de decisión y su regla de decisión.</p>
<p>d(ii). ¿Quién es más probable que compre un seguro de vida a término, casados o no casados? Proporcione una interpretación en términos de las probabilidades de comprar un seguro de vida a término para la variable MARSTAT1.</p>
<p>d(iii). Considere a un hombre casado que tiene 54 años. Suponga que esta persona tiene 13 años de educación, un salario anual de $70,000 y vive en un hogar compuesto por cuatro personas. Para este modelo, ¿cuál es la estimación de la probabilidad de comprar un seguro de vida a término?</p></li>
</ol>
<p>11.11 <strong>Éxito en los Estudios Actuariales</strong>. Al igual que en los campos médicos y legales, los miembros de la profesión actuarial enfrentan problemas interesantes y generalmente son bien remunerados por sus esfuerzos en resolver estos problemas. También, como en las profesiones médicas y legales, las barreras educativas para convertirse en actuario son desafiantes, limitando la entrada en el campo.</p>
<p>Para asesorar a los estudiantes sobre si tienen el potencial para cumplir con las demandas de este campo intelectualmente desafiante, Smith y Schumacher (2006) estudiaron los atributos de los estudiantes en una facultad de negocios. Específicamente, examinaron a <span class="math inline">\(n=185\)</span> estudiantes de primer año en la Universidad de Bryant en Rhode Island que habían comenzado sus carreras universitarias entre 1995 y 2001. La variable dependiente de interés era si se graduaron con una concentración en actuaría, para estos estudiantes el primer paso para convertirse en actuario profesional. De estos, 77 se graduaron con una concentración en actuaría y los otros 108 abandonaron la concentración (en Bryant, la mayoría se transfirió a otras concentraciones, aunque algunos dejaron la universidad).</p>
<p>Smith y Schumacher (2006) informaron sobre los efectos de cuatro mecanismos de evaluación temprana, así como GENDER, una variable de control. Los mecanismos de evaluación fueron: PLACE%, rendimiento en un examen de ubicación matemática administrado justo antes del primer año, MSAT y VSAT, las porciones de matemáticas (M) y verbal (V) del Scholastic Aptitude Test (SAT), y RANK, el rango en la escuela secundaria dado como una proporción (siendo más cercano a uno mejor). La Tabla <a href="C11Binary.html#tab:Tab1114">11.14</a> muestra que los estudiantes que eventualmente se graduaron con una concentración en actuaría obtuvieron mejores resultados en estos mecanismos de evaluación temprana que los que abandonaron la concentración actuarial.</p>
<p>Se ajustó una regresión logística a los datos, con los resultados reportados en la Tabla <a href="C11Binary.html#tab:Tab1114">11.14</a>.</p>
<ol style="list-style-type: lower-alpha">
<li><p>Para tener una idea de qué variables son estadísticamente significativas, calcule los <span class="math inline">\(t\)</span>-ratios para cada variable. Para cada variable, indique si es o no estadísticamente significativa.</p></li>
<li><p>Para tener una idea del impacto relativo de los mecanismos de evaluación, use los coeficientes en la Tabla <a href="C11Binary.html#tab:Tab1114">11.14</a> para calcular las probabilidades de éxito estimadas para las siguientes combinaciones de variables. En sus cálculos, asuma que GENDER=1.</p>
<p>b(i). Asuma PLACE% =0.80, MSAT = 680, VSAT=570 y RANK=0.90.</p>
<p>b(ii). Asuma PLACE% =0.60, MSAT = 680, VSAT=570 y RANK=0.90.</p>
<p>b(iii). Asuma PLACE% =0.80, MSAT = 620, VSAT=570 y RANK=0.90.</p>
<p>b(iv). Asuma PLACE% =0.80, MSAT = 680, VSAT=540 y RANK=0.90.</p>
<p>b(v). Asuma PLACE% =0.80, MSAT = 680, VSAT=570 y RANK=0.70.</p></li>
</ol>
<h5 style="text-align: center;">
<a id="displayCode.Table14.1Silly" href="javascript:togglecode('toggleCode.Table14.1Silly','displayCode.Table14.1Silly');"><i><strong></strong></i></a>
</h5>
<div id="toggleCode.Table14.1Silly" style="display: none">
<div class="sourceCode" id="cb75"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb75-1"><a href="C11Binary.html#cb75-1" tabindex="-1"></a>knitr<span class="sc">::</span><span class="fu">kable</span>(<span class="dv">2</span>, <span class="at">caption =</span> <span class="st">&quot;Silly. Create a table just to update the counter...&quot;</span>)</span></code></pre></div>
<table>
<caption><span id="tab:unnamed-chunk-84">Tabla 11.12: </span>Silly. Create a table just to update the counter…</caption>
<thead>
<tr class="header">
<th align="right">x</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="right">2</td>
</tr>
</tbody>
</table>
<div class="sourceCode" id="cb76"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb76-1"><a href="C11Binary.html#cb76-1" tabindex="-1"></a>knitr<span class="sc">::</span><span class="fu">kable</span>(<span class="dv">2</span>, <span class="at">caption =</span> <span class="st">&quot;Silly.&quot;</span>)</span></code></pre></div>
<table>
<caption><span id="tab:unnamed-chunk-85">Tabla 11.13: </span>Silly.</caption>
<thead>
<tr class="header">
<th align="right">x</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="right">2</td>
</tr>
</tbody>
</table>
</div>
<table class=" lightable-classic table table-striped table-condensed" style="font-size: 12px; font-family: Cambria; width: auto !important; margin-left: auto; margin-right: auto; margin-left: auto; margin-right: auto;">
<caption style="font-size: initial !important;">
<span id="tab:Tab1114">Tabla 11.14: </span><strong>Estadísticas Resumidas y Ajustes de Regresión Logística para Predecir Graduación Actuarial</strong>
</caption>
<thead>
<tr>
<th style="empty-cells: hide;" colspan="1">
</th>
<th style="padding-bottom:0; padding-left:3px;padding-right:3px;text-align: center; " colspan="2">
<div style="border-bottom: 1px solid #111111; margin-bottom: -1px; ">
Promedio para Actuariales
</div>
</th>
<th style="padding-bottom:0; padding-left:3px;padding-right:3px;text-align: center; " colspan="2">
<div style="border-bottom: 1px solid #111111; margin-bottom: -1px; ">
Regresión Logística
</div>
</th>
</tr>
<tr>
<th style="text-align:left;">
Variable
</th>
<th style="text-align:right;">
Graduados
</th>
<th style="text-align:right;">
Desertores
</th>
<th style="text-align:right;">
Estimación
</th>
<th style="text-align:right;">
Error Estándar
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;width: 2.5cm; border-right:1px solid;">
Intercepto
</td>
<td style="text-align:right;width: 1.6cm; ">
<ul>
<li></td>
<td style="text-align:right;width: 1.6cm; ">
<ul>
<li></td>
<td style="text-align:right;width: 1.6cm; ">
-12.094
</td>
<td style="text-align:right;width: 1.6cm; ">
2.575
</td>
</tr>
<tr>
<td style="text-align:left;width: 2.5cm; border-right:1px solid;">
GENDER
</td>
<td style="text-align:right;width: 1.6cm; ">
<ul>
<li></td>
<td style="text-align:right;width: 1.6cm; ">
<ul>
<li></td>
<td style="text-align:right;width: 1.6cm; ">
0.256
</td>
<td style="text-align:right;width: 1.6cm; ">
0.407
</td>
</tr>
<tr>
<td style="text-align:left;width: 2.5cm; border-right:1px solid;">
PLACE%
</td>
<td style="text-align:right;width: 1.6cm; ">
0.83
</td>
<td style="text-align:right;width: 1.6cm; ">
0.64
</td>
<td style="text-align:right;width: 1.6cm; ">
4.336
</td>
<td style="text-align:right;width: 1.6cm; ">
1.657
</td>
</tr>
<tr>
<td style="text-align:left;width: 2.5cm; border-right:1px solid;">
MSAT
</td>
<td style="text-align:right;width: 1.6cm; ">
679.25
</td>
<td style="text-align:right;width: 1.6cm; ">
624.25
</td>
<td style="text-align:right;width: 1.6cm; ">
0.008
</td>
<td style="text-align:right;width: 1.6cm; ">
0.004
</td>
</tr>
<tr>
<td style="text-align:left;width: 2.5cm; border-right:1px solid;">
VSAT
</td>
<td style="text-align:right;width: 1.6cm; ">
572.2
</td>
<td style="text-align:right;width: 1.6cm; ">
544.25
</td>
<td style="text-align:right;width: 1.6cm; ">
-0.002
</td>
<td style="text-align:right;width: 1.6cm; ">
0.003
</td>
</tr>
<tr>
<td style="text-align:left;width: 2.5cm; border-right:1px solid;">
RANK
</td>
<td style="text-align:right;width: 1.6cm; ">
0.88
</td>
<td style="text-align:right;width: 1.6cm; ">
0.76
</td>
<td style="text-align:right;width: 1.6cm; ">
4.442
</td>
<td style="text-align:right;width: 1.6cm; ">
1.836
</td>
</tr>
</tbody>
</table></li>
</ul></li>
</ul></li>
</ul></li>
</ul>
<p>11.12 <strong>Caso-Control.</strong> Considere el siguiente método de selección de muestra “caso-control” para variables dependientes binarias. Intuitivamente, si estamos trabajando con un problema donde el evento de interés es raro, queremos asegurarnos de que muestreamos una cantidad suficiente de eventos para que nuestros procedimientos de estimación sean confiables.</p>
<p>Suponga que tenemos una gran base de datos que consiste en <span class="math inline">\(\{y_i, \mathbf{x}_i\}\)</span>, con <span class="math inline">\(i=1,\ldots, N\)</span> observaciones. (Para los registros de una compañía de seguros, <span class="math inline">\(N\)</span> podría fácilmente ser de diez millones o más). Queremos asegurarnos de obtener una cantidad suficiente de <span class="math inline">\(y_i = 1\)</span> (correspondiente a reclamaciones o “casos”) en nuestra muestra, más una muestra de <span class="math inline">\(y_i = 0\)</span> (correspondiente a no reclamaciones o “controles”). Por lo tanto, dividimos el conjunto de datos en dos subconjuntos. Para el primer subconjunto que consiste en observaciones con <span class="math inline">\(y_i = 1\)</span>, tomamos una muestra aleatoria con probabilidad <span class="math inline">\(\tau_1\)</span>. De manera similar, para el segundo subconjunto que consiste en observaciones con <span class="math inline">\(y_i = 0\)</span>, tomamos una muestra aleatoria con probabilidad <span class="math inline">\(\tau_0\)</span>. Por ejemplo, en la práctica podríamos usar <span class="math inline">\(\tau_1=1\)</span> y <span class="math inline">\(\tau_0 = 0.10\)</span>, lo que correspondería a tomar todas las reclamaciones y una muestra del 10% de no reclamaciones - por lo tanto, se considera que <span class="math inline">\(\tau_1\)</span> y <span class="math inline">\(\tau_0\)</span> son conocidos por el analista.</p>
<ol style="list-style-type: lower-alpha">
<li><p>Sea <span class="math inline">\(\{r_i = 1\}\)</span> el evento que indica que la observación es seleccionada para ser parte del análisis. Determine <span class="math inline">\(\Pr(y_i = 1, r_i = 1)\)</span>, <span class="math inline">\(\Pr(y_i = 0, r_i = 1)\)</span> y <span class="math inline">\(\Pr(r_i = 1)\)</span>
en términos de <span class="math inline">\(\tau_0\)</span>, <span class="math inline">\(\tau_1\)</span> y <span class="math inline">\(\pi_i = \Pr(y_i=1)\)</span>.</p></li>
<li><p>Usando los cálculos en la parte (a), determine la probabilidad condicional <span class="math inline">\(\Pr(y_i=1 | r_i=1)\)</span>.</p></li>
<li><p>Ahora suponga que <span class="math inline">\(\pi_i\)</span> tiene una forma logística (<span class="math inline">\(\pi(z) = \exp(z)/(1+\exp(z))\)</span> y <span class="math inline">\(\pi_i= \pi(\mathbf{x}_i^{\prime}\boldsymbol \beta ))\)</span>. Reescriba su respuesta a la parte (b) usando esta forma logística.</p></li>
<li><p>Escriba la verosimilitud de los <span class="math inline">\(y_i\)</span> observados (condicional en <span class="math inline">\(r_i = 1, i=1, \ldots, n\)</span>). Muestre cómo podemos interpretar esto como la verosimilitud de una regresión logística usual con la excepción de que el intercepto ha cambiado. Especifique el nuevo intercepto en términos del intercepto original, <span class="math inline">\(\tau_0\)</span> y <span class="math inline">\(\tau_1\)</span>.</p></li>
</ol>
</div>
<div id="S:Sec119" class="section level2 hasAnchor" number="11.9">
<h2><span class="header-section-number">11.9</span> Suplementos Técnicos - Inferencia Basada en Verosimilitud<a href="C11Binary.html#S:Sec119" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Comencemos con variables aleatorias <span class="math inline">\(\left( y_1, \ldots, y_n \right) ^{\prime} = \mathbf y\)</span> cuya distribución conjunta es conocida hasta un vector de parámetros <span class="math inline">\(\boldsymbol \theta\)</span>. En aplicaciones de regresión, <span class="math inline">\(\boldsymbol \theta\)</span> consiste en los coeficientes de regresión, <span class="math inline">\(\boldsymbol \beta\)</span>, y posiblemente un parámetro de escala <span class="math inline">\(\sigma^2\)</span> así como parámetros adicionales. Esta función de densidad de probabilidad conjunta se denota como <span class="math inline">\(\mathrm{f}(\mathbf{y};\boldsymbol \theta)\)</span>. La función también puede ser una función de masa de probabilidad para variables aleatorias discretas o una distribución mixta para variables aleatorias que tienen componentes discretos y continuos. En cada caso, podemos usar la misma notación, <span class="math inline">\(\mathrm{f}(\mathbf{y};\boldsymbol \theta),\)</span> y llamarla la <em>función de verosimilitud</em>. La verosimilitud es una función de los parámetros con los datos (<span class="math inline">\(\mathbf{y}\)</span>) fijos en lugar de una función de los datos con los parámetros (<span class="math inline">\(\boldsymbol \theta\)</span>) fijos.</p>
<p>Es habitual trabajar con la versión logarítmica de la función de verosimilitud y así definimos la <em>función de log-verosimilitud</em> como
<span class="math display">\[
L(\boldsymbol \theta) = L(\mathbf{y};\boldsymbol \theta ) = \ln \mathrm{f}(\mathbf{y};\boldsymbol \theta),
\]</span>
evaluada en una realización de <span class="math inline">\(\mathbf{y}\)</span>. En parte, esto se debe a que a menudo trabajamos con el caso especial importante donde las variables aleatorias <span class="math inline">\(y_1, \ldots, y_n\)</span> son independientes. En este caso, la función de densidad conjunta se puede expresar como un producto de las funciones de densidad marginales y, al tomar logaritmos, podemos trabajar con sumas. Incluso cuando no se trata de variables aleatorias independientes, como con datos de series temporales, a menudo es más conveniente desde el punto de vista computacional trabajar con log-verosimilitudes en lugar de la función de verosimilitud original.</p>
<div id="S:Sec1191" class="section level3 hasAnchor" number="11.9.1">
<h3><span class="header-section-number">11.9.1</span> Propiedades de las Funciones de Verosimilitud<a href="C11Binary.html#S:Sec1191" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Dos propiedades básicas de las funciones de verosimilitud son:
<span class="math display" id="eq:eq11A1">\[\begin{equation}
\mathrm{E} \left( \frac{ \partial}{\partial \boldsymbol \theta}
L(\boldsymbol \theta) \right) = \mathbf 0
\tag{11.13}
\end{equation}\]</span>
y
<span class="math display" id="eq:eq11A2">\[\begin{equation}
\mathrm{E} \left( \frac{ \partial^2}{\partial \boldsymbol \theta
\partial \boldsymbol \theta^{\prime}} L(\boldsymbol \theta) \right)
+ \mathrm{E} \left( \frac{ \partial L(\boldsymbol \theta)}{\partial
\boldsymbol \theta} \frac{ \partial L(\boldsymbol \theta)}{\partial
\boldsymbol \theta^{\prime}}
\right) = \mathbf 0.
\tag{11.14}
\end{equation}\]</span></p>
<p>La derivada de la función de log-verosimilitud, <span class="math inline">\(\partial L(\boldsymbol \theta)/\partial \boldsymbol \theta\)</span>, se llama
<em>función de puntaje</em>. La ecuación <a href="C11Binary.html#eq:eq11A1">(11.13)</a> muestra que la
función de puntaje tiene media cero. Para ver esto, bajo condiciones de regularidad adecuadas, tenemos
<span class="math display">\[\begin{eqnarray*}
\mathrm{E} \left( \frac{ \partial}{\partial \boldsymbol \theta}
L(\boldsymbol \theta) \right) &amp;=&amp; \mathrm{E} \left( \frac{
\frac{\partial}{\partial \boldsymbol \theta}
\mathrm{f}(\mathbf{y};\boldsymbol \theta
)}{\mathrm{f}(\mathbf{y};\boldsymbol \theta )}  \right) = \int
\frac{\partial}{\partial \boldsymbol \theta}
\mathrm{f}(\mathbf{y};\boldsymbol \theta ) d \mathbf y =
\frac{\partial}{\partial \boldsymbol \theta} \int
\mathrm{f}(\mathbf{y};\boldsymbol \theta ) d \mathbf y \\
&amp;=&amp; \frac{\partial}{\partial \boldsymbol \theta} 1 = \mathbf 0.
\end{eqnarray*}\]</span>
Por conveniencia, esta demostración asume una densidad para f(<span class="math inline">\(\cdot\)</span>);
las extensiones a distribuciones de masa y mixtas son sencillas.
La demostración de la ecuación <a href="C11Binary.html#eq:eq11A2">(11.14)</a> es similar y se
omite. Para establecer la ecuación <a href="C11Binary.html#eq:eq11A1">(11.13)</a>, implícitamente
utilizamos “condiciones de regularidad adecuadas” para permitir el intercambio
de la derivada y el signo de integral. Para ser más precisos, un analista
que trabaje con un tipo específico de distribución puede utilizar esta
información para verificar que el intercambio de la derivada y el
signo de integral es válido.</p>
<p>Usando la ecuación <a href="C11Binary.html#eq:eq11A2">(11.14)</a>, podemos definir la <em>matriz de información</em>
<span class="math display" id="eq:eq11A3">\[\begin{equation}
\mathbf{I}(\boldsymbol \theta) = \mathrm{E} \left( \frac{ \partial
L(\boldsymbol \theta)}{\partial \boldsymbol \theta} \frac{ \partial
L(\boldsymbol \theta)}{\partial \boldsymbol \theta^{\prime}}
\right) = -\mathrm{E} \left( \frac{ \partial^2}{\partial \boldsymbol \theta
\partial \boldsymbol \theta^{\prime}} L(\boldsymbol \theta) \right).
\tag{11.15}
\end{equation}\]</span>
Esta cantidad se utiliza ampliamente en el estudio de las propiedades de muestras grandes
de las funciones de verosimilitud.</p>
<p>La matriz de información aparece en la distribución de muestras grandes de
la función de puntaje. Específicamente, bajo condiciones amplias, tenemos
que <span class="math inline">\(\partial L(\boldsymbol \theta)/\partial \boldsymbol \theta\)</span>
tiene una distribución normal en muestras grandes con media <strong>0</strong> y
varianza <span class="math inline">\(\mathbf{I}(\boldsymbol \theta)\)</span>. Para ilustrar, supongamos
que las variables aleatorias son independientes, de modo que la función de puntaje
se puede escribir como
<span class="math display">\[
\frac{ \partial}{\partial \boldsymbol \theta} L(\boldsymbol \theta)
=\frac{ \partial}{\partial \boldsymbol \theta} \ln \prod_{i=1}^n
\mathrm{f}(y_i;\boldsymbol \theta ) =\sum_{i=1}^n \frac{
\partial}{\partial \boldsymbol \theta}
\ln \mathrm{f}(y_i;\boldsymbol \theta ).
\]</span>
La función de puntaje es la suma de variables aleatorias con media cero debido
a la ecuación <a href="C11Binary.html#eq:eq11A1">(11.13)</a>; los teoremas del límite central están ampliamente
disponibles para garantizar que las sumas de variables aleatorias independientes tengan
distribuciones normales en muestras grandes (ver Sección 1.4 para un ejemplo).
Además, si las variables aleatorias son idénticas, entonces a partir de la ecuación
<a href="C11Binary.html#eq:eq11A3">(11.15)</a> podemos ver que el segundo momento de
<span class="math inline">\(\partial \ln \mathrm{f}(y_i;\boldsymbol \theta ) /\partial \boldsymbol \theta\)</span> es la matriz de información, obteniendo el resultado.</p>
</div>
<div id="S:Sec1192" class="section level3 hasAnchor" number="11.9.2">
<h3><span class="header-section-number">11.9.2</span> Estimadores de Máxima Verosimilitud<a href="C11Binary.html#S:Sec1192" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Los estimadores de máxima verosimilitud son valores de los parámetros <span class="math inline">\(\boldsymbol \theta\)</span> que son “más probables” de haber sido producidos por los datos. El valor de <span class="math inline">\(\boldsymbol \theta\)</span>, denotado como <span class="math inline">\(\boldsymbol \theta_{MLE}\)</span>, que maximiza <span class="math inline">\(\mathrm{f}(\mathbf{y};\boldsymbol \theta)\)</span> se llama el <em>estimador de máxima verosimilitud</em>. Debido a que <span class="math inline">\(\ln(\cdot)\)</span> es una función uno a uno, también podemos determinar <span class="math inline">\(\boldsymbol \theta_{MLE}\)</span> maximizando la función de log-verosimilitud, <span class="math inline">\(L(\boldsymbol \theta)\)</span>.</p>
<p>Bajo condiciones amplias, tenemos que <span class="math inline">\(\boldsymbol \theta_{MLE}\)</span> tiene una distribución normal en muestras grandes con media <span class="math inline">\(\boldsymbol \theta\)</span> y varianza <span class="math inline">\(\left( \mathbf{I}(\boldsymbol \theta) \right)^{-1}\)</span>. Este es un resultado crítico sobre el cual se basa gran parte de la estimación y la prueba de hipótesis. Para subrayar este resultado, examinamos el caso especial de la regresión “basada en normales”.</p>
<hr />
<p><strong>Caso Especial. Regresión con distribuciones normales.</strong> Supongamos que <span class="math inline">\(y_1, \ldots, y_n\)</span> son independientes y están distribuidos normalmente, con media <span class="math inline">\(\mathrm{E~}y_i = \mu_i = \mathbf{x}_i^{\prime} \boldsymbol \beta\)</span> y varianza <span class="math inline">\(\sigma^2\)</span>. Los parámetros se pueden resumir como <span class="math inline">\(\boldsymbol \theta = \left( \boldsymbol \beta^{\prime}, \sigma^2 \right)^{\prime}.\)</span> Recordemos de la ecuación (1.1) que la función de densidad de probabilidad normal es
<span class="math display">\[
\mathrm{f}(y; \mu_i, \sigma^2)=\frac{1}{\sigma \sqrt{2\pi }}\exp \left( -\frac{1}{2\sigma^2}\left( y-\mu_i \right)^2\right) .
\]</span>
Con esto, los dos componentes de la función de puntaje son
<span class="math display">\[\begin{eqnarray*}
\frac{ \partial}{\partial \boldsymbol \beta} L(\boldsymbol \theta) &amp;=&amp; \sum_{i=1}^n \frac{
\partial}{\partial \boldsymbol \beta}
\ln \mathrm{f}(y_i; \mathbf{x}_i^{\prime} \boldsymbol \beta,
\sigma^2) =-\frac{1}{2\sigma^2} \sum_{i=1}^n \frac{
\partial}{\partial \boldsymbol \beta}
\left(y_i-\mathbf{x}_i^{\prime} \boldsymbol \beta  \right)^2 \\ &amp;=&amp;
-\frac{(-2)}{2 \sigma^2} \sum_{i=1}^n
\left(y_i-\mathbf{x}_i^{\prime} \boldsymbol \beta  \right)
\mathbf{x}_i
\end{eqnarray*}\]</span>
y
<span class="math display">\[\begin{eqnarray*}
\frac{ \partial}{\partial \sigma^2} L(\boldsymbol \theta) &amp;=&amp;
\sum_{i=1}^n \frac{
\partial}{\partial  \sigma^2}
\ln \mathrm{f}(y_i; \mathbf{x}_i^{\prime} \boldsymbol \beta,
\sigma^2)  = -\frac{n}{2 \sigma^2} + \frac {1}{2 \sigma
^4}\sum_{i=1}^n \left(y_i-\mathbf{x}_i^{\prime} \boldsymbol \beta
\right)^2 .
\end{eqnarray*}\]</span>
Igualando estas ecuaciones a cero y resolviendo se obtienen los estimadores de máxima verosimilitud
<span class="math display">\[
\boldsymbol \beta_{MLE} = \left(\sum_{i=1}^n \mathbf{x}_i \mathbf{x}_i^{\prime}\right)^{-1} \sum_{i=1}^n \mathbf{x}_i y_i = \mathbf{b}
\]</span>
y
<span class="math display">\[
\sigma^2_{MLE} = \frac{1}{n} \sum_{i=1}^n \left( y_i - \mathbf{x}_i^{\prime} \mathbf{b} \right)^2 = \frac{n-(k+1)}{n} s^2.
\]</span>
Así, el estimador de máxima verosimilitud de <span class="math inline">\(\boldsymbol \beta\)</span> es igual al estimador habitual de mínimos cuadrados. El estimador de máxima verosimilitud de <span class="math inline">\(\sigma^2\)</span> es un múltiplo escalar del estimador habitual de mínimos cuadrados. El estimador de mínimos cuadrados <span class="math inline">\(s^2\)</span> es insesgado, mientras que <span class="math inline">\(\sigma^2_{MLE}\)</span> es solo aproximadamente insesgado en muestras grandes.</p>
<p>La matriz de información es</p>
<p><span class="math display">\[
\mathbf{I}(\boldsymbol \theta) = -\mathrm{E~} \left(
  \begin{array}{cc}
   \frac{ \partial^2}{\partial \boldsymbol \beta ~\partial \boldsymbol \beta^{\prime}} L(\boldsymbol \theta) &amp; \frac{ \partial^2}{\partial \boldsymbol \beta ~\partial \sigma^2} L(\boldsymbol \theta) \\
   \frac{ \partial^2}{\partial \sigma^2 \partial \boldsymbol \beta^{\prime} } L(\boldsymbol \theta) &amp; \frac{ \partial^2}{\partial \sigma^2 \partial \sigma^2} L(\boldsymbol \theta)\\
  \end{array}
  \right)=
  \left(
  \begin{array}{cc}
   \frac{ 1}{\sigma^2} \sum_{i=1}^n \mathbf{x}_i \mathbf{x}_i^{\prime} &amp; 0 \\
   0 &amp; \frac{n}{2 \sigma^4}\\
  \end{array}
  \right).
\]</span>
Así, <span class="math inline">\(\boldsymbol \beta_{MLE} = \mathbf{b}\)</span> tiene una distribución normal en muestras grandes con media <span class="math inline">\(\boldsymbol \beta\)</span> y matriz de varianza-covarianza <span class="math inline">\(\sigma^2 \left(\sum_{i=1}^n \mathbf{x}_i \mathbf{x}_i^{\prime} \right)^{-1}\)</span>, como se vio anteriormente. Además, <span class="math inline">\(\sigma^2_{MLE}\)</span> tiene una distribución normal en muestras grandes con media <span class="math inline">\(\sigma^2\)</span> y varianza <span class="math inline">\(2 \sigma^4 /n.\)</span></p>
<hr />
<p>La máxima verosimilitud es una técnica de estimación general que se puede aplicar en muchos contextos estadísticos, no solo en aplicaciones de regresión y series temporales. Se puede aplicar ampliamente y disfruta de ciertas propiedades de optimalidad. Ya hemos mencionado el resultado de que los estimadores de máxima verosimilitud suelen tener una distribución normal en muestras grandes. Además, los estimadores de máxima verosimilitud son los más eficientes en el siguiente sentido. Supongamos que <span class="math inline">\(\widehat{\boldsymbol \theta}\)</span> es un estimador alternativo insesgado. El teorema de Cramer-Rao establece, bajo condiciones de regularidad leves, para todos los vectores <span class="math inline">\(\mathbf c\)</span>, que <span class="math inline">\(\mathrm{Var~} \mathbf c^{\prime} \boldsymbol \theta_{MLE} \le \mathrm{Var~} \mathbf c^{\prime} \widehat{\boldsymbol \theta}\)</span>, para <span class="math inline">\(n\)</span> suficientemente grande.</p>
<p>También notamos que <span class="math inline">\(2 \left( L(\boldsymbol \theta_{MLE}) - L(\boldsymbol \theta) \right)\)</span> tiene una distribución chi-cuadrado con grados de libertad igual a la dimensión de <span class="math inline">\(\boldsymbol \theta\)</span>.</p>
<p>En algunas aplicaciones, como el caso de regresión con una distribución normal, los estimadores de máxima verosimilitud se pueden calcular analíticamente como una expresión de forma cerrada. Típicamente, esto se puede hacer encontrando raíces de la primera derivada de la función. Sin embargo, en general, los estimadores de máxima verosimilitud no se pueden calcular con expresiones de forma cerrada y se determinan iterativamente. Se utilizan ampliamente dos procedimientos generales:
1. <em>Newton-Raphson</em> utiliza el algoritmo iterativo
<span class="math display" id="eq:eq11A4">\[\begin{equation}
\boldsymbol \theta_{NEW} = \boldsymbol \theta_{OLD} - \left. \left\{
\left( \frac{ \partial^2 L}{\partial \boldsymbol \theta \partial \boldsymbol \theta^{\prime}} \right)^{-1}
\frac{\partial L}{\partial \boldsymbol \theta } \right\} \right|_ {\boldsymbol \theta = \boldsymbol \theta_{OLD}} .
\tag{11.16}
\end{equation}\]</span>
2. <em>Puntuación de Fisher</em> utiliza el algoritmo iterativo
<span class="math display" id="eq:eq11A5">\[\begin{equation}
\boldsymbol \theta_{NEW} = \boldsymbol \theta_{OLD} + \mathbf{I}(\boldsymbol \theta_{OLD})^{-1} \left. \left\{
\frac{\partial L}{\partial \boldsymbol \theta } \right\} \right|_ {\boldsymbol \theta = \boldsymbol \theta_{OLD}} .
\tag{11.17}
\end{equation}\]</span>
donde <span class="math inline">\(\mathbf{I}(\boldsymbol \theta)\)</span> es la matriz de información.</p>
</div>
<div id="S:Sec1193" class="section level3 hasAnchor" number="11.9.3">
<h3><span class="header-section-number">11.9.3</span> Pruebas de Hipótesis<a href="C11Binary.html#S:Sec1193" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Consideramos probar la hipótesis nula <span class="math inline">\(H_0: h(\boldsymbol \theta) = \mathbf{d}\)</span>, donde <span class="math inline">\(\mathbf{d}\)</span> es un vector conocido de dimensión <span class="math inline">\(r \times 1\)</span> y h(<span class="math inline">\(\cdot\)</span>) es conocido y diferenciable. Este marco de pruebas abarca como un caso especial la hipótesis lineal general introducida en el Capítulo 4.</p>
<p>Existen tres enfoques generales para probar hipótesis, denominados <em>razón de verosimilitud</em>, <em>Wald</em> y <em>Rao</em>. El enfoque de Wald evalúa una función de la verosimilitud en <span class="math inline">\(\boldsymbol \theta_{MLE}\)</span>. El enfoque de la razón de verosimilitud utiliza <span class="math inline">\(\boldsymbol \theta_{MLE}\)</span> y <span class="math inline">\(\boldsymbol \theta_{Reduced}\)</span>. Aquí, <span class="math inline">\(\boldsymbol \theta_{Reduced}\)</span> es el valor de <span class="math inline">\(\boldsymbol \theta\)</span> que maximiza <span class="math inline">\(L(\boldsymbol \theta_{Reduced})\)</span> bajo la restricción de que <span class="math inline">\(h(\boldsymbol \theta) = \mathbf{d}\)</span>. El enfoque de Rao también utiliza <span class="math inline">\(\boldsymbol \theta_{Reduced}\)</span> pero lo determina maximizando <span class="math inline">\(L(\boldsymbol \theta) - \boldsymbol \lambda^{\prime}(h(\boldsymbol \theta) -\mathbf{d})\)</span>, donde <span class="math inline">\(\boldsymbol \lambda\)</span> es un vector de multiplicadores de Lagrange. Por lo tanto, la prueba de Rao también se llama la <em>prueba del multiplicador de Lagrange</em>.</p>
<p>Las estadísticas de prueba asociadas con los tres enfoques son:</p>
<ul>
<li><span class="math inline">\(LRT = 2 \times \left\{L(\boldsymbol \theta_{MLE})-L(\boldsymbol \theta_{Reduced}) \right\}\)</span></li>
<li>Wald: <span class="math inline">\(TS_W(\boldsymbol \theta_{MLE})\)</span>, donde
<span class="math display">\[
TS_W(\boldsymbol \theta)=(h(\boldsymbol \theta) -\mathbf{d})^{\prime} \left\{ \frac{\partial}{\partial \boldsymbol \theta} h(\boldsymbol \theta)^{\prime} \left(-\mathbf{I}(\boldsymbol \theta) \right)^{-1} \frac{\partial}{\partial \boldsymbol \theta} h(\boldsymbol \theta) \right\}^{-1} (h(\boldsymbol \theta) -\mathbf{d}),
\]</span>
y</li>
<li>Rao: <span class="math inline">\(TS_R(\boldsymbol \theta_{Reduced})\)</span>, donde
<span class="math display">\[
TS_R(\boldsymbol \theta) = \frac{\partial}{\partial \boldsymbol \theta} L(\boldsymbol \theta) \left(-\mathbf{I}(\boldsymbol \theta) \right)^{-1} \frac{\partial}{\partial \boldsymbol \theta} L(\boldsymbol \theta)^{\prime}.
\]</span></li>
</ul>
<p>Bajo condiciones amplias, las tres estadísticas de prueba tienen distribuciones chi-cuadrado en muestras grandes con <span class="math inline">\(r\)</span> grados de libertad bajo <span class="math inline">\(H_0\)</span>. Los tres métodos funcionan bien cuando el número de parámetros es de dimensión finita y la hipótesis nula especifica que <span class="math inline">\(\boldsymbol \theta\)</span> está en el interior del espacio de parámetros.</p>
<p>La principal ventaja de la estadística de Wald es que solo requiere el cálculo de <span class="math inline">\(\boldsymbol \theta_{MLE}\)</span> y no de <span class="math inline">\(\boldsymbol \theta_{Reduced}\)</span>. En contraste, la principal ventaja de la estadística de Rao es que solo requiere el cálculo de <span class="math inline">\(\boldsymbol \theta_{Reduced}\)</span> y no de <span class="math inline">\(\boldsymbol \theta_{MLE}\)</span>. En muchas aplicaciones, el cálculo de <span class="math inline">\(\boldsymbol \theta_{MLE}\)</span> es laborioso. La prueba de razón de verosimilitud es una extensión directa de la prueba <span class="math inline">\(F\)</span> parcial introducida en el Capítulo 4: permite comparar directamente modelos anidados, una técnica útil en aplicaciones.</p>
</div>
<div id="S:Sec1194" class="section level3 hasAnchor" number="11.9.4">
<h3><span class="header-section-number">11.9.4</span> Criterios de Información<a href="C11Binary.html#S:Sec1194" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Las pruebas de razón de verosimilitud son útiles para elegir entre dos modelos que son <em>anidados</em>, es decir, donde un modelo es un subconjunto del otro. ¿Cómo comparamos modelos cuando no están anidados? Una forma es utilizar los siguientes criterios de información.</p>
<p>La distancia entre dos distribuciones de probabilidad dadas por funciones de densidad de probabilidad <span class="math inline">\(g\)</span> y <span class="math inline">\(f_{\boldsymbol \theta}\)</span> se puede resumir como
<span class="math display">\[
\mathrm{KL}(g,f_{\boldsymbol \theta}) = \mathrm{E}_g \ln \frac{g(y)}{f_{\boldsymbol \theta}(y)} .
\]</span>
Esta es la <em>distancia de Kullback-Leibler</em>. Aquí, hemos indexado <span class="math inline">\(f\)</span> con un vector de parámetros <span class="math inline">\(\boldsymbol \theta\)</span>. Si dejamos que la función de densidad <span class="math inline">\(g\)</span> sea fija en un valor hipotético, digamos <span class="math inline">\(f_{{\boldsymbol \theta}_0}\)</span>, entonces minimizar <span class="math inline">\(\mathrm{KL}(f_{{\boldsymbol \theta}_0},f_{\boldsymbol \theta})\)</span> es equivalente a maximizar el log-verosimilitud.</p>
<p>Sin embargo, maximizar la verosimilitud no impone una estructura suficiente en el problema porque sabemos que siempre podemos aumentar la verosimilitud introduciendo parámetros adicionales. Así, Akaike en 1974 mostró que una alternativa razonable es minimizar
<span class="math display">\[
AIC = -2 \times L(\boldsymbol \theta_{MLE}) + 2 \times (número~de~parámetros),
\]</span>
conocido como <em>Criterio de Información de Akaike</em>. Aquí, el término adicional <span class="math inline">\(2 \times (número~de~parámetros)\)</span> es una penalización por la complejidad del modelo. Con esta penalización, no se puede mejorar el ajuste simplemente introduciendo parámetros adicionales. Esta estadística se puede utilizar al comparar varios modelos alternativos que no necesariamente están anidados. Se elige el modelo que minimiza <span class="math inline">\(AIC\)</span>. Si los modelos bajo consideración tienen el mismo número de parámetros, esto es equivalente a elegir el modelo que maximiza el log-verosimilitud.</p>
<p>Observamos que esta definición no es adoptada uniformemente en la literatura. Por ejemplo, en análisis de series temporales, el <span class="math inline">\(AIC\)</span> se reescala por el número de parámetros. Otras versiones que proporcionan correcciones para muestras finitas también están disponibles en la literatura.</p>
<p>Schwarz en 1978 derivó un criterio alternativo utilizando métodos bayesianos. Su medida se conoce como el <em>Criterio de Información Bayesiano</em>, definido como
<span class="math display">\[
BIC = -2 \times L(\boldsymbol \theta_{MLE}) + (número~de~parámetros) \times \ln (número~de~observaciones),
\]</span>
Esta medida da un mayor peso al número de parámetros. Es decir, todo lo demás siendo igual, el <span class="math inline">\(BIC\)</span> sugerirá un modelo más parsimonioso que el <span class="math inline">\(AIC\)</span>.</p>
<p>Al igual que el coeficiente de determinación ajustado <span class="math inline">\(R^2_a\)</span> que hemos introducido en la literatura de regresión, tanto el <span class="math inline">\(AIC\)</span> como el <span class="math inline">\(BIC\)</span> proporcionan medidas de ajuste con una penalización por la complejidad del modelo. En los modelos de regresión lineal normal, la Sección 5.6 señaló que minimizar el <span class="math inline">\(AIC\)</span> es equivalente a minimizar <span class="math inline">\(n \ln s^2 + k\)</span>. Otra estadística de regresión lineal que equilibra la bondad de ajuste y la complejidad del modelo es la estadística <span class="math inline">\(C_p\)</span> de Mallows. Para <span class="math inline">\(p\)</span> variables candidatas en el modelo, esto se define como <span class="math inline">\(C_p = (Error~SS)_p/s^2 - (n-2p).\)</span> Véase, por ejemplo, Cameron y Trivedi (1998) para referencias y más discusión sobre criterios de información.</p>

<!-- # Chap 1 -->
<!-- # Chap 2 -->
<!-- # Chap 3 -->
<!-- # Chap 4 -->
<!-- # Chap 5 -->
<!-- # Chap 6 -->
<!-- # Chap 7 -->
<!-- # Chap 8 -->
<!-- # Chap 9 -->
<!-- # Chap 10 -->
<!-- # Chap 11 -->
</div>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="chap-10.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="C12Count.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": null,
"search": {
"engine": "fuse",
"options": null
},
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/latest.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
