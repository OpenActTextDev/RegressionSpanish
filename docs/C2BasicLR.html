<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Capítulo 2 Regresión Lineal Básica | Modelado de Regresión con Aplicaciones Actuariales y Financieras</title>
  <meta name="description" content="Spanish Translation of ‘Regression Modeling with Actuarial and Financial Applications’" />
  <meta name="generator" content="bookdown 0.39 and GitBook 2.6.7" />

  <meta property="og:title" content="Capítulo 2 Regresión Lineal Básica | Modelado de Regresión con Aplicaciones Actuariales y Financieras" />
  <meta property="og:type" content="book" />
  
  <meta property="og:description" content="Spanish Translation of ‘Regression Modeling with Actuarial and Financial Applications’" />
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Capítulo 2 Regresión Lineal Básica | Modelado de Regresión con Aplicaciones Actuariales y Financieras" />
  
  <meta name="twitter:description" content="Spanish Translation of ‘Regression Modeling with Actuarial and Financial Applications’" />
  

<meta name="author" content="Edward (Jed) Frees, University of Wisconsin - Madison, Australian National University" />



  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="regresión-y-la-distribución-normal.html"/>
<link rel="next" href="C3BasicMLR.html"/>
<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/anchor-sections-1.1.0/anchor-sections.css" rel="stylesheet" />
<link href="libs/anchor-sections-1.1.0/anchor-sections-hash.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.1.0/anchor-sections.js"></script>
<script src="libs/kePrint-0.0.1/kePrint.js"></script>
<link href="libs/lightable-0.0.1/lightable.css" rel="stylesheet" />

<!-- Mathjax Version 2-->
<script type='text/x-mathjax-config'>
		MathJax.Hub.Config({
			extensions: ['tex2jax.js'],
			jax: ['input/TeX', 'output/HTML-CSS'],
			tex2jax: {
				inlineMath: [ ['$','$'], ['\\(','\\)'] ],
				displayMath: [ ['$$','$$'], ['\\[','\\]'] ],
				processEscapes: true
			},
			'HTML-CSS': { availableFonts: ['TeX'] }
		});
</script>

<script type="text/javascript"  src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/MathJax.js?config=TeX-AMS_HTML"> </script>

<script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
<script type="text/javascript" src="https://unpkg.com/survey-jquery/survey.jquery.min.js"></script>
<link href="https://unpkg.com/survey-jquery/modern.min.css" type="text/css" rel="stylesheet">
<script src="https://unpkg.com/showdown/dist/showdown.min.js"></script>


<!-- Various toggle functions used throughout --> 
<script language="javascript">
function toggle(id1,id2) {
	var ele = document.getElementById(id1); var text = document.getElementById(id2);
	if (ele.style.display == "block") {ele.style.display = "none"; text.innerHTML = "Show Solution";}
		else {ele.style.display = "block"; text.innerHTML = "Hide Solution";}}
function togglecode(id1,id2) {
   var ele = document.getElementById(id1); var text = document.getElementById(id2);
   if (ele.style.display == "block") {ele.style.display = "none"; text.innerHTML = "Show R Code";}
      else {ele.style.display = "block"; text.innerHTML = "Hide R Code";}}
function toggleEX(id1,id2) {
   var ele = document.getElementById(id1); var text = document.getElementById(id2);
   if (ele.style.display == "block") {ele.style.display = "none"; text.innerHTML = "Show Example";}
      else {ele.style.display = "block"; text.innerHTML = "Hide Example";}}
function toggleTheory(id1,id2) {
   var ele = document.getElementById(id1); var text = document.getElementById(id2);
   if (ele.style.display == "block") {ele.style.display = "none"; text.innerHTML = "Show Theory";}
      else {ele.style.display = "block"; text.innerHTML = "Hide Theory";}}
function toggleSolution(id1,id2) {
   var ele = document.getElementById(id1); var text = document.getElementById(id2);
   if (ele.style.display == "block") {ele.style.display = "none"; text.innerHTML = "Show Solution";}
      else {ele.style.display = "block"; text.innerHTML = "Hide Solution";}}      
function toggleQuiz(id1,id2) {
   var ele = document.getElementById(id1); var text = document.getElementById(id2);
   if (ele.style.display == "block") {ele.style.display = "none"; text.innerHTML = "Show Quiz Solution";}
      else {ele.style.display = "block"; text.innerHTML = "Hide Quiz Solution";}}      
</script>

<!-- A few functions for revealing definitions -->
<script language="javascript">
<!--   $( function() {
    $("#tabs").tabs();
  } ); -->

$(document).ready(function(){
    $('[data-toggle="tooltip"]').tooltip();
});

$(document).ready(function(){
    $('[data-toggle="popover"]').popover(); 
});
</script>

<script language="javascript">
function openTab(evt, tabName) {
    var i, tabcontent, tablinks;
    tabcontent = document.getElementsByClassName("tabcontent");
    for (i = 0; i < tabcontent.length; i++) {
        tabcontent[i].style.display = "none";
    }
    tablinks = document.getElementsByClassName("tablinks");
    for (i = 0; i < tablinks.length; i++) {
        tablinks[i].className = tablinks[i].className.replace(" active", "");
    }
    document.getElementById(tabName).style.display = "block";
    evt.currentTarget.className += " active";
}

// Get the element with id="defaultOpen" and click on it
document.getElementById("defaultOpen").click();
</script>



<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { color: #008000; } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { color: #008000; font-weight: bold; } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<style type="text/css">
  
  div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Modelado de Regresión</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Prefacio</a>
<ul>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#prólogo"><i class="fa fa-check"></i>Prólogo</a>
<ul>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#para-quién-es-este-libro"><i class="fa fa-check"></i>¿Para Quién Es Este Libro?</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#de-qué-trata-este-libro"><i class="fa fa-check"></i>¿De Qué Trata Este Libro?</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#cómo-transmite-este-libro-su-mensaje"><i class="fa fa-check"></i>¿Cómo Transmite Este Libro Su Mensaje?</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#agradecimientos"><i class="fa fa-check"></i>Agradecimientos</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#dedicación"><i class="fa fa-check"></i>Dedicación</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="translation.html"><a href="translation.html"><i class="fa fa-check"></i>Translation</a></li>
<li class="chapter" data-level="1" data-path="regresión-y-la-distribución-normal.html"><a href="regresión-y-la-distribución-normal.html"><i class="fa fa-check"></i><b>1</b> Regresión y la Distribución Normal</a>
<ul>
<li class="chapter" data-level="1.1" data-path="regresión-y-la-distribución-normal.html"><a href="regresión-y-la-distribución-normal.html#Sec11"><i class="fa fa-check"></i><b>1.1</b> ¿Qué es el Análisis de Regresión?</a></li>
<li class="chapter" data-level="1.2" data-path="regresión-y-la-distribución-normal.html"><a href="regresión-y-la-distribución-normal.html#Sec12"><i class="fa fa-check"></i><b>1.2</b> Ajuste de Datos a una Distribución Normal</a></li>
<li class="chapter" data-level="1.3" data-path="regresión-y-la-distribución-normal.html"><a href="regresión-y-la-distribución-normal.html#Sec13"><i class="fa fa-check"></i><b>1.3</b> Transformaciones de Potencia</a></li>
<li class="chapter" data-level="1.4" data-path="regresión-y-la-distribución-normal.html"><a href="regresión-y-la-distribución-normal.html#Sec14"><i class="fa fa-check"></i><b>1.4</b> Muestreo y el Papel de la Normalidad</a></li>
<li class="chapter" data-level="1.5" data-path="regresión-y-la-distribución-normal.html"><a href="regresión-y-la-distribución-normal.html#Sec15"><i class="fa fa-check"></i><b>1.5</b> Regresión y Diseños de Muestreo</a></li>
<li class="chapter" data-level="1.6" data-path="regresión-y-la-distribución-normal.html"><a href="regresión-y-la-distribución-normal.html#Sec16"><i class="fa fa-check"></i><b>1.6</b> Aplicaciones Actuariales de la Regresión</a></li>
<li class="chapter" data-level="1.7" data-path="regresión-y-la-distribución-normal.html"><a href="regresión-y-la-distribución-normal.html#Sec17"><i class="fa fa-check"></i><b>1.7</b> Lecturas Adicionales y Referencias</a></li>
<li class="chapter" data-level="1.8" data-path="regresión-y-la-distribución-normal.html"><a href="regresión-y-la-distribución-normal.html#Sec18"><i class="fa fa-check"></i><b>1.8</b> Ejercicios</a></li>
<li class="chapter" data-level="1.9" data-path="regresión-y-la-distribución-normal.html"><a href="regresión-y-la-distribución-normal.html#Sec19"><i class="fa fa-check"></i><b>1.9</b> Suplemento Técnico - Teorema del Límite Central</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="C2BasicLR.html"><a href="C2BasicLR.html"><i class="fa fa-check"></i><b>2</b> Regresión Lineal Básica</a>
<ul>
<li class="chapter" data-level="2.1" data-path="C2BasicLR.html"><a href="C2BasicLR.html#Sec21"><i class="fa fa-check"></i><b>2.1</b> Correlaciones y Mínimos Cuadrados</a></li>
<li class="chapter" data-level="2.2" data-path="C2BasicLR.html"><a href="C2BasicLR.html#Sec22"><i class="fa fa-check"></i><b>2.2</b> Modelo Básico de Regresión Lineal</a></li>
<li class="chapter" data-level="2.3" data-path="C2BasicLR.html"><a href="C2BasicLR.html#Sec23"><i class="fa fa-check"></i><b>2.3</b> ¿Es Útil el Modelo? Algunas Medidas de Resumen Básicas</a>
<ul>
<li class="chapter" data-level="2.3.1" data-path="C2BasicLR.html"><a href="C2BasicLR.html#Sec231"><i class="fa fa-check"></i><b>2.3.1</b> Particionando la Variabilidad</a></li>
<li class="chapter" data-level="2.3.2" data-path="C2BasicLR.html"><a href="C2BasicLR.html#Sec232"><i class="fa fa-check"></i><b>2.3.2</b> El Tamaño de una Desviación Típica: <em>s</em></a></li>
</ul></li>
<li class="chapter" data-level="2.4" data-path="C2BasicLR.html"><a href="C2BasicLR.html#Sec24"><i class="fa fa-check"></i><b>2.4</b> Propiedades de los Estimadores del Coeficiente de Regresión</a></li>
<li class="chapter" data-level="2.5" data-path="C2BasicLR.html"><a href="C2BasicLR.html#Sec25"><i class="fa fa-check"></i><b>2.5</b> Inferencia Estadística</a>
<ul>
<li class="chapter" data-level="2.5.1" data-path="C2BasicLR.html"><a href="C2BasicLR.html#Sec251"><i class="fa fa-check"></i><b>2.5.1</b> ¿Es Importante la Variable Explicativa?: La Prueba <em>t</em></a></li>
<li class="chapter" data-level="2.5.2" data-path="C2BasicLR.html"><a href="C2BasicLR.html#Sec252"><i class="fa fa-check"></i><b>2.5.2</b> Intervalos de Confianza</a></li>
<li class="chapter" data-level="2.5.3" data-path="C2BasicLR.html"><a href="C2BasicLR.html#Sec253"><i class="fa fa-check"></i><b>2.5.3</b> Intervalos de Predicción</a></li>
</ul></li>
<li class="chapter" data-level="2.6" data-path="C2BasicLR.html"><a href="C2BasicLR.html#Sec26"><i class="fa fa-check"></i><b>2.6</b> Construyendo un Mejor Modelo: Análisis de Residuos</a></li>
<li class="chapter" data-level="2.7" data-path="C2BasicLR.html"><a href="C2BasicLR.html#Sec27"><i class="fa fa-check"></i><b>2.7</b> Aplicación: Modelo de Valoración de Activos Financieros</a></li>
<li class="chapter" data-level="2.8" data-path="C2BasicLR.html"><a href="C2BasicLR.html#Sec28"><i class="fa fa-check"></i><b>2.8</b> Salida Computacional Ilustrativa de Regresión</a></li>
<li class="chapter" data-level="2.9" data-path="C2BasicLR.html"><a href="C2BasicLR.html#Sec29"><i class="fa fa-check"></i><b>2.9</b> Lecturas Adicionales y Referencias</a></li>
<li class="chapter" data-level="2.10" data-path="C2BasicLR.html"><a href="C2BasicLR.html#Sec210"><i class="fa fa-check"></i><b>2.10</b> Ejercicios</a></li>
<li class="chapter" data-level="2.11" data-path="C2BasicLR.html"><a href="C2BasicLR.html#Sec211"><i class="fa fa-check"></i><b>2.11</b> Suplemento Técnico - Elementos del Álgebra de Matrices</a>
<ul>
<li class="chapter" data-level="2.11.1" data-path="C2BasicLR.html"><a href="C2BasicLR.html#Sec2111"><i class="fa fa-check"></i><b>2.11.1</b> Definiciones Básicas</a></li>
<li class="chapter" data-level="2.11.2" data-path="C2BasicLR.html"><a href="C2BasicLR.html#Sec2112"><i class="fa fa-check"></i><b>2.11.2</b> Algunas Matrices Especiales</a></li>
<li class="chapter" data-level="2.11.3" data-path="C2BasicLR.html"><a href="C2BasicLR.html#Sec2113"><i class="fa fa-check"></i><b>2.11.3</b> Operaciones Básicas</a></li>
<li class="chapter" data-level="2.11.4" data-path="C2BasicLR.html"><a href="C2BasicLR.html#Sec2114"><i class="fa fa-check"></i><b>2.11.4</b> Matrices Aleatorias</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="3" data-path="C3BasicMLR.html"><a href="C3BasicMLR.html"><i class="fa fa-check"></i><b>3</b> Regresión Lineal Múltiple - I</a>
<ul>
<li class="chapter" data-level="3.1" data-path="C3BasicMLR.html"><a href="C3BasicMLR.html#Sec31"><i class="fa fa-check"></i><b>3.1</b> Método de Mínimos Cuadrados</a></li>
<li class="chapter" data-level="3.2" data-path="C3BasicMLR.html"><a href="C3BasicMLR.html#Sec32"><i class="fa fa-check"></i><b>3.2</b> Modelo de Regresión Lineal y Propiedades de los Estimadores</a>
<ul>
<li class="chapter" data-level="3.2.1" data-path="C3BasicMLR.html"><a href="C3BasicMLR.html#Sec321"><i class="fa fa-check"></i><b>3.2.1</b> Función de Regresión</a></li>
<li class="chapter" data-level="3.2.2" data-path="C3BasicMLR.html"><a href="C3BasicMLR.html#Sec322"><i class="fa fa-check"></i><b>3.2.2</b> Interpretación del Coeficiente de Regresión</a></li>
<li class="chapter" data-level="3.2.3" data-path="C3BasicMLR.html"><a href="C3BasicMLR.html#Sec323"><i class="fa fa-check"></i><b>3.2.3</b> Suposiciones del Modelo</a></li>
<li class="chapter" data-level="3.2.4" data-path="C3BasicMLR.html"><a href="C3BasicMLR.html#Sec324"><i class="fa fa-check"></i><b>3.2.4</b> Propiedades de los Estimadores de los Coeficientes de Regresión</a></li>
</ul></li>
<li class="chapter" data-level="3.3" data-path="C3BasicMLR.html"><a href="C3BasicMLR.html#Sec33"><i class="fa fa-check"></i><b>3.3</b> Estimación y Bondad de Ajuste</a></li>
<li class="chapter" data-level="3.4" data-path="C3BasicMLR.html"><a href="C3BasicMLR.html#Sec34"><i class="fa fa-check"></i><b>3.4</b> Inferencia Estadística para un Coeficiente Único</a>
<ul>
<li class="chapter" data-level="3.4.1" data-path="C3BasicMLR.html"><a href="C3BasicMLR.html#Sec341"><i class="fa fa-check"></i><b>3.4.1</b> La Prueba <em>t</em></a></li>
<li class="chapter" data-level="3.4.2" data-path="C3BasicMLR.html"><a href="C3BasicMLR.html#Sec342"><i class="fa fa-check"></i><b>3.4.2</b> Intervalos de Confianza</a></li>
<li class="chapter" data-level="3.4.3" data-path="C3BasicMLR.html"><a href="C3BasicMLR.html#Sec343"><i class="fa fa-check"></i><b>3.4.3</b> Gráficos de Variables Añadidas</a></li>
<li class="chapter" data-level="3.4.4" data-path="C3BasicMLR.html"><a href="C3BasicMLR.html#Sec344"><i class="fa fa-check"></i><b>3.4.4</b> Coeficientes de Correlación Parcial</a></li>
</ul></li>
<li class="chapter" data-level="3.5" data-path="C3BasicMLR.html"><a href="C3BasicMLR.html#Sec35"><i class="fa fa-check"></i><b>3.5</b> Algunas Variables Explicativas Especiales</a>
<ul>
<li class="chapter" data-level="3.5.1" data-path="C3BasicMLR.html"><a href="C3BasicMLR.html#Sec351"><i class="fa fa-check"></i><b>3.5.1</b> Variables Binarias</a></li>
<li class="chapter" data-level="3.5.2" data-path="C3BasicMLR.html"><a href="C3BasicMLR.html#Sec352"><i class="fa fa-check"></i><b>3.5.2</b> Transformación de Variables Explicativas</a></li>
<li class="chapter" data-level="3.5.3" data-path="C3BasicMLR.html"><a href="C3BasicMLR.html#Sec353"><i class="fa fa-check"></i><b>3.5.3</b> Términos de Interacción</a></li>
</ul></li>
<li class="chapter" data-level="3.6" data-path="C3BasicMLR.html"><a href="C3BasicMLR.html#Sec36"><i class="fa fa-check"></i><b>3.6</b> Lectura Adicional y Referencias</a></li>
<li class="chapter" data-level="3.7" data-path="C3BasicMLR.html"><a href="C3BasicMLR.html#Sec37"><i class="fa fa-check"></i><b>3.7</b> Ejercicios</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="C4MLRANOVA.html"><a href="C4MLRANOVA.html"><i class="fa fa-check"></i><b>4</b> Regresión Lineal Múltiple - II</a>
<ul>
<li class="chapter" data-level="4.1" data-path="C4MLRANOVA.html"><a href="C4MLRANOVA.html#Sec41"><i class="fa fa-check"></i><b>4.1</b> El Papel de las Variables Binarias</a></li>
<li class="chapter" data-level="4.2" data-path="C4MLRANOVA.html"><a href="C4MLRANOVA.html#Sec42"><i class="fa fa-check"></i><b>4.2</b> Inferencia Estadística para Varios Coeficientes</a>
<ul>
<li class="chapter" data-level="4.2.1" data-path="C4MLRANOVA.html"><a href="C4MLRANOVA.html#Sec421"><i class="fa fa-check"></i><b>4.2.1</b> Conjuntos de Coeficientes de Regresión</a></li>
<li class="chapter" data-level="4.2.2" data-path="C4MLRANOVA.html"><a href="C4MLRANOVA.html#Sec422"><i class="fa fa-check"></i><b>4.2.2</b> La Hipótesis Lineal General</a></li>
<li class="chapter" data-level="4.2.3" data-path="C4MLRANOVA.html"><a href="C4MLRANOVA.html#Sec423"><i class="fa fa-check"></i><b>4.2.3</b> Estimando y Prediciendo Varios Coeficientes</a></li>
</ul></li>
<li class="chapter" data-level="4.3" data-path="C4MLRANOVA.html"><a href="C4MLRANOVA.html#Sec43"><i class="fa fa-check"></i><b>4.3</b> Modelo ANOVA de Un Factor</a></li>
<li class="chapter" data-level="4.4" data-path="C4MLRANOVA.html"><a href="C4MLRANOVA.html#Sec44"><i class="fa fa-check"></i><b>4.4</b> Combinando Variables Explicativas Categóricas y Continuas</a></li>
<li class="chapter" data-level="4.5" data-path="C4MLRANOVA.html"><a href="C4MLRANOVA.html#Sec45"><i class="fa fa-check"></i><b>4.5</b> Lecturas Adicionales y Referencias</a></li>
<li class="chapter" data-level="4.6" data-path="C4MLRANOVA.html"><a href="C4MLRANOVA.html#Sec46"><i class="fa fa-check"></i><b>4.6</b> Ejercicios</a></li>
<li class="chapter" data-level="4.7" data-path="C4MLRANOVA.html"><a href="C4MLRANOVA.html#Sec47"><i class="fa fa-check"></i><b>4.7</b> Suplemento Técnico - Expresiones Matriciales</a>
<ul>
<li class="chapter" data-level="4.7.1" data-path="C4MLRANOVA.html"><a href="C4MLRANOVA.html#Sec471"><i class="fa fa-check"></i><b>4.7.1</b> Expresión de Modelos con Variables Categóricas en Forma Matricial</a></li>
<li class="chapter" data-level="4.7.2" data-path="C4MLRANOVA.html"><a href="C4MLRANOVA.html#Sec472"><i class="fa fa-check"></i><b>4.7.2</b> Cálculo Recursivo de Mínimos Cuadrados</a></li>
<li class="chapter" data-level="4.7.3" data-path="C4MLRANOVA.html"><a href="C4MLRANOVA.html#Sec473"><i class="fa fa-check"></i><b>4.7.3</b> Modelo Lineal General</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="5" data-path="C5VarSelect.html"><a href="C5VarSelect.html"><i class="fa fa-check"></i><b>5</b> Selección de Variables</a>
<ul>
<li class="chapter" data-level="5.1" data-path="C5VarSelect.html"><a href="C5VarSelect.html#Sec51"><i class="fa fa-check"></i><b>5.1</b> Un Enfoque Iterativo para el Análisis de Datos y Modelado</a></li>
<li class="chapter" data-level="5.2" data-path="C5VarSelect.html"><a href="C5VarSelect.html#Sec52"><i class="fa fa-check"></i><b>5.2</b> Procedimientos Automáticos de Selección de Variables</a></li>
<li class="chapter" data-level="5.3" data-path="C5VarSelect.html"><a href="C5VarSelect.html#Sec53"><i class="fa fa-check"></i><b>5.3</b> Análisis de Residuales</a>
<ul>
<li class="chapter" data-level="5.3.1" data-path="C5VarSelect.html"><a href="C5VarSelect.html#Sec531"><i class="fa fa-check"></i><b>5.3.1</b> Residuales</a></li>
<li class="chapter" data-level="5.3.2" data-path="C5VarSelect.html"><a href="C5VarSelect.html#Sec532"><i class="fa fa-check"></i><b>5.3.2</b> Uso de los Residuales para Identificar Valores Atípicos</a></li>
<li class="chapter" data-level="5.3.3" data-path="C5VarSelect.html"><a href="C5VarSelect.html#Sec533"><i class="fa fa-check"></i><b>5.3.3</b> Uso de los Residuales para Seleccionar Variables Explicativas</a></li>
</ul></li>
<li class="chapter" data-level="5.4" data-path="C5VarSelect.html"><a href="C5VarSelect.html#Sec54"><i class="fa fa-check"></i><b>5.4</b> Puntos Influyentes</a>
<ul>
<li class="chapter" data-level="5.4.1" data-path="C5VarSelect.html"><a href="C5VarSelect.html#Sec541"><i class="fa fa-check"></i><b>5.4.1</b> Apalancamiento</a></li>
<li class="chapter" data-level="5.4.2" data-path="C5VarSelect.html"><a href="C5VarSelect.html#Sec542"><i class="fa fa-check"></i><b>5.4.2</b> Distancia de Cook</a></li>
</ul></li>
<li class="chapter" data-level="5.5" data-path="C5VarSelect.html"><a href="C5VarSelect.html#Sec55"><i class="fa fa-check"></i><b>5.5</b> Colinealidad</a>
<ul>
<li class="chapter" data-level="5.5.1" data-path="C5VarSelect.html"><a href="C5VarSelect.html#Sec551"><i class="fa fa-check"></i><b>5.5.1</b> ¿Qué es la Colinealidad?</a></li>
<li class="chapter" data-level="5.5.2" data-path="C5VarSelect.html"><a href="C5VarSelect.html#Sec552"><i class="fa fa-check"></i><b>5.5.2</b> Factores de Inflación de Varianza</a></li>
<li class="chapter" data-level="5.5.3" data-path="C5VarSelect.html"><a href="C5VarSelect.html#Sec553"><i class="fa fa-check"></i><b>5.5.3</b> Colinealidad e Influencia</a></li>
<li class="chapter" data-level="5.5.4" data-path="C5VarSelect.html"><a href="C5VarSelect.html#Sec554"><i class="fa fa-check"></i><b>5.5.4</b> Variables Suprensoras</a></li>
<li class="chapter" data-level="5.5.5" data-path="C5VarSelect.html"><a href="C5VarSelect.html#Sec555"><i class="fa fa-check"></i><b>5.5.5</b> Variables Ortogonales</a></li>
</ul></li>
<li class="chapter" data-level="5.6" data-path="C5VarSelect.html"><a href="C5VarSelect.html#Sec56"><i class="fa fa-check"></i><b>5.6</b> Criterios de Selección</a>
<ul>
<li class="chapter" data-level="5.6.1" data-path="C5VarSelect.html"><a href="C5VarSelect.html#Sec561"><i class="fa fa-check"></i><b>5.6.1</b> Bondad de Ajuste</a></li>
<li class="chapter" data-level="5.6.2" data-path="C5VarSelect.html"><a href="C5VarSelect.html#Sec562"><i class="fa fa-check"></i><b>5.6.2</b> Validación del Modelo</a></li>
<li class="chapter" data-level="5.6.3" data-path="C5VarSelect.html"><a href="C5VarSelect.html#Sec563"><i class="fa fa-check"></i><b>5.6.3</b> Validación Cruzada</a></li>
</ul></li>
<li class="chapter" data-level="5.7" data-path="C5VarSelect.html"><a href="C5VarSelect.html#Sec57"><i class="fa fa-check"></i><b>5.7</b> Heterocedasticidad</a>
<ul>
<li class="chapter" data-level="5.7.1" data-path="C5VarSelect.html"><a href="C5VarSelect.html#Sec571"><i class="fa fa-check"></i><b>5.7.1</b> Detección de Heterocedasticidad</a></li>
<li class="chapter" data-level="5.7.2" data-path="C5VarSelect.html"><a href="C5VarSelect.html#Sec572"><i class="fa fa-check"></i><b>5.7.2</b> Errores Estándar Consistentes con Heterocedasticidad</a></li>
<li class="chapter" data-level="5.7.3" data-path="C5VarSelect.html"><a href="C5VarSelect.html#Sec573"><i class="fa fa-check"></i><b>5.7.3</b> Mínimos Cuadrados Ponderados</a></li>
<li class="chapter" data-level="5.7.4" data-path="C5VarSelect.html"><a href="C5VarSelect.html#Sec574"><i class="fa fa-check"></i><b>5.7.4</b> Transformaciones</a></li>
</ul></li>
<li class="chapter" data-level="5.8" data-path="C5VarSelect.html"><a href="C5VarSelect.html#Sec58"><i class="fa fa-check"></i><b>5.8</b> Lectura Adicional y Referencias</a></li>
<li class="chapter" data-level="5.9" data-path="C5VarSelect.html"><a href="C5VarSelect.html#Sec59"><i class="fa fa-check"></i><b>5.9</b> Ejercicios</a></li>
<li class="chapter" data-level="5.10" data-path="C5VarSelect.html"><a href="C5VarSelect.html#Sec510"><i class="fa fa-check"></i><b>5.10</b> Suplementos Técnicos para el Capítulo 5</a>
<ul>
<li class="chapter" data-level="5.10.1" data-path="C5VarSelect.html"><a href="C5VarSelect.html#Sec5101"><i class="fa fa-check"></i><b>5.10.1</b> Matriz de Proyección</a></li>
<li class="chapter" data-level="5.10.2" data-path="C5VarSelect.html"><a href="C5VarSelect.html#Sec5102"><i class="fa fa-check"></i><b>5.10.2</b> Estadísticas Leave-One-Out</a></li>
<li class="chapter" data-level="5.10.3" data-path="C5VarSelect.html"><a href="C5VarSelect.html#Sec5103"><i class="fa fa-check"></i><b>5.10.3</b> Omisión de Variables</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="6" data-path="interpretación-de-resultados-de-regresión.html"><a href="interpretación-de-resultados-de-regresión.html"><i class="fa fa-check"></i><b>6</b> Interpretación de Resultados de Regresión</a>
<ul>
<li class="chapter" data-level="6.1" data-path="interpretación-de-resultados-de-regresión.html"><a href="interpretación-de-resultados-de-regresión.html#Sec61"><i class="fa fa-check"></i><b>6.1</b> Lo que nos dice el proceso de modelado</a>
<ul>
<li class="chapter" data-level="6.1.1" data-path="interpretación-de-resultados-de-regresión.html"><a href="interpretación-de-resultados-de-regresión.html#Sec611"><i class="fa fa-check"></i><b>6.1.1</b> Interpretación de efectos individuales</a></li>
<li class="chapter" data-level="6.1.2" data-path="interpretación-de-resultados-de-regresión.html"><a href="interpretación-de-resultados-de-regresión.html#Sec612"><i class="fa fa-check"></i><b>6.1.2</b> Otras Interpretaciones</a></li>
</ul></li>
<li class="chapter" data-level="6.2" data-path="interpretación-de-resultados-de-regresión.html"><a href="interpretación-de-resultados-de-regresión.html#Sec62"><i class="fa fa-check"></i><b>6.2</b> La Importancia de la Selección de Variables</a>
<ul>
<li class="chapter" data-level="6.2.1" data-path="interpretación-de-resultados-de-regresión.html"><a href="interpretación-de-resultados-de-regresión.html#Sec621"><i class="fa fa-check"></i><b>6.2.1</b> Sobreajuste del Modelo</a></li>
<li class="chapter" data-level="6.2.2" data-path="interpretación-de-resultados-de-regresión.html"><a href="interpretación-de-resultados-de-regresión.html#Sec622"><i class="fa fa-check"></i><b>6.2.2</b> Subajuste del Modelo</a></li>
</ul></li>
<li class="chapter" data-level="6.3" data-path="interpretación-de-resultados-de-regresión.html"><a href="interpretación-de-resultados-de-regresión.html#Sec63"><i class="fa fa-check"></i><b>6.3</b> La Importancia de la Recolección de Datos</a>
<ul>
<li class="chapter" data-level="6.3.1" data-path="interpretación-de-resultados-de-regresión.html"><a href="interpretación-de-resultados-de-regresión.html#Sec631"><i class="fa fa-check"></i><b>6.3.1</b> Error en el Marco Muestral y Selección Adversa</a></li>
<li class="chapter" data-level="6.3.2" data-path="interpretación-de-resultados-de-regresión.html"><a href="interpretación-de-resultados-de-regresión.html#Sec632"><i class="fa fa-check"></i><b>6.3.2</b> Regiones de Muestreo Limitadas</a></li>
<li class="chapter" data-level="6.3.3" data-path="interpretación-de-resultados-de-regresión.html"><a href="interpretación-de-resultados-de-regresión.html#Sec633"><i class="fa fa-check"></i><b>6.3.3</b> Variables Dependientes Limitadas, Censura y Truncamiento</a></li>
<li class="chapter" data-level="6.3.4" data-path="interpretación-de-resultados-de-regresión.html"><a href="interpretación-de-resultados-de-regresión.html#Sec634"><i class="fa fa-check"></i><b>6.3.4</b> Variables Omitidas y Endógenas</a></li>
<li class="chapter" data-level="6.3.5" data-path="interpretación-de-resultados-de-regresión.html"><a href="interpretación-de-resultados-de-regresión.html#Sec635"><i class="fa fa-check"></i><b>6.3.5</b> Datos Faltantes</a></li>
</ul></li>
<li class="chapter" data-level="6.4" data-path="interpretación-de-resultados-de-regresión.html"><a href="interpretación-de-resultados-de-regresión.html#Sec64"><i class="fa fa-check"></i><b>6.4</b> Modelos de Datos Faltantes</a>
<ul>
<li class="chapter" data-level="6.4.1" data-path="interpretación-de-resultados-de-regresión.html"><a href="interpretación-de-resultados-de-regresión.html#Sec641"><i class="fa fa-check"></i><b>6.4.1</b> Faltante al Azar</a></li>
<li class="chapter" data-level="6.4.2" data-path="interpretación-de-resultados-de-regresión.html"><a href="interpretación-de-resultados-de-regresión.html#Sec642"><i class="fa fa-check"></i><b>6.4.2</b> Datos Faltantes No Ignorables</a></li>
</ul></li>
<li class="chapter" data-level="6.5" data-path="interpretación-de-resultados-de-regresión.html"><a href="interpretación-de-resultados-de-regresión.html#Sec65"><i class="fa fa-check"></i><b>6.5</b> Aplicación: Eficiencia en el Costo de los Gestores de Riesgos</a></li>
<li class="chapter" data-level="6.6" data-path="interpretación-de-resultados-de-regresión.html"><a href="interpretación-de-resultados-de-regresión.html#Sec66"><i class="fa fa-check"></i><b>6.6</b> Lecturas Adicionales y Referencias</a></li>
<li class="chapter" data-level="6.7" data-path="interpretación-de-resultados-de-regresión.html"><a href="interpretación-de-resultados-de-regresión.html#Sec67"><i class="fa fa-check"></i><b>6.7</b> Ejercicios</a></li>
<li class="chapter" data-level="6.8" data-path="interpretación-de-resultados-de-regresión.html"><a href="interpretación-de-resultados-de-regresión.html#Sec68"><i class="fa fa-check"></i><b>6.8</b> Suplementos Técnicos para el Capítulo 6</a>
<ul>
<li class="chapter" data-level="6.8.1" data-path="interpretación-de-resultados-de-regresión.html"><a href="interpretación-de-resultados-de-regresión.html#Sec681"><i class="fa fa-check"></i><b>6.8.1</b> Efectos de la Especificación Incorrecta del Modelo</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="7" data-path="C7Trends.html"><a href="C7Trends.html"><i class="fa fa-check"></i><b>7</b> Modelado de Tendencias</a>
<ul>
<li class="chapter" data-level="7.1" data-path="C7Trends.html"><a href="C7Trends.html#introducción-1"><i class="fa fa-check"></i><b>7.1</b> Introducción</a>
<ul>
<li class="chapter" data-level="" data-path="C7Trends.html"><a href="C7Trends.html#series-temporales-y-procesos-estocásticos"><i class="fa fa-check"></i>Series Temporales y Procesos Estocásticos</a></li>
<li class="chapter" data-level="" data-path="C7Trends.html"><a href="C7Trends.html#series-temporales-versus-modelos-causales"><i class="fa fa-check"></i>Series Temporales versus Modelos Causales</a></li>
</ul></li>
<li class="chapter" data-level="7.2" data-path="C7Trends.html"><a href="C7Trends.html#S7:Trends"><i class="fa fa-check"></i><b>7.2</b> Ajuste de Tendencias en el Tiempo</a>
<ul>
<li class="chapter" data-level="" data-path="C7Trends.html"><a href="C7Trends.html#comprendiendo-patrones-en-el-tiempo"><i class="fa fa-check"></i>Comprendiendo Patrones en el Tiempo</a></li>
<li class="chapter" data-level="" data-path="C7Trends.html"><a href="C7Trends.html#ajuste-de-tendencias-en-el-tiempo"><i class="fa fa-check"></i>Ajuste de Tendencias en el Tiempo</a></li>
<li class="chapter" data-level="" data-path="C7Trends.html"><a href="C7Trends.html#ajuste-de-tendencias-estacionales"><i class="fa fa-check"></i>Ajuste de Tendencias Estacionales</a></li>
<li class="chapter" data-level="" data-path="C7Trends.html"><a href="C7Trends.html#confiabilidad-de-los-pronósticos-de-series-temporales"><i class="fa fa-check"></i>Confiabilidad de los Pronósticos de Series Temporales</a></li>
</ul></li>
<li class="chapter" data-level="7.3" data-path="C7Trends.html"><a href="C7Trends.html#S7:RandomWalk"><i class="fa fa-check"></i><b>7.3</b> Estacionariedad y Modelos de Paseo Aleatorio</a>
<ul>
<li class="chapter" data-level="" data-path="C7Trends.html"><a href="C7Trends.html#ruido-blanco"><i class="fa fa-check"></i>Ruido Blanco</a></li>
<li class="chapter" data-level="" data-path="C7Trends.html"><a href="C7Trends.html#paseo-aleatorio"><i class="fa fa-check"></i>Paseo Aleatorio</a></li>
</ul></li>
<li class="chapter" data-level="7.4" data-path="C7Trends.html"><a href="C7Trends.html#inferencia-usando-modelos-de-paseo-aleatorio"><i class="fa fa-check"></i><b>7.4</b> Inferencia usando Modelos de Paseo Aleatorio</a>
<ul>
<li class="chapter" data-level="" data-path="C7Trends.html"><a href="C7Trends.html#propiedades-del-modelo"><i class="fa fa-check"></i>Propiedades del Modelo</a></li>
<li class="chapter" data-level="" data-path="C7Trends.html"><a href="C7Trends.html#pronósticos"><i class="fa fa-check"></i>Pronósticos</a></li>
<li class="chapter" data-level="" data-path="C7Trends.html"><a href="C7Trends.html#identificación-de-estacionariedad"><i class="fa fa-check"></i>Identificación de Estacionariedad</a></li>
<li class="chapter" data-level="" data-path="C7Trends.html"><a href="C7Trends.html#identificación-de-paseos-aleatorios"><i class="fa fa-check"></i>Identificación de Paseos Aleatorios</a></li>
<li class="chapter" data-level="" data-path="C7Trends.html"><a href="C7Trends.html#paseo-aleatorio-versus-modelo-de-tendencia-lineal-en-el-tiempo"><i class="fa fa-check"></i>Paseo Aleatorio versus Modelo de Tendencia Lineal en el Tiempo</a></li>
</ul></li>
<li class="chapter" data-level="7.5" data-path="C7Trends.html"><a href="C7Trends.html#filtrado-para-lograr-estacionariedad"><i class="fa fa-check"></i><b>7.5</b> Filtrado para Lograr Estacionariedad</a>
<ul>
<li class="chapter" data-level="" data-path="C7Trends.html"><a href="C7Trends.html#transformaciones"><i class="fa fa-check"></i>Transformaciones</a></li>
</ul></li>
<li class="chapter" data-level="7.6" data-path="C7Trends.html"><a href="C7Trends.html#evaluación-de-pronósticos"><i class="fa fa-check"></i><b>7.6</b> Evaluación de Pronósticos</a></li>
<li class="chapter" data-level="7.7" data-path="C7Trends.html"><a href="C7Trends.html#lecturas-adicionales-y-referencias"><i class="fa fa-check"></i><b>7.7</b> Lecturas Adicionales y Referencias</a></li>
<li class="chapter" data-level="7.8" data-path="C7Trends.html"><a href="C7Trends.html#ejercicios"><i class="fa fa-check"></i><b>7.8</b> Ejercicios</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="C8AR.html"><a href="C8AR.html"><i class="fa fa-check"></i><b>8</b> Autocorrelaciones y Modelos Autorregresivos</a>
<ul>
<li class="chapter" data-level="8.1" data-path="C8AR.html"><a href="C8AR.html#S8:Autocorrs"><i class="fa fa-check"></i><b>8.1</b> Autocorrelaciones</a>
<ul>
<li class="chapter" data-level="" data-path="C8AR.html"><a href="C8AR.html#aplicación-retornos-de-bonos-con-inflación"><i class="fa fa-check"></i>Aplicación: Retornos de Bonos con Inflación</a></li>
</ul></li>
<li class="chapter" data-level="8.2" data-path="C8AR.html"><a href="C8AR.html#modelos-autorregresivos-de-orden-uno"><i class="fa fa-check"></i><b>8.2</b> Modelos Autorregresivos de Orden Uno</a></li>
<li class="chapter" data-level="8.3" data-path="C8AR.html"><a href="C8AR.html#S8:Estimation"><i class="fa fa-check"></i><b>8.3</b> Estimación y Verificación de Diagnóstico</a></li>
<li class="chapter" data-level="8.4" data-path="C8AR.html"><a href="C8AR.html#S8:AR1Smooth"><i class="fa fa-check"></i><b>8.4</b> Suavización y Predicción</a></li>
<li class="chapter" data-level="8.5" data-path="C8AR.html"><a href="C8AR.html#S8:BoxJenkins"><i class="fa fa-check"></i><b>8.5</b> Modelado y Pronóstico de Box-Jenkins</a>
<ul>
<li class="chapter" data-level="8.5.1" data-path="C8AR.html"><a href="C8AR.html#modelos"><i class="fa fa-check"></i><b>8.5.1</b> Modelos</a></li>
<li class="chapter" data-level="8.5.2" data-path="C8AR.html"><a href="C8AR.html#pronóstico"><i class="fa fa-check"></i><b>8.5.2</b> Pronóstico</a></li>
</ul></li>
<li class="chapter" data-level="8.6" data-path="C8AR.html"><a href="C8AR.html#aplicación-tasas-de-cambio-de-hong-kong"><i class="fa fa-check"></i><b>8.6</b> Aplicación: Tasas de Cambio de Hong Kong</a></li>
<li class="chapter" data-level="8.7" data-path="C8AR.html"><a href="C8AR.html#lecturas-adicionales-y-referencias-1"><i class="fa fa-check"></i><b>8.7</b> Lecturas Adicionales y Referencias</a></li>
</ul></li>
<li class="chapter" data-level="9" data-path="C9Forecast.html"><a href="C9Forecast.html"><i class="fa fa-check"></i><b>9</b> Pronósticos y Modelos de Series Temporales</a>
<ul>
<li class="chapter" data-level="9.1" data-path="C9Forecast.html"><a href="C9Forecast.html#suavización-con-promedios-móviles"><i class="fa fa-check"></i><b>9.1</b> Suavización con Promedios Móviles</a></li>
<li class="chapter" data-level="9.2" data-path="C9Forecast.html"><a href="C9Forecast.html#S9:ExponSmooth"><i class="fa fa-check"></i><b>9.2</b> Suavización Exponencial</a></li>
<li class="chapter" data-level="9.3" data-path="C9Forecast.html"><a href="C9Forecast.html#S9:SeasonalTSModels"><i class="fa fa-check"></i><b>9.3</b> Modelos de Series Temporales Estacionales</a></li>
<li class="chapter" data-level="9.4" data-path="C9Forecast.html"><a href="C9Forecast.html#pruebas-de-raíces-unitarias"><i class="fa fa-check"></i><b>9.4</b> Pruebas de Raíces Unitarias</a></li>
<li class="chapter" data-level="9.5" data-path="C9Forecast.html"><a href="C9Forecast.html#modelos-archgarch"><i class="fa fa-check"></i><b>9.5</b> Modelos ARCH/GARCH</a></li>
<li class="chapter" data-level="9.6" data-path="C9Forecast.html"><a href="C9Forecast.html#lecturas-y-referencias-adicionales"><i class="fa fa-check"></i><b>9.6</b> Lecturas y Referencias Adicionales</a></li>
</ul></li>
<li class="chapter" data-level="10" data-path="C10Panel.html"><a href="C10Panel.html"><i class="fa fa-check"></i><b>10</b> Modelos de Datos Longitudinales y de Panel</a>
<ul>
<li class="chapter" data-level="10.1" data-path="C10Panel.html"><a href="C10Panel.html#S10:Intro"><i class="fa fa-check"></i><b>10.1</b> ¿Qué son los Datos Longitudinales y de Panel?</a></li>
<li class="chapter" data-level="10.2" data-path="C10Panel.html"><a href="C10Panel.html#S10:Visual"><i class="fa fa-check"></i><b>10.2</b> Visualización de Datos Longitudinales y de Panel</a></li>
<li class="chapter" data-level="10.3" data-path="C10Panel.html"><a href="C10Panel.html#S10:FEModels"><i class="fa fa-check"></i><b>10.3</b> Modelos Básicos de Efectos Fijos</a></li>
<li class="chapter" data-level="10.4" data-path="C10Panel.html"><a href="C10Panel.html#S10:FEModels2"><i class="fa fa-check"></i><b>10.4</b> Modelos Extendidos de Efectos Fijos</a></li>
<li class="chapter" data-level="10.5" data-path="C10Panel.html"><a href="C10Panel.html#S10:REModels"><i class="fa fa-check"></i><b>10.5</b> Modelos de Efectos Aleatorios</a></li>
<li class="chapter" data-level="10.6" data-path="C10Panel.html"><a href="C10Panel.html#S10:References"><i class="fa fa-check"></i><b>10.6</b> Lecturas Adicionales y Referencias</a></li>
</ul></li>
<li class="chapter" data-level="11" data-path="C11Binary.html"><a href="C11Binary.html"><i class="fa fa-check"></i><b>11</b> Variables Dependientes Categóricas</a>
<ul>
<li class="chapter" data-level="11.1" data-path="C11Binary.html"><a href="C11Binary.html#S:Sec111"><i class="fa fa-check"></i><b>11.1</b> Variables Dependientes Binarias</a></li>
<li class="chapter" data-level="11.2" data-path="C11Binary.html"><a href="C11Binary.html#S:Sec112"><i class="fa fa-check"></i><b>11.2</b> Modelos de Regresión Logística y Probit</a>
<ul>
<li class="chapter" data-level="11.2.1" data-path="C11Binary.html"><a href="C11Binary.html#S:Sec1121"><i class="fa fa-check"></i><b>11.2.1</b> Uso de Funciones No Lineales de Variables Explicativas</a></li>
<li class="chapter" data-level="11.2.2" data-path="C11Binary.html"><a href="C11Binary.html#S:Sec1122"><i class="fa fa-check"></i><b>11.2.2</b> Interpretación del Umbral</a></li>
<li class="chapter" data-level="11.2.3" data-path="C11Binary.html"><a href="C11Binary.html#S:Sec1123"><i class="fa fa-check"></i><b>11.2.3</b> Interpretación de Utilidad Aleatoria</a></li>
<li class="chapter" data-level="11.2.4" data-path="C11Binary.html"><a href="C11Binary.html#S:Sec1124"><i class="fa fa-check"></i><b>11.2.4</b> Regresión Logística</a></li>
</ul></li>
<li class="chapter" data-level="11.3" data-path="C11Binary.html"><a href="C11Binary.html#S:Sec113"><i class="fa fa-check"></i><b>11.3</b> Inferencia para Modelos de Regresión Logística y Probit</a>
<ul>
<li class="chapter" data-level="11.3.1" data-path="C11Binary.html"><a href="C11Binary.html#estimación-de-parámetros"><i class="fa fa-check"></i><b>11.3.1</b> Estimación de Parámetros</a></li>
<li class="chapter" data-level="11.3.2" data-path="C11Binary.html"><a href="C11Binary.html#inferencia-adicional"><i class="fa fa-check"></i><b>11.3.2</b> Inferencia Adicional</a></li>
</ul></li>
<li class="chapter" data-level="11.4" data-path="C11Binary.html"><a href="C11Binary.html#S:Sec114"><i class="fa fa-check"></i><b>11.4</b> Aplicación: Gastos Médicos</a></li>
<li class="chapter" data-level="11.5" data-path="C11Binary.html"><a href="C11Binary.html#S:Sec115"><i class="fa fa-check"></i><b>11.5</b> Variables Dependientes Nominales</a>
<ul>
<li class="chapter" data-level="11.5.1" data-path="C11Binary.html"><a href="C11Binary.html#S:Sec1151"><i class="fa fa-check"></i><b>11.5.1</b> Logit Generalizado</a></li>
<li class="chapter" data-level="11.5.2" data-path="C11Binary.html"><a href="C11Binary.html#S:Sec1152"><i class="fa fa-check"></i><b>11.5.2</b> Logit Multinomial</a></li>
<li class="chapter" data-level="11.5.3" data-path="C11Binary.html"><a href="C11Binary.html#S:Sec1153"><i class="fa fa-check"></i><b>11.5.3</b> Logit Anidado</a></li>
</ul></li>
<li class="chapter" data-level="11.6" data-path="C11Binary.html"><a href="C11Binary.html#S:Sec116"><i class="fa fa-check"></i><b>11.6</b> Variables Dependientes Ordinales</a>
<ul>
<li class="chapter" data-level="11.6.1" data-path="C11Binary.html"><a href="C11Binary.html#logit-acumulativo"><i class="fa fa-check"></i><b>11.6.1</b> Logit Acumulativo</a></li>
<li class="chapter" data-level="11.6.2" data-path="C11Binary.html"><a href="C11Binary.html#probit-acumulativo"><i class="fa fa-check"></i><b>11.6.2</b> Probit Acumulativo</a></li>
</ul></li>
<li class="chapter" data-level="11.7" data-path="C11Binary.html"><a href="C11Binary.html#S:Sec117"><i class="fa fa-check"></i><b>11.7</b> Lecturas Adicionales y Referencias</a></li>
<li class="chapter" data-level="11.8" data-path="C11Binary.html"><a href="C11Binary.html#S:Sec118"><i class="fa fa-check"></i><b>11.8</b> Ejercicios</a></li>
<li class="chapter" data-level="11.9" data-path="C11Binary.html"><a href="C11Binary.html#S:Sec119"><i class="fa fa-check"></i><b>11.9</b> Suplementos Técnicos - Inferencia Basada en Verosimilitud</a>
<ul>
<li class="chapter" data-level="11.9.1" data-path="C11Binary.html"><a href="C11Binary.html#S:Sec1191"><i class="fa fa-check"></i><b>11.9.1</b> Propiedades de las Funciones de Verosimilitud</a></li>
<li class="chapter" data-level="11.9.2" data-path="C11Binary.html"><a href="C11Binary.html#S:Sec1192"><i class="fa fa-check"></i><b>11.9.2</b> Estimadores de Máxima Verosimilitud</a></li>
<li class="chapter" data-level="11.9.3" data-path="C11Binary.html"><a href="C11Binary.html#S:Sec1193"><i class="fa fa-check"></i><b>11.9.3</b> Pruebas de Hipótesis</a></li>
<li class="chapter" data-level="11.9.4" data-path="C11Binary.html"><a href="C11Binary.html#S:Sec1194"><i class="fa fa-check"></i><b>11.9.4</b> Criterios de Información</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="12" data-path="C12Count.html"><a href="C12Count.html"><i class="fa fa-check"></i><b>12</b> Variables Dependientes de Conteo</a>
<ul>
<li class="chapter" data-level="12.1" data-path="C12Count.html"><a href="C12Count.html#S:Sec121"><i class="fa fa-check"></i><b>12.1</b> Regresión de Poisson</a>
<ul>
<li class="chapter" data-level="12.1.1" data-path="C12Count.html"><a href="C12Count.html#S:Sec1211"><i class="fa fa-check"></i><b>12.1.1</b> Distribución de Poisson</a></li>
<li class="chapter" data-level="12.1.2" data-path="C12Count.html"><a href="C12Count.html#S:Sec1212"><i class="fa fa-check"></i><b>12.1.2</b> Modelo de Regresión</a></li>
<li class="chapter" data-level="12.1.3" data-path="C12Count.html"><a href="C12Count.html#S:Sec1213"><i class="fa fa-check"></i><b>12.1.3</b> Estimación</a></li>
<li class="chapter" data-level="12.1.4" data-path="C12Count.html"><a href="C12Count.html#S:Sec1214"><i class="fa fa-check"></i><b>12.1.4</b> Inferencia Adicional</a></li>
</ul></li>
<li class="chapter" data-level="12.2" data-path="C12Count.html"><a href="C12Count.html#S:Sec122"><i class="fa fa-check"></i><b>12.2</b> Aplicación: Seguro de Automóviles en Singapur</a></li>
<li class="chapter" data-level="12.3" data-path="C12Count.html"><a href="C12Count.html#S:Sec123"><i class="fa fa-check"></i><b>12.3</b> Sobre dispersión y Modelos Binomiales Negativos</a></li>
<li class="chapter" data-level="12.4" data-path="C12Count.html"><a href="C12Count.html#S:Sec124"><i class="fa fa-check"></i><b>12.4</b> Otros Modelos de Conteo</a>
<ul>
<li class="chapter" data-level="12.4.1" data-path="C12Count.html"><a href="C12Count.html#modelos-inflados-en-ceros"><i class="fa fa-check"></i><b>12.4.1</b> Modelos Inflados en Ceros</a></li>
<li class="chapter" data-level="12.4.2" data-path="C12Count.html"><a href="C12Count.html#modelos-hurdle"><i class="fa fa-check"></i><b>12.4.2</b> Modelos Hurdle</a></li>
<li class="chapter" data-level="12.4.3" data-path="C12Count.html"><a href="C12Count.html#modelos-de-heterogeneidad"><i class="fa fa-check"></i><b>12.4.3</b> Modelos de Heterogeneidad</a></li>
<li class="chapter" data-level="12.4.4" data-path="C12Count.html"><a href="C12Count.html#modelos-de-clases-latentes"><i class="fa fa-check"></i><b>12.4.4</b> Modelos de Clases Latentes</a></li>
</ul></li>
<li class="chapter" data-level="12.5" data-path="C12Count.html"><a href="C12Count.html#S:Sec125"><i class="fa fa-check"></i><b>12.5</b> Lecturas Adicionales y Referencias</a></li>
<li class="chapter" data-level="12.6" data-path="C12Count.html"><a href="C12Count.html#S:Sec126"><i class="fa fa-check"></i><b>12.6</b> Ejercicios</a></li>
</ul></li>
<li class="chapter" data-level="13" data-path="C13GLM.html"><a href="C13GLM.html"><i class="fa fa-check"></i><b>13</b> Modelos Lineales Generalizados</a>
<ul>
<li class="chapter" data-level="13.1" data-path="C13GLM.html"><a href="C13GLM.html#S:Sec131"><i class="fa fa-check"></i><b>13.1</b> Introducción</a></li>
<li class="chapter" data-level="13.2" data-path="C13GLM.html"><a href="C13GLM.html#S:Sec132"><i class="fa fa-check"></i><b>13.2</b> Modelo GLM</a>
<ul>
<li class="chapter" data-level="13.2.1" data-path="C13GLM.html"><a href="C13GLM.html#S:Sec1321"><i class="fa fa-check"></i><b>13.2.1</b> Familia Exponencial Lineal de Distribuciones</a></li>
<li class="chapter" data-level="13.2.2" data-path="C13GLM.html"><a href="C13GLM.html#S:Sec1322"><i class="fa fa-check"></i><b>13.2.2</b> Funciones de Enlace</a></li>
</ul></li>
<li class="chapter" data-level="13.3" data-path="C13GLM.html"><a href="C13GLM.html#S:Sec133"><i class="fa fa-check"></i><b>13.3</b> Estimación</a>
<ul>
<li class="chapter" data-level="13.3.1" data-path="C13GLM.html"><a href="C13GLM.html#S:Sec1331"><i class="fa fa-check"></i><b>13.3.1</b> Estimación de Máxima Verosimilitud para Enlaces Canónicos</a></li>
<li class="chapter" data-level="13.3.2" data-path="C13GLM.html"><a href="C13GLM.html#sobredispersión"><i class="fa fa-check"></i><b>13.3.2</b> Sobredispersión</a></li>
<li class="chapter" data-level="13.3.3" data-path="C13GLM.html"><a href="C13GLM.html#S:Sec1333"><i class="fa fa-check"></i><b>13.3.3</b> Estadísticas de Bondad de Ajuste</a></li>
</ul></li>
<li class="chapter" data-level="13.4" data-path="C13GLM.html"><a href="C13GLM.html#S:Sec134"><i class="fa fa-check"></i><b>13.4</b> Aplicación: Gastos Médicos</a></li>
<li class="chapter" data-level="13.5" data-path="C13GLM.html"><a href="C13GLM.html#S:Sec135"><i class="fa fa-check"></i><b>13.5</b> Residuales</a></li>
<li class="chapter" data-level="13.6" data-path="C13GLM.html"><a href="C13GLM.html#S:Sec136"><i class="fa fa-check"></i><b>13.6</b> Distribución de Tweedie</a></li>
<li class="chapter" data-level="13.7" data-path="C13GLM.html"><a href="C13GLM.html#S:Sec137"><i class="fa fa-check"></i><b>13.7</b> Lecturas adicionales y referencias</a></li>
<li class="chapter" data-level="13.8" data-path="C13GLM.html"><a href="C13GLM.html#S:Sec138"><i class="fa fa-check"></i><b>13.8</b> Ejercicios</a></li>
<li class="chapter" data-level="13.9" data-path="C13GLM.html"><a href="C13GLM.html#S:Sec139"><i class="fa fa-check"></i><b>13.9</b> Suplementos Técnicos - Familia Exponencial</a>
<ul>
<li class="chapter" data-level="13.9.1" data-path="C13GLM.html"><a href="C13GLM.html#S:Sec1391"><i class="fa fa-check"></i><b>13.9.1</b> Familia Exponencial Lineal de Distribuciones</a></li>
<li class="chapter" data-level="13.9.2" data-path="C13GLM.html"><a href="C13GLM.html#S:Sec1392"><i class="fa fa-check"></i><b>13.9.2</b> Momentos</a></li>
<li class="chapter" data-level="13.9.3" data-path="C13GLM.html"><a href="C13GLM.html#S:Sec1393"><i class="fa fa-check"></i><b>13.9.3</b> Estimación de Máxima Verosimilitud para Enlaces Generales</a></li>
<li class="chapter" data-level="13.9.4" data-path="C13GLM.html"><a href="C13GLM.html#S:Sec1394"><i class="fa fa-check"></i><b>13.9.4</b> Mínimos Cuadrados Reponderados Iterativos</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="14" data-path="C14Survival.html"><a href="C14Survival.html"><i class="fa fa-check"></i><b>14</b> Modelos de Supervivencia</a>
<ul>
<li class="chapter" data-level="14.1" data-path="C14Survival.html"><a href="C14Survival.html#introducción-2"><i class="fa fa-check"></i><b>14.1</b> Introducción</a></li>
<li class="chapter" data-level="14.2" data-path="C14Survival.html"><a href="C14Survival.html#S:Sec142"><i class="fa fa-check"></i><b>14.2</b> Censura y Truncamiento</a>
<ul>
<li class="chapter" data-level="14.2.1" data-path="C14Survival.html"><a href="C14Survival.html#definiciones-y-ejemplos"><i class="fa fa-check"></i><b>14.2.1</b> Definiciones y Ejemplos</a></li>
<li class="chapter" data-level="14.2.2" data-path="C14Survival.html"><a href="C14Survival.html#inferencia-por-verosimilitud"><i class="fa fa-check"></i><b>14.2.2</b> Inferencia por Verosimilitud</a></li>
<li class="chapter" data-level="14.2.3" data-path="C14Survival.html"><a href="C14Survival.html#estimador-producto-límite"><i class="fa fa-check"></i><b>14.2.3</b> Estimador Producto-Límite</a></li>
</ul></li>
<li class="chapter" data-level="14.3" data-path="C14Survival.html"><a href="C14Survival.html#S:Sec143"><i class="fa fa-check"></i><b>14.3</b> Modelo de Tiempo de Fallo Acelerado</a></li>
<li class="chapter" data-level="14.4" data-path="C14Survival.html"><a href="C14Survival.html#S:Sec144"><i class="fa fa-check"></i><b>14.4</b> Modelo de Riesgos Proporcionales</a>
<ul>
<li class="chapter" data-level="14.4.1" data-path="C14Survival.html"><a href="C14Survival.html#S:Sec1441"><i class="fa fa-check"></i><b>14.4.1</b> Riesgos Proporcionales</a></li>
<li class="chapter" data-level="14.4.2" data-path="C14Survival.html"><a href="C14Survival.html#S:Sec1442"><i class="fa fa-check"></i><b>14.4.2</b> Inferencia</a></li>
</ul></li>
<li class="chapter" data-level="14.5" data-path="C14Survival.html"><a href="C14Survival.html#S:Sec145"><i class="fa fa-check"></i><b>14.5</b> Eventos Recurrentes</a></li>
<li class="chapter" data-level="14.6" data-path="C14Survival.html"><a href="C14Survival.html#S:Sec146"><i class="fa fa-check"></i><b>14.6</b> Lecturas Adicionales y Referencias</a></li>
</ul></li>
<li class="chapter" data-level="15" data-path="C15Misc.html"><a href="C15Misc.html"><i class="fa fa-check"></i><b>15</b> Temas Misceláneos de Regresión</a>
<ul>
<li class="chapter" data-level="15.1" data-path="C15Misc.html"><a href="C15Misc.html#S:Sec151"><i class="fa fa-check"></i><b>15.1</b> Modelos Lineales Mixtos</a>
<ul>
<li class="chapter" data-level="15.1.1" data-path="C15Misc.html"><a href="C15Misc.html#mínimos-cuadrados-ponderados-2"><i class="fa fa-check"></i><b>15.1.1</b> Mínimos Cuadrados Ponderados</a></li>
<li class="chapter" data-level="15.1.2" data-path="C15Misc.html"><a href="C15Misc.html#S:Sec1512"><i class="fa fa-check"></i><b>15.1.2</b> Estimación de Componentes de Varianza</a></li>
<li class="chapter" data-level="15.1.3" data-path="C15Misc.html"><a href="C15Misc.html#mejor-predicción-lineal-insesgada"><i class="fa fa-check"></i><b>15.1.3</b> Mejor Predicción Lineal Insesgada</a></li>
</ul></li>
<li class="chapter" data-level="15.2" data-path="C15Misc.html"><a href="C15Misc.html#regresión-bayesiana"><i class="fa fa-check"></i><b>15.2</b> Regresión Bayesiana</a></li>
<li class="chapter" data-level="15.3" data-path="C15Misc.html"><a href="C15Misc.html#S:Sec153"><i class="fa fa-check"></i><b>15.3</b> Estimación de Densidad y Suavizado de Diagramas de Dispersión</a></li>
<li class="chapter" data-level="15.4" data-path="C15Misc.html"><a href="C15Misc.html#S:Sec154"><i class="fa fa-check"></i><b>15.4</b> Modelos Aditivos Generalizados</a></li>
<li class="chapter" data-level="15.5" data-path="C15Misc.html"><a href="C15Misc.html#bootstrapping"><i class="fa fa-check"></i><b>15.5</b> Bootstrapping</a></li>
<li class="chapter" data-level="15.6" data-path="C15Misc.html"><a href="C15Misc.html#lecturas-adicionales-y-referencias-2"><i class="fa fa-check"></i><b>15.6</b> Lecturas Adicionales y Referencias</a></li>
</ul></li>
<li class="chapter" data-level="16" data-path="C16FreqSev.html"><a href="C16FreqSev.html"><i class="fa fa-check"></i><b>16</b> Modelos de Frecuencia-Severidad</a>
<ul>
<li class="chapter" data-level="16.1" data-path="C16FreqSev.html"><a href="C16FreqSev.html#S:Sec161"><i class="fa fa-check"></i><b>16.1</b> Introducción</a></li>
<li class="chapter" data-level="16.2" data-path="C16FreqSev.html"><a href="C16FreqSev.html#S:Sec162"><i class="fa fa-check"></i><b>16.2</b> Modelo Tobit</a></li>
<li class="chapter" data-level="16.3" data-path="C16FreqSev.html"><a href="C16FreqSev.html#S:Sec163"><i class="fa fa-check"></i><b>16.3</b> Aplicación: Gastos Médicos</a></li>
<li class="chapter" data-level="16.4" data-path="C16FreqSev.html"><a href="C16FreqSev.html#S:Sec164"><i class="fa fa-check"></i><b>16.4</b> Modelo de Dos Partes</a></li>
<li class="chapter" data-level="16.5" data-path="C16FreqSev.html"><a href="C16FreqSev.html#S:Sec165"><i class="fa fa-check"></i><b>16.5</b> Modelo de Pérdidas Agregadas</a></li>
<li class="chapter" data-level="16.6" data-path="C16FreqSev.html"><a href="C16FreqSev.html#S:Sec166"><i class="fa fa-check"></i><b>16.6</b> Lecturas Adicionales y Referencias</a></li>
<li class="chapter" data-level="16.7" data-path="C16FreqSev.html"><a href="C16FreqSev.html#S:Sec167"><i class="fa fa-check"></i><b>16.7</b> Ejercicios</a></li>
</ul></li>
<li class="chapter" data-level="17" data-path="C17Fat.html"><a href="C17Fat.html"><i class="fa fa-check"></i><b>17</b> Modelos de Regresión con Colas Gruesas</a>
<ul>
<li class="chapter" data-level="17.1" data-path="C17Fat.html"><a href="C17Fat.html#introducción-3"><i class="fa fa-check"></i><b>17.1</b> Introducción</a></li>
<li class="chapter" data-level="17.2" data-path="C17Fat.html"><a href="C17Fat.html#S:Sec172"><i class="fa fa-check"></i><b>17.2</b> Transformaciones</a></li>
<li class="chapter" data-level="17.3" data-path="C17Fat.html"><a href="C17Fat.html#S:Sec173"><i class="fa fa-check"></i><b>17.3</b> Modelos Lineales Generalizados</a>
<ul>
<li class="chapter" data-level="17.3.1" data-path="C17Fat.html"><a href="C17Fat.html#S:Sec1731"><i class="fa fa-check"></i><b>17.3.1</b> ¿Qué significa “Cola Gruesa”?</a></li>
<li class="chapter" data-level="17.3.2" data-path="C17Fat.html"><a href="C17Fat.html#S:Sec1732"><i class="fa fa-check"></i><b>17.3.2</b> Aplicación: Asilos de Ancianos en Wisconsin</a></li>
</ul></li>
<li class="chapter" data-level="17.4" data-path="C17Fat.html"><a href="C17Fat.html#S:Sec174"><i class="fa fa-check"></i><b>17.4</b> Distribuciones Generalizadas</a>
<ul>
<li class="chapter" data-level="" data-path="C17Fat.html"><a href="C17Fat.html#aplicación-hogares-de-ancianos-en-wisconsin"><i class="fa fa-check"></i>Aplicación: Hogares de Ancianos en Wisconsin</a></li>
</ul></li>
<li class="chapter" data-level="17.5" data-path="C17Fat.html"><a href="C17Fat.html#S:Sec175"><i class="fa fa-check"></i><b>17.5</b> Regresión por Cuantiles</a></li>
<li class="chapter" data-level="17.6" data-path="C17Fat.html"><a href="C17Fat.html#S:Sec176"><i class="fa fa-check"></i><b>17.6</b> Modelos de Valores Extremos</a></li>
<li class="chapter" data-level="17.7" data-path="C17Fat.html"><a href="C17Fat.html#lecturas-adicionales-y-referencias-3"><i class="fa fa-check"></i><b>17.7</b> Lecturas Adicionales y Referencias</a></li>
<li class="chapter" data-level="17.8" data-path="C17Fat.html"><a href="C17Fat.html#ejercicios-1"><i class="fa fa-check"></i><b>17.8</b> Ejercicios</a></li>
</ul></li>
<li class="chapter" data-level="18" data-path="C18Cred.html"><a href="C18Cred.html"><i class="fa fa-check"></i><b>18</b> Credibilidad y Bonus-Malus</a>
<ul>
<li class="chapter" data-level="18.1" data-path="C18Cred.html"><a href="C18Cred.html#clasificación-de-riesgos-y-experiencia"><i class="fa fa-check"></i><b>18.1</b> Clasificación de Riesgos y Experiencia</a></li>
<li class="chapter" data-level="18.2" data-path="C18Cred.html"><a href="C18Cred.html#S:Sec182"><i class="fa fa-check"></i><b>18.2</b> Credibilidad</a>
<ul>
<li class="chapter" data-level="18.2.1" data-path="C18Cred.html"><a href="C18Cred.html#S:Sec1821"><i class="fa fa-check"></i><b>18.2.1</b> Credibilidad de Fluctuación Limitada</a></li>
<li class="chapter" data-level="18.2.2" data-path="C18Cred.html"><a href="C18Cred.html#S:Sec1822"><i class="fa fa-check"></i><b>18.2.2</b> Credibilidad de Máxima Precisión</a></li>
</ul></li>
<li class="chapter" data-level="18.3" data-path="C18Cred.html"><a href="C18Cred.html#S:Sec183"><i class="fa fa-check"></i><b>18.3</b> Credibilidad y Regresión</a>
<ul>
<li class="chapter" data-level="18.3.1" data-path="C18Cred.html"><a href="C18Cred.html#modelo-de-efectos-aleatorios-unidireccional"><i class="fa fa-check"></i><b>18.3.1</b> Modelo de Efectos Aleatorios Unidireccional</a></li>
<li class="chapter" data-level="18.3.2" data-path="C18Cred.html"><a href="C18Cred.html#modelos-longitudinales"><i class="fa fa-check"></i><b>18.3.2</b> Modelos Longitudinales</a></li>
</ul></li>
<li class="chapter" data-level="18.4" data-path="C18Cred.html"><a href="C18Cred.html#S:Sec184"><i class="fa fa-check"></i><b>18.4</b> Bonus-Malus</a></li>
</ul></li>
<li class="chapter" data-level="19" data-path="C19Triangles.html"><a href="C19Triangles.html"><i class="fa fa-check"></i><b>19</b> Triángulos de Reclamos</a>
<ul>
<li class="chapter" data-level="19.1" data-path="C19Triangles.html"><a href="C19Triangles.html#introducción-4"><i class="fa fa-check"></i><b>19.1</b> Introducción</a>
<ul>
<li class="chapter" data-level="19.1.1" data-path="C19Triangles.html"><a href="C19Triangles.html#S:Sec1911"><i class="fa fa-check"></i><b>19.1.1</b> Evolución de los Reclamos</a></li>
<li class="chapter" data-level="19.1.2" data-path="C19Triangles.html"><a href="C19Triangles.html#S:Sec1912"><i class="fa fa-check"></i><b>19.1.2</b> Triángulos de Reclamos</a></li>
<li class="chapter" data-level="19.1.3" data-path="C19Triangles.html"><a href="C19Triangles.html#S:Sec1913"><i class="fa fa-check"></i><b>19.1.3</b> Método de Escalera de Cadenas</a></li>
</ul></li>
<li class="chapter" data-level="19.2" data-path="C19Triangles.html"><a href="C19Triangles.html#S:Sec192"><i class="fa fa-check"></i><b>19.2</b> Regresión Usando Funciones del Tiempo como Variables Explicativas</a>
<ul>
<li class="chapter" data-level="19.2.1" data-path="C19Triangles.html"><a href="C19Triangles.html#S:Sec1921"><i class="fa fa-check"></i><b>19.2.1</b> Modelo Lognormal</a></li>
<li class="chapter" data-level="19.2.2" data-path="C19Triangles.html"><a href="C19Triangles.html#S:Sec1922"><i class="fa fa-check"></i><b>19.2.2</b> Curva de Hoerl</a></li>
<li class="chapter" data-level="19.2.3" data-path="C19Triangles.html"><a href="C19Triangles.html#S:Sec1923"><i class="fa fa-check"></i><b>19.2.3</b> Modelos de Poisson</a></li>
</ul></li>
<li class="chapter" data-level="19.3" data-path="C19Triangles.html"><a href="C19Triangles.html#S:Sec193"><i class="fa fa-check"></i><b>19.3</b> Usando Desarrollos Pasados</a>
<ul>
<li class="chapter" data-level="19.3.1" data-path="C19Triangles.html"><a href="C19Triangles.html#S:Sec1931"><i class="fa fa-check"></i><b>19.3.1</b> Modelo de Mack</a></li>
<li class="chapter" data-level="19.3.2" data-path="C19Triangles.html"><a href="C19Triangles.html#S:Sec1932"><i class="fa fa-check"></i><b>19.3.2</b> Modelos Distribucionales</a></li>
</ul></li>
<li class="chapter" data-level="19.4" data-path="C19Triangles.html"><a href="C19Triangles.html#lecturas-adicionales-y-referencias-4"><i class="fa fa-check"></i><b>19.4</b> Lecturas Adicionales y Referencias</a></li>
<li class="chapter" data-level="19.5" data-path="C19Triangles.html"><a href="C19Triangles.html#ejercicios-2"><i class="fa fa-check"></i><b>19.5</b> Ejercicios</a></li>
</ul></li>
<li class="chapter" data-level="20" data-path="C20Report.html"><a href="C20Report.html"><i class="fa fa-check"></i><b>20</b> Redacción de Informes: Comunicando Resultados del Análisis de Datos</a>
<ul>
<li class="chapter" data-level="20.1" data-path="C20Report.html"><a href="C20Report.html#S20:Overview"><i class="fa fa-check"></i><b>20.1</b> Visión General</a></li>
<li class="chapter" data-level="20.2" data-path="C20Report.html"><a href="C20Report.html#S20:Methods"><i class="fa fa-check"></i><b>20.2</b> Métodos para Comunicar Datos</a>
<ul>
<li class="chapter" data-level="" data-path="C20Report.html"><a href="C20Report.html#datos-dentro-del-texto"><i class="fa fa-check"></i>Datos Dentro del Texto</a></li>
<li class="chapter" data-level="" data-path="C20Report.html"><a href="C20Report.html#gráficos"><i class="fa fa-check"></i>Gráficos</a></li>
</ul></li>
<li class="chapter" data-level="20.3" data-path="C20Report.html"><a href="C20Report.html#S20:Organize"><i class="fa fa-check"></i><b>20.3</b> Cómo Organizar</a>
<ul>
<li class="chapter" data-level="" data-path="C20Report.html"><a href="C20Report.html#título-y-resumen"><i class="fa fa-check"></i>Título y Resumen</a></li>
<li class="chapter" data-level="" data-path="C20Report.html"><a href="C20Report.html#introducción-5"><i class="fa fa-check"></i>Introducción</a></li>
<li class="chapter" data-level="" data-path="C20Report.html"><a href="C20Report.html#selección-e-interpretación-del-modelo"><i class="fa fa-check"></i>Selección e Interpretación del Modelo</a></li>
<li class="chapter" data-level="" data-path="C20Report.html"><a href="C20Report.html#referencias-y-apéndice"><i class="fa fa-check"></i>Referencias y Apéndice</a></li>
</ul></li>
<li class="chapter" data-level="20.4" data-path="C20Report.html"><a href="C20Report.html#sugerencias-adicionales-para-la-redacción-de-informes"><i class="fa fa-check"></i><b>20.4</b> Sugerencias Adicionales para la Redacción de Informes</a></li>
<li class="chapter" data-level="20.5" data-path="C20Report.html"><a href="C20Report.html#estudio-de-caso-reclamos-de-automóviles-en-suecia"><i class="fa fa-check"></i><b>20.5</b> Estudio de Caso: Reclamos de Automóviles en Suecia</a></li>
<li class="chapter" data-level="20.6" data-path="C20Report.html"><a href="C20Report.html#ejercicios-3"><i class="fa fa-check"></i><b>20.6</b> Ejercicios</a></li>
</ul></li>
<li class="chapter" data-level="21" data-path="C21Design.html"><a href="C21Design.html"><i class="fa fa-check"></i><b>21</b> Designing Effective Graphs</a>
<ul>
<li class="chapter" data-level="21.1" data-path="C21Design.html"><a href="C21Design.html#S21:Intro"><i class="fa fa-check"></i><b>21.1</b> Introduction</a></li>
<li class="chapter" data-level="21.2" data-path="C21Design.html"><a href="C21Design.html#S21:GDesign"><i class="fa fa-check"></i><b>21.2</b> Graphic Design Choices Make a Difference</a></li>
<li class="chapter" data-level="21.3" data-path="C21Design.html"><a href="C21Design.html#S21:DesignGuide"><i class="fa fa-check"></i><b>21.3</b> Design Guidelines</a>
<ul>
<li class="chapter" data-level="" data-path="C21Design.html"><a href="C21Design.html#guideline-one-avoid-chartjunk"><i class="fa fa-check"></i>Guideline One: Avoid Chartjunk</a></li>
<li class="chapter" data-level="" data-path="C21Design.html"><a href="C21Design.html#guideline-two-use-small-multiples-to-promote-comparisons-and-assess-change"><i class="fa fa-check"></i>Guideline Two: Use Small Multiples to Promote Comparisons and Assess Change</a></li>
<li class="chapter" data-level="" data-path="C21Design.html"><a href="C21Design.html#guideline-three-use-complex-graphs-to-portray-complex-patterns"><i class="fa fa-check"></i>Guideline Three: Use Complex Graphs to Portray Complex Patterns</a></li>
<li class="chapter" data-level="" data-path="C21Design.html"><a href="C21Design.html#guideline-four-relate-graph-size-to-information-content"><i class="fa fa-check"></i>Guideline Four: Relate Graph Size to Information Content</a></li>
<li class="chapter" data-level="" data-path="C21Design.html"><a href="C21Design.html#guideline-five-use-graphical-forms-that-promote-comparisons"><i class="fa fa-check"></i>Guideline Five: Use Graphical Forms That Promote Comparisons</a></li>
<li class="chapter" data-level="" data-path="C21Design.html"><a href="C21Design.html#guideline-six-integrate-graphs-and-text"><i class="fa fa-check"></i>Guideline Six: Integrate Graphs and Text</a></li>
<li class="chapter" data-level="" data-path="C21Design.html"><a href="C21Design.html#guideline-seven-demonstrate-an-important-message"><i class="fa fa-check"></i>Guideline Seven: Demonstrate an Important Message</a></li>
<li class="chapter" data-level="" data-path="C21Design.html"><a href="C21Design.html#guideline-eight-know-your-audience"><i class="fa fa-check"></i>Guideline Eight: Know Your Audience</a></li>
</ul></li>
<li class="chapter" data-level="21.4" data-path="C21Design.html"><a href="C21Design.html#S21:EmpiricalFoundations"><i class="fa fa-check"></i><b>21.4</b> Empirical Foundations For Guidelines</a>
<ul>
<li class="chapter" data-level="21.4.1" data-path="C21Design.html"><a href="C21Design.html#graphs-as-units-of-study"><i class="fa fa-check"></i><b>21.4.1</b> Graphs as Units of Study</a></li>
</ul></li>
<li class="chapter" data-level="21.5" data-path="C21Design.html"><a href="C21Design.html#S21:Conclude"><i class="fa fa-check"></i><b>21.5</b> Concluding Remarks</a></li>
<li class="chapter" data-level="21.6" data-path="C21Design.html"><a href="C21Design.html#S21:References"><i class="fa fa-check"></i><b>21.6</b> Further Reading and References</a></li>
</ul></li>
<li class="chapter" data-level="22" data-path="apéndices.html"><a href="apéndices.html"><i class="fa fa-check"></i><b>22</b> Apéndices</a>
<ul>
<li class="chapter" data-level="" data-path="apéndices.html"><a href="apéndices.html#apéndice-a1.-inferencia-estadística-básica"><i class="fa fa-check"></i>Apéndice A1. Inferencia Estadística Básica</a>
<ul>
<li class="chapter" data-level="" data-path="apéndices.html"><a href="apéndices.html#distribuciones-de-funciones-de-variables-aleatorias"><i class="fa fa-check"></i>Distribuciones de Funciones de Variables Aleatorias</a></li>
<li class="chapter" data-level="" data-path="apéndices.html"><a href="apéndices.html#estimación-y-predicción"><i class="fa fa-check"></i>Estimación y Predicción</a></li>
<li class="chapter" data-level="" data-path="apéndices.html"><a href="apéndices.html#pruebas-de-hipótesis"><i class="fa fa-check"></i>Pruebas de Hipótesis</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="apéndices.html"><a href="apéndices.html#apéndice-a2.-álgebra-de-matrices"><i class="fa fa-check"></i>Apéndice A2. Álgebra de Matrices</a>
<ul>
<li class="chapter" data-level="" data-path="apéndices.html"><a href="apéndices.html#definiciones-básicas"><i class="fa fa-check"></i>Definiciones Básicas</a></li>
<li class="chapter" data-level="" data-path="apéndices.html"><a href="apéndices.html#revisión-de-operaciones-básicas"><i class="fa fa-check"></i>Revisión de Operaciones Básicas</a></li>
<li class="chapter" data-level="" data-path="apéndices.html"><a href="apéndices.html#definiciones-adicionales"><i class="fa fa-check"></i>Definiciones Adicionales</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="apéndices.html"><a href="apéndices.html#apéndice-a3.-tablas-de-probabilidad"><i class="fa fa-check"></i>Apéndice A3. Tablas de Probabilidad</a>
<ul>
<li class="chapter" data-level="" data-path="apéndices.html"><a href="apéndices.html#distribución-normal"><i class="fa fa-check"></i>Distribución Normal</a></li>
<li class="chapter" data-level="" data-path="apéndices.html"><a href="apéndices.html#distribución-chi-cuadrado"><i class="fa fa-check"></i>Distribución Chi-Cuadrado</a></li>
<li class="chapter" data-level="" data-path="apéndices.html"><a href="apéndices.html#distribución-t"><i class="fa fa-check"></i>Distribución <em>t</em></a></li>
<li class="chapter" data-level="" data-path="apéndices.html"><a href="apéndices.html#distribución-f"><i class="fa fa-check"></i>Distribución <em>F</em></a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="" data-path="brief-answers-to-selected-exercises.html"><a href="brief-answers-to-selected-exercises.html"><i class="fa fa-check"></i>Brief Answers to Selected Exercises</a></li>
<li class="divider"></li>
<li><a href="https://github.com/OpenActTextDev/RegressionSpanish/" target="blank">Regresión en Español en GitHub</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Modelado de Regresión con Aplicaciones Actuariales y Financieras</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="C2BasicLR" class="section level1 hasAnchor" number="2">
<h1><span class="header-section-number">Capítulo 2</span> Regresión Lineal Básica<a href="C2BasicLR.html#C2BasicLR" class="anchor-section" aria-label="Anchor link to header"></a></h1>
<p><em>Vista previa del capítulo</em>. Este capítulo considera la regresión en el caso de tener solo una variable explicativa. A pesar de esta aparente simplicidad, la mayoría de las ideas profundas de la regresión pueden desarrollarse en este marco. Al limitarnos al caso de una variable, podemos expresar muchos cálculos usando álgebra simple. Esto nos permitirá desarrollar nuestra intuición sobre las técnicas de regresión al reforzarla con demostraciones simples. Además, podemos ilustrar las relaciones entre dos variables gráficamente porque estamos trabajando en solo dos dimensiones. Las herramientas gráficas resultan ser importantes para desarrollar un vínculo entre los datos y un modelo.</p>
<div id="Sec21" class="section level2 hasAnchor" number="2.1">
<h2><span class="header-section-number">2.1</span> Correlaciones y Mínimos Cuadrados<a href="C2BasicLR.html#Sec21" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>La regresión trata sobre relaciones. Específicamente, estudiaremos cómo dos variables, una <span class="math inline">\(x\)</span> y una <span class="math inline">\(y\)</span>, están relacionadas. Queremos poder responder preguntas como, si cambiamos el nivel de <span class="math inline">\(x\)</span>, ¿qué pasará con el nivel de <span class="math inline">\(y\)</span>? Si comparamos dos “sujetos” que parecen similares excepto por la medición de <span class="math inline">\(x\)</span>, ¿cómo diferirán sus mediciones de <span class="math inline">\(y\)</span>? Entender las relaciones entre variables es fundamental para la gestión cuantitativa, particularmente en ciencias actuariales donde la incertidumbre es tan prevalente.</p>
<p>Es útil trabajar con un ejemplo específico para familiarizarnos con conceptos clave. El análisis de ventas de lotería no ha sido parte de la práctica actuarial tradicional, pero es un área de crecimiento en la que los actuarios podrían contribuir.</p>
<hr />
<p><strong>Ejemplo: Ventas de la Lotería de Wisconsin.</strong> Los administradores de la lotería del estado de Wisconsin están interesados en evaluar los factores que afectan las ventas de lotería. Las ventas consisten en boletos de lotería en línea que se venden en establecimientos minoristas seleccionados en Wisconsin. Estos boletos generalmente tienen un precio de $1.00, por lo que el número de boletos vendidos equivale a los ingresos de la lotería. Analizamos las ventas promedio de lotería (SALES) durante un período de cuarenta semanas, de abril de 1998 a enero de 1999, en cincuenta áreas seleccionadas al azar identificadas por código postal (ZIP) dentro del estado de Wisconsin.</p>
<p>Aunque muchas variables económicas y demográficas podrían influir en las ventas, nuestro primer análisis se centra en la población (POP) como un determinante clave. El Capítulo 3 mostrará cómo considerar variables explicativas adicionales. Intuitivamente, parece claro que las áreas geográficas con más personas tendrán mayores ventas. Entonces, otras cosas siendo iguales, un <span class="math inline">\(x=POP\)</span> más grande significa un <span class="math inline">\(y=SALES\)</span> más grande. Sin embargo, la lotería es una fuente importante de ingresos para el estado y queremos ser lo más precisos posible.</p>
<p>Una notación adicional será útil posteriormente. En esta muestra, hay cincuenta áreas geográficas y usamos subíndices para identificar cada área. Por ejemplo, <span class="math inline">\(y_1\)</span> = 1,285.4 representa las ventas para la primera área en la muestra que tiene una población de <span class="math inline">\(x_1\)</span> = 435. Llamamos al par ordenado (<span class="math inline">\(x_1\)</span>, <span class="math inline">\(y_1\)</span>) = (435, 1285.4) la primera <em>observación</em>. Extendiendo esta notación, la muestra completa que contiene cincuenta observaciones puede representarse por (<span class="math inline">\(x_1\)</span>, <span class="math inline">\(y_1\)</span>), …, (<span class="math inline">\(x_{50}\)</span>, <span class="math inline">\(y_{50}\)</span>). Los puntos suspensivos ( … ) significan que el patrón continúa hasta que se encuentra el último objeto. A menudo hablaremos de un miembro genérico de la muestra, refiriéndonos a (<span class="math inline">\(x_i\)</span>, <span class="math inline">\(y_i\)</span>) como la <span class="math inline">\(i\)</span>-ésima observación.</p>
<p>Los conjuntos de datos pueden complicarse, por lo que será útil si comienza trabajando con cada variable por separado. Los dos paneles en la Figura <a href="C2BasicLR.html#fig:Fig21">2.1</a> muestran histogramas que dan una impresión visual rápida de la distribución de cada variable de forma aislada. La Tabla <a href="C2BasicLR.html#tab:Tab21">2.1</a> proporciona resúmenes numéricos correspondientes. Para ilustrar, para la variable población (POP), vemos que el área con el menor número contenía 280 personas, mientras que la más grande contenía 39,098. El promedio, sobre 50 códigos postales, fue de 9,311.04. Para nuestra segunda variable, las ventas fueron tan bajas como 189 y tan altas como 33,181.</p>

<div class="figure" style="text-align: center"><span style="display:block;" id="fig:Fig21"></span>
<img src="RegressionMarkdown_files/figure-html/Fig21-1.png" alt="Histogramas de Población y Ventas. Cada distribución está sesgada a la derecha, lo que indica que hay muchas áreas pequeñas en comparación con unas pocas áreas con mayores ventas y poblaciones." width="60%" />
<p class="caption">
Figura 2.1: <strong>Histogramas de Población y Ventas.</strong> Cada distribución está sesgada a la derecha, lo que indica que hay muchas áreas pequeñas en comparación con unas pocas áreas con mayores ventas y poblaciones.
</p>
</div>
<table class=" lightable-classic table table-striped table-condensed" style="font-size: 12px; font-family: Cambria; width: auto !important; margin-left: auto; margin-right: auto; margin-left: auto; margin-right: auto;border-bottom: 0;">
<caption style="font-size: initial !important;">
<span id="tab:Tab21">Tabla 2.1: </span><strong>Estadísticas Resumen de Cada Variable</strong>
</caption>
<thead>
<tr>
<th style="text-align:left;">
</th>
<th style="text-align:right;">
Promedio
</th>
<th style="text-align:right;">
Mediana
</th>
<th style="text-align:right;">
Desviación Estándar
</th>
<th style="text-align:right;">
Mínimo
</th>
<th style="text-align:right;">
Máximo
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;width: 2.5cm; border-right:1px solid;">
POP
</td>
<td style="text-align:right;width: 1.6cm; ">
9,311
</td>
<td style="text-align:right;width: 1.6cm; ">
4,406
</td>
<td style="text-align:right;width: 1.6cm; ">
11,098
</td>
<td style="text-align:right;width: 1.6cm; ">
280
</td>
<td style="text-align:right;width: 1.6cm; ">
39,098
</td>
</tr>
<tr>
<td style="text-align:left;width: 2.5cm; border-right:1px solid;">
SALES
</td>
<td style="text-align:right;width: 1.6cm; ">
6,495
</td>
<td style="text-align:right;width: 1.6cm; ">
2,426
</td>
<td style="text-align:right;width: 1.6cm; ">
8,103
</td>
<td style="text-align:right;width: 1.6cm; ">
189
</td>
<td style="text-align:right;width: 1.6cm; ">
33,181
</td>
</tr>
</tbody>
<tfoot>
<tr>
<td style="padding: 0; " colspan="100%">
<span style="font-style: italic;">Fuente:</span> <sup></sup> Frees y Miller (2003)
</td>
</tr>
</tfoot>
</table>
<h5 style="text-align: center;">
<a id="displayCode.Fig21.Hide" href="javascript:togglecode('toggleCode.Fig21.Hide','displayCode.Fig21.Hide');"><i><strong>Código R para producir la Figura 2.1 y la Tabla 2.1</strong></i></a>
</h5>
<div id="toggleCode.Fig21.Hide" style="display: none">
<div class="sourceCode" id="cb7"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb7-1"><a href="C2BasicLR.html#cb7-1" tabindex="-1"></a>Lot <span class="ot">&lt;-</span> <span class="fu">read.csv</span>(<span class="st">&quot;CSVData/WiscLottery.csv&quot;</span>, <span class="at">header=</span><span class="cn">TRUE</span>)</span>
<span id="cb7-2"><a href="C2BasicLR.html#cb7-2" tabindex="-1"></a><span class="co">#  FIGURA 2.1</span></span>
<span id="cb7-3"><a href="C2BasicLR.html#cb7-3" tabindex="-1"></a><span class="fu">par</span>(<span class="at">mfrow=</span><span class="fu">c</span>(<span class="dv">1</span>, <span class="dv">2</span>), <span class="at">cex=</span><span class="fl">1.3</span>, <span class="at">mar=</span><span class="fu">c</span>(<span class="fl">4.1</span>,<span class="fl">3.1</span>,<span class="fl">1.2</span>,<span class="dv">1</span>))</span>
<span id="cb7-4"><a href="C2BasicLR.html#cb7-4" tabindex="-1"></a><span class="fu">hist</span>(Lot<span class="sc">$</span>POP, <span class="at">main=</span><span class="st">&quot;&quot;</span>, <span class="at">ylab=</span><span class="st">&quot;&quot;</span>, <span class="at">las=</span><span class="dv">1</span>, <span class="at">xlab =</span> <span class="st">&quot;POP&quot;</span>)</span>
<span id="cb7-5"><a href="C2BasicLR.html#cb7-5" tabindex="-1"></a><span class="fu">mtext</span>(<span class="st">&quot;Frecuencia&quot;</span>, <span class="at">side=</span><span class="dv">2</span>, <span class="at">at=</span><span class="dv">30</span>, <span class="at">las=</span><span class="dv">1</span>, <span class="at">cex=</span><span class="fl">1.3</span>, <span class="at">adj=</span>.<span class="dv">6</span>)</span>
<span id="cb7-6"><a href="C2BasicLR.html#cb7-6" tabindex="-1"></a><span class="fu">hist</span>(Lot<span class="sc">$</span>SALES, <span class="at">main=</span><span class="st">&quot;&quot;</span>, <span class="at">ylab=</span><span class="st">&quot;&quot;</span>, <span class="at">las=</span><span class="dv">1</span>, <span class="at">xlab =</span> <span class="st">&quot;SALES&quot;</span>)</span>
<span id="cb7-7"><a href="C2BasicLR.html#cb7-7" tabindex="-1"></a><span class="fu">mtext</span>(<span class="st">&quot;Frecuencia&quot;</span>, <span class="at">side=</span><span class="dv">2</span>, <span class="at">at=</span><span class="dv">34</span>, <span class="at">las=</span><span class="dv">1</span>, <span class="at">cex=</span><span class="fl">1.3</span>, <span class="at">adj=</span>.<span class="dv">6</span>)</span></code></pre></div>
<div class="sourceCode" id="cb8"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb8-1"><a href="C2BasicLR.html#cb8-1" tabindex="-1"></a><span class="co">#  TABLA 2.1 ESTADÍSTICAS RESUMEN</span></span>
<span id="cb8-2"><a href="C2BasicLR.html#cb8-2" tabindex="-1"></a>BookSummStats <span class="ot">&lt;-</span> <span class="cf">function</span>(Xymat){</span>
<span id="cb8-3"><a href="C2BasicLR.html#cb8-3" tabindex="-1"></a>meanSummary <span class="ot">&lt;-</span> <span class="fu">sapply</span>(Xymat, mean,  <span class="at">na.rm=</span><span class="cn">TRUE</span>) </span>
<span id="cb8-4"><a href="C2BasicLR.html#cb8-4" tabindex="-1"></a>sdSummary   <span class="ot">&lt;-</span> <span class="fu">sapply</span>(Xymat, sd,    <span class="at">na.rm=</span><span class="cn">TRUE</span>) </span>
<span id="cb8-5"><a href="C2BasicLR.html#cb8-5" tabindex="-1"></a>minSummary  <span class="ot">&lt;-</span> <span class="fu">sapply</span>(Xymat, min,   <span class="at">na.rm=</span><span class="cn">TRUE</span>) </span>
<span id="cb8-6"><a href="C2BasicLR.html#cb8-6" tabindex="-1"></a>maxSummary  <span class="ot">&lt;-</span> <span class="fu">sapply</span>(Xymat, max,   <span class="at">na.rm=</span><span class="cn">TRUE</span>) </span>
<span id="cb8-7"><a href="C2BasicLR.html#cb8-7" tabindex="-1"></a>medSummary  <span class="ot">&lt;-</span> <span class="fu">sapply</span>(Xymat, median,<span class="at">na.rm=</span><span class="cn">TRUE</span>) </span>
<span id="cb8-8"><a href="C2BasicLR.html#cb8-8" tabindex="-1"></a>tableMat  <span class="ot">&lt;-</span> <span class="fu">cbind</span>(meanSummary, medSummary, sdSummary, minSummary, maxSummary)</span>
<span id="cb8-9"><a href="C2BasicLR.html#cb8-9" tabindex="-1"></a><span class="fu">return</span>(tableMat)</span>
<span id="cb8-10"><a href="C2BasicLR.html#cb8-10" tabindex="-1"></a>}</span>
<span id="cb8-11"><a href="C2BasicLR.html#cb8-11" tabindex="-1"></a>Xymat <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(<span class="fu">cbind</span>(Lot<span class="sc">$</span>POP,Lot<span class="sc">$</span>SALES)) </span>
<span id="cb8-12"><a href="C2BasicLR.html#cb8-12" tabindex="-1"></a>tableMat  <span class="ot">&lt;-</span> <span class="fu">BookSummStats</span>(Xymat)</span>
<span id="cb8-13"><a href="C2BasicLR.html#cb8-13" tabindex="-1"></a></span>
<span id="cb8-14"><a href="C2BasicLR.html#cb8-14" tabindex="-1"></a><span class="fu">colnames</span>(tableMat)  <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="st">&quot;Promedio&quot;</span> , <span class="st">&quot;Mediana&quot;</span> , <span class="st">&quot;Desviación Estándar&quot;</span> , </span>
<span id="cb8-15"><a href="C2BasicLR.html#cb8-15" tabindex="-1"></a>                         <span class="st">&quot;Mínimo&quot;</span> , <span class="st">&quot;Máximo&quot;</span>)</span>
<span id="cb8-16"><a href="C2BasicLR.html#cb8-16" tabindex="-1"></a><span class="fu">rownames</span>(tableMat)  <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="st">&quot;POP&quot;</span>, <span class="st">&quot;SALES&quot;</span>)</span>
<span id="cb8-17"><a href="C2BasicLR.html#cb8-17" tabindex="-1"></a>tableMat1 <span class="ot">&lt;-</span> <span class="fu">format</span>(<span class="fu">round</span>(tableMat, <span class="at">digits=</span><span class="dv">0</span>), <span class="at">big.mark =</span> <span class="st">&#39;,&#39;</span>)</span>
<span id="cb8-18"><a href="C2BasicLR.html#cb8-18" tabindex="-1"></a></span>
<span id="cb8-19"><a href="C2BasicLR.html#cb8-19" tabindex="-1"></a><span class="fu">TableGen1</span>(<span class="at">TableData=</span>tableMat1, </span>
<span id="cb8-20"><a href="C2BasicLR.html#cb8-20" tabindex="-1"></a>         <span class="at">TextTitle=</span><span class="st">&#39;Estadísticas Resumen de Cada Variable&#39;</span>, </span>
<span id="cb8-21"><a href="C2BasicLR.html#cb8-21" tabindex="-1"></a>         <span class="at">Align=</span><span class="st">&#39;r&#39;</span>, <span class="at">Digits=</span><span class="dv">0</span>, <span class="at">ColumnSpec=</span><span class="dv">1</span><span class="sc">:</span><span class="dv">5</span>,</span>
<span id="cb8-22"><a href="C2BasicLR.html#cb8-22" tabindex="-1"></a>         <span class="at">ColWidth =</span> ColWidth5) <span class="sc">%&gt;%</span></span>
<span id="cb8-23"><a href="C2BasicLR.html#cb8-23" tabindex="-1"></a>  <span class="fu">footnote</span>(<span class="at">general =</span> <span class="st">&quot;Frees y Miller (2003)&quot;</span>, </span>
<span id="cb8-24"><a href="C2BasicLR.html#cb8-24" tabindex="-1"></a>           <span class="at">general_title =</span> <span class="st">&quot;Fuente:&quot;</span>, </span>
<span id="cb8-25"><a href="C2BasicLR.html#cb8-25" tabindex="-1"></a>           <span class="at">footnote_as_chunk =</span> <span class="cn">TRUE</span>)</span></code></pre></div>
</div>
<p>Como muestra la Tabla <a href="C2BasicLR.html#tab:Tab21">2.1</a>, las estadísticas resumen básicas
dan ideas útiles de la estructura de las características clave de los datos.
Después de entender la información en cada variable de forma aislada,
podemos comenzar a explorar la relación entre las dos variables.</p>
<div id="gráfico-de-dispersión-y-coeficientes-de-correlación---herramientas-básicas-de-resumen" class="section level4 unnumbered hasAnchor">
<h4>Gráfico de Dispersión y Coeficientes de Correlación - Herramientas Básicas de Resumen<a href="C2BasicLR.html#gráfico-de-dispersión-y-coeficientes-de-correlación---herramientas-básicas-de-resumen" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>La herramienta gráfica básica utilizada para investigar la relación
entre dos variables es un <em>gráfico de dispersión</em>, como se muestra en la Figura
<a href="C2BasicLR.html#fig:Fig22">2.2</a>. Aunque podemos perder los valores exactos de las
observaciones al graficar los datos, ganamos una impresión visual de la
relación entre la población y las ventas. En la Figura
<a href="C2BasicLR.html#fig:Fig22">2.2</a> vemos que las áreas con poblaciones más grandes tienden
a comprar más boletos de lotería. ¿Qué tan fuerte es esta relación?
¿Puede el conocimiento de la población del área ayudarnos a anticipar los
ingresos por ventas de lotería? Exploramos estas dos preguntas a continuación.</p>

<div class="figure" style="text-align: center"><span style="display:block;" id="fig:Fig22"></span>
<img src="RegressionMarkdown_files/figure-html/Fig22-1.png" alt="Un gráfico de dispersión de los datos de la lotería. Cada uno de los 50 símbolos de la gráfica corresponde a un código postal en el estudio. Esta figura sugiere que las áreas postales con poblaciones más grandes tienen mayores ingresos de lotería." width="60%" />
<p class="caption">
Figura 2.2: <strong>Un gráfico de dispersión de los datos de la lotería</strong>. Cada uno de los 50 símbolos de la gráfica corresponde a un código postal en el estudio. Esta figura sugiere que las áreas postales con poblaciones más grandes tienen mayores ingresos de lotería.
</p>
</div>
<h5 style="text-align: center;">
<a id="displayCode.Fig22.Hide" href="javascript:togglecode('toggleCode.Fig22.Hide','displayCode.Fig22.Hide');"><i><strong>Código R para Producir la Figura 2.2</strong></i></a>
</h5>
<div id="toggleCode.Fig22.Hide" style="display: none">
<div class="sourceCode" id="cb9"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb9-1"><a href="C2BasicLR.html#cb9-1" tabindex="-1"></a><span class="co">#Lot &lt;- read.csv(&quot;CSVData/WiscLottery.csv&quot;, header=TRUE)</span></span>
<span id="cb9-2"><a href="C2BasicLR.html#cb9-2" tabindex="-1"></a><span class="co">#  FIGURA 2.2, CON CORRELACIONES</span></span>
<span id="cb9-3"><a href="C2BasicLR.html#cb9-3" tabindex="-1"></a><span class="fu">par</span>(<span class="at">mar=</span><span class="fu">c</span>(<span class="fl">4.1</span>,<span class="fl">3.8</span>,<span class="dv">2</span>,<span class="dv">1</span>),<span class="at">cex=</span><span class="fl">1.1</span>)</span>
<span id="cb9-4"><a href="C2BasicLR.html#cb9-4" tabindex="-1"></a><span class="fu">plot</span>(Lot<span class="sc">$</span>POP, Lot<span class="sc">$</span>SALES, <span class="at">ylab=</span><span class="st">&quot;&quot;</span>, <span class="at">las=</span><span class="dv">1</span>, <span class="at">xlab =</span> <span class="st">&quot;POP&quot;</span>)</span>
<span id="cb9-5"><a href="C2BasicLR.html#cb9-5" tabindex="-1"></a><span class="fu">mtext</span>(<span class="st">&quot;SALES&quot;</span>,<span class="at">side=</span><span class="dv">2</span>, <span class="at">at=</span><span class="dv">36000</span>, <span class="at">las=</span><span class="dv">1</span>, <span class="at">cex=</span><span class="fl">1.1</span>)</span></code></pre></div>
</div>
<p>Una forma de resumir la fuerza de la relación entre dos variables es a través de una estadística de <em>correlación</em>.</p>
<div class="blackbox">
<p><em>Definición</em>. El coeficiente de <em>correlación ordinario, o de Pearson</em> se define como
<span class="math display">\[\begin{equation*}
r=\frac{1}{(n-1)s_xs_y}\sum_{i=1}^{n}\left(
x_{i}-\overline{x}\right) \left( y_{i}-\overline{y}\right) .
\end{equation*}\]</span></p>
<p>Aquí, usamos la desviación estándar de la muestra <span class="math inline">\(s_y = \sqrt{(n-1)^{-1} \sum_{i=1}^{n}\left( y_i - \overline{y}\right)^{2}}\)</span> definida en la Sección 1.2, con una notación similar para <span class="math inline">\(s_x\)</span>.</p>
</div>
<p>Aunque existen otras estadísticas de correlación, el coeficiente de
correlación ideado por Pearson (1895) tiene varias propiedades deseables. Una propiedad importante es que, para cualquier conjunto de datos, <span class="math inline">\(r\)</span> está
acotado entre -1 y 1, es decir, <span class="math inline">\(-1\leq r\leq 1\)</span>. (El Ejercicio 2.3
proporciona pasos para comprobar esta propiedad.) Si <span class="math inline">\(r\)</span> es mayor
que cero, se dice que las variables están <em>correlacionadas
positivamente</em>. Si <span class="math inline">\(r\)</span> es menor que cero, se dice que las variables están
<em>correlacionadas negativamente</em>. Cuanto mayor sea el coeficiente en
valor absoluto, más fuerte será la relación. De hecho, si <span class="math inline">\(r=1\)</span>,
entonces las variables están perfectamente correlacionadas. En este caso, todos los
datos se encuentran en una línea recta que pasa por los cuadrantes inferior izquierdo y
superior derecho. Si <span class="math inline">\(r=-1\)</span>, entonces todos los datos se encuentran en una
línea que pasa por los cuadrantes superior izquierdo e inferior derecho. El coeficiente <span class="math inline">\(r\)</span> es una medida de una relación <em>lineal</em>
entre dos variables.</p>
<p>Se dice que el coeficiente de correlación es <em>invariante a la ubicación y la escala</em>. Así, el centro de ubicación de cada variable no importa
en el cálculo de <span class="math inline">\(r\)</span>. Por ejemplo, si agregamos $100 a las ventas
de cada código postal, cada <span class="math inline">\(y_i\)</span> aumentará en 100. Sin embargo,
<span class="math inline">\(\overline{y}\)</span>, el precio de compra promedio, también aumentará en 100
de modo que la desviación <span class="math inline">\(y_i - \overline{y}\)</span> permanece sin cambios, o
invariante. Además, la escala de cada variable no importa en
el cálculo de <span class="math inline">\(r\)</span>. Por ejemplo, supongamos que dividimos cada
población entre 1000, de modo que <span class="math inline">\(x_i\)</span> ahora representa la población en
miles. Así, <span class="math inline">\(\overline{x}\)</span> también se divide entre 1000 y usted
debería verificar que <span class="math inline">\(s_x\)</span> también se divide entre 1000. Así, la
versión estandarizada de <span class="math inline">\(x_i\)</span>, <span class="math inline">\(\left( x_i-\overline{x}\right) /s_x\)</span>, permanece sin cambios, o invariante. Muchos paquetes estadísticos
calculan una versión estandarizada de una variable restando el
promedio y dividiendo por la desviación estándar. Ahora, usemos
<span class="math inline">\(y_{i,std}=\left( y_i- \overline{y}\right) /s_y\)</span> y
<span class="math inline">\(x_{i,std}=\left( x_i-\overline{x} \right) /s_x\)</span> para que sean las
versiones estandarizadas de <span class="math inline">\(y_i\)</span> y <span class="math inline">\(x_i\)</span>, respectivamente. Con esta
notación, podemos expresar el coeficiente de correlación como
<span class="math inline">\(r=(n-1)^{-1}\sum_{i=1}^{n}x_{i,std}\times y_{i,std}.\)</span></p>
<p>Se dice que el coeficiente de correlación es una medida <em>adimensional</em>. Esto se debe a que hemos eliminado dólares, y todas las demás
unidades de medida, considerando las variables estandarizadas
<span class="math inline">\(x_{i,std}\)</span> y <span class="math inline">\(y_{i,std}\)</span>. Debido a que el coeficiente de correlación
no depende de las unidades de medida, es una estadística que puede
compararse fácilmente entre diferentes conjuntos de datos.</p>
<p>En el mundo de los negocios, el término “correlación” se usa a menudo como sinónimo del término “relación.” Para los propósitos de este texto, utilizamos el término correlación cuando nos referimos únicamente a relaciones lineales. La relación no lineal clásica es <span class="math inline">\(y=x^{2}\)</span>, una relación cuadrática. Considere esta relación y el conjunto de datos ficticios para <span class="math inline">\(x\)</span>, <span class="math inline">\(\{-2,1,0,1,2\}\)</span>. Ahora, como ejercicio (2.2), produzca un gráfico aproximado del conjunto de datos:</p>
<p><span class="math display">\[
\begin{array}{l|rrrrr}
\hline
i &amp; 1 &amp; 2 &amp; 3 &amp; 4 &amp; 5 \\ \hline
x_i &amp; -2 &amp; -1 &amp; 0 &amp; 1 &amp; 2 \\
y_i &amp; 4 &amp; 1 &amp; 0 &amp; 1 &amp; 4 \\ \hline
\end{array}
\]</span></p>
<p>El coeficiente de correlación para este conjunto de datos resulta ser <span class="math inline">\(r=0\)</span>
(verifíquelo). Por lo tanto, a pesar de que hay una relación perfecta
entre <span class="math inline">\(x\)</span> y <span class="math inline">\(y\)</span> (<span class="math inline">\(=x^{2}\)</span>), hay una correlación cero. Recuerde que
los cambios de ubicación y escala no son relevantes en las discusiones sobre correlación, por lo que
podríamos cambiar fácilmente los valores de <span class="math inline">\(x\)</span> y <span class="math inline">\(y\)</span> para que sean más representativos
de un conjunto de datos de negocios.</p>
<p>¿Qué tan fuerte es la relación entre <span class="math inline">\(y\)</span> y <span class="math inline">\(x\)</span> para los datos de la lotería? Gráficamente, la respuesta es un gráfico de dispersión, como en la Figura
<a href="C2BasicLR.html#fig:Fig22">2.2</a>. Numéricamente, la respuesta principal es el
coeficiente de correlación, que resulta ser <span class="math inline">\(r\)</span> = 0.886 para este
conjunto de datos. Interpretamos esta estadística diciendo que SALES y POP están
correlacionados (positivamente). La fuerza de la relación es
fuerte porque <span class="math inline">\(r\)</span> = 0.886 está cerca de uno. En resumen, podemos
describir esta relación diciendo que hay una fuerte
correlación entre SALES y POP.</p>
</div>
<div id="método-de-mínimos-cuadrados" class="section level4 unnumbered hasAnchor">
<h4>Método de Mínimos Cuadrados<a href="C2BasicLR.html#método-de-mínimos-cuadrados" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>Ahora comenzamos a explorar la pregunta: “¿Puede el conocimiento de la población ayudarnos a entender las ventas?” Para responder a esta pregunta, identificamos las ventas como la variable de <em>respuesta</em>, o <em>dependiente</em>. La variable de población, que se usa para ayudar a entender las ventas, se llama la variable <em>explicativa</em>, o <em>independiente</em>.</p>
<p>Supongamos que tenemos disponibles los datos de muestra de cincuenta ventas <span class="math inline">\(\{y_1, \ldots, y_{50} \}\)</span> y tu trabajo es predecir las ventas de un código postal seleccionado al azar. Sin conocimiento de la variable de población, un predictor sensato es simplemente <span class="math inline">\(\overline{y}=6,495\)</span>, el promedio de la muestra disponible. Naturalmente, anticipas que las áreas con mayores poblaciones tendrán mayores ventas. Es decir, si también tienes conocimiento de la población, ¿puede mejorarse esta estimación? Si es así, ¿cuánto?</p>
<p>Para responder a estas preguntas, el primer paso asume una relación lineal aproximada entre <span class="math inline">\(x\)</span> y <span class="math inline">\(y\)</span>. Para ajustar una línea a nuestro conjunto de datos, usamos el <em>método de mínimos cuadrados</em>. Necesitamos una técnica general para que, si diferentes analistas están de acuerdo en los datos y en la técnica de ajuste, entonces estarán de acuerdo en la línea. Si diferentes analistas ajustan un conjunto de datos usando aproximaciones a ojo, en general llegarán a diferentes líneas, incluso usando el mismo conjunto de datos.</p>
<p>El método comienza con la línea <span class="math inline">\(y=b_0^{\ast}+b_1^{\ast}x\)</span>, donde la intersección y la pendiente, <span class="math inline">\(b_0^{\ast}\)</span> y <span class="math inline">\(b_1^{\ast}\)</span>, son meramente valores genéricos. Para la <span class="math inline">\(i\)</span>-ésima observación, <span class="math inline">\(y_i-\left( b_0^{\ast}+b_1^{\ast}x_i\right)\)</span> representa la desviación del valor observado <span class="math inline">\(y_i\)</span> de la línea en <span class="math inline">\(x_i\)</span>. La cantidad
<span class="math display">\[\begin{equation*}
SS(b_0^{\ast},b_1^{\ast})=\sum_{i=1}^{n}\left( y_i-\left(
b_0^{\ast}+b_1^{\ast}x_i\right) \right) ^{2}
\end{equation*}\]</span>
representa la suma de desviaciones cuadradas para esta línea candidata. El método de mínimos cuadrados consiste en determinar los valores de <span class="math inline">\(b_0^{\ast}\)</span> y <span class="math inline">\(b_1^{\ast}\)</span> que minimizan <span class="math inline">\(SS(b_0^{\ast},b_1^{\ast})\)</span>. Este es un problema fácil que puede resolverse mediante cálculo, de la siguiente manera. Tomando derivadas parciales con respecto a cada argumento obtenemos
<span class="math display">\[\begin{equation*}
\frac{\partial }{\partial
b_0^{\ast}}SS(b_0^{\ast},b_1^{\ast})=\sum_{i=1}^{n}(-2)\left(
y_i-\left( b_0^{\ast}+b_1^{\ast}x_i\right) \right)
\end{equation*}\]</span>
y
<span class="math display">\[\begin{equation*}
\frac{\partial }{\partial
b_1^{\ast}}SS(b_0^{\ast},b_1^{\ast})=\sum_{i=1}^{n}(-2x_i)\left(
y_i-\left( b_0^{\ast}+b_1^{\ast}x_i\right) \right) .
\end{equation*}\]</span>
Se invita al lector a tomar las segundas derivadas parciales para asegurarse de que estamos minimizando, no maximizando, esta función. Igualando estas cantidades a cero y cancelando términos constantes obtenemos
<span class="math display">\[\begin{equation*}
\sum_{i=1}^{n}\left( y_i-\left( b_0^{\ast}+b_1^{\ast}x_i\right)
\right) =0
\end{equation*}\]</span>
y
<span class="math display">\[\begin{equation*}
\sum_{i=1}^{n}x_i\left( y_i-\left( b_0^{\ast}+b_1^{\ast}x_i\right)
\right) =0,
\end{equation*}\]</span>
que son conocidas como las <em>ecuaciones normales</em>. Resolver estas ecuaciones proporciona los valores de <span class="math inline">\(b_0^{\ast}\)</span> y <span class="math inline">\(b_1^{\ast}\)</span> que minimizan la suma de cuadrados.</p>
<div class="blackbox">
<p><em>Definición.</em> Las <em>estimaciones de intersección y pendiente de mínimos cuadrados</em> son</p>
<p><span class="math display">\[\begin{equation*}
b_1=r\frac{s_y}{s_x}~~~~~\mathrm{y}~~~~~b_0=\overline{y}-b_1
\overline{x}.
\end{equation*}\]</span>
La línea que determinan, <span class="math inline">\(\widehat{y}=b_0+b_1x\)</span>, se llama la <em>línea de regresión ajustada</em>.</p>
</div>
<p>Hemos eliminado la notación de asterisco, o estrella, porque <span class="math inline">\(b_0\)</span> y <span class="math inline">\(b_1\)</span> ya no son valores “candidatos”.</p>
<p>¿Proporciona este procedimiento una línea sensata para nuestras ventas de lotería de Wisconsin? Anteriormente, calculamos <span class="math inline">\(r=0.886\)</span>. A partir de esto y de las estadísticas básicas resumidas en la Tabla <a href="C2BasicLR.html#tab:Tab21">2.1</a>, tenemos <span class="math inline">\(b_1 = 0.886 \left( 8,103\right) /11,098=0.647\)</span> y <span class="math inline">\(b_0 = 6,495-(0.647)9,311 = 469.7\)</span>. Esto produce la línea de regresión ajustada
<span class="math display">\[\begin{equation*}
\widehat{y} = 469.7 + (0.647)x.
\end{equation*}\]</span>
El sombrero, o “gorro”, encima de la <span class="math inline">\(y\)</span> nos recuerda que esta <span class="math inline">\(\widehat{y}\)</span>, o <span class="math inline">\(\widehat{SALES}\)</span>, es un valor ajustado. Una aplicación de la línea de regresión es estimar ventas para una población específica, digamos, <span class="math inline">\(x=10,000\)</span>. La estimación es la altura de la línea de regresión, que es <span class="math inline">\(469.7 + (0.647)(10,000) = 6,939.7\)</span>.</p>
<hr />
<p><strong>Ejemplo: Resumiendo Simulaciones.</strong> El análisis de regresión es una herramienta para resumir datos complejos. En el trabajo práctico, los actuarios a menudo simulan escenarios financieros complicados; a menudo se pasa por alto que la regresión puede usarse para resumir relaciones de interés.</p>
<p>Para ilustrar, Manistre y Hancock (2005) simularon muchas realizaciones de una opción put europea a 10 años y demostraron la relación entre dos medidas de riesgo actuarial, el valor en riesgo (VaR) y la expectativa de cola condicional (CTE). Para un ejemplo, estos autores examinaron rendimientos de acciones distribuidos logarítmicamente con un precio inicial de $100, de modo que en 10 años el precio de la acción estaría distribuido como
<span class="math display">\[\begin{equation*}
S(Z)=100 \exp \left( (.08) 10 + .15 \sqrt{10} Z \right),
\end{equation*}\]</span>
basado en un retorno medio anual del 8%, desviación estándar del 15% y el resultado de una variable aleatoria normal estándar <span class="math inline">\(Z\)</span>. La opción put paga la diferencia entre el precio de ejercicio, que se tomará como 110 para este ejemplo, y <span class="math inline">\(S(Z)\)</span>. El valor presente de esta opción es
<span class="math display">\[\begin{equation*}
C(Z)= \mathrm{e}^{-0.06(10)} \mathrm{max} \left(0, 110-S(Z) \right),
\end{equation*}\]</span>
basado en una tasa de descuento del 6%.</p>
<p>Para estimar el VaR y el CTE, para cada <span class="math inline">\(i\)</span>, se simularon 1000 variables aleatorias normales estándar i.i.d. y se usaron para calcular 1000 valores presentes, <span class="math inline">\(C_{i1}, \ldots, C_{i,1000}.\)</span> El percentil 95 de estos valores presentes es la estimación del valor en riesgo, denotado como <span class="math inline">\(VaR_i.\)</span> El promedio de los 50 valores presentes más altos (<span class="math inline">\(= (1-.05) \times 1000\)</span>) es la estimación de la expectativa de cola condicional, denotada como <span class="math inline">\(CTE_i\)</span>. Manistre y Hancock (2005) realizaron este cálculo <span class="math inline">\(i=1, \ldots, 1000\)</span> veces; el resultado se presenta en la Figura <a href="C2BasicLR.html#fig:Fig23">2.3</a>. El diagrama de dispersión muestra una relación fuerte pero no perfecta entre el <span class="math inline">\(VaR\)</span> y el <span class="math inline">\(CTE\)</span>, el coeficiente de correlación resulta ser <span class="math inline">\(r=0.782\)</span>.</p>

<div class="figure" style="text-align: center"><span style="display:block;" id="fig:Fig23"></span>
<img src="RegressionMarkdown_files/figure-html/Fig23-1.png" alt="Gráfico de la Expectativa de Cola Condicional (CTE) frente al Valor en Riesgo (VaR). Basado en \(n=1,000\) simulaciones de un bono put europeo a 10 años. Fuente: Manistre y Hancock (2005)." width="60%" />
<p class="caption">
Figura 2.3: <strong>Gráfico de la Expectativa de Cola Condicional (CTE) frente al Valor en Riesgo (VaR).</strong> Basado en <span class="math inline">\(n=1,000\)</span> simulaciones de un bono put europeo a 10 años. <em>Fuente</em>: Manistre y Hancock (2005).
</p>
</div>
<h5 style="text-align: center;">
<a id="displayCode.Fig23.Hide" href="javascript:togglecode('toggleCode.Fig23.Hide','displayCode.Fig23.Hide');"><i><strong>Código R para producir la Figura 2.3</strong></i></a>
</h5>
<div id="toggleCode.Fig23.Hide" style="display: none">
<div class="sourceCode" id="cb10"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb10-1"><a href="C2BasicLR.html#cb10-1" tabindex="-1"></a><span class="co"># FIGURA 2.3</span></span>
<span id="cb10-2"><a href="C2BasicLR.html#cb10-2" tabindex="-1"></a><span class="co"># simulación</span></span>
<span id="cb10-3"><a href="C2BasicLR.html#cb10-3" tabindex="-1"></a>S <span class="ot">&lt;-</span> <span class="fu">vector</span>(<span class="at">mode =</span> <span class="st">&quot;numeric&quot;</span>, <span class="at">length =</span> <span class="dv">1000</span>)</span>
<span id="cb10-4"><a href="C2BasicLR.html#cb10-4" tabindex="-1"></a>C <span class="ot">&lt;-</span> <span class="fu">vector</span>(<span class="at">mode =</span> <span class="st">&quot;numeric&quot;</span>, <span class="at">length =</span> <span class="dv">1000</span>)</span>
<span id="cb10-5"><a href="C2BasicLR.html#cb10-5" tabindex="-1"></a>Var <span class="ot">&lt;-</span> <span class="fu">vector</span>(<span class="at">mode =</span> <span class="st">&quot;numeric&quot;</span>, <span class="at">length =</span> <span class="dv">1000</span>)</span>
<span id="cb10-6"><a href="C2BasicLR.html#cb10-6" tabindex="-1"></a>CTE <span class="ot">&lt;-</span> <span class="fu">vector</span>(<span class="at">mode =</span> <span class="st">&quot;numeric&quot;</span>, <span class="at">length =</span> <span class="dv">1000</span>)</span>
<span id="cb10-7"><a href="C2BasicLR.html#cb10-7" tabindex="-1"></a><span class="cf">for</span> (i <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span><span class="dv">1000</span>){</span>
<span id="cb10-8"><a href="C2BasicLR.html#cb10-8" tabindex="-1"></a>  <span class="cf">for</span> (j <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span><span class="dv">1000</span>){</span>
<span id="cb10-9"><a href="C2BasicLR.html#cb10-9" tabindex="-1"></a>    S[j] <span class="ot">&lt;-</span> <span class="dv">100</span> <span class="sc">*</span> <span class="fu">exp</span>(.<span class="dv">08</span> <span class="sc">*</span> <span class="dv">10</span> <span class="sc">+</span> .<span class="dv">15</span> <span class="sc">*</span> (<span class="dv">10</span> <span class="sc">^</span> .<span class="dv">5</span>) <span class="sc">*</span> <span class="fu">rnorm</span>(<span class="dv">1</span>))</span>
<span id="cb10-10"><a href="C2BasicLR.html#cb10-10" tabindex="-1"></a>    C[j] <span class="ot">&lt;-</span> <span class="fu">exp</span>(<span class="sc">-</span>.<span class="dv">06</span> <span class="sc">*</span> <span class="dv">10</span>) <span class="sc">*</span> <span class="fu">max</span>(<span class="dv">0</span>, <span class="dv">110</span> <span class="sc">-</span> S[j]) </span>
<span id="cb10-11"><a href="C2BasicLR.html#cb10-11" tabindex="-1"></a>  }</span>
<span id="cb10-12"><a href="C2BasicLR.html#cb10-12" tabindex="-1"></a>  C <span class="ot">&lt;-</span> <span class="fu">sort</span>(C)</span>
<span id="cb10-13"><a href="C2BasicLR.html#cb10-13" tabindex="-1"></a>  Var[i] <span class="ot">&lt;-</span> C[<span class="dv">950</span>]</span>
<span id="cb10-14"><a href="C2BasicLR.html#cb10-14" tabindex="-1"></a>  CTE[i] <span class="ot">&lt;-</span> <span class="fu">mean</span>(C[<span class="dv">950</span><span class="sc">:</span><span class="dv">1000</span>])  </span>
<span id="cb10-15"><a href="C2BasicLR.html#cb10-15" tabindex="-1"></a>}</span>
<span id="cb10-16"><a href="C2BasicLR.html#cb10-16" tabindex="-1"></a></span>
<span id="cb10-17"><a href="C2BasicLR.html#cb10-17" tabindex="-1"></a>model <span class="ot">&lt;-</span> <span class="fu">lm</span>(CTE <span class="sc">~</span> Var)</span>
<span id="cb10-18"><a href="C2BasicLR.html#cb10-18" tabindex="-1"></a>b0 <span class="ot">&lt;-</span> <span class="fu">round</span>(model<span class="sc">$</span>coef[<span class="dv">1</span>], <span class="at">digits =</span> <span class="dv">3</span>)</span>
<span id="cb10-19"><a href="C2BasicLR.html#cb10-19" tabindex="-1"></a>b1 <span class="ot">&lt;-</span> <span class="fu">round</span>(model<span class="sc">$</span>coef[<span class="dv">2</span>], <span class="at">digits =</span> <span class="dv">3</span>)</span>
<span id="cb10-20"><a href="C2BasicLR.html#cb10-20" tabindex="-1"></a>R2 <span class="ot">&lt;-</span> <span class="fu">round</span>(<span class="fu">summary</span>(model)<span class="sc">$</span>r.squared, <span class="at">digits =</span> <span class="dv">4</span>)</span>
<span id="cb10-21"><a href="C2BasicLR.html#cb10-21" tabindex="-1"></a></span>
<span id="cb10-22"><a href="C2BasicLR.html#cb10-22" tabindex="-1"></a><span class="fu">plot</span>(Var, CTE,</span>
<span id="cb10-23"><a href="C2BasicLR.html#cb10-23" tabindex="-1"></a>     <span class="at">xlab =</span> <span class="fu">expression</span>(<span class="fu">paste</span>(<span class="st">&quot;Estimaciones de VaR&quot;</span>)),</span>
<span id="cb10-24"><a href="C2BasicLR.html#cb10-24" tabindex="-1"></a>     <span class="at">ylab =</span> <span class="fu">expression</span>(<span class="fu">paste</span>(<span class="st">&quot;Estimaciones de CTE&quot;</span>)),</span>
<span id="cb10-25"><a href="C2BasicLR.html#cb10-25" tabindex="-1"></a>     <span class="at">xlim =</span> <span class="fu">c</span>(<span class="dv">0</span>, <span class="dv">12</span>), <span class="at">ylim =</span> <span class="fu">c</span>(<span class="dv">8</span>, <span class="dv">20</span>), <span class="at">xaxs =</span> <span class="st">&quot;i&quot;</span>, <span class="at">yaxs =</span> <span class="st">&quot;i&quot;</span>, <span class="at">pch =</span> <span class="dv">20</span>, <span class="at">cex =</span> <span class="fl">0.4</span>)</span>
<span id="cb10-26"><a href="C2BasicLR.html#cb10-26" tabindex="-1"></a><span class="fu">lines</span>(Var, model<span class="sc">$</span>fitted, <span class="at">lwd =</span> .<span class="dv">5</span>)</span>
<span id="cb10-27"><a href="C2BasicLR.html#cb10-27" tabindex="-1"></a><span class="fu">abline</span>(<span class="at">h =</span> <span class="fu">c</span>(<span class="dv">10</span>, <span class="dv">12</span>, <span class="dv">14</span>, <span class="dv">16</span>, <span class="dv">18</span>, <span class="dv">20</span>), <span class="at">col =</span> <span class="st">&quot;grey&quot;</span>)</span></code></pre></div>
</div>
</div>
</div>
<div id="Sec22" class="section level2 hasAnchor" number="2.2">
<h2><span class="header-section-number">2.2</span> Modelo Básico de Regresión Lineal<a href="C2BasicLR.html#Sec22" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>El diagrama de dispersión, el coeficiente de correlación y la línea de regresión ajustada son herramientas útiles para resumir la relación entre dos variables para un conjunto de datos específico. Para inferir relaciones generales, necesitamos modelos para representar los resultados de poblaciones amplias.</p>
<p>Este capítulo se centra en un modelo de “regresión lineal básica”. La parte de “regresión lineal” proviene del hecho de que ajustamos una línea a los datos. La parte de “básica” es porque usamos solo una variable explicativa, <span class="math inline">\(x\)</span>. Este modelo también se conoce como una “regresión lineal simple”. Este texto evita este lenguaje porque da la falsa impresión de que las ideas e interpretaciones de regresión con una variable explicativa son siempre sencillas.</p>
<p>Ahora introducimos dos conjuntos de supuestos del modelo básico, las representaciones “observables” y de “error”. Son equivalentes, pero cada una nos ayudará a medida que extendamos los modelos de regresión más allá de lo básico.</p>
<p><span class="math display">\[
{\small
\begin{array}{l} \hline  \hline
&amp;\textbf{Modelo Básico de Regresión Lineal} \\
&amp;\textbf{Supuestos de Muestreo de la Representación Observable} \\ \hline
\text{F1}. &amp; \mathrm{E}~y_i=\beta_0 + \beta_1 x_i . \\
\text{F2}.  &amp; \{x_1,\ldots ,x_n\}  \text{son variables no estocásticas}. \\
\text{F3}. &amp; \mathrm{Var}~y_i=\sigma ^{2}. \\
\text{F4}. &amp; \{ y_i\} \text{son variables aleatorias independientes}. \\ \hline\
\end{array}
}
\]</span></p>
<p>La “representación observable” se enfoca en variables que podemos ver (u observar), <span class="math inline">\((x_i,y_i)\)</span>. La inferencia sobre la distribución de <span class="math inline">\(y\)</span> es condicional a las variables explicativas observadas, de modo que podemos tratar <span class="math inline">\(\{x_1,\ldots ,x_n\}\)</span> como variables no estocásticas (supuesto F2). Al considerar tipos de mecanismos de muestreo para <span class="math inline">\((x_i,y_i)\)</span>, es conveniente pensar en un esquema de <em>muestreo aleatorio estratificado</em>, donde los valores de <span class="math inline">\(\{x_1,\ldots ,x_n\}\)</span> se tratan como los estratos, o grupos. Bajo el muestreo estratificado, para cada valor único de <span class="math inline">\(x_i\)</span>, tomamos una muestra aleatoria de una población. Para ilustrar, supongamos que se está extrayendo de una base de datos de empresas para comprender el rendimiento de las acciones (<span class="math inline">\(y\)</span>) y desea estratificar según el tamaño de la empresa. Si la cantidad de activos es una variable continua, entonces podemos imaginar tomar una muestra de tamaño 1 para cada empresa. De esta manera, hipotetizamos una distribución de rendimientos de acciones condicional al tamaño de los activos de la empresa.</p>
<p><em>Digresión</em>: A menudo verá informes que resumen resultados para los “50 mejores gerentes” o las “100 mejores universidades”, medidos por alguna variable de resultado. En aplicaciones de regresión, asegúrese de no seleccionar observaciones basadas en una variable dependiente, como el rendimiento más alto de las acciones, porque esto es estratificar basado en el <span class="math inline">\(y\)</span>, no en el <span class="math inline">\(x\)</span>. El Capítulo 6 discutirá los procedimientos de muestreo con mayor detalle.</p>
<p>El muestreo estratificado también proporciona motivación para el supuesto F4, la independencia entre respuestas. Se puede motivar el supuesto F1 pensando en <span class="math inline">\((x_i,y_i)\)</span> como una extracción de una población, donde la media de la distribución condicional de <span class="math inline">\(y_i\)</span> dado {<span class="math inline">\(x_i\)</span>} es lineal en la variable explicativa. El supuesto F3 se conoce como <em>homocedasticidad</em>, que discutiremos ampliamente en la Sección 5.7. Ver Goldberger (1991) para más información sobre esta representación.</p>
<p>Un quinto supuesto que a menudo se usa implícitamente es:
<span class="math display">\[
\text{F5}. \{y_i\} \text{ están distribuidos normalmente}.
\]</span>
Este supuesto no es necesario para muchos procedimientos de inferencia estadística porque los teoremas del límite central proporcionan normalidad aproximada para muchas estadísticas de interés. Sin embargo, la justificación formal para algunas, como las estadísticas <span class="math inline">\(t\)</span>, requieren este supuesto adicional.</p>
<p>En contraste con la representación observable, un conjunto alternativo de supuestos se enfoca en las desviaciones, o “errores”, en la regresión, definidos como <span class="math inline">\(\varepsilon_i=y_i-\left( \beta_0 + \beta_1 x_i \right)\)</span>.</p>
<p><span class="math display">\[
{\small
\begin{array}{l} \hline  \hline
&amp;\textbf{Modelo Básico de Regresión Lineal} \\
&amp;\textbf{Supuestos de Muestreo de la Representación de Error} \\ \hline
\text{E1}. &amp; y_i=\beta_0 + \beta_1 x_i + \varepsilon_i . \\
\text{E2}.  &amp; \{x_1,\ldots ,x_n\}  \text{ son variables no estocásticas}. \\
\text{E3}. &amp; \mathrm{E}~\varepsilon_i=0 \text{ y } \mathrm{Var}~\varepsilon_i=\sigma ^{2}. \\
\text{E4}. &amp; \{ \varepsilon_i\} \text{ son variables aleatorias independientes}. \\ \hline\
\end{array}
}
\]</span></p>
<p>La “representación de error” se basa en la teoría gaussiana de errores (ver Stigler, 1986, para un contexto histórico). El supuesto E1 asume que <span class="math inline">\(y\)</span> es en parte debido a una función lineal de la variable explicativa observada, <span class="math inline">\(x\)</span>. Otras variables no observadas que influyen en la medición de <span class="math inline">\(y\)</span> se interpretan como incluidas en el término de “error” <span class="math inline">\(\varepsilon_i\)</span>, que también se conoce como el término de “perturbación”. La independencia de errores, E4, puede motivarse asumiendo que {<span class="math inline">\(\varepsilon_i\)</span>} se realizan a través de una muestra aleatoria simple de una población desconocida de errores.</p>
<p>Los supuestos E1-E4 son equivalentes a F1-F4. La representación de error proporciona una base útil para motivar las medidas de ajuste (Sección <a href="C2BasicLR.html#Sec23">2.3</a>). Sin embargo, una desventaja de la representación de error es que desvía la atención de las cantidades observables <span class="math inline">\((x_i,y_i)\)</span> a una cantidad no observable, {<span class="math inline">\(\varepsilon_i\)</span>}. Para ilustrar, la base de muestreo, ver {<span class="math inline">\(\varepsilon_i\)</span>} como una muestra aleatoria simple, no es directamente verificable porque no se puede observar directamente la muestra {<span class="math inline">\(\varepsilon_i\)</span>}. Además, el supuesto de errores aditivos en E1 será problemático cuando consideremos modelos de regresión no lineales.</p>
<p>La Figura <a href="C2BasicLR.html#fig:Fig24">2.4</a> ilustra algunos de los supuestos del modelo básico de regresión lineal. Los datos (<span class="math inline">\(x_1,y_1\)</span>), (<span class="math inline">\(x_2,y_2\)</span>) y (<span class="math inline">\(x_3,y_3\)</span>) son observados y se representan con los símbolos de trazado circulares opacos. Según el modelo, estas observaciones deben estar cerca de la línea de regresión <span class="math inline">\(\mathrm{E}~y = \beta_0 + \beta_1 x\)</span>. Cada desviación de la línea es aleatoria. A menudo asumimos que la distribución de desviaciones puede representarse por una curva normal, como en la Figura <a href="C2BasicLR.html#fig:Fig24">2.4</a>.</p>

<div class="figure" style="text-align: center"><span style="display:block;" id="fig:Fig24"></span>
<img src="RegressionMarkdown_files/figure-html/Fig24-1.png" alt="La distribución de la respuesta varía según el nivel de la variable explicativa." width="60%" />
<p class="caption">
Figura 2.4: <strong>La distribución de la respuesta varía según el nivel de la variable explicativa.</strong>
</p>
</div>
<p>Los supuestos del modelo básico de regresión lineal describen la población subyacente. <a href="C2BasicLR.html#Table22">Tabla 2.2</a> destaca la idea de que las características de esta población pueden resumirse mediante los parámetros <span class="math inline">\(\beta_0\)</span>, <span class="math inline">\(\beta_1\)</span> y <span class="math inline">\(\sigma ^{2}\)</span>. En la Sección 2.1, resumimos datos de una muestra, introduciendo las estadísticas <span class="math inline">\(b_0\)</span> y <span class="math inline">\(b_1\)</span>. La Sección <a href="C2BasicLR.html#Sec23">2.3</a> introducirá <span class="math inline">\(s^{2}\)</span>, la estadística correspondiente al parámetro <span class="math inline">\(\sigma ^{2}\)</span>.</p>
<p><a id=Table22></a></p>
<p><span id="Table22">Tabla 2.2</span>. <strong>Medidas Resumen de la Población y la Muestra</strong></p>
<p><span class="math display">\[
{\small
\begin{array}{llccc}\hline\hline
&amp; \text{Resumen} \\
\text{Datos} &amp; \text{Medidas} &amp; \text{Intercepto} &amp; \text{Pendiente} &amp; \text{Varianza} \\\hline
\text{Población} &amp; \text{Parámetros} &amp; \beta_0 &amp; \beta_1 &amp; \sigma^2 \\
\text{Muestra} &amp; \text{Estadísticas} &amp; b_0 &amp; b_1 &amp; s^2 \\
\hline
\end{array}
}
\]</span></p>
</div>
<div id="Sec23" class="section level2 hasAnchor" number="2.3">
<h2><span class="header-section-number">2.3</span> ¿Es Útil el Modelo? Algunas Medidas de Resumen Básicas<a href="C2BasicLR.html#Sec23" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Aunque la estadística es la ciencia de resumir datos, también es el arte de argumentar con datos. Esta sección desarrolla algunas de las herramientas básicas usadas para justificar el modelo de regresión lineal básica. Un diagrama de dispersión puede proporcionar una fuerte evidencia <em>visual</em> de que <span class="math inline">\(x\)</span> influye en <span class="math inline">\(y\)</span>; desarrollar evidencia <em>numérica</em> nos permitirá cuantificar la fuerza de la relación. Además, la evidencia numérica será útil cuando consideremos otros conjuntos de datos donde la evidencia gráfica no sea convincente.</p>
<div id="Sec231" class="section level3 hasAnchor" number="2.3.1">
<h3><span class="header-section-number">2.3.1</span> Particionando la Variabilidad<a href="C2BasicLR.html#Sec231" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Las desviaciones cuadradas, <span class="math inline">\(\left( y_i-\overline{y}\right) ^2\)</span>, proporcionan una base para medir la dispersión de los datos. Si deseamos estimar la <span class="math inline">\(i\)</span>-ésima variable dependiente <em>sin</em> conocimiento de <span class="math inline">\(x\)</span>, entonces <span class="math inline">\(\overline{y}\)</span> es una estimación adecuada y <span class="math inline">\(y_i- \overline{y}\)</span> representa la desviación de la estimación. Usamos <span class="math inline">\(Total~SS=\sum_{i=1}^{n}\left( y_i-\overline{y}\right) ^2\)</span>, la suma total de cuadrados, para representar la variación en todas las respuestas.</p>
<p>Supongamos ahora que también tenemos conocimiento de <span class="math inline">\(x\)</span>, una variable explicativa. Usando la línea de regresión ajustada, para cada observación podemos calcular el <em>valor ajustado</em> correspondiente, <span class="math inline">\(\widehat{y}_i = b_0 + b_1x_i\)</span>. El valor ajustado es nuestra estimación <em>con</em> conocimiento de la variable explicativa. Como antes, la diferencia entre la respuesta y el valor ajustado, <span class="math inline">\(y_i- \widehat{y}_i\)</span>, representa la desviación de esta estimación. Ahora tenemos dos “estimaciones” de <span class="math inline">\(y_i\)</span>, que son <span class="math inline">\(\widehat{y}_i\)</span> y <span class="math inline">\(\overline{y}\)</span>. Presumiblemente, si la línea de regresión es útil, entonces <span class="math inline">\(\widehat{y}_i\)</span> es una medida más precisa que <span class="math inline">\(\overline{y}\)</span>. Para juzgar esta utilidad, descomponemos algebraicamente la desviación total como:</p>
<p><span class="math display" id="eq:eq21">\[\begin{equation}
{\small
\begin{array}{ccccc}
\underbrace{y_i-\overline{y}} &amp; = &amp;
\underbrace{y_i-\widehat{y}_i}
&amp; + &amp; \underbrace{\widehat{y}_i-\overline{y}} \\
\text{desviación} &amp; = &amp; \text{desviación} &amp; + &amp; \text{desviación} \\
\text{total} &amp;  &amp; \text{no explicada} &amp;  &amp; \text{explicada} \\
\end{array}
\tag{2.1}
}
\end{equation}\]</span>
Interpreta esta ecuación como “la desviación sin conocimiento de <span class="math inline">\(x\)</span> es igual a la desviación con conocimiento de <span class="math inline">\(x\)</span> más la desviación explicada por <span class="math inline">\(x\)</span>.” La Figura <a href="C2BasicLR.html#fig:Fig25">2.5</a> es una representación geométrica de esta descomposición. En la figura, se eligió una observación por encima de la línea, lo que da una desviación positiva de la línea de regresión ajustada, para hacer que el gráfico sea más fácil de leer. Un buen ejercicio es hacer un boceto aproximado correspondiente a la Figura <a href="C2BasicLR.html#fig:Fig25">2.5</a> con una observación por debajo de la línea de regresión ajustada.</p>

<div class="figure" style="text-align: center"><span style="display:block;" id="fig:Fig25"></span>
<img src="RegressionMarkdown_files/figure-html/Fig25-1.png" alt="Representación geométrica de la descomposición de la desviación." width="60%" />
<p class="caption">
Figura 2.5: <strong>Representación geométrica de la descomposición de la desviación.</strong>
</p>
</div>
<p>Ahora, a partir de la descomposición algebraica en la ecuación <a href="C2BasicLR.html#eq:eq21">(2.1)</a>, eleva al cuadrado cada lado de la ecuación y suma sobre todas las observaciones. Después de un poco de manipulación algebraica, esto da como resultado
<span class="math display" id="eq:eq22">\[\begin{equation}
\sum_{i=1}^{n}\left( y_i-\overline{y}\right) ^2=\sum_{i=1}^{n}\left(
y_i-\widehat{y}_i\right) ^2+\sum_{i=1}^{n}\left( \widehat{y}_i-
\overline{y}\right) ^2.
\tag{2.2}
\end{equation}\]</span>
Reescribimos esto como <span class="math inline">\(Total~SS=Error~SS+Regression~SS\)</span> donde <span class="math inline">\(SS\)</span> significa suma de cuadrados. Interpretamos:</p>
<ul>
<li><p><span class="math inline">\(Total~SS\)</span> como la variación total sin conocimiento de <span class="math inline">\(x\)</span>,</p></li>
<li><p><span class="math inline">\(Error~SS\)</span> como la variación total que queda después de introducir <span class="math inline">\(x\)</span>, y</p></li>
<li><p><span class="math inline">\(Regression~SS\)</span> como la diferencia entre el <span class="math inline">\(Total~SS\)</span> y el <span class="math inline">\(Error~SS\)</span>, o la variación total “explicada” mediante el conocimiento de <span class="math inline">\(x\)</span>.</p></li>
</ul>
<p>Al elevar al cuadrado el lado derecho de la ecuación <a href="C2BasicLR.html#eq:eq21">(2.1)</a>, tenemos el término de producto cruzado <span class="math inline">\(2\left(y_i-\widehat{y}_i\right) \left( \widehat{y}_i-\overline{y}\right)\)</span>. Con la “manipulación algebraica”, se puede comprobar que la suma de los productos cruzados sobre todas las observaciones es cero. Este resultado no es cierto para todas las líneas ajustadas, pero es una propiedad especial de la línea ajustada por mínimos cuadrados.</p>
<p>En muchos casos, la descomposición de la variabilidad se reporta a través de un solo estadístico.</p>
<div class="blackbox">
<p><em>Definición</em>. El <em>coeficiente de determinación</em> se denota por el símbolo <span class="math inline">\(R^2\)</span>, llamado “<span class="math inline">\(R\)</span>-cuadrado”, y se define como
<span class="math display">\[\begin{equation*}
R^2=\frac{Regression~SS}{Total~SS}.
\end{equation*}\]</span></p>
</div>
<p>Interpretamos <span class="math inline">\(R^2\)</span> como la proporción de variabilidad explicada por la línea de regresión. En un caso extremo donde la línea de regresión se ajusta perfectamente a los datos, tenemos <span class="math inline">\(Error~SS=0\)</span> y <span class="math inline">\(R^2=1\)</span>. En el otro caso extremo donde la línea de regresión no proporciona ninguna información sobre la respuesta, tenemos <span class="math inline">\(Regression~SS=0\)</span> y <span class="math inline">\(R^2=0\)</span>. El coeficiente de determinación está limitado por las desigualdades <span class="math inline">\(0 \leq R^2 \leq 1\)</span> con valores mayores que implican un mejor ajuste.</p>
</div>
<div id="Sec232" class="section level3 hasAnchor" number="2.3.2">
<h3><span class="header-section-number">2.3.2</span> El Tamaño de una Desviación Típica: <em>s</em><a href="C2BasicLR.html#Sec232" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>En el modelo de regresión lineal básica, la desviación de la respuesta
de la línea de regresión, $y_i-( _0+_1x_i) $,
no es una cantidad observable porque los parámetros <span class="math inline">\(\beta_0\)</span> y
<span class="math inline">\(\beta_1\)</span> no son observados. Sin embargo, usando los estimadores <span class="math inline">\(b_0\)</span> y
<span class="math inline">\(b_1\)</span>, podemos aproximar esta desviación usando
<span class="math display">\[\begin{equation*}
e_i=y_i-\widehat{y}_i=y_i-\left( b_0+b_1x_i\right) ,
\end{equation*}\]</span>
conocido como el <em>residuo</em>.</p>
<p>Los residuos serán cruciales para desarrollar estrategias para mejorar
la especificación del modelo en la Sección <a href="C2BasicLR.html#Sec26">2.6</a>. Ahora mostramos
cómo usar los residuos para estimar <span class="math inline">\(\sigma ^2\)</span>. De un primer
curso en estadística, sabemos que si se pudieran observar las
desviaciones <span class="math inline">\(\varepsilon_i\)</span>, entonces una estimación deseable de <span class="math inline">\(\sigma ^2\)</span> sería <span class="math inline">\((n-1)^{-1}\sum_{i=1}^{n}\left( \varepsilon _i-\overline{\varepsilon }\right) ^2\)</span>. Como <span class="math inline">\(\{\varepsilon_i\}\)</span>
no se observan, usamos lo siguiente.</p>
<div class="blackbox">
<p><em>Definición</em>. Un estimador de <span class="math inline">\(\sigma ^2\)</span>, el <em>error cuadrático medio (MSE)</em>, se define como
<span class="math display" id="eq:eq23">\[\begin{equation}
s^2=\frac{1}{n-2}\sum_{i=1}^{n}e_i{}^2.
\tag{2.3}
\end{equation}\]</span>
La raíz cuadrada positiva, <span class="math inline">\(s=\sqrt{s^2},\)</span> se llama la <em>desviación estándar residual</em>.</p>
</div>
<p>Comparando las definiciones de <span class="math inline">\(s^2\)</span> y <span class="math inline">\((n-1)^{-1}\sum_{i=1}^{n}\left( \varepsilon_i-\overline{\varepsilon }\right) ^2\)</span>, verá dos diferencias importantes. Primero, al definir <span class="math inline">\(s^2\)</span> no hemos restado el residuo promedio de cada
residuo antes de elevar al cuadrado. Esto se debe a que el residuo promedio es cero, una propiedad especial de la estimación de mínimos cuadrados (ver Ejercicio 2.14). Este resultado se puede mostrar usando álgebra y está garantizado para todos los conjuntos de datos.</p>
<p>En segundo lugar, al definir <span class="math inline">\(s^2\)</span> hemos dividido por <span class="math inline">\(n-2\)</span> en lugar de <span class="math inline">\(n-1\)</span>. Intuitivamente, dividir por <span class="math inline">\(n\)</span> o <span class="math inline">\(n-1\)</span> tiende a subestimar <span class="math inline">\(\sigma ^2\)</span>. La razón es que, al ajustar líneas a los datos, necesitamos al menos dos observaciones para determinar una línea. Por ejemplo, debemos
tener al menos tres observaciones para que haya alguna variabilidad alrededor de una línea. ¿Cuánta “libertad” hay para la variabilidad alrededor de una línea? Diremos que los grados de libertad del error son el número de observaciones disponibles, <span class="math inline">\(n\)</span>, menos el número de observaciones necesarias para determinar una línea, 2 (con símbolos, <span class="math inline">\(df=n-2\)</span>). Sin embargo, como vimos en la subsección de estimación de mínimos cuadrados, no necesitamos identificar dos observaciones reales para determinar una línea. La idea es que si un analista conoce la línea y <span class="math inline">\(n-2\)</span> observaciones, entonces las dos observaciones restantes se pueden determinar, sin variabilidad. Al
dividir por <span class="math inline">\(n-2\)</span>, se puede mostrar que <span class="math inline">\(s^2\)</span> es un estimador insesgado de <span class="math inline">\(\sigma ^2\)</span>.</p>
<p>También podemos expresar <span class="math inline">\(s^2\)</span> en términos de las sumas de cuadrados. Es decir,</p>
<p><span class="math display">\[\begin{equation*}
s^2=\frac{1}{n-2}\sum_{i=1}^{n}\left( y_i-\widehat{y}_i\right) ^2=
\frac{Error~SS}{n-2}=MSE.
\end{equation*}\]</span></p>
<p>Esto nos lleva a la <em>tabla de análisis de varianza</em> o <em>ANOVA</em>:</p>
<p><span class="math display">\[
{\small
\begin{array}{llcl}
\hline \hline
\text{Tabla ANOVA} \\ \hline
\text{Fuente} &amp; \text{Suma de Cuadrados} &amp; df &amp; \text{Cuadrado Medio} \\ \hline
\text{Regresión} &amp; Regression~SS &amp; 1 &amp; Regression~MS \\
\text{Error} &amp; Error~SS &amp; n-2 &amp; MSE \\
\text{Total} &amp; Total~SS &amp; n-1 &amp;  \\ \hline \hline
\end{array}
}
\]</span></p>
<p>La tabla ANOVA es simplemente un dispositivo de contabilidad utilizado para
hacer un seguimiento de las fuentes de variabilidad; aparece rutinariamente en
paquetes de software estadístico como parte de los resultados de la regresión. Las
figuras de la columna de cuadrados medios se definen como las sumas de cuadrados
(<span class="math inline">\(SS\)</span>) divididas por sus respectivos grados de libertad
(<span class="math inline">\(df\)</span>). En particular, el cuadrado medio de los errores (<span class="math inline">\(MSE\)</span>) es igual a
<span class="math inline">\(s^2\)</span> y la suma de cuadrados de la regresión es igual al cuadrado medio de la regresión. Esta última propiedad es específica para la regresión con una variable; no es cierta cuando consideramos más de una
variable explicativa.</p>
<p>Los grados de libertad del error en la tabla ANOVA son <span class="math inline">\(n-2\)</span>. Los grados de libertad totales son <span class="math inline">\(n-1\)</span>, lo que refleja el hecho de que la suma total de cuadrados se centra en la media (se requieren al menos dos observaciones para una variabilidad positiva). El grado de libertad único asociado con la parte de regresión significa que la pendiente, más una observación, es suficiente información para
determinar la línea. Esto se debe a que se necesitan dos observaciones para determinar una línea y al menos tres observaciones para que haya alguna variabilidad alrededor de la línea.</p>
<p>La tabla de análisis de varianza para los datos de la lotería es:</p>
<table class="table lightable-classic" style="width: auto !important; margin-left: auto; margin-right: auto; font-size: 12px; font-family: Cambria; margin-left: auto; margin-right: auto;">
<thead>
<tr>
<th style="text-align:left;">
</th>
<th style="text-align:right;">
Suma de Cuadrados
</th>
<th style="text-align:right;">
<span class="math inline">\(df\)</span>
</th>
<th style="text-align:right;">
Cuadrado Medio
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">
Regresión
</td>
<td style="text-align:right;">
2,527,165,015
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
2,527,165,015
</td>
</tr>
<tr>
<td style="text-align:left;">
Error
</td>
<td style="text-align:right;">
690,116,755
</td>
<td style="text-align:right;">
48
</td>
<td style="text-align:right;">
14,377,432
</td>
</tr>
<tr>
<td style="text-align:left;">
Total
</td>
<td style="text-align:right;">
3,217,281,770
</td>
<td style="text-align:right;">
49
</td>
<td style="text-align:right;">
</td>
</tr>
</tbody>
</table>
<h5 style="text-align: center;">
<a id="displayCode.LotANOVA.Hide" href="javascript:togglecode('toggleCode.LotANOVA.Hide','displayCode.LotANOVA.Hide');"><i><strong>Código R para Producir la Tabla ANOVA de Lotería</strong></i></a>
</h5>
<div id="toggleCode.LotANOVA.Hide" style="display: none">
<div class="sourceCode" id="cb11"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb11-1"><a href="C2BasicLR.html#cb11-1" tabindex="-1"></a><span class="co">#Lot &lt;- read.csv(&quot;CSVData/WiscLottery.csv&quot;, header=TRUE)</span></span>
<span id="cb11-2"><a href="C2BasicLR.html#cb11-2" tabindex="-1"></a></span>
<span id="cb11-3"><a href="C2BasicLR.html#cb11-3" tabindex="-1"></a>model.basiclinearreg<span class="ot">&lt;-</span><span class="fu">lm</span>(Lot<span class="sc">$</span>SALES <span class="sc">~</span> Lot<span class="sc">$</span>POP)</span>
<span id="cb11-4"><a href="C2BasicLR.html#cb11-4" tabindex="-1"></a><span class="co">#summary(model.basiclinearreg)</span></span>
<span id="cb11-5"><a href="C2BasicLR.html#cb11-5" tabindex="-1"></a>ANOVA <span class="ot">&lt;-</span> <span class="fu">anova</span>(model.basiclinearreg)</span>
<span id="cb11-6"><a href="C2BasicLR.html#cb11-6" tabindex="-1"></a>row1 <span class="ot">&lt;-</span> <span class="fu">c</span>(ANOVA<span class="sc">$</span><span class="st">`</span><span class="at">Sum Sq</span><span class="st">`</span>[<span class="dv">1</span>], ANOVA<span class="sc">$</span><span class="st">`</span><span class="at">Df</span><span class="st">`</span>[<span class="dv">1</span>], ANOVA<span class="sc">$</span><span class="st">`</span><span class="at">Mean Sq</span><span class="st">`</span>[<span class="dv">1</span>])</span>
<span id="cb11-7"><a href="C2BasicLR.html#cb11-7" tabindex="-1"></a>row2 <span class="ot">&lt;-</span> <span class="fu">c</span>(ANOVA<span class="sc">$</span><span class="st">`</span><span class="at">Sum Sq</span><span class="st">`</span>[<span class="dv">2</span>], ANOVA<span class="sc">$</span><span class="st">`</span><span class="at">Df</span><span class="st">`</span>[<span class="dv">2</span>], ANOVA<span class="sc">$</span><span class="st">`</span><span class="at">Mean Sq</span><span class="st">`</span>[<span class="dv">2</span>])</span>
<span id="cb11-8"><a href="C2BasicLR.html#cb11-8" tabindex="-1"></a>row3 <span class="ot">&lt;-</span> <span class="fu">c</span>(ANOVA<span class="sc">$</span><span class="st">`</span><span class="at">Sum Sq</span><span class="st">`</span>[<span class="dv">1</span>]<span class="sc">+</span>ANOVA<span class="sc">$</span><span class="st">`</span><span class="at">Sum Sq</span><span class="st">`</span>[<span class="dv">2</span>], </span>
<span id="cb11-9"><a href="C2BasicLR.html#cb11-9" tabindex="-1"></a>          ANOVA<span class="sc">$</span><span class="st">`</span><span class="at">Df</span><span class="st">`</span>[<span class="dv">1</span>] <span class="sc">+</span>ANOVA<span class="sc">$</span><span class="st">`</span><span class="at">Df</span><span class="st">`</span>[<span class="dv">2</span>], <span class="cn">NaN</span>)</span>
<span id="cb11-10"><a href="C2BasicLR.html#cb11-10" tabindex="-1"></a>ANOVATable <span class="ot">&lt;-</span> <span class="fu">rbind</span>(row1, row2, row3)</span>
<span id="cb11-11"><a href="C2BasicLR.html#cb11-11" tabindex="-1"></a>ANOVATable1 <span class="ot">&lt;-</span> <span class="fu">format</span>(<span class="fu">round</span>(ANOVATable, <span class="at">digits =</span> <span class="dv">0</span>), <span class="at">big.mark =</span> <span class="st">&#39;,&#39;</span>)</span>
<span id="cb11-12"><a href="C2BasicLR.html#cb11-12" tabindex="-1"></a>ANOVATable1[<span class="dv">3</span>,<span class="dv">3</span>] <span class="ot">&lt;-</span> <span class="st">&quot;&quot;</span></span>
<span id="cb11-13"><a href="C2BasicLR.html#cb11-13" tabindex="-1"></a><span class="fu">rownames</span>(ANOVATable1) <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="st">&quot;Regresión&quot;</span>, <span class="st">&quot;Error&quot;</span>, <span class="st">&quot;Total&quot;</span>)</span>
<span id="cb11-14"><a href="C2BasicLR.html#cb11-14" tabindex="-1"></a><span class="fu">colnames</span>(ANOVATable1) <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="st">&quot;Suma de Cuadrados&quot;</span>, <span class="st">&quot;$df$&quot;</span>, <span class="st">&quot;Cuadrado Medio&quot;</span>)</span>
<span id="cb11-15"><a href="C2BasicLR.html#cb11-15" tabindex="-1"></a></span>
<span id="cb11-16"><a href="C2BasicLR.html#cb11-16" tabindex="-1"></a><span class="fu">kable</span>(ANOVATable1, <span class="at">align =</span> <span class="st">&#39;r&#39;</span>) <span class="sc">%&gt;%</span></span>
<span id="cb11-17"><a href="C2BasicLR.html#cb11-17" tabindex="-1"></a>  <span class="fu">kable_styling</span>(<span class="at">position =</span> <span class="st">&quot;center&quot;</span>, <span class="at">full_width =</span> <span class="cn">FALSE</span>) <span class="sc">%&gt;%</span></span>
<span id="cb11-18"><a href="C2BasicLR.html#cb11-18" tabindex="-1"></a>     kableExtra<span class="sc">::</span><span class="fu">kable_classic</span>(<span class="at">font =</span> <span class="dv">12</span>,  </span>
<span id="cb11-19"><a href="C2BasicLR.html#cb11-19" tabindex="-1"></a>                               <span class="at">html_font =</span> <span class="st">&quot;Cambria&quot;</span>) </span></code></pre></div>
</div>
<p>De esta tabla, puede verificar que <span class="math inline">\(R^2=78.5\%\)</span> y <span class="math inline">\(s=3,792.\)</span></p>
</div>
</div>
<div id="Sec24" class="section level2 hasAnchor" number="2.4">
<h2><span class="header-section-number">2.4</span> Propiedades de los Estimadores del Coeficiente de Regresión<a href="C2BasicLR.html#Sec24" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Las estimaciones de mínimos cuadrados se pueden expresar como una suma ponderada de las respuestas. Para ver esto, define los pesos
<span class="math display">\[\begin{equation*}
w_i=\frac{x_i-\overline{x}}{s_x^2(n-1)}.
\end{equation*}\]</span>
Como la suma de las desviaciones de <span class="math inline">\(x\)</span> (<span class="math inline">\(x_i-\overline{x}\)</span>) es cero, vemos que <span class="math inline">\(\sum_{i=1}^{n}w_i=0\)</span>. Así, podemos expresar la estimación de la pendiente
<span class="math display" id="eq:eq24">\[\begin{equation}
b_1=r\frac{s_y}{s_x}=\frac{1}{(n-1)s_x^2}\sum_{i=1}^{n}\left(
x_i-\overline{x}\right) \left( y_i-\overline{y}\right)
=\sum_{i=1}^{n}w_i\left( y_i-\overline{y}\right)
=\sum_{i=1}^{n}w_iy_i.
\tag{2.4}
\end{equation}\]</span></p>
<p>Los ejercicios piden al lector verificar que <span class="math inline">\(b_0\)</span> también puede expresarse como una suma ponderada de las respuestas, por lo que nuestra discusión se refiere a ambos coeficientes de regresión. Dado que los coeficientes de regresión son sumas ponderadas de respuestas, pueden verse afectados drásticamente por observaciones inusuales (ver Sección <a href="C2BasicLR.html#Sec26">2.6</a>).</p>
<p>Como <span class="math inline">\(b_1\)</span> es una suma ponderada, es sencillo derivar la esperanza y la varianza de esta estadística. Por la linealidad de las esperanzas y la Suposición F1, tenemos
<span class="math display">\[\begin{equation*}
\mathrm{E}~b_1=\sum_{i=1}^{n}w_i~\mathrm{E}~y_i=\beta_0\sum_{i=1}^{n}w_i+\beta_1\sum_{i=1}^{n}w_ix_i=\beta_1.
\end{equation*}\]</span>
Es decir, <span class="math inline">\(b_1\)</span> es un estimador imparcial de <span class="math inline">\(\beta_1\)</span>. Aquí, la suma <span class="math inline">\(\sum_{i=1}^{n}w_ix_i\)</span> <span class="math inline">\(=\)</span> <span class="math inline">\(\left[ s_x^2(n-1)\right] ^{-1}\sum_{i=1}^{n}\left( x_i-\overline{x}\right) x_i\)</span> <span class="math inline">\(=\left[s_x^2(n-1)\right] ^{-1}\sum_{i=1}^{n}\left( x_i-\overline{x}\right) ^2=1.\)</span> A partir de la definición de los pesos, una sencilla algebra también muestra que <span class="math inline">\(\sum_{i=1}^{n}w_i^2=1/\left( s_x^2(n-1)\right)\)</span>. Además, la independencia de las respuestas implica que la varianza de la suma es la suma de las varianzas, y así tenemos
<span class="math display">\[\begin{equation*}
\mathrm{Var}~b_1
=\sum_{i=1}^{n}w_i^2\mathrm{Var}~y_i=\frac{\sigma^2}{s_x^2(n-1)}.
\end{equation*}\]</span>
Sustituyendo <span class="math inline">\(\sigma ^2\)</span> por su estimador <span class="math inline">\(s^2\)</span> y tomando raíces cuadradas se obtiene lo siguiente.</p>
<div class="blackbox">
<p><em>Definición</em>. El <em>error estándar</em> de <span class="math inline">\(b_1\)</span>, la desviación estándar estimada de <span class="math inline">\(b_1\)</span>, se define como
<span class="math display" id="eq:eq25">\[\begin{equation}
se(b_1)=\frac{s}{s_x\sqrt{n-1}}.
\tag{2.5}
\end{equation}\]</span></p>
</div>
<p>Esta es nuestra medida de la fiabilidad, o precisión, del estimador de la pendiente. Usando la ecuación <a href="C2BasicLR.html#eq:eq25">(2.5)</a>, vemos que <span class="math inline">\(se(b_1)\)</span> está determinado por tres cantidades: <span class="math inline">\(n\)</span>, <span class="math inline">\(s\)</span> y <span class="math inline">\(s_x\)</span>, de la siguiente manera:</p>
<ul>
<li>Si tenemos más observaciones, de manera que <span class="math inline">\(n\)</span> sea mayor, entonces <span class="math inline">\(se(b_1)\)</span> será menor, manteniendo todo lo demás constante.</li>
<li>Si las observaciones tienen una mayor tendencia a estar más cerca de la línea, de manera que <span class="math inline">\(s\)</span> sea menor, entonces <span class="math inline">\(se(b_1)\)</span> será menor, manteniendo todo lo demás constante.</li>
<li>Si los valores de la variable explicativa están más dispersos, de manera que <span class="math inline">\(s_x\)</span> aumenta, entonces <span class="math inline">\(se(b_1)\)</span> será menor, manteniendo todo lo demás constante.</li>
</ul>
<p>Valores menores de <span class="math inline">\(se(b_1)\)</span> ofrecen una mejor oportunidad para detectar relaciones entre <span class="math inline">\(y\)</span> y <span class="math inline">\(x\)</span>. La Figura <a href="C2BasicLR.html#fig:Fig26">2.6</a> ilustra estas relaciones. Aquí, el diagrama de dispersión en el medio tiene el valor más pequeño de <span class="math inline">\(se(b_1)\)</span>. Comparado con el gráfico del medio, el gráfico de la izquierda tiene un valor mayor de <span class="math inline">\(s\)</span> y por lo tanto <span class="math inline">\(se(b_1)\)</span>. Comparado con el gráfico de la derecha, el gráfico del medio tiene un valor mayor de <span class="math inline">\(s_x\)</span>, y por lo tanto un valor menor de <span class="math inline">\(se(b_1)\)</span>.</p>

<div class="figure" style="text-align: center"><span style="display:block;" id="fig:Fig26"></span>
<img src="RegressionMarkdown_files/figure-html/Fig26-1.png" alt="Estos tres diagramas de dispersión muestran la misma relación lineal entre \(y\) y \(x\). El gráfico a la izquierda muestra una mayor variabilidad alrededor de la línea que el gráfico del medio. El gráfico a la derecha muestra una desviación estándar menor en \(x\) que el gráfico del medio." width="100%" />
<p class="caption">
Figura 2.6: <strong>Estos tres diagramas de dispersión muestran la misma relación lineal entre <span class="math inline">\(y\)</span> y <span class="math inline">\(x\)</span>.</strong> El gráfico a la izquierda muestra una mayor variabilidad alrededor de la línea que el gráfico del medio. El gráfico a la derecha muestra una desviación estándar menor en <span class="math inline">\(x\)</span> que el gráfico del medio.
</p>
</div>
<h5 style="text-align: center;">
<a id="displayCode.Fig26.Hide" href="javascript:togglecode('toggleCode.Fig26.Hide','displayCode.Fig26.Hide');"><i><strong>Código R para producir la Figura 2.6</strong></i></a>
</h5>
<div id="toggleCode.Fig26.Hide" style="display: none">
<div class="sourceCode" id="cb12"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb12-1"><a href="C2BasicLR.html#cb12-1" tabindex="-1"></a><span class="co">#  FIGURA 2.6 AQUÍ</span></span>
<span id="cb12-2"><a href="C2BasicLR.html#cb12-2" tabindex="-1"></a></span>
<span id="cb12-3"><a href="C2BasicLR.html#cb12-3" tabindex="-1"></a><span class="fu">par</span>(<span class="at">mfrow=</span><span class="fu">c</span>(<span class="dv">1</span>, <span class="dv">3</span>),<span class="at">mar=</span><span class="fu">c</span>(<span class="fl">3.8</span>,<span class="fl">2.8</span>,<span class="dv">1</span>,<span class="dv">1</span>), <span class="at">cex=</span><span class="fl">1.3</span>)</span>
<span id="cb12-4"><a href="C2BasicLR.html#cb12-4" tabindex="-1"></a>x <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="dv">1</span>,<span class="dv">2</span>,<span class="fl">2.3</span>,<span class="fl">2.5</span>,<span class="fl">1.5</span>,<span class="fl">1.7</span>,<span class="fl">2.6</span>,<span class="fl">2.8</span>,.<span class="dv">9</span>,.<span class="dv">88</span>,.<span class="dv">8</span>,<span class="fl">1.2</span>,<span class="fl">1.3</span>,<span class="fl">1.45</span>,<span class="fl">1.8</span>,<span class="fl">2.2</span>,<span class="fl">2.1</span>)</span>
<span id="cb12-5"><a href="C2BasicLR.html#cb12-5" tabindex="-1"></a>y <span class="ot">&lt;-</span> <span class="fu">c</span>(.<span class="dv">5</span>,<span class="fl">2.2</span>,<span class="fl">2.6</span>,<span class="fl">2.5</span>,.<span class="dv">8</span>,<span class="fl">1.5</span>,<span class="fl">2.3</span>,<span class="fl">2.4</span>,.<span class="dv">75</span>,.<span class="dv">7</span>,<span class="fl">1.3</span>,<span class="fl">1.5</span>,<span class="fl">1.7</span>,<span class="fl">2.3</span>,<span class="fl">2.3</span>,<span class="fl">2.7</span>,<span class="fl">1.25</span>)</span>
<span id="cb12-6"><a href="C2BasicLR.html#cb12-6" tabindex="-1"></a><span class="fu">plot</span>(x,y, <span class="at">xlim=</span><span class="fu">c</span>(<span class="fl">0.5</span>,<span class="dv">3</span>), <span class="at">ylim=</span><span class="fu">c</span>(<span class="dv">0</span>,<span class="fl">3.5</span>), <span class="at">bty=</span><span class="st">&quot;l&quot;</span>, <span class="at">xaxt=</span><span class="st">&quot;n&quot;</span>, <span class="at">yaxt=</span><span class="st">&quot;n&quot;</span>, <span class="at">ylab=</span><span class="st">&quot;&quot;</span>, <span class="at">xlab=</span><span class="st">&quot;&quot;</span>)</span>
<span id="cb12-7"><a href="C2BasicLR.html#cb12-7" tabindex="-1"></a><span class="fu">mtext</span>(<span class="st">&quot;y&quot;</span>, <span class="at">side=</span><span class="dv">2</span>, <span class="at">at=</span><span class="fl">3.5</span>, <span class="at">line=</span><span class="dv">2</span>, <span class="at">las=</span><span class="dv">1</span>, <span class="at">cex=</span><span class="fl">1.3</span>)</span>
<span id="cb12-8"><a href="C2BasicLR.html#cb12-8" tabindex="-1"></a><span class="fu">mtext</span>(<span class="st">&quot;x&quot;</span>, <span class="at">side=</span><span class="dv">1</span>, <span class="at">line=</span><span class="dv">2</span>, <span class="at">cex=</span><span class="fl">1.3</span>)</span>
<span id="cb12-9"><a href="C2BasicLR.html#cb12-9" tabindex="-1"></a>a <span class="ot">&lt;-</span> <span class="fu">seq</span>(.<span class="dv">75</span>,<span class="fl">2.75</span>, <span class="at">by =</span> .<span class="dv">001</span>)</span>
<span id="cb12-10"><a href="C2BasicLR.html#cb12-10" tabindex="-1"></a>b <span class="ot">=</span> a</span>
<span id="cb12-11"><a href="C2BasicLR.html#cb12-11" tabindex="-1"></a><span class="fu">lines</span>(a,b)</span>
<span id="cb12-12"><a href="C2BasicLR.html#cb12-12" tabindex="-1"></a></span>
<span id="cb12-13"><a href="C2BasicLR.html#cb12-13" tabindex="-1"></a>x <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="dv">1</span>,<span class="dv">2</span>,<span class="fl">2.3</span>,<span class="fl">2.5</span>,<span class="fl">1.5</span>,<span class="fl">1.7</span>,<span class="fl">2.6</span>,<span class="fl">2.8</span>,.<span class="dv">9</span>,.<span class="dv">88</span>,.<span class="dv">8</span>,<span class="fl">1.2</span>,<span class="fl">1.3</span>,<span class="fl">1.45</span>,<span class="fl">1.8</span>,<span class="fl">2.2</span>,<span class="fl">2.45</span>)</span>
<span id="cb12-14"><a href="C2BasicLR.html#cb12-14" tabindex="-1"></a>y <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="dv">1</span>,<span class="dv">2</span>,<span class="fl">2.3</span>,<span class="fl">2.5</span>,<span class="fl">1.2</span>,<span class="fl">1.6</span>,<span class="fl">2.4</span>,<span class="fl">2.6</span>,<span class="fl">1.1</span>,<span class="fl">1.11</span>,<span class="fl">1.2</span>,<span class="fl">1.3</span>,<span class="fl">1.45</span>,<span class="fl">1.6</span>,<span class="fl">1.95</span>,<span class="fl">2.3</span>,<span class="fl">2.7</span>)</span>
<span id="cb12-15"><a href="C2BasicLR.html#cb12-15" tabindex="-1"></a><span class="fu">plot</span>(x,y, <span class="at">xlim=</span><span class="fu">c</span>(<span class="fl">0.5</span>,<span class="dv">3</span>), <span class="at">ylim=</span><span class="fu">c</span>(<span class="dv">0</span>,<span class="fl">3.5</span>), <span class="at">bty=</span><span class="st">&quot;l&quot;</span>, <span class="at">xaxt=</span><span class="st">&quot;n&quot;</span>, <span class="at">yaxt=</span><span class="st">&quot;n&quot;</span>, <span class="at">ylab=</span><span class="st">&quot;&quot;</span>, <span class="at">xlab=</span><span class="st">&quot;&quot;</span>)</span>
<span id="cb12-16"><a href="C2BasicLR.html#cb12-16" tabindex="-1"></a><span class="fu">mtext</span>(<span class="st">&quot;y&quot;</span>, <span class="at">side=</span><span class="dv">2</span>, <span class="at">at=</span><span class="fl">3.5</span>, <span class="at">line=</span><span class="dv">2</span>, <span class="at">las=</span><span class="dv">1</span>, <span class="at">cex=</span><span class="fl">1.3</span>)</span>
<span id="cb12-17"><a href="C2BasicLR.html#cb12-17" tabindex="-1"></a><span class="fu">mtext</span>(<span class="st">&quot;x&quot;</span>, <span class="at">side=</span><span class="dv">1</span>, <span class="at">line=</span><span class="dv">2</span>, <span class="at">cex=</span><span class="fl">1.3</span>)</span>
<span id="cb12-18"><a href="C2BasicLR.html#cb12-18" tabindex="-1"></a>a <span class="ot">&lt;-</span> <span class="fu">seq</span>(.<span class="dv">75</span>,<span class="fl">2.75</span>, <span class="at">by =</span> .<span class="dv">001</span>)</span>
<span id="cb12-19"><a href="C2BasicLR.html#cb12-19" tabindex="-1"></a>b <span class="ot">=</span> a</span>
<span id="cb12-20"><a href="C2BasicLR.html#cb12-20" tabindex="-1"></a><span class="fu">lines</span>(a,b)</span>
<span id="cb12-21"><a href="C2BasicLR.html#cb12-21" tabindex="-1"></a></span>
<span id="cb12-22"><a href="C2BasicLR.html#cb12-22" tabindex="-1"></a>x <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="dv">1</span>,<span class="dv">2</span>,<span class="fl">2.3</span>,<span class="fl">2.5</span>,<span class="fl">1.5</span>,<span class="fl">1.7</span>,<span class="fl">2.6</span>,<span class="fl">2.8</span>,<span class="fl">2.6</span>,<span class="fl">1.5</span>,<span class="dv">2</span>,<span class="fl">1.2</span>,<span class="fl">1.3</span>,<span class="fl">1.45</span>,<span class="fl">1.8</span>,<span class="fl">2.2</span>,<span class="fl">2.45</span>)</span>
<span id="cb12-23"><a href="C2BasicLR.html#cb12-23" tabindex="-1"></a>y <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="dv">1</span>,<span class="dv">2</span>,<span class="fl">2.3</span>,<span class="fl">2.5</span>,<span class="fl">1.2</span>,<span class="fl">1.6</span>,<span class="fl">2.4</span>,<span class="fl">2.6</span>,<span class="dv">2</span>,<span class="dv">2</span>,<span class="fl">2.4</span>,<span class="fl">1.3</span>,<span class="fl">1.55</span>,<span class="fl">1.6</span>,<span class="fl">1.95</span>,<span class="fl">1.6</span>,<span class="fl">2.7</span>)</span>
<span id="cb12-24"><a href="C2BasicLR.html#cb12-24" tabindex="-1"></a><span class="fu">plot</span>(x,y, <span class="at">xlim=</span><span class="fu">c</span>(<span class="sc">-</span><span class="fl">1.5</span>,<span class="dv">5</span>), <span class="at">ylim=</span><span class="fu">c</span>(<span class="sc">-</span><span class="dv">2</span>,<span class="fl">5.5</span>), <span class="at">bty=</span><span class="st">&quot;l&quot;</span>, <span class="at">xaxt=</span><span class="st">&quot;n&quot;</span>, <span class="at">yaxt=</span><span class="st">&quot;n&quot;</span>, <span class="at">ylab=</span><span class="st">&quot;&quot;</span>, <span class="at">xlab=</span><span class="st">&quot;&quot;</span>)</span>
<span id="cb12-25"><a href="C2BasicLR.html#cb12-25" tabindex="-1"></a><span class="fu">mtext</span>(<span class="st">&quot;y&quot;</span>, <span class="at">side=</span><span class="dv">2</span>, <span class="at">at=</span><span class="fl">5.1</span>, <span class="at">line=</span><span class="dv">2</span>, <span class="at">las=</span><span class="dv">1</span>, <span class="at">cex=</span><span class="fl">1.3</span>)</span>
<span id="cb12-26"><a href="C2BasicLR.html#cb12-26" tabindex="-1"></a><span class="fu">mtext</span>(<span class="st">&quot;x&quot;</span>, <span class="at">side=</span><span class="dv">1</span>, <span class="at">line=</span><span class="dv">2</span>, <span class="at">cex=</span><span class="fl">1.3</span>)</span>
<span id="cb12-27"><a href="C2BasicLR.html#cb12-27" tabindex="-1"></a>a <span class="ot">&lt;-</span> <span class="fu">seq</span>(<span class="sc">-</span>.<span class="dv">5</span>,<span class="fl">4.5</span>, <span class="at">by =</span> .<span class="dv">001</span>)</span>
<span id="cb12-28"><a href="C2BasicLR.html#cb12-28" tabindex="-1"></a>b <span class="ot">=</span> a</span>
<span id="cb12-29"><a href="C2BasicLR.html#cb12-29" tabindex="-1"></a><span class="fu">lines</span>(a,b)</span></code></pre></div>
</div>
<p>La ecuación <a href="C2BasicLR.html#eq:eq24">(2.4)</a> también implica que el coeficiente de regresión <span class="math inline">\(b_1\)</span> sigue una distribución normal. Es decir, recordemos de la estadística matemática que las combinaciones lineales de variables aleatorias normales también son normales. Así, si se cumple la Suposición F5, entonces <span class="math inline">\(b_1\)</span> sigue una distribución normal. Además, existen varias versiones de los teoremas del límite central para sumas ponderadas (ver, por ejemplo, Serfling, 1980). Así, como se discute en la Sección 1.4, si las respuestas <span class="math inline">\(y_i\)</span> están siquiera aproximadamente distribuidas normalmente, entonces será razonable usar una aproximación normal para la distribución muestral de <span class="math inline">\(b_1\)</span>. Usando <span class="math inline">\(se(b_1)\)</span> como la desviación estándar estimada de <span class="math inline">\(b_1\)</span>, para valores grandes de <span class="math inline">\(n\)</span> tenemos que <span class="math inline">\(\left( b_1-\beta_1\right) /se(b_1)\)</span> tiene una distribución normal estándar aproximada. Aunque no lo probaremos aquí, bajo la Suposición F5 <span class="math inline">\(\left( b_1-\beta_1\right) /se(b_1)\)</span> sigue una distribución <span class="math inline">\(t\)</span> con grados de libertad <span class="math inline">\(df=n-2\)</span>.</p>
</div>
<div id="Sec25" class="section level2 hasAnchor" number="2.5">
<h2><span class="header-section-number">2.5</span> Inferencia Estadística<a href="C2BasicLR.html#Sec25" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Una vez que hemos ajustado un modelo con un conjunto de datos, podemos hacer una serie de afirmaciones importantes. Generalmente, es útil pensar en estas afirmaciones en tres categorías: (i) pruebas de ideas hipotetizadas, (ii) estimaciones de parámetros del modelo y (iii) predicciones de nuevos resultados.</p>
<div id="Sec251" class="section level3 hasAnchor" number="2.5.1">
<h3><span class="header-section-number">2.5.1</span> ¿Es Importante la Variable Explicativa?: La Prueba <em>t</em><a href="C2BasicLR.html#Sec251" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Respondemos a la pregunta de si la variable explicativa es importante investigando si <span class="math inline">\(\beta_1=0\)</span>. La lógica es que si <span class="math inline">\(\beta_1=0\)</span>, entonces el modelo de regresión lineal básico ya no incluye una variable explicativa <span class="math inline">\(x\)</span>. Por lo tanto, traducimos nuestra pregunta sobre la importancia de la variable explicativa en una pregunta más específica que puede ser respondida utilizando el marco de pruebas de hipótesis. Esta pregunta más específica es: ¿es válida la hipótesis nula <span class="math inline">\(H_0:\beta_1=0\)</span>? Respondemos a esta pregunta observando la estadística de prueba:</p>
<div class="blackbox">
<p><span class="math display">\[
{\small
t-\mathrm{ratio}=\frac{\mathrm{valor~estimado~del~parámetro~-~valor~hipotetizado}}
{\mathrm{error~estándar~del~estimador}}.
}
\]</span></p>
</div>
<p>En el caso de <span class="math inline">\(H_0:\beta_1=0\)</span>, examinamos la razón <em>t</em> <span class="math inline">\(t(b_1)=b_1/se(b_1)\)</span> porque el valor hipotetizado de <span class="math inline">\(\beta_1\)</span> es 0. Esta es la estandarización apropiada porque, bajo la hipótesis nula y las suposiciones del modelo descritas en la Sección 2.4, la distribución muestral de <span class="math inline">\(t(b_1)\)</span> se puede demostrar que sigue una distribución <em>t</em> con <span class="math inline">\(df=n-2\)</span> grados de libertad. Así, para probar la hipótesis nula <span class="math inline">\(H_0\)</span> contra la alternativa <span class="math inline">\(H_{a}:\beta_1\neq 0\)</span>, rechazamos <span class="math inline">\(H_0\)</span> a favor de <span class="math inline">\(H_{a}\)</span> si <span class="math inline">\(|t(b_1)|\)</span> excede un valor <em>t</em>. Aquí, este valor <em>t</em> es un percentil de la distribución <em>t</em> usando <span class="math inline">\(df=n-2\)</span> grados de libertad. Denotamos el nivel de significancia como <span class="math inline">\(\alpha\)</span> y este valor <em>t</em> como <span class="math inline">\(t_{n-2,1-\alpha /2}\)</span>.</p>
<hr />
<p><strong>Ejemplo: Ventas de Lotería - Continuación.</strong> Para el ejemplo de ventas de lotería, la desviación estándar residual es <span class="math inline">\(s=3,792\)</span>. En la Tabla <a href="C2BasicLR.html#tab:Tab21">2.1</a>, tenemos <span class="math inline">\(s_x = 11,098\)</span>. Por lo tanto, el error estándar de la pendiente es <span class="math inline">\(se(b_1) = 3792/(11098\sqrt{50-1})=0.0488\)</span>. Según la Sección 2.1, la estimación de la pendiente es <span class="math inline">\(b_1=0.647\)</span>. Por lo tanto, la estadística <em>t</em> es <span class="math inline">\(t(b_1) = 0.647/0.0488 = 13.4\)</span>. Interpretamos esto diciendo que la pendiente está 13.4 errores estándar por encima de cero. Para el nivel de significancia, usamos el valor habitual de <span class="math inline">\(\alpha\)</span> = 5%. El percentil 97.5 de una distribución <em>t</em> con <span class="math inline">\(df=50-2=48\)</span> grados de libertad es <span class="math inline">\(t_{48,0.975}=2.011\)</span>. Dado que <span class="math inline">\(|13.4|&gt;2.011\)</span>, rechazamos la hipótesis nula de que la pendiente <span class="math inline">\(\beta_1 = 0\)</span> a favor de la alternativa de que <span class="math inline">\(\beta_1 \neq 0\)</span>.</p>
<hr />
<p>Tomar decisiones comparando una razón <em>t</em> con un valor <em>t</em> se llama una <em>prueba t</em>. Probar <span class="math inline">\(H_0:\beta_1=0\)</span> frente a <span class="math inline">\(H_{a}:\beta_1\neq 0\)</span> es solo una de las muchas pruebas de hipótesis que se pueden realizar, aunque es la más común. <a href="C2BasicLR.html#Table23">Tabla 2.3</a> describe procedimientos alternativos para la toma de decisiones. Estos procedimientos son para probar <span class="math inline">\(H_0:\beta_1 = d\)</span> donde <span class="math inline">\(d\)</span> es un valor prescrito por el usuario que puede ser igual a cero o cualquier otro valor conocido. Por ejemplo, en nuestro ejemplo de la Sección 2.7, usaremos <span class="math inline">\(d=1\)</span> para probar teorías financieras sobre el mercado de valores.</p>
<p><a id=Table23></a></p>
<p><span id="Table23">Tabla 2.3</span> <strong>Procedimientos de Toma de Decisiones para Probar <span class="math inline">\(H_0:\beta_1 = d\)</span></strong></p>
<p><span class="math display">\[
{\small
\begin{array}{c|c}
\hline \text{Hipótesis Alternativa} (H_{a}) &amp; \text{Procedimiento: Rechazar } H_0 \text{ a favor de }  H_{a} \text{ si} \\ \hline
\beta_1&gt;d &amp; t-\mathrm{ratio}&gt;t_{n-2,1-\alpha }. \\
\beta_1&lt;d &amp; t-\mathrm{ratio}&lt;-t_{n-2,1-\alpha }. \\
\beta_1\neq d &amp; |t-\mathrm{ratio}\mathit{|}&gt;t_{n-2,1-\alpha /2}. \\
\end{array} }\\
{\small
\begin{array}{l}
\hline \text{Notas: El nivel de significancia es } \alpha . \text{Aquí, }t_{n-2,1-\alpha} \text{ es el percentil } (1-\alpha )\\
~~\text{de la distribución *t* con } df=n-2 \text{ grados de libertad.}\\
~~\text{La estadística de prueba es }t-\mathrm{ratio} = (b_1 -d)/se(b_1) . \\  \hline
\end{array}
}
\]</span></p>
<p>Alternativamente, se pueden construir valores de probabilidad (<span class="math inline">\(p\)</span>-) y compararlos con los niveles de significancia dados. El valor <span class="math inline">\(p\)</span>- es una estadística resumen útil para el analista de datos ya que permite al lector del informe entender la fuerza de la desviación de la hipótesis nula. <a href="C2BasicLR.html#Table24">Tabla 2.4</a> resume el procedimiento para calcular los valores <span class="math inline">\(p\)</span>-.</p>
<p><a id=Table24></a></p>
<p><span id="Table24">Tabla 2.4</span> <strong>Valores de Probabilidad para Probar <span class="math inline">\(H_0:\beta_1 = d\)</span></strong></p>
<p><span class="math display">\[
{\small
\begin{array}{c|ccc}
\hline
\text{Hipótesis} &amp;  &amp;  &amp;  \\
\text{Alternativa} (H_a) &amp; \beta_1&gt;d &amp; \beta_1&lt;d &amp; \beta_1\neq d
\\ \hline
p-value &amp; \Pr(t_{n-2}&gt;t-\mathrm{ratio}) &amp;
\Pr(t_{n-2}&lt;t-\mathrm{ratio}) &amp; \Pr
(|t_{n-2}|&gt;|t-\mathrm{ratio}\mathit{|}) \\\hline
\end{array} }\\
{\small
\begin{array}{l}
\hline \text{Notas: Aquí, }t_{n-2} \text{ es una variable aleatoria distribuida como *t* con } df=n-2 \text{ grados de libertad.}\\
~~\text{La estadística de prueba es }t-\mathrm{ratio} = (b_1 -d)/se(b_1) . \\  \hline
\end{array}
}
\]</span></p>
<p>Otra forma interesante de abordar la cuestión de la importancia de una variable explicativa es a través del coeficiente de correlación. Recuerda que el coeficiente de correlación es una medida de la relación lineal entre <span class="math inline">\(x\)</span> e <span class="math inline">\(y\)</span>. Denotemos esta estadística por <span class="math inline">\(r(y,x)\)</span>. Esta cantidad no se ve afectada por cambios de escala en ninguna de las variables. Por ejemplo, si multiplicamos la variable <span class="math inline">\(x\)</span> por el número <span class="math inline">\(b_1\)</span>, entonces el coeficiente de correlación permanece sin cambios. Además, las correlaciones no cambian con los desplazamientos aditivos. Así, si agregamos un número, digamos <span class="math inline">\(b_0\)</span>, a cada variable <span class="math inline">\(x\)</span>, entonces el coeficiente de correlación permanece sin cambios. Usar un cambio de escala y un desplazamiento aditivo en la variable <span class="math inline">\(x\)</span> puede utilizarse para producir el valor ajustado <span class="math inline">\(\widehat{y}=b_0+b_1x\)</span>. Por lo tanto, usando la notación, tenemos <span class="math inline">\(|r(y,x)|=r(y,\widehat{y})\)</span>. Así, podemos interpretar que la correlación entre las respuestas y la variable explicativa es igual a la correlación entre las respuestas y los valores ajustados. Esto lleva al siguiente hecho algebraico interesante: <span class="math inline">\(R^2=r^2.\)</span> Es decir, el coeficiente de determinación es igual al cuadrado del coeficiente de correlación. Esto es mucho más fácil de interpretar si uno piensa en <span class="math inline">\(r\)</span> como la correlación entre los valores observados y los ajustados. Consulta el Ejercicio 2.13 para los pasos útiles para confirmar este resultado.</p>
</div>
<div id="Sec252" class="section level3 hasAnchor" number="2.5.2">
<h3><span class="header-section-number">2.5.2</span> Intervalos de Confianza<a href="C2BasicLR.html#Sec252" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Los investigadores a menudo citan el mecanismo formal de pruebas de hipótesis para responder a la pregunta: “¿Tiene la variable explicativa una influencia real en la respuesta?” Una pregunta de seguimiento natural es: “¿En qué medida afecta <span class="math inline">\(x\)</span> a <span class="math inline">\(y\)</span>?” Hasta cierto punto, se puede responder utilizando el tamaño del <span class="math inline">\(t\)</span>-ratio o el valor de <span class="math inline">\(p\)</span>. Sin embargo, en muchos casos, un <em>intervalo de confianza</em> para la pendiente es más útil.</p>
<p>Para introducir los intervalos de confianza para la pendiente, recordemos que <span class="math inline">\(b_1\)</span> es nuestro estimador puntual de la verdadera pendiente desconocida <span class="math inline">\(\beta_1\)</span>. La Sección 2.4 argumentó que este estimador tiene un error estándar <span class="math inline">\(se(b_1)\)</span> y que <span class="math inline">\(\left( b_1-\beta_1\right) /se(b_1)\)</span> sigue una distribución <span class="math inline">\(t\)</span> con <span class="math inline">\(n-2\)</span> grados de libertad. Las declaraciones de probabilidad se pueden invertir para obtener intervalos de confianza. Usando esta lógica, tenemos el siguiente intervalo de confianza para la pendiente <span class="math inline">\(\beta_1\)</span>.</p>
<div class="blackbox">
<p><em>Definición</em>. Un intervalo de confianza del <span class="math inline">\(100(1-\alpha)\)</span>% para la pendiente <span class="math inline">\(\beta_1\)</span> es
<span class="math display" id="eq:eq26">\[\begin{equation}
b_1\pm t_{n-2,1-\alpha /2} ~se(b_1).
\tag{2.6}
\end{equation}\]</span></p>
</div>
<p>Al igual que con las pruebas de hipótesis, <span class="math inline">\(t_{n-2,1-\alpha /2}\)</span> es el percentil (1-<span class="math inline">\(\alpha\)</span> /2) de la distribución <span class="math inline">\(t\)</span> con <span class="math inline">\(df=n-2\)</span> grados de libertad. Debido a la naturaleza bilateral de los intervalos de confianza, el percentil es 1 - (1 - nivel de confianza) / 2. En este texto, por simplicidad, generalmente usamos un intervalo de confianza del 95%, por lo que el percentil es 1-(1-0.95)/2 = 0.975. El intervalo de confianza proporciona un rango de confiabilidad que mide la utilidad de la estimación.</p>
<p>En la Sección 2.1, establecimos que la estimación de la pendiente por mínimos cuadrados para el ejemplo de ventas de lotería es <span class="math inline">\(b_1=0.647\)</span>. La interpretación es que si la población de un código postal difiere en 1,000, entonces esperamos que las ventas promedio de lotería difieran en $647. ¿Qué tan confiable es esta estimación? Resulta que <span class="math inline">\(se(b_1)=0.0488\)</span> y, por lo tanto, un intervalo de confianza aproximado del 95% para la pendiente es
<span class="math display">\[\begin{equation*}
0.647\pm (2.011)(.0488),
\end{equation*}\]</span>
o (0.549, 0.745). De manera similar, si la población difiere en 1,000, un intervalo de confianza del 95% para el cambio esperado en las ventas es (549, 745). Aquí, usamos el valor <span class="math inline">\(t\)</span> <span class="math inline">\(t_{48,0.975}=2.011\)</span> porque hay 48 (= <span class="math inline">\(n\)</span>-2) grados de libertad y, para un intervalo de confianza del 95%, necesitamos el percentil 97.5.</p>
</div>
<div id="Sec253" class="section level3 hasAnchor" number="2.5.3">
<h3><span class="header-section-number">2.5.3</span> Intervalos de Predicción<a href="C2BasicLR.html#Sec253" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>En la Sección 2.1, mostramos cómo usar los estimadores de mínimos cuadrados para predecir las ventas de lotería para un código postal, fuera de nuestra muestra, con una población de 10,000. Dado que la predicción es una tarea tan importante para los actuarios, formalizamos el procedimiento para que pueda ser utilizado regularmente.</p>
<p>Para predecir una observación adicional, asumimos que el nivel de la variable explicativa es conocido y se denota por <span class="math inline">\(x_{\ast}\)</span>. Por ejemplo, en nuestro ejemplo anterior de ventas de lotería usamos <span class="math inline">\(x_{\ast} = 10,000\)</span>. También asumimos que la observación adicional sigue el mismo modelo de regresión lineal que las observaciones en la muestra.</p>
<p>Usando nuestros estimadores de mínimos cuadrados, nuestra predicción puntual es
<span class="math inline">\(\widehat{y}_{\ast} = b_0 + b_1 x_{\ast}\)</span>, la altura de la línea de regresión ajustada en <span class="math inline">\(x_{\ast}\)</span>. Podemos descomponer el error de predicción en dos partes:</p>
<p><span class="math display">\[
\begin{array}{ccccc}
\underbrace{y_{\ast} - \widehat{y}_{\ast}} &amp; = &amp;
\underbrace{\beta_0 - b_0 + \left( \beta_1 - b_1 \right) x_{\ast}}
&amp; + &amp; \underbrace{\varepsilon_{\ast}} \\
{\small \text{error de predicción}} &amp; {\small =} &amp; {\small \text{error en la estimación de la }} &amp;
{\small +} &amp; {\small \text{desviación de la observación adicional}} \\
&amp;  &amp; {\small \text{línea de regresión en } x}_{\ast} &amp;  &amp; {\small
\text{respuesta de su media}}
\end{array}
\]</span></p>
<p>Se puede demostrar que el error estándar de la predicción es
<span class="math display">\[\begin{equation*}
se(pred) = s \sqrt{1+\frac{1}{n}+\frac{\left(
x_{\ast}-\overline{x}\right) ^2}{(n-1)s_x^2}}.
\end{equation*}\]</span>
Al igual que con <span class="math inline">\(se(b_1)\)</span>, los términos <span class="math inline">\(n^{-1}\)</span> y $(
x_{}- ) ^2/$ se acercan
a cero a medida que el tamaño de la muestra <span class="math inline">\(n\)</span> se vuelve grande. Por lo tanto, para grandes <span class="math inline">\(n\)</span>, tenemos que <span class="math inline">\(se(pred)\approx s\)</span>, lo que refleja que el error en
la estimación de la línea de regresión en un punto se vuelve insignificante y la
desviación de la respuesta adicional de su media se convierte en la
única fuente de incertidumbre.</p>
<div class="blackbox">
<p><em>Definición</em>. Un intervalo de predicción del <span class="math inline">\(100(1-\alpha)\)</span>% en <span class="math inline">\(x_{\ast}\)</span> es
<span class="math display" id="eq:eq27">\[\begin{equation}
\widehat{y}_{\ast} \pm t_{n-2,1-\alpha /2} ~se(pred)
\tag{2.7}
\end{equation}\]</span>
donde el valor <span class="math inline">\(t\)</span> <span class="math inline">\(t_{n-2,1-\alpha /2}\)</span> es el mismo que se usa para la prueba de hipótesis y el intervalo de confianza.</p>
</div>
<p>Por ejemplo, la predicción puntual en <span class="math inline">\(x_{\ast} = 10,000\)</span> es <span class="math inline">\(\widehat{y}_{\ast}\)</span>= 469.7 + 0.647 (10000) = 6,939.7. El error estándar de esta predicción es
<span class="math display">\[\begin{equation*}
se(pred) = 3,792 \sqrt{1+\frac{1}{50} + \frac{\left(
10,000-9,311\right)^2}{(50-1)(11,098)^2}} = 3,829.6.
\end{equation*}\]</span>
Con un valor <span class="math inline">\(t\)</span> igual a 2.011, esto da lugar a un intervalo de predicción aproximado del 95%
<span class="math display">\[\begin{equation*}
6,939.7 \pm (2.011)(3,829.6) = 6,939.7 \pm 7,701.3 = (-761.6,
~14,641.0).
\end{equation*}\]</span>
Interpretamos estos resultados señalando primero que nuestra mejor estimación de ventas de lotería para un código postal con una población de 10,000 es 6,939.70. Nuestro intervalo de predicción del 95% representa un rango de confiabilidad para esta predicción. Si pudiéramos observar muchos códigos postales, cada uno con una población de 10,000, en promedio esperaríamos que aproximadamente 19 de cada 20, o el 95%, tendrían ventas de lotería entre 0 y 14,641. Es habitual truncar el límite inferior del intervalo de predicción a cero si se considera que los valores negativos de la respuesta son inapropiados.</p>
<h5 style="text-align: center;">
<a id="displayCode.Section25.Hide" href="javascript:togglecode('toggleCode.Section25.Hide','displayCode.Section25.Hide');"><i><strong>Código R para producir los análisis de la Sección 2.5</strong></i></a>
</h5>
<div id="toggleCode.Section25.Hide" style="display: none">
<div class="sourceCode" id="cb13"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb13-1"><a href="C2BasicLR.html#cb13-1" tabindex="-1"></a><span class="co">#  RESULTADOS DE LA SECCIÓN 2.1</span></span>
<span id="cb13-2"><a href="C2BasicLR.html#cb13-2" tabindex="-1"></a>model.basiclinearreg<span class="ot">&lt;-</span><span class="fu">lm</span>(SALES <span class="sc">~</span> POP, <span class="at">data =</span> Lot)</span>
<span id="cb13-3"><a href="C2BasicLR.html#cb13-3" tabindex="-1"></a><span class="fu">summary</span>(model.basiclinearreg)</span>
<span id="cb13-4"><a href="C2BasicLR.html#cb13-4" tabindex="-1"></a></span>
<span id="cb13-5"><a href="C2BasicLR.html#cb13-5" tabindex="-1"></a><span class="co">#  SECCIÓN 2.5.2 INTERVALOS DE CONFIANZA</span></span>
<span id="cb13-6"><a href="C2BasicLR.html#cb13-6" tabindex="-1"></a><span class="fu">confint</span>(model.basiclinearreg)</span>
<span id="cb13-7"><a href="C2BasicLR.html#cb13-7" tabindex="-1"></a><span class="fu">confint</span>(model.basiclinearreg, <span class="at">level=</span>.<span class="dv">90</span>)</span>
<span id="cb13-8"><a href="C2BasicLR.html#cb13-8" tabindex="-1"></a></span>
<span id="cb13-9"><a href="C2BasicLR.html#cb13-9" tabindex="-1"></a><span class="co">#  SECCIÓN 2.5.3 INTERVALOS DE PREDICCIÓN</span></span>
<span id="cb13-10"><a href="C2BasicLR.html#cb13-10" tabindex="-1"></a>newdata <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(POP <span class="ot">&lt;-</span> <span class="dv">10000</span>)</span>
<span id="cb13-11"><a href="C2BasicLR.html#cb13-11" tabindex="-1"></a><span class="fu">predict</span>(model.basiclinearreg, newdata, <span class="at">interval=</span><span class="st">&quot;prediction&quot;</span>)</span>
<span id="cb13-12"><a href="C2BasicLR.html#cb13-12" tabindex="-1"></a><span class="fu">predict</span>(model.basiclinearreg, newdata, <span class="at">interval=</span><span class="st">&quot;prediction&quot;</span>, <span class="at">level=</span>.<span class="dv">90</span>)</span>
<span id="cb13-13"><a href="C2BasicLR.html#cb13-13" tabindex="-1"></a><span class="co">#  PROPORCIONA EL PERCENTIL 97.5 DE UNA DISTRIBUCIÓN T, SOLO PARA COMPROBAR</span></span>
<span id="cb13-14"><a href="C2BasicLR.html#cb13-14" tabindex="-1"></a><span class="fu">qt</span>(.<span class="dv">975</span>, <span class="dv">48</span>)</span></code></pre></div>
</div>
</div>
</div>
<div id="Sec26" class="section level2 hasAnchor" number="2.6">
<h2><span class="header-section-number">2.6</span> Construyendo un Mejor Modelo: Análisis de Residuos<a href="C2BasicLR.html#Sec26" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Las disciplinas cuantitativas calibran modelos con datos. La estadística lleva esto un paso más allá, utilizando las discrepancias entre las suposiciones y los datos para mejorar la especificación del modelo. Examinaremos las suposiciones del modelo de la Sección 2.2 a la luz de los datos y utilizaremos cualquier desajuste para especificar un mejor modelo; este proceso se conoce como <em>verificación diagnóstica</em> (como cuando vas al médico y él o ella realiza pruebas diagnósticas para revisar tu salud).</p>
<p>Comenzaremos con la representación del error de la Sección 2.2. Bajo este conjunto de suposiciones, las desviaciones {<span class="math inline">\(\varepsilon_i\)</span>} son
idénticamente e independientemente distribuidas (i.i.d), y bajo
la suposición F5, distribuidas normalmente. Para evaluar la validez de estas
suposiciones, se usan los residuos (observados) {<span class="math inline">\(e_i\)</span>} como
aproximaciones para las desviaciones (no observadas) {<span class="math inline">\(\varepsilon_i\)</span>}.
El tema básico es que si los residuos están relacionados con una variable
o muestran algún otro patrón reconocible, entonces deberíamos poder
aprovechar esta información y mejorar la especificación de nuestro modelo.
Los residuos deberían contener poca o ninguna información
y representar solo la variación natural de la muestra que no se puede
atribuir a ninguna fuente específica. <em>Análisis de residuos</em> es
el ejercicio de verificar los residuos en busca de patrones.</p>
<p>Existen cinco tipos de discrepancias en el modelo que los analistas comúnmente buscan. Si se detectan, las discrepancias pueden corregirse con los ajustes apropiados en la especificación del modelo.</p>
<div class="blackbox">
<p><strong>Problemas de Especificación del Modelo</strong></p>
<ul>
<li><strong>Falta de Independencia</strong>. Puede haber relaciones entre las desviaciones {<span class="math inline">\(\varepsilon_i\)</span>} de modo que no sean independientes.</li>
<li><strong>Heterocedasticidad</strong>. La suposición E3 indica que todas las observaciones tienen una variabilidad común (aunque desconocida), conocida como <em>homocedasticidad</em>. <em>Heterocedasticidad</em> es el término usado cuando la variabilidad varía según la observación.</li>
<li><strong>Relaciones entre Desviaciones del Modelo y Variables Explicativas</strong>.
Si una variable explicativa tiene la capacidad de ayudar a explicar la desviación <span class="math inline">\(\varepsilon\)</span>, entonces deberíamos poder usar esta información para predecir mejor <span class="math inline">\(y\)</span>.</li>
<li><strong>Distribuciones No Normales</strong>. Si la distribución de la desviación representa una desviación seria de la normalidad, entonces los procedimientos de inferencia usuales ya no son válidos.</li>
<li><strong>Puntos Inusuales</strong>. Las observaciones individuales pueden tener un gran efecto en el ajuste del modelo de regresión, lo que significa que los resultados pueden ser sensibles al impacto de una sola observación.</li>
</ul>
</div>
<p>Esta lista servirá al lector durante el estudio del análisis de regresión. Por supuesto, con solo una introducción a los modelos básicos aún no hemos visto modelos alternativos que podrían usarse cuando encontramos estas discrepancias en el modelo. En la Parte II de este libro sobre modelos de series temporales, estudiaremos la falta de independencia entre datos ordenados en el tiempo. El Capítulo 5 considerará la heterocedasticidad con más detalle. La introducción a la regresión lineal múltiple en el Capítulo 3 será nuestra primera vista sobre cómo manejar las relaciones entre {<span class="math inline">\(\varepsilon_i\)</span>} y variables explicativas adicionales. Sin embargo, ya hemos tenido una introducción al efecto de las distribuciones normales, viendo que los gráficos <span class="math inline">\(qq\)</span> pueden detectar la no normalidad y que las transformaciones pueden ayudar a inducir la normalidad aproximada. En esta sección, discutimos los efectos de los puntos inusuales.</p>
<p>Gran parte del análisis de residuos se realiza examinando un <em>residuo estandarizado</em>, que es un residuo dividido por su error estándar. Un error estándar aproximado del residuo es <span class="math inline">\(s\)</span>; en el Capítulo 3 daremos una definición matemática precisa. Hay dos razones por las que a menudo examinamos residuos estandarizados en lugar de residuos básicos. Primero, si las respuestas están distribuidas normalmente, entonces los residuos estandarizados son aproximadamente realizaciones de una distribución normal estándar. Esto proporciona una distribución de referencia para comparar los valores de los residuos estandarizados. Por ejemplo, si un residuo estandarizado supera dos en valor absoluto, esto se considera inusualmente grande y la
observación se llama <em>outlier</em> (punto atípico). Segundo, dado que los residuos estandarizados son adimensionales, podemos transferir la experiencia de un conjunto de datos a otro. Esto es cierto independientemente de si la distribución de referencia normal es aplicable o no.</p>
<p><strong>Puntos Atípicos y Puntos de Alta Influencia.</strong> Otra parte importante del análisis de residuos es la identificación de observaciones inusuales en un conjunto de datos. Debido a que las estimaciones de regresión son promedios ponderados con pesos que varían según la observación, algunas observaciones son más importantes que otras. Esta ponderación es más importante de lo que muchos usuarios del análisis de regresión se dan cuenta. De hecho, el ejemplo a continuación demuestra que una sola observación puede tener un efecto dramático en un gran conjunto de datos.</p>
<p>Hay dos direcciones en las que un punto de datos puede ser inusual: la dirección horizontal y la dirección vertical. Por “inusual”, nos referimos a que una observación bajo consideración parece estar lejos de la mayoría del conjunto de datos. Una observación que es inusual en la dirección vertical se llama <em>punto atípico</em>. Una observación que es inusual en la dirección horizontal se llama <em>punto de alta influencia</em>. Una observación puede ser tanto un punto atípico como un punto de alta influencia.</p>
<hr />
<p><strong>Ejemplo: Puntos Atípicos y Puntos de Alta Influencia.</strong> Considera el conjunto de datos ficticio de 19 puntos más tres puntos, etiquetados como A, B y C, que se muestra en la Figura <a href="C2BasicLR.html#fig:Fig27">2.7</a> y <a href="C2BasicLR.html#Table25">Tabla 2.5</a>. Piensa en los primeros 19 puntos como observaciones “buenas” que representan algún tipo de fenómeno. Queremos investigar el efecto de agregar un solo punto aberrante.</p>
<p><a id=Table25></a></p>
<p><span id="Table25">Tabla 2.5</span>. <strong>19 Puntos Base Más Tres Tipos de Observaciones Inusuales</strong></p>
<p><span class="math display">\[
\small{
\begin{array}{c|cccccccccc|ccc}
\hline Variables &amp; &amp;&amp;&amp;&amp;&amp;&amp;&amp;&amp;&amp; &amp; A &amp; B &amp; C
\\
\hline x &amp; 1.5 &amp; 1.7 &amp; 2.0 &amp; 2.2 &amp; 2.5 &amp; 2.5 &amp; 2.7 &amp; 2.9 &amp; 3.0
&amp; 3.5 &amp; 3.4 &amp; 9.5
&amp; 9.5 \\
y &amp; 3.0 &amp; 2.5 &amp; 3.5 &amp; 3.0 &amp; 3.1 &amp; 3.6 &amp; 3.2 &amp; 3.9 &amp; 4.0 &amp; 4.0 &amp; 8.0 &amp; 8.0
&amp; 2.5 \\ \hline
x &amp; 3.8 &amp; 4.2 &amp; 4.3 &amp; 4.6 &amp; 4.0 &amp; 5.1 &amp; 5.1 &amp; 5.2 &amp; 5.5 &amp;  &amp;  &amp;  &amp;  \\
y &amp; 4.2 &amp; 4.1 &amp; 4.8 &amp; 4.2 &amp; 5.1 &amp; 5.1 &amp; 5.1 &amp; 4.8 &amp; 5.3 &amp;  &amp;  &amp;  &amp;  \\
\hline
\end{array}
}
\]</span></p>

<div class="figure" style="text-align: center"><span style="display:block;" id="fig:Fig27"></span>
<img src="RegressionMarkdown_files/figure-html/Fig27-1.png" alt="Gráfico de dispersión de 19 puntos base más tres puntos inusuales, etiquetados A, B, y C." width="60%" />
<p class="caption">
Figura 2.7: <strong>Gráfico de dispersión de 19 puntos base más tres puntos inusuales, etiquetados A, B, y C.</strong>
</p>
</div>
<h5 style="text-align: center;">
<a id="displayCode.Fig27.Hide" href="javascript:togglecode('toggleCode.Fig27.Hide','displayCode.Fig27.Hide');"><i><strong>Código R para Producir la Figura 2.7</strong></i></a>
</h5>
<div id="toggleCode.Fig27.Hide" style="display: none">
<div class="sourceCode" id="cb14"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb14-1"><a href="C2BasicLR.html#cb14-1" tabindex="-1"></a><span class="co">#  EJEMPLO 2.6 PUNTO ATÍPICO</span></span>
<span id="cb14-2"><a href="C2BasicLR.html#cb14-2" tabindex="-1"></a>OUTLR  <span class="ot">&lt;-</span> <span class="fu">read.csv</span>(<span class="st">&quot;CSVData/OutlierExample.csv&quot;</span>, <span class="at">header=</span><span class="cn">TRUE</span>)</span>
<span id="cb14-3"><a href="C2BasicLR.html#cb14-3" tabindex="-1"></a></span>
<span id="cb14-4"><a href="C2BasicLR.html#cb14-4" tabindex="-1"></a><span class="co">#  FIGURA 2.7</span></span>
<span id="cb14-5"><a href="C2BasicLR.html#cb14-5" tabindex="-1"></a><span class="fu">par</span>(<span class="at">mar=</span><span class="fu">c</span>(<span class="fl">4.1</span>,<span class="fl">3.1</span>,<span class="fl">1.1</span>,.<span class="dv">1</span>), <span class="at">cex=</span><span class="fl">1.3</span>)</span>
<span id="cb14-6"><a href="C2BasicLR.html#cb14-6" tabindex="-1"></a><span class="fu">plot</span>(OUTLR<span class="sc">$</span>X, OUTLR<span class="sc">$</span>Y, <span class="at">xlab=</span><span class="st">&quot;x&quot;</span>, <span class="at">ylab=</span><span class="st">&quot;&quot;</span>, <span class="at">xlim=</span><span class="fu">c</span>(<span class="dv">0</span>, <span class="dv">10</span>), <span class="at">ylim=</span><span class="fu">c</span>(<span class="dv">2</span>, <span class="dv">9</span>), <span class="at">las=</span><span class="dv">1</span>)</span>
<span id="cb14-7"><a href="C2BasicLR.html#cb14-7" tabindex="-1"></a><span class="fu">mtext</span>(<span class="st">&quot;y&quot;</span>, <span class="at">at=</span><span class="fl">5.5</span>,<span class="at">side=</span><span class="dv">2</span>,<span class="at">las=</span><span class="dv">1</span>,<span class="at">cex=</span><span class="fl">1.3</span>, <span class="at">line=</span><span class="fl">2.3</span>)</span>
<span id="cb14-8"><a href="C2BasicLR.html#cb14-8" tabindex="-1"></a><span class="fu">points</span>(<span class="fl">4.3</span>, <span class="fl">8.0</span>)</span>
<span id="cb14-9"><a href="C2BasicLR.html#cb14-9" tabindex="-1"></a><span class="fu">text</span>(<span class="fl">4.7</span>, <span class="fl">8.0</span>, <span class="st">&quot;A&quot;</span>, <span class="at">cex=</span><span class="fl">1.3</span>)</span>
<span id="cb14-10"><a href="C2BasicLR.html#cb14-10" tabindex="-1"></a><span class="fu">points</span>(<span class="fl">9.5</span>, <span class="fl">8.0</span>)</span>
<span id="cb14-11"><a href="C2BasicLR.html#cb14-11" tabindex="-1"></a><span class="fu">text</span>(<span class="fl">9.9</span>, <span class="fl">8.0</span>, <span class="st">&quot;B&quot;</span>, <span class="at">cex=</span><span class="fl">1.3</span>)</span>
<span id="cb14-12"><a href="C2BasicLR.html#cb14-12" tabindex="-1"></a><span class="fu">points</span>(<span class="fl">9.5</span>, <span class="fl">2.5</span>)</span>
<span id="cb14-13"><a href="C2BasicLR.html#cb14-13" tabindex="-1"></a><span class="fu">text</span>(<span class="fl">9.9</span>, <span class="fl">2.5</span>, <span class="st">&quot;C&quot;</span>, <span class="at">cex=</span><span class="fl">1.3</span>)</span></code></pre></div>
</div>
<p>Para investigar el efecto de cada tipo de punto aberrante, <a href="C2BasicLR.html#Table26">Tabla 2.6</a> resume los resultados de cuatro regresiones separadas. La primera regresión es para los diecinueve puntos base. Las otras tres regresiones utilizan los diecinueve puntos base más cada tipo de observación inusual.</p>
<p><a id=Table26></a></p>
<p><span id="Table26">Tabla 2.6</span>. <strong>Resultados de Cuatro Regresiones</strong></p>
<p><span class="math display">\[
{\small
\begin{array}{l|rrrrr}
\hline Datos &amp; b_0 &amp; b_1 &amp; s &amp; R^2(\%) &amp; t(b_1) \\
\hline
19 \text{ Puntos Base} &amp; 1.869 &amp; 0.611 &amp; 0.288 &amp; 89.0 &amp; 11.71 \\
19 \text{ Puntos Base} ~+~ A &amp; 1.750 &amp; 0.693 &amp; 0.846 &amp; 53.7 &amp; 4.57 \\
19 \text{ Puntos Base} ~+~ B &amp; 1.775 &amp; 0.640 &amp; 0.285 &amp; 94.7 &amp; 18.01 \\
19 \text{ Puntos Base} ~+~ C &amp; 3.356 &amp; 0.155 &amp; 0.865 &amp; 10.3 &amp; 1.44 \\
\hline
\end{array}
}
\]</span></p>
<p><a href="C2BasicLR.html#Table26">Tabla 2.6</a> muestra que una línea de regresión proporciona un buen ajuste para los diecinueve puntos base. El coeficiente de determinación, <span class="math inline">\(R^2\)</span>, indica que alrededor del 89% de la variabilidad ha sido explicada por la línea. El tamaño del error típico, <span class="math inline">\(s\)</span>, es
de aproximadamente 0.29, pequeño en comparación con la dispersión en los valores de <span class="math inline">\(y\)</span>. Además, el cociente <span class="math inline">\(t\)</span> para el coeficiente de la pendiente es grande.</p>
<p>Cuando se agrega el punto atípico A a los diecinueve puntos base, la situación empeora dramáticamente. El <span class="math inline">\(R^2\)</span> baja del 89% al 53.7% y <span class="math inline">\(s\)</span> aumenta de aproximadamente 0.29 a alrededor de 0.85. La línea de regresión ajustada en sí no cambia mucho, aunque nuestra confianza en las estimaciones ha disminuido.</p>
<p>Un punto atípico es inusual en el valor de <span class="math inline">\(y\)</span>, pero “inusual en el valor de <span class="math inline">\(y\)</span>” depende del valor de <span class="math inline">\(x\)</span>. Para ver esto, mantén el valor de <span class="math inline">\(y\)</span> del Punto A igual, pero aumenta el valor de <span class="math inline">\(x\)</span> y llama al punto B.</p>
<p>Cuando se agrega el punto B a los diecinueve puntos base, la línea de regresión proporciona un ajuste <em>mejor</em>. El punto B está cerca de estar en la línea de ajuste de regresión generada por los diecinueve puntos base. Así, la línea de regresión ajustada y el tamaño del error típico, <span class="math inline">\(s\)</span>, no cambian mucho. Sin embargo, <span class="math inline">\(R^2\)</span> aumenta del 89% a casi el 95%. Si pensamos en <span class="math inline">\(R^2\)</span> como <span class="math inline">\(1-(Error~SS)/(Total~SS)\)</span>, al agregar el punto B hemos aumentado <span class="math inline">\(Total~SS\)</span>, la desviación total cuadrada en los <span class="math inline">\(y\)</span>, aunque el <span class="math inline">\(Error~SS\)</span> se mantiene relativamente sin cambios. El punto B no es un punto atípico, pero es un punto de alta influencia.</p>
<p>Para mostrar cuán influyente es este punto, reduce considerablemente el valor de <span class="math inline">\(y\)</span> y llama a este el nuevo punto C. Cuando se agrega este punto a los diecinueve puntos base, la situación empeora dramáticamente. El coeficiente <span class="math inline">\(R^2\)</span> baja del 89% al 10%, y el <span class="math inline">\(s\)</span> más que se triplica, de 0.29 a 0.87. Además, los coeficientes de la línea de regresión cambian drásticamente.</p>
<p>La mayoría de los usuarios de la regresión al principio no creen que un punto de veinte pueda tener un efecto tan dramático en el ajuste de la regresión. El ajuste de una línea de regresión siempre puede mejorarse eliminando un punto atípico. Si el punto es un punto de alta influencia y no un punto atípico, no está claro si el ajuste mejorará cuando el punto sea eliminado.</p>
<hr />
<p>¡Simplemente porque puedes mejorar dramáticamente un ajuste de regresión omitiendo una observación no significa que siempre debas hacerlo! El objetivo del análisis de datos es comprender la información en los datos. A lo largo del texto, encontraremos muchos conjuntos de datos donde los puntos inusuales proporcionan alguna de la información más interesante sobre los datos. El objetivo de esta subsección es reconocer los efectos de los puntos inusuales; el Capítulo 5 proporcionará opciones para manejar puntos inusuales en tu análisis.</p>
<p>Todas las disciplinas cuantitativas, como contabilidad, economía, programación lineal, etc., practican el arte del <em>análisis de sensibilidad</em>. El análisis de sensibilidad es una descripción de los cambios globales en un sistema debido a un pequeño cambio local en un elemento del sistema. Examinar los efectos de observaciones individuales en el ajuste de regresión es un tipo de análisis de sensibilidad.</p>
<p><strong>Ejemplo: Ventas de Lotería – Continuación.</strong> La Figura <a href="C2BasicLR.html#fig:Fig28">2.8</a> muestra un valor atípico; el punto en la parte superior izquierda del gráfico representa un código postal que incluye a Kenosha, Wisconsin. Las ventas para este código postal son inusualmente altas dada su población. Kenosha está cerca de la frontera con Illinois; los residentes de Illinois probablemente participen en la lotería de Wisconsin, lo que aumenta efectivamente el potencial de ventas en Kenosha. <a href="C2BasicLR.html#Table27">Tabla 2.7</a> resume el ajuste de la regresión tanto con como sin este código postal.</p>
<p><a id=Table27></a></p>
<p><span id="Table27">Tabla 2.7</span>. <strong>Resultados de la Regresión con y sin Kenosha</strong></p>
<p><span class="math display">\[
{\small
\begin{array}{l|rrrrr}
\hline
\text{Datos} &amp; b_0 &amp; b_1 &amp; s &amp; R^2(\%) &amp; t(b_1) \\ \hline
\text{Con Kenosha} &amp; 469.7 &amp; 0.647 &amp; 3,792 &amp; 78.5 &amp; 13.26 \\
\text{Sin Kenosha} &amp; -43.5 &amp; 0.662 &amp; 2,728 &amp; 88.3 &amp; 18.82 \\ \hline
\end{array}
}
\]</span></p>

<div class="figure" style="text-align: center"><span style="display:block;" id="fig:Fig28"></span>
<img src="RegressionMarkdown_files/figure-html/Fig28-1.png" alt="Gráfico de dispersión de SALES versus POP, con el valor atípico correspondiente a Kenosha marcado." width="60%" />
<p class="caption">
Figura 2.8: <strong>Gráfico de dispersión de SALES versus POP, con el valor atípico correspondiente a Kenosha marcado.</strong>
</p>
</div>
<h5 style="text-align: center;">
<a id="displayCode.Fig28.Hide" href="javascript:togglecode('toggleCode.Fig28.Hide','displayCode.Fig28.Hide');"><i><strong>Código R para producir la Figura 2.8 y la Tabla 2.7</strong></i></a>
</h5>
<div id="toggleCode.Fig28.Hide" style="display: none">
<div class="sourceCode" id="cb15"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb15-1"><a href="C2BasicLR.html#cb15-1" tabindex="-1"></a>Lot <span class="ot">&lt;-</span> <span class="fu">read.csv</span>(<span class="st">&quot;CSVData/WiscLottery.csv&quot;</span>, <span class="at">header=</span><span class="cn">TRUE</span>)</span>
<span id="cb15-2"><a href="C2BasicLR.html#cb15-2" tabindex="-1"></a><span class="co">#  FIGURA 2.8</span></span>
<span id="cb15-3"><a href="C2BasicLR.html#cb15-3" tabindex="-1"></a><span class="fu">par</span>(<span class="at">mar=</span><span class="fu">c</span>(<span class="fl">4.1</span>,<span class="fl">3.9</span>,<span class="dv">2</span>,<span class="dv">1</span>),<span class="at">cex=</span><span class="fl">1.1</span>)</span>
<span id="cb15-4"><a href="C2BasicLR.html#cb15-4" tabindex="-1"></a><span class="fu">plot</span>(Lot<span class="sc">$</span>POP, Lot<span class="sc">$</span>SALES, <span class="at">ylab=</span><span class="st">&quot;&quot;</span>, <span class="at">las=</span><span class="dv">1</span>, <span class="at">xlab =</span> <span class="st">&quot;POP&quot;</span>)</span>
<span id="cb15-5"><a href="C2BasicLR.html#cb15-5" tabindex="-1"></a><span class="fu">mtext</span>(<span class="st">&quot;SALES&quot;</span>,<span class="at">side=</span><span class="dv">2</span>, <span class="at">at=</span><span class="dv">36000</span>, <span class="at">las=</span><span class="dv">1</span>, <span class="at">cex=</span><span class="fl">1.1</span>)</span>
<span id="cb15-6"><a href="C2BasicLR.html#cb15-6" tabindex="-1"></a><span class="fu">text</span>(<span class="dv">5000</span>, <span class="dv">24000</span>, <span class="st">&quot;Kenosha&quot;</span>)</span></code></pre></div>
<div class="sourceCode" id="cb16"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb16-1"><a href="C2BasicLR.html#cb16-1" tabindex="-1"></a><span class="co">#  TABLA 2.7</span></span>
<span id="cb16-2"><a href="C2BasicLR.html#cb16-2" tabindex="-1"></a>model.basiclinearreg<span class="ot">&lt;-</span><span class="fu">lm</span>(SALES <span class="sc">~</span> POP, Lot)</span>
<span id="cb16-3"><a href="C2BasicLR.html#cb16-3" tabindex="-1"></a><span class="fu">summary</span>(model.basiclinearreg)</span>
<span id="cb16-4"><a href="C2BasicLR.html#cb16-4" tabindex="-1"></a>model.Kenosha<span class="ot">&lt;-</span><span class="fu">lm</span>(SALES <span class="sc">~</span> POP, Lot, <span class="at">subset=</span><span class="sc">-</span><span class="fu">c</span>(<span class="dv">9</span>))</span>
<span id="cb16-5"><a href="C2BasicLR.html#cb16-5" tabindex="-1"></a><span class="fu">summary</span>(model.Kenosha)</span></code></pre></div>
</div>
<p>Para los propósitos de inferencia sobre la pendiente, la presencia de Kenosha no altera los resultados de manera dramática. Ambas estimaciones de la pendiente son cualitativamente similares y los correspondientes valores <span class="math inline">\(t\)</span> son muy altos, muy por encima de los umbrales para la significancia estadística. Sin embargo, hay diferencias notables al evaluar la calidad del ajuste. El coeficiente de determinación, <span class="math inline">\(R^2\)</span>, aumentó del 78.5% al 88.3% al eliminar Kenosha. Además, nuestro “desviación típica” <span class="math inline">\(s\)</span> disminuyó en más de $1,000. Esto es particularmente importante si queremos ajustar nuestros intervalos de predicción.</p>
<p>Para verificar la exactitud de nuestras suposiciones, también es común revisar la suposición de normalidad. Una forma de hacerlo es mediante el gráfico <span class="math inline">\(qq\)</span>, introducido en la Sección 1.2. Los dos paneles en las Figuras <a href="C2BasicLR.html#fig:Fig29">2.9</a> son gráficos <span class="math inline">\(qq\)</span> con y sin el código postal de Kenosha. Recuerda que los puntos “cercanos” a una línea indican normalidad aproximada. En el panel derecho de la Figura <a href="C2BasicLR.html#fig:Fig29">2.9</a>, la secuencia parece ser lineal, por lo que los residuos están aproximadamente distribuidos de manera normal. Este no es el caso en el panel izquierdo, donde la secuencia de puntos parece aumentar dramáticamente para grandes cuantiles. Lo interesante es que la no-normalidad de la distribución se debe a un solo valor atípico, no a un patrón de sesgo común a todas las observaciones.</p>

<div class="figure" style="text-align: center"><span style="display:block;" id="fig:Fig29"></span>
<img src="RegressionMarkdown_files/figure-html/Fig29-1.png" alt="Gráficos \(qq\) de los residuos de la Lotería de Wisconsin. El panel izquierdo se basa en los 50 puntos. El panel derecho se basa en 49 puntos, residuos de una regresión después de eliminar Kenosha." width="60%" />
<p class="caption">
Figura 2.9: <strong>Gráficos <span class="math inline">\(qq\)</span> de los residuos de la Lotería de Wisconsin.</strong> El panel izquierdo se basa en los 50 puntos. El panel derecho se basa en 49 puntos, residuos de una regresión después de eliminar Kenosha.
</p>
</div>
<h5 style="text-align: center;">
<a id="displayCode.Fig29.Hide" href="javascript:togglecode('toggleCode.Fig29.Hide','displayCode.Fig29.Hide');"><i><strong>Código R para producir la Figura 2.9</strong></i></a>
</h5>
<div id="toggleCode.Fig29.Hide" style="display: none">
<div class="sourceCode" id="cb17"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb17-1"><a href="C2BasicLR.html#cb17-1" tabindex="-1"></a><span class="co">#Lot &lt;- read.csv(&quot;CSVData/WiscLottery.csv&quot;, header=TRUE)</span></span>
<span id="cb17-2"><a href="C2BasicLR.html#cb17-2" tabindex="-1"></a><span class="co">#  FIGURA 2.9</span></span>
<span id="cb17-3"><a href="C2BasicLR.html#cb17-3" tabindex="-1"></a></span>
<span id="cb17-4"><a href="C2BasicLR.html#cb17-4" tabindex="-1"></a><span class="co">#  TABLA 2.7</span></span>
<span id="cb17-5"><a href="C2BasicLR.html#cb17-5" tabindex="-1"></a>model.basiclinearreg<span class="ot">&lt;-</span><span class="fu">lm</span>(SALES <span class="sc">~</span> POP, Lot)</span>
<span id="cb17-6"><a href="C2BasicLR.html#cb17-6" tabindex="-1"></a><span class="co">#summary(model.basiclinearreg)</span></span>
<span id="cb17-7"><a href="C2BasicLR.html#cb17-7" tabindex="-1"></a>model.Kenosha<span class="ot">&lt;-</span><span class="fu">lm</span>(SALES <span class="sc">~</span> POP, Lot, <span class="at">subset=</span><span class="sc">-</span><span class="fu">c</span>(<span class="dv">9</span>))</span>
<span id="cb17-8"><a href="C2BasicLR.html#cb17-8" tabindex="-1"></a><span class="co">#summary(model.Kenosha)</span></span>
<span id="cb17-9"><a href="C2BasicLR.html#cb17-9" tabindex="-1"></a></span>
<span id="cb17-10"><a href="C2BasicLR.html#cb17-10" tabindex="-1"></a><span class="fu">par</span>(<span class="at">mfrow=</span><span class="fu">c</span>(<span class="dv">1</span>, <span class="dv">2</span>), <span class="at">mar=</span><span class="fu">c</span>(<span class="fl">4.1</span>,<span class="fl">3.9</span>,<span class="fl">1.7</span>,<span class="dv">1</span>),<span class="at">cex=</span><span class="fl">1.1</span>)</span>
<span id="cb17-11"><a href="C2BasicLR.html#cb17-11" tabindex="-1"></a><span class="fu">qqnorm</span>(<span class="fu">residuals</span>(model.basiclinearreg), <span class="at">main=</span><span class="st">&quot;&quot;</span>, <span class="at">ylab=</span><span class="st">&quot;&quot;</span>, <span class="at">las=</span><span class="dv">1</span>)</span>
<span id="cb17-12"><a href="C2BasicLR.html#cb17-12" tabindex="-1"></a><span class="fu">mtext</span>(<span class="st">&quot;Cuantiles Muestrales&quot;</span>, <span class="at">side=</span><span class="dv">2</span>,<span class="at">at=</span><span class="dv">20500</span>,<span class="at">las=</span><span class="dv">1</span>,<span class="at">cex=</span><span class="fl">1.1</span>, <span class="at">adj=</span>.<span class="dv">5</span>)</span>
<span id="cb17-13"><a href="C2BasicLR.html#cb17-13" tabindex="-1"></a><span class="fu">qqnorm</span>(<span class="fu">residuals</span>(model.Kenosha), <span class="at">main=</span><span class="st">&quot;&quot;</span>, <span class="at">ylab=</span><span class="st">&quot;&quot;</span>, <span class="at">las=</span><span class="dv">1</span>)</span>
<span id="cb17-14"><a href="C2BasicLR.html#cb17-14" tabindex="-1"></a><span class="fu">mtext</span>(<span class="st">&quot;Cuantiles Muestrales&quot;</span>, <span class="at">side=</span><span class="dv">2</span>,<span class="at">at=</span><span class="dv">9050</span>,<span class="at">las=</span><span class="dv">1</span>,<span class="at">cex=</span><span class="fl">1.1</span>, <span class="at">adj=</span>.<span class="dv">5</span>)</span></code></pre></div>
</div>
</div>
<div id="Sec27" class="section level2 hasAnchor" number="2.7">
<h2><span class="header-section-number">2.7</span> Aplicación: Modelo de Valoración de Activos Financieros<a href="C2BasicLR.html#Sec27" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>En esta sección, estudiamos una aplicación financiera, el Modelo de Valoración de Activos Financieros, a menudo conocido por el acrónimo CAPM. El nombre es algo engañoso, ya que el modelo realmente trata sobre <em>rendimientos</em> basados en activos de capital, no sobre los precios en sí mismos. Los tipos de activos que examinamos son valores de acciones que se negocian en un mercado activo, como la Bolsa de Valores de Nueva York (NYSE). Para una acción en la bolsa, podemos relacionar los rendimientos con los precios mediante la siguiente expresión:</p>
<p><span class="math display">\[
{\small
\mathrm{rendimiento =}\frac{\mathrm{precio~al~final~de~un~período+dividendos-precio~al~inicio~de~un~período}}{\mathrm{precio~al~inicio~de~un~período}}.
}
\]</span></p>
<p>Si podemos estimar los rendimientos que genera una acción, entonces el conocimiento del precio al inicio de un período financiero genérico nos permite estimar el valor al final del período (precio final más dividendos). Por lo tanto, seguimos la práctica estándar y modelamos los rendimientos de una acción.</p>
<p>Una idea intuitivamente atractiva, y una de las características básicas del CAPM, es que debería haber una relación entre el rendimiento de una acción y el mercado. Una justificación es simplemente que si las fuerzas económicas hacen que el mercado mejore, entonces esas mismas fuerzas deberían actuar sobre una acción individual, sugiriendo que también debería mejorar. Como se mencionó anteriormente, medimos el rendimiento de una acción a través del rendimiento. Para medir el rendimiento del mercado, existen varios índices de mercado que resumen el rendimiento de cada bolsa. Usaremos el índice “ponderado por igual” del Standard &amp; Poor’s 500. El Standard &amp; Poor’s 500 es la colección de las 500 empresas más grandes que se negocian en la NYSE, donde “grande” es identificado por Standard &amp; Poor’s, una organización de calificación de servicios financieros. El índice ponderado por igual se define asumiendo que se crea una cartera invirtiendo un dólar en cada una de las 500 empresas.</p>
<p>Otra justificación para una relación entre los rendimientos de las acciones y el mercado proviene de la teoría de la economía financiera. Esta es la teoría CAPM, atribuida a Sharpe (1964) y Lintner (1965) y basada en las ideas de diversificación de cartera de Harry Markowitz (1959). Otros factores iguales, los inversionistas desearían seleccionar un rendimiento con un alto valor esperado y una baja desviación estándar, esta última siendo una medida de riesgo. Una de las propiedades deseables de usar desviaciones estándar como medida de riesgo es que es sencillo calcular la desviación estándar de una cartera. Solo es necesario conocer la desviación estándar de cada acción y las correlaciones entre acciones. Una acción notable es una libre de riesgo, es decir, una acción que teóricamente tiene una desviación estándar cero. Los inversionistas a menudo utilizan un bono del Tesoro de EE. UU. a 30 días como una aproximación de una acción libre de riesgo, argumentando que la probabilidad de default del gobierno de EE. UU. dentro de 30 días es insignificante. Positando la existencia de un activo libre de riesgo y algunas otras condiciones suaves, bajo la teoría CAPM existe una frontera eficiente llamada la <em>línea de mercado de valores</em>. Esta frontera especifica el rendimiento mínimo esperado que los inversionistas deberían exigir para un nivel específico de riesgo. Para estimar esta línea, podemos usar la ecuación:
<span class="math display">\[\begin{equation*}
\mathrm{E}~r = \beta_0 + \beta_1 r_m
\end{equation*}\]</span>
donde <span class="math inline">\(r\)</span> es el rendimiento de la acción y <span class="math inline">\(r_m\)</span> es el rendimiento del mercado. Interpretamos <span class="math inline">\(\beta_1 r_m\)</span> como una medida de la cantidad de rendimiento de la acción que se atribuye al comportamiento del mercado.</p>
<p>Probar la teoría económica, o modelos que surgen de cualquier disciplina, implica recolectar datos. La teoría CAPM trata sobre rendimientos ex-ante (antes del hecho), aunque solo podemos probar con rendimientos ex-post (después del hecho). Antes del hecho, los rendimientos son desconocidos y hay toda una distribución de rendimientos. Después del hecho, solo hay una realización única del rendimiento de la acción y del mercado. Debido a que se requieren al menos dos observaciones para determinar una línea, los modelos CAPM se estiman usando datos de acciones y del mercado recopilados a lo largo del tiempo. De esta manera, se pueden realizar varias observaciones. Para los propósitos de nuestras discusiones, seguimos la práctica estándar en la industria de valores y examinamos precios mensuales.</p>
<div id="datos" class="section level4 unnumbered hasAnchor">
<h4>Datos<a href="C2BasicLR.html#datos" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>Para ilustrar, considere los rendimientos mensuales durante el período de cinco años desde enero de 1986 hasta diciembre de 1990, inclusive. Específicamente, usamos los rendimientos de la acción de Lincoln National Insurance Corporation como la variable dependiente (<span class="math inline">\(y\)</span>) y los rendimientos del mercado del índice Standard &amp; Poor’s 500 como la variable explicativa (<span class="math inline">\(x\)</span>). En ese momento, Lincoln era una gran compañía de seguros multirama, con sede en el medio oeste de EE. UU., específicamente en Fort Wayne, Indiana. Debido a que era bien conocida por su gestión prudente y estabilidad, es una buena compañía para comenzar nuestro análisis de la relación entre el mercado y una acción individual.</p>
<p>Comenzamos interpretando algunas estadísticas básicas, en la Tabla <a href="C2BasicLR.html#tab:Tab28">2.8</a>, en términos de teoría financiera. Primero, un inversionista en Lincoln estará preocupado de que el rendimiento promedio de cinco años, <span class="math inline">\(\overline{y}=0.00510\)</span>, esté por debajo del rendimiento del mercado, <span class="math inline">\(\overline{x}=0.00741\)</span>. Los estudiantes de teoría de intereses reconocen que los rendimientos mensuales se pueden convertir a una base anual usando la capitalización geométrica. Por ejemplo, el rendimiento anual de Lincoln es <span class="math inline">\((1.0051)^{12}-1=0.062946\)</span>, o aproximadamente 6.29 por ciento. Esto se compara con un rendimiento anual de 9.26% (= (1<span class="math inline">\(00((1.00741)^{12}-1\)</span>)) para el mercado. Una medida de riesgo, o volatilidad, que se usa en finanzas es la desviación estándar. Así, interprete <span class="math inline">\(s_y\)</span> = 0.0859 <span class="math inline">\(&gt;\)</span> 0.05254 = <span class="math inline">\(s_x\)</span> para significar que una inversión en Lincoln es más riesgosa que la del mercado. Otro aspecto interesante de la Tabla <a href="C2BasicLR.html#tab:Tab28">2.8</a> es que el rendimiento más bajo del mercado, -0.22052, está 4.338 desviaciones estándar por debajo de su promedio ((-0.22052-0.00741)/0.05254 = -4.338). Esto es muy inusual con respecto a una distribución normal.</p>
<h5 style="text-align: center;">
<a id="displayCode.Motivation.1Silly" href="javascript:togglecode('toggleCode.Motivation.1Silly','displayCode.Motivation.1Silly');"><i><strong></strong></i></a>
</h5>
<div id="toggleCode.Motivation.1Silly" style="display: none">
<div class="sourceCode" id="cb18"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb18-1"><a href="C2BasicLR.html#cb18-1" tabindex="-1"></a>knitr<span class="sc">::</span><span class="fu">kable</span>(<span class="dv">2</span>, <span class="at">caption =</span> <span class="st">&quot;Silly. Crear una tabla solo para actualizar el contador...&quot;</span>)</span></code></pre></div>
<table>
<caption><span id="tab:unnamed-chunk-25">Tabla 2.2: </span>Silly. Crear una tabla solo para actualizar el contador…</caption>
<thead>
<tr class="header">
<th align="right">x</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="right">2</td>
</tr>
</tbody>
</table>
<div class="sourceCode" id="cb19"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb19-1"><a href="C2BasicLR.html#cb19-1" tabindex="-1"></a>knitr<span class="sc">::</span><span class="fu">kable</span>(<span class="dv">2</span>, <span class="at">caption =</span> <span class="st">&quot;Silly.&quot;</span>)</span></code></pre></div>
<table>
<caption><span id="tab:unnamed-chunk-26">Tabla 2.3: </span>Silly.</caption>
<thead>
<tr class="header">
<th align="right">x</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="right">2</td>
</tr>
</tbody>
</table>
<div class="sourceCode" id="cb20"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb20-1"><a href="C2BasicLR.html#cb20-1" tabindex="-1"></a>knitr<span class="sc">::</span><span class="fu">kable</span>(<span class="dv">2</span>, <span class="at">caption =</span> <span class="st">&quot;Silly. &quot;</span>)</span></code></pre></div>
<table>
<caption><span id="tab:unnamed-chunk-27">Tabla 2.4: </span>Silly.</caption>
<thead>
<tr class="header">
<th align="right">x</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="right">2</td>
</tr>
</tbody>
</table>
<div class="sourceCode" id="cb21"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb21-1"><a href="C2BasicLR.html#cb21-1" tabindex="-1"></a>knitr<span class="sc">::</span><span class="fu">kable</span>(<span class="dv">2</span>, <span class="at">caption =</span> <span class="st">&quot;Silly.&quot;</span>)</span></code></pre></div>
<table>
<caption><span id="tab:unnamed-chunk-28">Tabla 2.5: </span>Silly.</caption>
<thead>
<tr class="header">
<th align="right">x</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="right">2</td>
</tr>
</tbody>
</table>
<div class="sourceCode" id="cb22"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb22-1"><a href="C2BasicLR.html#cb22-1" tabindex="-1"></a>knitr<span class="sc">::</span><span class="fu">kable</span>(<span class="dv">2</span>, <span class="at">caption =</span> <span class="st">&quot;Silly.&quot;</span>)</span></code></pre></div>
<table>
<caption><span id="tab:unnamed-chunk-29">Tabla 2.6: </span>Silly.</caption>
<thead>
<tr class="header">
<th align="right">x</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="right">2</td>
</tr>
</tbody>
</table>
<table>
<caption><span id="tab:unnamed-chunk-30">Tabla 2.7: </span>Silly.</caption>
<thead>
<tr class="header">
<th align="right">x</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="right">2</td>
</tr>
</tbody>
</table>
</div>
<table class=" lightable-classic table table-striped table-condensed" style="font-size: 12px; font-family: Cambria; width: auto !important; margin-left: auto; margin-right: auto; margin-left: auto; margin-right: auto;border-bottom: 0;">
<caption style="font-size: initial !important;">
<span id="tab:Tab28">Tabla 2.8: </span><strong>Estadísticas Resumen de 60 Observaciones Mensuales</strong>
</caption>
<thead>
<tr>
<th style="text-align:left;">
</th>
<th style="text-align:right;">
Promedio
</th>
<th style="text-align:right;">
Mediana
</th>
<th style="text-align:right;">
Desviación Estándar
</th>
<th style="text-align:right;">
Mínimo
</th>
<th style="text-align:right;">
Máximo
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;width: 2.5cm; border-right:1px solid;">
LINCOLN
</td>
<td style="text-align:right;width: 1.6cm; ">
0.0051
</td>
<td style="text-align:right;width: 1.6cm; ">
0.0075
</td>
<td style="text-align:right;width: 1.6cm; ">
0.0859
</td>
<td style="text-align:right;width: 1.6cm; ">
-0.2803
</td>
<td style="text-align:right;width: 1.6cm; ">
0.3147
</td>
</tr>
<tr>
<td style="text-align:left;width: 2.5cm; border-right:1px solid;">
MARKET
</td>
<td style="text-align:right;width: 1.6cm; ">
0.0074
</td>
<td style="text-align:right;width: 1.6cm; ">
0.0142
</td>
<td style="text-align:right;width: 1.6cm; ">
0.0525
</td>
<td style="text-align:right;width: 1.6cm; ">
-0.2205
</td>
<td style="text-align:right;width: 1.6cm; ">
0.1275
</td>
</tr>
</tbody>
<tfoot>
<tr>
<td style="padding: 0; " colspan="100%">
<span style="font-style: italic;">Fuente:</span> <sup></sup> Center for Research on Security Prices, University of Chicago
</td>
</tr>
</tfoot>
</table>
<p>A continuación, examinamos los datos a lo largo del tiempo, como se muestra gráficamente en la Figura @ref(fig:Fig2.10). Estos son gráficos de dispersión de los rendimientos versus el tiempo, llamados <em>gráficos de series temporales</em>. En la Figura @ref(fig:Fig2.10), se puede ver claramente</p>
<p>el rendimiento más bajo del mercado y un vistazo rápido al eje horizontal revela que este punto inusual está en octubre de 1987, el momento del conocido colapso del mercado.</p>
<p>(ref:Fig2.10) <strong>Gráfico de series temporales de los rendimientos de la Lincoln National Corporation y del mercado.</strong> Hay 60 rendimientos mensuales durante el período de enero de 1986 a diciembre de 1990.</p>
<div class="figure" style="text-align: center">
<img src="RegressionMarkdown_files/figure-html/Fig2.10-1.png" alt="(ref:Fig2.10)" width="60%" />
<p class="caption">
(#fig:Fig2.10)(ref:Fig2.10)
</p>
</div>
<p>El gráfico de dispersión en la Figura @ref(fig:Fig2.11) resume gráficamente la relación entre el rendimiento de Lincoln y el rendimiento del mercado. El colapso del mercado es claramente evidente en la Figura @ref(fig:Fig2.11) y representa un punto de alta influencia. Con la línea de regresión (descrita a continuación) superpuesta, los dos puntos atípicos que se pueden ver en la Figura @ref(fig:Fig2.10) también son evidentes. A pesar de estas anomalías, el gráfico en la Figura @ref(fig:Fig2.11) sugiere que hay una relación lineal entre los rendimientos de Lincoln y del mercado.</p>
<p>(ref:Fig2.11) <strong>Gráfico de dispersión del rendimiento de Lincoln versus el rendimiento del índice S&amp;P 500.</strong> La línea de regresión está superpuesta, lo que nos permite identificar el colapso del mercado y dos puntos atípicos.</p>
<div class="figure" style="text-align: center">
<img src="RegressionMarkdown_files/figure-html/Fig2.11-1.png" alt="(ref:Fig2.11)" width="60%" />
<p class="caption">
(#fig:Fig2.11)(ref:Fig2.11)
</p>
</div>
<h5 style="text-align: center;">
<a id="displayCode.CAPMAnalysis.Hide" href="javascript:togglecode('toggleCode.CAPMAnalysis.Hide','displayCode.CAPMAnalysis.Hide');"><i><strong>Código R para producir la Tabla 2.8 y las Figuras 2.10 y 2.11</strong></i></a>
</h5>
<div id="toggleCode.CAPMAnalysis.Hide" style="display: none">
<div class="sourceCode" id="cb23"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb23-1"><a href="C2BasicLR.html#cb23-1" tabindex="-1"></a>CAPM <span class="ot">&lt;-</span> <span class="fu">read.csv</span>(<span class="st">&quot;CSVData/CAPM.csv&quot;</span>, <span class="at">header=</span><span class="cn">TRUE</span>)</span>
<span id="cb23-2"><a href="C2BasicLR.html#cb23-2" tabindex="-1"></a></span>
<span id="cb23-3"><a href="C2BasicLR.html#cb23-3" tabindex="-1"></a><span class="co">#  TABLA 2.8 ESTADÍSTICAS RESUMEN</span></span>
<span id="cb23-4"><a href="C2BasicLR.html#cb23-4" tabindex="-1"></a></span>
<span id="cb23-5"><a href="C2BasicLR.html#cb23-5" tabindex="-1"></a>Xymat <span class="ot">&lt;-</span> <span class="fu">data.frame</span>(<span class="fu">cbind</span>(CAPM<span class="sc">$</span>LINCOLN,CAPM<span class="sc">$</span>MARKET)) </span>
<span id="cb23-6"><a href="C2BasicLR.html#cb23-6" tabindex="-1"></a>tableMat  <span class="ot">&lt;-</span> <span class="fu">BookSummStats</span>(Xymat)</span>
<span id="cb23-7"><a href="C2BasicLR.html#cb23-7" tabindex="-1"></a><span class="fu">colnames</span>(tableMat)  <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="st">&quot;Promedio&quot;</span> , <span class="st">&quot;Mediana&quot;</span> , <span class="st">&quot;Desviación Estándar&quot;</span> , </span>
<span id="cb23-8"><a href="C2BasicLR.html#cb23-8" tabindex="-1"></a>                         <span class="st">&quot;Mínimo&quot;</span> , <span class="st">&quot;Máximo&quot;</span>)</span>
<span id="cb23-9"><a href="C2BasicLR.html#cb23-9" tabindex="-1"></a><span class="fu">rownames</span>(tableMat)  <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="st">&quot;LINCOLN&quot;</span>, <span class="st">&quot;MARKET&quot;</span>)</span>
<span id="cb23-10"><a href="C2BasicLR.html#cb23-10" tabindex="-1"></a><span class="co">#tableMat1 &lt;- format(round(tableMat, digits=0), big.mark = &#39;,&#39;)</span></span>
<span id="cb23-11"><a href="C2BasicLR.html#cb23-11" tabindex="-1"></a></span>
<span id="cb23-12"><a href="C2BasicLR.html#cb23-12" tabindex="-1"></a><span class="fu">TableGen1</span>(<span class="at">TableData=</span>tableMat, </span>
<span id="cb23-13"><a href="C2BasicLR.html#cb23-13" tabindex="-1"></a>         <span class="at">TextTitle=</span><span class="st">&#39;Estadísticas Resumen de 60 Observaciones Mensuales&#39;</span>, </span>
<span id="cb23-14"><a href="C2BasicLR.html#cb23-14" tabindex="-1"></a>         <span class="at">Align=</span><span class="st">&#39;r&#39;</span>, <span class="at">Digits=</span><span class="dv">4</span>, <span class="at">ColumnSpec=</span><span class="dv">1</span><span class="sc">:</span><span class="dv">5</span>,</span>
<span id="cb23-15"><a href="C2BasicLR.html#cb23-15" tabindex="-1"></a>         <span class="at">ColWidth =</span> ColWidth5) <span class="sc">%&gt;%</span></span>
<span id="cb23-16"><a href="C2BasicLR.html#cb23-16" tabindex="-1"></a>  <span class="fu">footnote</span>(<span class="at">general =</span> <span class="st">&quot;Center for Research on Security Prices, University of Chicago&quot;</span>, </span>
<span id="cb23-17"><a href="C2BasicLR.html#cb23-17" tabindex="-1"></a>           <span class="at">general_title =</span> <span class="st">&quot;Fuente:&quot;</span>, </span>
<span id="cb23-18"><a href="C2BasicLR.html#cb23-18" tabindex="-1"></a>           <span class="at">footnote_as_chunk =</span> <span class="cn">TRUE</span>)</span></code></pre></div>
<div class="sourceCode" id="cb24"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb24-1"><a href="C2BasicLR.html#cb24-1" tabindex="-1"></a><span class="co">#  FIGURA 2.10</span></span>
<span id="cb24-2"><a href="C2BasicLR.html#cb24-2" tabindex="-1"></a><span class="fu">par</span>(<span class="at">mar=</span><span class="fu">c</span>(<span class="fl">4.1</span>,<span class="fl">3.1</span>,<span class="dv">2</span>,<span class="dv">1</span>),<span class="at">cex=</span><span class="fl">1.1</span>, <span class="at">las=</span><span class="dv">1</span>)</span>
<span id="cb24-3"><a href="C2BasicLR.html#cb24-3" tabindex="-1"></a>foo <span class="ot">&lt;-</span> <span class="fu">ts</span>(CAPM, <span class="at">freq =</span> <span class="dv">12</span>, <span class="at">start =</span> <span class="fu">c</span>(<span class="dv">1986</span>, <span class="dv">1</span>))</span>
<span id="cb24-4"><a href="C2BasicLR.html#cb24-4" tabindex="-1"></a><span class="fu">ts.plot</span>(foo[,<span class="dv">2</span>], foo[,<span class="dv">3</span>], <span class="at">xlab=</span><span class="st">&quot;Año&quot;</span>, <span class="at">ylab=</span><span class="st">&quot;&quot;</span>, <span class="at">type=</span><span class="st">&quot;o&quot;</span>, <span class="at">lty=</span><span class="fu">c</span>(<span class="dv">1</span>, <span class="dv">2</span>))</span>
<span id="cb24-5"><a href="C2BasicLR.html#cb24-5" tabindex="-1"></a><span class="fu">mtext</span>(<span class="st">&quot;Rendimiento Mensual&quot;</span>, <span class="at">side=</span><span class="dv">2</span>, <span class="at">at=</span>.<span class="dv">38</span>,<span class="at">las=</span><span class="dv">1</span>,<span class="at">cex=</span><span class="fl">1.1</span>, <span class="at">adj=</span>.<span class="dv">5</span>)</span>
<span id="cb24-6"><a href="C2BasicLR.html#cb24-6" tabindex="-1"></a><span class="fu">legend</span>(<span class="dv">1986</span>, <span class="fl">0.3</span>, <span class="fu">c</span>(<span class="st">&quot;LINCOLN&quot;</span>, <span class="st">&quot;MARKET&quot;</span>), <span class="at">lty=</span><span class="dv">1</span><span class="sc">:</span><span class="dv">2</span>, <span class="at">cex=</span><span class="fl">0.5</span>)</span></code></pre></div>
<div class="sourceCode" id="cb25"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb25-1"><a href="C2BasicLR.html#cb25-1" tabindex="-1"></a><span class="co">#  FIGURA 2.11</span></span>
<span id="cb25-2"><a href="C2BasicLR.html#cb25-2" tabindex="-1"></a></span>
<span id="cb25-3"><a href="C2BasicLR.html#cb25-3" tabindex="-1"></a><span class="fu">par</span>(<span class="at">mar=</span><span class="fu">c</span>(<span class="fl">4.1</span>,<span class="fl">3.1</span>,<span class="fl">1.4</span>,<span class="fl">0.2</span>),<span class="at">cex=</span><span class="fl">1.1</span>, <span class="at">las=</span><span class="dv">1</span>)</span>
<span id="cb25-4"><a href="C2BasicLR.html#cb25-4" tabindex="-1"></a><span class="fu">plot</span>(CAPM<span class="sc">$</span>MARKET, CAPM<span class="sc">$</span>LINCOLN, <span class="at">xlab=</span><span class="st">&quot;MARKET&quot;</span>, <span class="at">ylab=</span><span class="st">&quot;&quot;</span>, <span class="at">xlim=</span><span class="fu">c</span>(<span class="sc">-</span><span class="fl">0.3</span>, <span class="fl">0.2</span>), <span class="at">ylim=</span><span class="fu">c</span>(<span class="sc">-</span><span class="fl">0.3</span>, <span class="fl">0.4</span>),<span class="at">las=</span><span class="dv">1</span>)</span>
<span id="cb25-5"><a href="C2BasicLR.html#cb25-5" tabindex="-1"></a><span class="fu">mtext</span>(<span class="st">&quot;LINCOLN&quot;</span>, <span class="at">side=</span><span class="dv">2</span>,<span class="at">at=</span><span class="fl">0.46</span>,<span class="at">las=</span><span class="dv">1</span>, <span class="at">cex=</span><span class="fl">1.1</span>, <span class="at">adj=</span>.<span class="dv">5</span>)</span>
<span id="cb25-6"><a href="C2BasicLR.html#cb25-6" tabindex="-1"></a>reg <span class="ot">&lt;-</span> <span class="fu">lm</span>(LINCOLN <span class="sc">~</span> MARKET, <span class="at">data =</span> CAPM)</span>
<span id="cb25-7"><a href="C2BasicLR.html#cb25-7" tabindex="-1"></a><span class="fu">abline</span>(reg)</span>
<span id="cb25-8"><a href="C2BasicLR.html#cb25-8" tabindex="-1"></a><span class="fu">arrows</span>(<span class="sc">-</span><span class="fl">0.22</span>, <span class="sc">-</span><span class="fl">0.1</span>, <span class="sc">-</span><span class="fl">0.22</span>, <span class="sc">-</span><span class="fl">0.22</span>,<span class="at">length=</span><span class="fl">0.1</span>, <span class="at">angle =</span> <span class="dv">10</span>)</span>
<span id="cb25-9"><a href="C2BasicLR.html#cb25-9" tabindex="-1"></a><span class="fu">text</span>(<span class="sc">-</span><span class="fl">0.22</span>, <span class="sc">-</span><span class="fl">0.08</span>, <span class="st">&quot;COLAPSO DE OCTUBRE, 1987&quot;</span>, <span class="at">cex=</span><span class="fl">0.8</span>)</span>
<span id="cb25-10"><a href="C2BasicLR.html#cb25-10" tabindex="-1"></a><span class="fu">arrows</span>(<span class="fl">0.1</span>, <span class="fl">0.02</span>, <span class="dv">0</span>, <span class="sc">-</span><span class="fl">0.27</span>,<span class="at">length=</span><span class="fl">0.1</span>, <span class="at">angle =</span> <span class="dv">10</span>)</span>
<span id="cb25-11"><a href="C2BasicLR.html#cb25-11" tabindex="-1"></a><span class="fu">arrows</span>(<span class="fl">0.1</span>, <span class="fl">0.02</span>, <span class="fl">0.06</span>, <span class="fl">0.3</span>,<span class="at">length=</span><span class="fl">0.1</span>, <span class="at">angle =</span> <span class="dv">10</span>)</span>
<span id="cb25-12"><a href="C2BasicLR.html#cb25-12" tabindex="-1"></a><span class="fu">text</span>(<span class="fl">0.16</span>, <span class="fl">0.02</span>, <span class="st">&quot;PUNTOS ATÍPICOS DE 1990&quot;</span>, <span class="at">cex=</span><span class="fl">0.8</span>)</span></code></pre></div>
</div>
</div>
<div id="puntos-inusuales" class="section level4 unnumbered hasAnchor">
<h4>Puntos Inusuales<a href="C2BasicLR.html#puntos-inusuales" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>Para resumir la relación entre el mercado y el rendimiento de Lincoln, se ajustó un modelo de regresión. La regresión ajustada es</p>
<p><span class="math display">\[\begin{equation*}
\widehat{LINCOLN}=-0.00214+0.973 MARKET.
\end{equation*}\]</span></p>
<p>El error estándar estimado resultante, <span class="math inline">\(s = 0.0696\)</span>, es menor que la desviación estándar de los rendimientos de Lincoln, <span class="math inline">\(s_y=0.0859\)</span>. Por lo tanto, el modelo de regresión explica parte de la variabilidad de los rendimientos de Lincoln. Además, el estadístico <span class="math inline">\(t\)</span> asociado con la pendiente <span class="math inline">\(b_1\)</span> resulta ser <span class="math inline">\(t(b_1)=5.64\)</span>, lo cual es significativamente alto. Un aspecto decepcionante es que el estadístico <span class="math inline">\(R^2=35.4\%\)</span> se puede interpretar como que el mercado explica solo un poco más de un tercio de la variabilidad. Por lo tanto, aunque el mercado es claramente un determinante importante, como lo evidencian el alto estadístico <span class="math inline">\(t\)</span>, solo proporciona una explicación parcial del rendimiento de los rendimientos de Lincoln.</p>
<p>En el contexto del modelo de mercado, podemos interpretar la desviación estándar del mercado, <span class="math inline">\(s_x\)</span>, como <em>riesgo no diversificable</em>. Por lo tanto, el riesgo de un valor puede descomponerse en dos componentes: el componente diversificable y el componente del mercado, que es no diversificable. La idea es que, al combinar varios valores, podemos crear una cartera de valores que, en la mayoría de los casos, reducirá el riesgo de nuestras inversiones en comparación con un solo valor. Nuevamente, la razón para tener un valor es que estamos compensados con rendimientos esperados más altos al tener un valor con mayor riesgo. Para cuantificar el riesgo relativo, no es difícil demostrar que</p>
<p><span class="math display" id="eq:eq28">\[\begin{equation}
s_y^2 = b_1^2 s_x^2 + s^2 \frac{n-2}{n-1}.
\tag{2.8}
\end{equation}\]</span></p>
<p>El riesgo de un valor se debe al riesgo del mercado más el riesgo de un componente diversificable. Tenga en cuenta que el riesgo del componente del mercado, <span class="math inline">\(s_x^2\)</span>, es mayor para los valores con pendientes más grandes. Por esta razón, los inversores consideran que los valores con pendientes <span class="math inline">\(b_1\)</span> mayores que uno son “agresivos” y las pendientes menores que uno como “defensivos”.</p>
</div>
<div id="análisis-de-sensibilidad" class="section level4 unnumbered hasAnchor">
<h4>Análisis de Sensibilidad<a href="C2BasicLR.html#análisis-de-sensibilidad" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>El resumen anterior plantea inmediatamente dos cuestiones adicionales. Primero, ¿cuál es el efecto del colapso de octubre de 1987 en la ecuación de regresión ajustada? Sabemos que las observaciones inusuales, como el colapso, pueden influir mucho en el ajuste. Con este fin, se volvió a ejecutar la regresión sin la observación correspondiente al colapso. La motivación para esto es que el colapso de octubre de 1987 representa una combinación de eventos altamente inusuales (la interacción de varios programas de comercio automatizado operados por grandes casas de corretaje de valores) que no deseamos representar con el mismo modelo que nuestras otras observaciones. Eliminando esta observación, la regresión ajustada es</p>
<p><span class="math display">\[\begin{equation*}
\widehat{LINCOLN} = -0.00181 + 0.956 MARKET,
\end{equation*}\]</span></p>
<p>con <span class="math inline">\(R^2=26.4\%\)</span>, <span class="math inline">\(t(b_1)=4.52\)</span>, <span class="math inline">\(s=0.0702\)</span> y <span class="math inline">\(s_y=0.0811\)</span>. Interpretamos estas estadísticas de la misma manera que el modelo ajustado que incluye el colapso de octubre de 1987. Sin embargo, es interesante notar que la proporción de variabilidad explicada ha <em>disminuido</em> al excluir el punto influyente. Esto sirve para ilustrar un punto importante. Los puntos de alta influencia a menudo son temidos por los analistas de datos porque, por definición, son diferentes de otras observaciones en el conjunto de datos y requieren una atención especial. Sin embargo, al ajustar las relaciones entre variables, también representan una oportunidad porque permiten al analista de datos observar la relación entre variables en rangos más amplios que de otro modo serían posibles. La desventaja es que estas relaciones pueden ser no lineales o seguir un patrón completamente diferente en comparación con las relaciones observadas en la parte principal de los datos.</p>
<p>La segunda pregunta planteada por el análisis de regresión es qué se puede decir sobre las circunstancias inusuales que dieron lugar al comportamiento inusual de los rendimientos de Lincoln en octubre y noviembre de 1990. Una característica útil del análisis de regresión es identificar y plantear la pregunta; no la resuelve. Debido a que el análisis señala claramente dos puntos altamente inusuales, sugiere al analista de datos que vuelva y haga algunas preguntas específicas sobre las fuentes de los datos. En este caso, la respuesta es directa. En octubre de 1990, la compañía Travelers’ Insurance, una competidora, anunció que tomaría una gran amortización en su cartera de bienes raíces debido a un número sin precedentes de incumplimientos hipotecarios. El mercado reaccionó rápidamente a esta noticia, y los inversores asumieron que otras grandes compañías de seguros de vida también anunciarían pronto grandes amortizaciones. Anticipando esta noticia, los inversores trataron de vender sus carteras de, por ejemplo, las acciones de Lincoln, lo que provocó una caída en el precio. Sin embargo, resultó que los inversores reaccionaron en exceso a esta noticia y que la cartera de bienes raíces de Lincoln estaba en realidad en buen estado. Así, los precios rápidamente volvieron a sus niveles históricos.</p>
</div>
</div>
<div id="Sec28" class="section level2 hasAnchor" number="2.8">
<h2><span class="header-section-number">2.8</span> Salida Computacional Ilustrativa de Regresión<a href="C2BasicLR.html#Sec28" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Las computadoras y los paquetes de software estadístico que realizan cálculos especializados juegan un papel vital en los análisis estadísticos modernos. Las capacidades informáticas económicas han permitido a los analistas de datos centrarse en las relaciones de interés. Es mucho menos importante especificar modelos que sean atractivos únicamente por su simplicidad computacional en comparación con épocas anteriores a la disponibilidad generalizada de computación económica. Un tema importante de este texto es centrarse en las relaciones de interés y confiar en el software estadístico ampliamente disponible para estimar los modelos que especificamos.</p>
<p>Con cualquier paquete de computadora, generalmente las partes más difíciles de operar el paquete son (i) la entrada, (ii) el uso de los comandos y (iii) la interpretación de la salida. Encontrarás que la mayoría de los paquetes estadísticos modernos aceptan archivos en formato de hoja de cálculo o texto, lo que facilita la entrada de datos. Los paquetes de software estadístico para computadoras personales tienen lenguajes de comando basados en menús con facilidades de ayuda en línea fácilmente accesibles. Una vez que decides qué hacer, encontrar los comandos correctos es relativamente fácil.</p>
<p>Esta sección proporciona orientación para interpretar la salida de los paquetes estadísticos. La mayoría de los paquetes estadísticos generan salidas similares. A continuación, se presentan tres ejemplos de paquetes estadísticos estándar: <code>EXCEL</code>, <code>SAS</code> y <code>R</code>. El símbolo de anotación “[.]” marca una cantidad estadística que se describe en la leyenda. Así, esta sección proporciona un enlace entre la notación utilizada en el texto y la salida de algunos de los paquetes estadísticos estándar.</p>
<hr />
<p><strong>Salida en EXCEL</strong></p>
<div class="sourceCode" id="cb26"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb26-1"><a href="C2BasicLR.html#cb26-1" tabindex="-1"></a>Regression Statistics</span>
<span id="cb26-2"><a href="C2BasicLR.html#cb26-2" tabindex="-1"></a>Multiple R              <span class="fl">0.886283</span>[F]</span>
<span id="cb26-3"><a href="C2BasicLR.html#cb26-3" tabindex="-1"></a>R Square                <span class="fl">0.785497</span>[k]</span>
<span id="cb26-4"><a href="C2BasicLR.html#cb26-4" tabindex="-1"></a>Adjusted R Square       <span class="fl">0.781028</span>[l]</span>
<span id="cb26-5"><a href="C2BasicLR.html#cb26-5" tabindex="-1"></a>Standard Error          <span class="fl">3791.758</span>[j]</span>
<span id="cb26-6"><a href="C2BasicLR.html#cb26-6" tabindex="-1"></a>Observations              <span class="dv">50</span>[a]</span>
<span id="cb26-7"><a href="C2BasicLR.html#cb26-7" tabindex="-1"></a></span>
<span id="cb26-8"><a href="C2BasicLR.html#cb26-8" tabindex="-1"></a>ANOVA</span>
<span id="cb26-9"><a href="C2BasicLR.html#cb26-9" tabindex="-1"></a>           df              SS          MS             F     Significance F</span>
<span id="cb26-10"><a href="C2BasicLR.html#cb26-10" tabindex="-1"></a>Regression   <span class="dv">1</span>[m]   <span class="dv">2527165015</span> [p]  <span class="dv">2527165015</span> [s]  <span class="fl">175.773</span>[u]   <span class="fl">1.15757E-17</span>[v]</span>
<span id="cb26-11"><a href="C2BasicLR.html#cb26-11" tabindex="-1"></a>Residual    <span class="dv">48</span>[n]   <span class="fl">690116754.8</span>[q]  <span class="fl">14377432.39</span>[t]</span>
<span id="cb26-12"><a href="C2BasicLR.html#cb26-12" tabindex="-1"></a>Total       <span class="dv">49</span>[o]   <span class="dv">3217281770</span> [r]</span>
<span id="cb26-13"><a href="C2BasicLR.html#cb26-13" tabindex="-1"></a></span>
<span id="cb26-14"><a href="C2BasicLR.html#cb26-14" tabindex="-1"></a>        Coefficients    Standard Error      t Stat         P<span class="sc">-</span>value</span>
<span id="cb26-15"><a href="C2BasicLR.html#cb26-15" tabindex="-1"></a>Intercept    <span class="fl">469.7036</span>[b] <span class="fl">702.9061896</span>[d]   <span class="fl">0.668230846</span>[f] <span class="fl">0.507187</span>[h]</span>
<span id="cb26-16"><a href="C2BasicLR.html#cb26-16" tabindex="-1"></a>X Variable <span class="dv">1</span> <span class="fl">0.647095</span>[c] <span class="fl">0.048808085</span>[e]   <span class="fl">13.25794257</span>[g] <span class="fl">1.16E-17</span>[i]</span></code></pre></div>
<hr />
<p><strong>El Sistema SAS</strong></p>
<div class="sourceCode" id="cb27"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb27-1"><a href="C2BasicLR.html#cb27-1" tabindex="-1"></a>                         The REG Procedure</span>
<span id="cb27-2"><a href="C2BasicLR.html#cb27-2" tabindex="-1"></a>                    Dependent Variable<span class="sc">:</span> SALES</span>
<span id="cb27-3"><a href="C2BasicLR.html#cb27-3" tabindex="-1"></a></span>
<span id="cb27-4"><a href="C2BasicLR.html#cb27-4" tabindex="-1"></a>                        Analysis of Variance</span>
<span id="cb27-5"><a href="C2BasicLR.html#cb27-5" tabindex="-1"></a>                               Sum of           Mean</span>
<span id="cb27-6"><a href="C2BasicLR.html#cb27-6" tabindex="-1"></a>Source                   DF        Squares         Square     F Value      Pr <span class="sc">&gt;</span> F</span>
<span id="cb27-7"><a href="C2BasicLR.html#cb27-7" tabindex="-1"></a>Model                  <span class="dv">1</span>[m]   <span class="dv">2527165015</span>[p]   <span class="dv">2527165015</span>[s]   <span class="fl">175.77</span>[u]    <span class="sc">&lt;</span>.<span class="dv">0001</span>[v]</span>
<span id="cb27-8"><a href="C2BasicLR.html#cb27-8" tabindex="-1"></a>Error                 <span class="dv">48</span>[n]    <span class="dv">690116755</span>[q]     <span class="dv">14377432</span>[t]</span>
<span id="cb27-9"><a href="C2BasicLR.html#cb27-9" tabindex="-1"></a>Corrected Total       <span class="dv">49</span>[o]   <span class="dv">3217281770</span>[r]</span>
<span id="cb27-10"><a href="C2BasicLR.html#cb27-10" tabindex="-1"></a></span>
<span id="cb27-11"><a href="C2BasicLR.html#cb27-11" tabindex="-1"></a>        Root MSE           <span class="fl">3791.75848</span>[j]    R<span class="sc">-</span>Square     <span class="fl">0.7855</span>[k]</span>
<span id="cb27-12"><a href="C2BasicLR.html#cb27-12" tabindex="-1"></a>        Dependent Mean     <span class="fl">6494.82900</span>[H]    Adj R<span class="sc">-</span>Sq     <span class="fl">0.7810</span>[l]</span>
<span id="cb27-13"><a href="C2BasicLR.html#cb27-13" tabindex="-1"></a>        Coeff Var            <span class="fl">58.38119</span>[I]</span>
<span id="cb27-14"><a href="C2BasicLR.html#cb27-14" tabindex="-1"></a></span>
<span id="cb27-15"><a href="C2BasicLR.html#cb27-15" tabindex="-1"></a>                        Parameter Estimates</span>
<span id="cb27-16"><a href="C2BasicLR.html#cb27-16" tabindex="-1"></a>                           Parameter       Standard</span>
<span id="cb27-17"><a href="C2BasicLR.html#cb27-17" tabindex="-1"></a>Variable     Label        DF     Estimate        Error      t  Value    Pr <span class="sc">&gt;</span> <span class="er">|</span>t<span class="sc">|</span></span>
<span id="cb27-18"><a href="C2BasicLR.html#cb27-18" tabindex="-1"></a>Intercept    Intercept     <span class="dv">1</span>   <span class="fl">469.70360</span>[b]  <span class="fl">702.90619</span>[d]    <span class="fl">0.67</span>[f]    <span class="fl">0.5072</span>[h]</span>
<span id="cb27-19"><a href="C2BasicLR.html#cb27-19" tabindex="-1"></a>POP          POP           <span class="dv">1</span>     <span class="fl">0.64709</span>[c]    <span class="fl">0.04881</span>[e]   <span class="fl">13.26</span>[g]    <span class="sc">&lt;</span>.<span class="dv">0001</span>[i]</span></code></pre></div>
<hr />
<p><strong>Salida en R</strong></p>
<div class="sourceCode" id="cb28"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb28-1"><a href="C2BasicLR.html#cb28-1" tabindex="-1"></a>Analysis of Variance Table</span>
<span id="cb28-2"><a href="C2BasicLR.html#cb28-2" tabindex="-1"></a></span>
<span id="cb28-3"><a href="C2BasicLR.html#cb28-3" tabindex="-1"></a>Response<span class="sc">:</span> SALES</span>
<span id="cb28-4"><a href="C2BasicLR.html#cb28-4" tabindex="-1"></a>          Df     Sum Sq      Mean Sq        F value         <span class="fu">Pr</span>(<span class="sc">&gt;</span>F)</span>
<span id="cb28-5"><a href="C2BasicLR.html#cb28-5" tabindex="-1"></a>POP        <span class="dv">1</span>[m] <span class="dv">2527165015</span>[p] <span class="dv">2527165015</span>[s] <span class="fl">175.77304</span>[u] <span class="sc">&lt;</span><span class="fl">2.22e-16</span>[v]<span class="sc">**</span><span class="er">*</span></span>
<span id="cb28-6"><a href="C2BasicLR.html#cb28-6" tabindex="-1"></a>Residuals <span class="dv">48</span>[n]  <span class="dv">690116755</span>[q]   <span class="dv">14377432</span>[t]</span>
<span id="cb28-7"><a href="C2BasicLR.html#cb28-7" tabindex="-1"></a><span class="sc">---</span></span>
<span id="cb28-8"><a href="C2BasicLR.html#cb28-8" tabindex="-1"></a>Call<span class="sc">:</span> <span class="fu">lm</span>(<span class="at">formula =</span> SALES <span class="sc">~</span> POP)</span>
<span id="cb28-9"><a href="C2BasicLR.html#cb28-9" tabindex="-1"></a></span>
<span id="cb28-10"><a href="C2BasicLR.html#cb28-10" tabindex="-1"></a>Residuals<span class="sc">:</span></span>
<span id="cb28-11"><a href="C2BasicLR.html#cb28-11" tabindex="-1"></a>   Min     1Q Median     3Q    Max</span>
<span id="cb28-12"><a href="C2BasicLR.html#cb28-12" tabindex="-1"></a> <span class="sc">-</span><span class="dv">6047</span>  <span class="sc">-</span><span class="dv">1461</span>   <span class="sc">-</span><span class="dv">670</span>    <span class="dv">486</span>  <span class="dv">18229</span></span>
<span id="cb28-13"><a href="C2BasicLR.html#cb28-13" tabindex="-1"></a></span>
<span id="cb28-14"><a href="C2BasicLR.html#cb28-14" tabindex="-1"></a>Coefficients<span class="sc">:</span></span>
<span id="cb28-15"><a href="C2BasicLR.html#cb28-15" tabindex="-1"></a>            Estimate     Std. Error t value     <span class="fu">Pr</span>(<span class="sc">&gt;</span><span class="er">|</span>t<span class="sc">|</span>)</span>
<span id="cb28-16"><a href="C2BasicLR.html#cb28-16" tabindex="-1"></a>(Intercept) <span class="fl">469.7036</span>[b] <span class="fl">702.9062</span>[d]  <span class="fl">0.67</span>[f]    <span class="fl">0.51</span>     [h]</span>
<span id="cb28-17"><a href="C2BasicLR.html#cb28-17" tabindex="-1"></a>POP           <span class="fl">0.6471</span>[c]   <span class="fl">0.0488</span>[e] <span class="fl">13.26</span>[g]   <span class="sc">&lt;</span><span class="fl">2e-16</span> <span class="sc">**</span><span class="er">*</span>[i]</span>
<span id="cb28-18"><a href="C2BasicLR.html#cb28-18" tabindex="-1"></a><span class="sc">---</span></span>
<span id="cb28-19"><a href="C2BasicLR.html#cb28-19" tabindex="-1"></a>Signif. codes<span class="sc">:</span>  <span class="dv">0</span> ?<span class="sc">**</span><span class="er">*</span>? <span class="fl">0.001</span> ?<span class="sc">**</span>? <span class="fl">0.01</span> ?<span class="sc">*</span>? <span class="fl">0.05</span> ?.? <span class="fl">0.1</span> ? ? <span class="dv">1</span></span>
<span id="cb28-20"><a href="C2BasicLR.html#cb28-20" tabindex="-1"></a></span>
<span id="cb28-21"><a href="C2BasicLR.html#cb28-21" tabindex="-1"></a>Residual standard error<span class="sc">:</span> <span class="dv">3792</span>[j] on <span class="dv">48</span>[n] degrees of freedom</span>
<span id="cb28-22"><a href="C2BasicLR.html#cb28-22" tabindex="-1"></a>Multiple R<span class="sc">-</span>Squared<span class="sc">:</span> <span class="fl">0.785</span>[k],      Adjusted R<span class="sc">-</span>squared<span class="sc">:</span> <span class="fl">0.781</span>[l]</span>
<span id="cb28-23"><a href="C2BasicLR.html#cb28-23" tabindex="-1"></a>F<span class="sc">-</span>statistic<span class="sc">:</span>  <span class="dv">176</span>[u] on <span class="dv">1</span>[m] and <span class="dv">48</span>[n] DF,  p<span class="sc">-</span>value<span class="sc">:</span> <span class="er">&lt;</span><span class="fl">2e-16</span>[v]</span></code></pre></div>
<hr />
<p><strong>Definición de Anotación de Leyenda, Símbolo</strong></p>
<p>[a] Número de observaciones <span class="math inline">\(n\)</span>. <br>
[b] La intersección estimada <span class="math inline">\(b_0\)</span>. <br>
[c] La pendiente estimada <span class="math inline">\(b_1\)</span>. <br>
[d] El error estándar de la intersección, <span class="math inline">\(se(b_0)\)</span>. <br>
[e] El error estándar de la pendiente, <span class="math inline">\(se(b_1)\)</span>. <br>
[f] El valor del <span class="math inline">\(t\)</span> asociado con la intersección, <span class="math inline">\(t(b_0) = b_0/se(b_0)\)</span>. <br>
[g] El valor del <span class="math inline">\(t\)</span> asociado con la pendiente, <span class="math inline">\(t(b_1) = b_1/se(b_1)\)</span>. <br>
[h] El valor <span class="math inline">\(p\)</span> asociado con la intersección; aquí, <span class="math inline">\(p-value=Pr(|t_{n-2}|&gt;|t(b_0)|)\)</span>, donde <span class="math inline">\(t(b_0)\)</span> es el valor realizado (0.67 aquí) y <span class="math inline">\(t_{n-2}\)</span> tiene una distribución <span class="math inline">\(t\)</span> con <span class="math inline">\(df=n-2\)</span>. <br>
[i] El valor <span class="math inline">\(p\)</span> asociado con la pendiente; aquí, <span class="math inline">\(p-value=Pr(|t_{n-2}|&gt;|t(b_1)|)\)</span>, donde <span class="math inline">\(t(b_1)\)</span> es el valor realizado (13.26 aquí) y <span class="math inline">\(t_{n-2}\)</span> tiene una distribución <span class="math inline">\(t\)</span> con <span class="math inline">\(df=n-2\)</span>. <br>
[j] La desviación estándar residual, <span class="math inline">\(s\)</span>. <br>
[k] El coeficiente de determinación, <span class="math inline">\(R^2\)</span>. <br>
[l] El coeficiente de determinación ajustado por grados de libertad, <span class="math inline">\(R_{a}^2\)</span>. (Este término se definirá en el Capítulo 3.) <br>
[m] Grados de libertad para el componente de regresión. Esto es 1 para una variable explicativa. <br>
[n] Grados de libertad para el componente de error, <span class="math inline">\(n-2\)</span>, para la regresión con una variable explicativa. <br>
[o] Grados de libertad totales, <span class="math inline">\(n-1\)</span>. <br>
[p] La suma de cuadrados de la regresión, <span class="math inline">\(Regression~SS\)</span>. <br>
[q] La suma de cuadrados del error, <span class="math inline">\(Error~SS\)</span>. <br>
[r] La suma total de cuadrados, <span class="math inline">\(Total~SS\)</span>. <br>
[s] El cuadrado medio de la regresión, <span class="math inline">\(Regression~MS = Regression~SS/1\)</span>, para una variable explicativa. <br>
[t] El cuadrado medio del error, <span class="math inline">\(s^2=Error~MS = Error~SS/(n-2)\)</span>, para una variable explicativa. <br>
[u] El <span class="math inline">\(F-ratio=(Regression~MS)/(Error~MS)\)</span>. (Este término se definirá en el Capítulo 3.) <br>
[v] El valor <span class="math inline">\(p\)</span> asociado con el <span class="math inline">\(F-ratio\)</span>. (Este término se definirá en el Capítulo 3.) <br>
[w] El número de observación, <span class="math inline">\(i\)</span>. <br>
[x] El valor de la variable explicativa para la <span class="math inline">\(i\)</span>-ésima observación, <span class="math inline">\(x_i\)</span>. <br>
[y] La respuesta para la <span class="math inline">\(i\)</span>-ésima observación, <span class="math inline">\(y_i\)</span>. <br>
[z] El valor ajustado para la <span class="math inline">\(i\)</span>-ésima observación, <span class="math inline">\(\widehat{y}_i\)</span>. <br>
[A] El error estándar del ajuste, <span class="math inline">\(se(\widehat{y}_i)\)</span>. <br>
[B] El residual para la <span class="math inline">\(i\)</span>-ésima observación, <span class="math inline">\(e_i\)</span>. <br>
[C] El residual estandarizado para la <span class="math inline">\(i\)</span>-ésima observación, <span class="math inline">\(e_i/se(e_i)\)</span>. El error estándar <span class="math inline">\(se(e_i)\)</span> se definirá en la Sección 5.3.1. <br>
[F] El coeficiente de correlación múltiple es la raíz cuadrada del coeficiente de determinación, <span class="math inline">\(R=\sqrt{R^2}\)</span>. Esto se definirá en el Capítulo 3. <br>
[G] El coeficiente estandarizado es <span class="math inline">\(b_1s_x/s_y\)</span>. Para regresión con una variable explicativa, esto es equivalente a <span class="math inline">\(r\)</span>, el coeficiente de correlación. <br>
[H] La respuesta promedio, <span class="math inline">\(\overline{y}\)</span>. <br>
[I] El coeficiente de variación de la respuesta es <span class="math inline">\(s_y/\overline{y}\)</span>. SAS imprime <span class="math inline">\(100s_y/\overline{y}\)</span>. <br></p>
</div>
<div id="Sec29" class="section level2 hasAnchor" number="2.9">
<h2><span class="header-section-number">2.9</span> Lecturas Adicionales y Referencias<a href="C2BasicLR.html#Sec29" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Relativamente pocas aplicaciones de la regresión son básicas en el sentido de que usan solo una variable explicativa; el propósito del análisis de regresión es reducir las relaciones complejas entre muchas variables. La Sección <a href="C2BasicLR.html#Sec27">2.7</a> describe una excepción importante a esta regla general, el modelo financiero CAPM; consulta a Panjer et al. (1998) para descripciones actuariales adicionales de este modelo. Campbell et al. (1997) ofrece una perspectiva desde la econometría financiera.</p>
<p><strong>Referencias del Capítulo</strong></p>
<ul>
<li>Anscombe, Frank (1973). Graphs in statistical analysis. <em>The American Statistician</em> 27, 17-21.</li>
<li>Campbell, John Y., Andrew W. Lo and A. Craig MacKinlay (1997). <em>The Econometrics of Financial Markets</em>. Princeton University Press, Princeton, New Jersey.</li>
<li>Frees, Edward W. and Tom W. Miller (2003). Sales forecasting using longitudinal data models. <em>International Journal of Forecasting</em> 20, 97-111.</li>
<li>Goldberger, Arthur (1991). <em>A Course in Econometrics</em>. Harvard University Press, Cambridge.</li>
<li>Koch, Gary J. (1985). A basic demonstration of the [-1, 1] range for the correlation coefficient. <em>American Statistician</em> 39, 201-202.</li>
<li>Linter, J. (1965). The valuation of risky assets and the selection of risky investments in stock portfolios and capital budgets. <em>Review of Economics and Statistics</em>, 13-37.</li>
<li>Manistre, B. John and Geoffrey H. Hancock (2005). Variance of the CTE estimator. <em>North American Actuarial Journal</em> 9(2), 129-156.</li>
<li>Markowitz, Harry (1959). <em>Portfolio Selection: Efficient Diversification of Investments</em>. John Wiley, New York.</li>
<li>Panjer, Harry H., Phelim P. Boyle, Samuel H. Cox, Daniel Dufresne, Hans U. Gerber, Heinz H. Mueller, Hal W. Pedersen, Stanley R. Pliska, Michael Sherris, Elias S. Shiu and Ken S. Tan (1998). <em>Financial Economics: With Applications to Investment, Insurance and Pensions</em>. Society of Actuaries, Schaumburg, Illinois.</li>
<li>Pearson, Karl (1895). <em>Royal Society Proceedings</em> 58, 241.</li>
<li>Serfling, Robert J. (1980). <em>Approximation Theorems of Mathematical Statistics</em>. John Wiley and Sons, New York.</li>
<li>Sharpe, William F. (1964). Capital asset prices: A theory of market equilibrium under risk. <em>Journal of Finance</em>, 425-442.</li>
<li>Stigler, Steven M. (1986). <em>The History of Statistics: The Measurement of Uncertainty before 1900</em>. Harvard University Press, Cambridge, MA.</li>
</ul>
</div>
<div id="Sec210" class="section level2 hasAnchor" number="2.10">
<h2><span class="header-section-number">2.10</span> Ejercicios<a href="C2BasicLR.html#Sec210" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<div id="secciones-2.1-2.2" class="section level4 unnumbered hasAnchor">
<h4>Secciones 2.1-2.2<a href="C2BasicLR.html#secciones-2.1-2.2" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>2.1 Considera el siguiente conjunto de datos
<span class="math display">\[
\begin{array}{l|ccc}
\hline
i &amp; 1 &amp; 2 &amp; 3 \\ \hline
x_i &amp; 2 &amp; -6 &amp; 7 \\
y_i &amp; 3 &amp; 4 &amp; 6\\ \hline
\end{array}
\]</span></p>
<p>Ajusta una línea de regresión utilizando el método de mínimos cuadrados. Determina <span class="math inline">\(r\)</span>, <span class="math inline">\(b_1\)</span> y <span class="math inline">\(b_0\)</span>.</p>
<p>2.2 <strong>Una relación perfecta, pero sin correlación.</strong> Considera la relación cuadrática <span class="math inline">\(y=x^2\)</span>, con datos</p>
<p><span class="math display">\[
\begin{array}{l|ccccc}
\hline
i &amp; 1 &amp; 2 &amp; 3 &amp; 4 &amp; 5\\ \hline
x_i &amp; -2 &amp; -1 &amp; 0 &amp; 1 &amp; 2 \\
y_i &amp; 4 &amp; 1 &amp; 0 &amp; 1 &amp; 4\\ \hline
\end{array}
\]</span></p>
<ol style="list-style-type: lower-alpha">
<li>Produce un gráfico aproximado para este conjunto de datos.<br />
</li>
<li>Verifica que el coeficiente de correlación es <span class="math inline">\(r=0\)</span>.</li>
</ol>
<p>2.3 <strong>Acotación del coeficiente de correlación.</strong> Utiliza los siguientes pasos para demostrar que <span class="math inline">\(r\)</span> está acotado entre -1 y 1 (Estos pasos son de Koch, 1990).</p>
<ol style="list-style-type: lower-alpha">
<li>Deja que <span class="math inline">\(a\)</span> y <span class="math inline">\(c\)</span> sean constantes genéricas. Verifica
<span class="math display">\[\begin{eqnarray*}
0 &amp; \leq &amp; \frac{1}{n-1}\sum_{i=1}^{n}\left(
a\frac{x_i-\overline{x}}{s_x}-c
\frac{y_i-\overline{y}}{s_y}\right) ^2 \\
&amp;=&amp; a^2+c^2-2acr.
\end{eqnarray*}\]</span></li>
<li>Utiliza los resultados del apartado (a) para demostrar que <span class="math inline">\(2ac(r-1)\leq (a-c)^2.\)</span><br />
</li>
<li>Al tomar <span class="math inline">\(a=c\)</span>, utiliza el resultado del apartado (b) para demostrar que <span class="math inline">\(r\leq 1\)</span>.<br />
</li>
<li>Al tomar <span class="math inline">\(a=-c\)</span>, utiliza los resultados del apartado (b) para demostrar que <span class="math inline">\(r\geq -1\)</span>.<br />
</li>
<li>¿En qué condiciones es <span class="math inline">\(r=-1\)</span>? ¿En qué condiciones es <span class="math inline">\(r=1\)</span>?</li>
</ol>
<p>2.4 <strong>Los coeficientes de regresión son sumas ponderadas.</strong> Demuestra que el término de intercepto, <span class="math inline">\(b_0\)</span>, puede expresarse como una suma ponderada de las variables dependientes. Es decir, demuestra que
<span class="math inline">\(b_0=\sum_{i=1}^{n}w_{i,0}y_i.\)</span> Además, expresa los pesos en términos de los pesos de la pendiente, <span class="math inline">\(w_i\)</span>.</p>
<p>2.5 <strong>Otra expresión para la pendiente como una suma ponderada</strong></p>
<ol style="list-style-type: lower-alpha">
<li>Utilizando álgebra, establece una expresión alternativa
<span class="math display">\[\begin{equation*}
b_1=\frac{\sum_{i=1}^{n}weight_i~slope_i}{ \sum_{i=1}^{n}weight_i}.
\end{equation*}\]</span>
Aquí, <span class="math inline">\(slope_i\)</span> es la pendiente entre <span class="math inline">\((x_i,y_i)\)</span> y <span class="math inline">\((\bar{x},\bar{y})\)</span>. Da una forma precisa para el peso <span class="math inline">\(weight_i\)</span> como una función de la variable explicativa <span class="math inline">\(x\)</span>.<br />
</li>
<li>Supón que <span class="math inline">\(\bar{x} = 4, \bar{y} = 3, x_1 = 2 \text{ y } y_1= 6\)</span>. Determina la pendiente y el peso para la primera observación, es decir, <span class="math inline">\(slope_1\)</span> y <span class="math inline">\(weight_1\)</span>.</li>
</ol>
<p>2.6 Considera dos variables, <span class="math inline">\(y\)</span> y <span class="math inline">\(x\)</span>. Realiza una regresión de <span class="math inline">\(y\)</span> sobre <span class="math inline">\(x\)</span> para obtener un coeficiente de pendiente que llamaremos <span class="math inline">\(b_{1,x,y}\)</span>. Realiza otra regresión de <span class="math inline">\(x\)</span> sobre <span class="math inline">\(y\)</span> para obtener un coeficiente de pendiente que llamaremos <span class="math inline">\(b_{1,y,x}\)</span>. Demuestra que el coeficiente de correlación entre <span class="math inline">\(x\)</span> y <span class="math inline">\(y\)</span> es la media geométrica de los dos coeficientes de pendiente según el signo, es decir, demuestra que <span class="math inline">\(|r|=\sqrt{ b_{1,x,y}b_{1,y,x}}.\)</span></p>
<p>2.7 <strong>Regresión a través del origen.</strong> Considera el modelo <span class="math inline">\(y_i=\beta_1 x_i + \varepsilon_i\)</span>, es decir, regresión con una variable explicativa <em>sin</em> el término de intercepto. Este modelo se llama <em>regresión a través del origen</em> porque la verdadera línea de regresión <span class="math inline">\(\mathrm{E}y = \beta_1 x\)</span> pasa por el origen (el punto (0, 0)). Para este modelo, la estimación de mínimos cuadrados de <span class="math inline">\(\beta_1\)</span> es ese número <span class="math inline">\(b_1\)</span> que minimiza la suma de cuadrados <span class="math inline">\(\mathrm{SS}(b_1^{\ast} )=\sum_{i=1}^{n}\left( y_i - b_1^{\ast}x_i\right) ^2.\)</span></p>
<ol style="list-style-type: lower-alpha">
<li><p>Verifica que
<span class="math display">\[\begin{equation*}
b_1 = \frac{\sum_{i=1}^{n} x_i y_i}{\sum_{i=1}^{n}x_i^2}.
\end{equation*}\]</span></p></li>
<li><p>Considera el modelo <span class="math inline">\(y_i=\beta_1 z_i^2 + \varepsilon_i\)</span>, un modelo cuadrático que pasa por el origen. Utiliza el resultado del apartado (a) para determinar la estimación de mínimos cuadrados de <span class="math inline">\(\beta_1\)</span>.</p></li>
</ol>
<p>2.8 a. Demuestra que
<span class="math display">\[\begin{equation*}
s_y^2=\frac{1}{n-1}\sum_{i=1}^{n}\left( y_i-\overline{y}\right) ^2=
\frac{1}{n-1}\left( \sum_{i=1}^{n}y_i^2-n\overline{y}^2\right) .
\end{equation*}\]</span></p>
<ol start="2" style="list-style-type: lower-alpha">
<li>Sigue los mismos pasos para demostrar que <span class="math inline">\(\sum_{i=1}^{n}\left( y_i - \overline{y} \right) \left( x_i-\overline{x}\right) =\sum_{i=1}^{n} x_i y_i - n \overline{x}~\overline{y}.\)</span><br />
</li>
<li>Demuestra que
<span class="math display">\[
b_{1}=\frac{\sum_{i=1}^{n}\left( y_i-\overline{y}\right) \left( x_i-
\overline{x}\right) }{\sum_{i=1}^{n}\left( x_i - \overline{x}
\right) ^2}
\]</span></li>
<li>Establece la fórmula comúnmente utilizada
<span class="math display">\[
b_{1}=
\frac{\sum_{i=1}^{n}x_iy_i-n\overline{x}~\overline{y}}
{\sum_{i=1}^{n}x_i^2 - n\overline{x}^2}.
\]</span></li>
</ol>
<p>2.9 <strong>Interpretación de los coeficientes asociados con una variable explicativa binaria.</strong> Supón que <span class="math inline">\(x_i\)</span> solo toma los valores 0 y 1. De las <span class="math inline">\(n\)</span> observaciones, <span class="math inline">\(n_1\)</span> toman el valor <span class="math inline">\(x=0\)</span>. Estas <span class="math inline">\(n_1\)</span> observaciones tienen un valor promedio <span class="math inline">\(y\)</span> de <span class="math inline">\(\overline{y}_1\)</span>. Las restantes <span class="math inline">\(n-n_1\)</span> observaciones tienen el valor <span class="math inline">\(x=1\)</span> y un valor promedio <span class="math inline">\(y\)</span> de <span class="math inline">\(\overline{y}_2\)</span>. Utiliza el Ejercicio 2.8 para demostrar que <span class="math inline">\(b_1 = \overline{y}_2 - \overline{y}_1.\)</span></p>
<p>2.10 <strong>Utilización de Hogares de Cuidado.</strong><br />
Este ejercicio considera los datos de hogares de cuidado proporcionados por el Departamento de Salud y Servicios Familiares de Wisconsin (DHFS) y descritos en el Ejercicio 1.2.</p>
<p><strong>Parte 1:</strong> Utiliza los datos del año 2000 y realiza el siguiente análisis.</p>
<ol style="list-style-type: lower-alpha">
<li><p>Correlaciones</p>
<p>a(i). Calcula la correlación entre TPY y LOGTPY. Comenta tu resultado. <br>
a(ii). Calcula la correlación entre TPY, NUMBED y SQRFOOT. ¿Parecen estas variables altamente correlacionadas? <br>
a(iii). Calcula la correlación entre TPY y NUMBED/10. Comenta tu resultado. <br></p></li>
<li><p>Diagramas de dispersión. Grafica TPY versus NUMBED y TPY versus SQRFOOT. Comenta los gráficos.</p></li>
<li><p>Regresión lineal básica.</p>
<p>c(i). Ajusta un modelo de regresión lineal básico usando TPY como variable de resultado y NUMBED como variable explicativa. Resume el ajuste citando el coeficiente de determinación, <span class="math inline">\(R^2\)</span>, y el estadístico <span class="math inline">\(t\)</span> para NUMBED. <br>
c(ii). Repite c(i), usando SQRFOOT en lugar de NUMBED. En términos de <span class="math inline">\(R^2\)</span>, ¿cuál modelo se ajusta mejor? <br>
c(iii). Repite c(i), usando LOGTPY como variable de resultado y LOG(NUMBED) como variable explicativa. <br>
c(iv). Repite c(iii), usando LOGTPY como variable de resultado y LOG(SQRFOOT) como variable explicativa. <br></p></li>
</ol>
<p><strong>Parte 2:</strong> Ajusta el modelo en la Parte 1.c(i) usando datos de 2001. ¿Son los patrones estables a lo largo del tiempo?</p>
</div>
<div id="secciones-2.3-2.4" class="section level4 unnumbered hasAnchor">
<h4>Secciones 2.3-2.4<a href="C2BasicLR.html#secciones-2.3-2.4" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>2.11 Supón que, para un tamaño de muestra de <span class="math inline">\(n\)</span> = 3, tienes <span class="math inline">\(e_2\)</span> = 24 y <span class="math inline">\(e_{3}\)</span> = -1. Determina <span class="math inline">\(e_{1}\)</span>.</p>
<p>2.12 Supón que <span class="math inline">\(r=0\)</span>, <span class="math inline">\(n=15\)</span> y <span class="math inline">\(s_y = 10\)</span>. Determina <span class="math inline">\(s\)</span>.</p>
<p>2.13 <strong>El coeficiente de correlación y el coeficiente de determinación.</strong> Usa los siguientes pasos para establecer una relación entre el coeficiente de determinación y el coeficiente de correlación.</p>
<ol style="list-style-type: lower-alpha">
<li>Muestra que <span class="math inline">\(\widehat{y}_i-\overline{y}=b_1(x_i-\overline{x}).\)</span><br />
</li>
<li>Usa el apartado (a) para mostrar que <span class="math inline">\(Regress~SS=\sum_{i=1}^{n}\left(\widehat{y}_i - \overline{y} \right)^2 = b_1^2s_x^2(n-1).\)</span><br />
</li>
<li>Usa el apartado (b) para establecer que <span class="math inline">\(R^2=r^2.\)</span></li>
</ol>
<p>2.14 Muestra que el residuo promedio es cero, es decir, muestra que <span class="math inline">\(n^{-1}\sum_{i=1}^{n} e_i=0.\)</span></p>
<p>2.15 <strong>Correlación entre residuos y variables explicativas.</strong> Considera una secuencia genérica de pares de números <span class="math inline">\((x_1,y_1)\)</span>, …, <span class="math inline">\((x_n,y_n)\)</span> con el coeficiente de correlación calculado como<br />
<span class="math inline">\(r(y,x)=\left[ (n-1)s_ys_x\right] ^{-1}\sum_{i=1}^{n}\left( y_i-\overline{y}\right) \left( x_i-\overline{x}\right) .\)</span></p>
<ol style="list-style-type: lower-alpha">
<li>Supón que <span class="math inline">\(\overline{y}=0\)</span>, <span class="math inline">\(\overline{x}=0\)</span> o ambos <span class="math inline">\(\overline{x}\)</span> y <span class="math inline">\(\overline{y}=0\)</span>. Luego, verifica que <span class="math inline">\(r(y,x)=0\)</span> implica <span class="math inline">\(\sum_{i=1}^{n}y_i x_i=0\)</span> y viceversa.<br />
</li>
<li>Muestra que la correlación entre los residuos y las variables explicativas es cero. Haz esto usando la parte (a) del Ejercicio 2.13 para mostrar que <span class="math inline">\(\sum_{i=1}^{n} x_i e_i = 0\)</span> y luego aplica la parte (a).<br />
</li>
<li>Muestra que la correlación entre los residuos y los valores ajustados es cero. Haz esto mostrando que <span class="math inline">\(\sum_{i=1}^n \widehat{y}_i e_i = 0\)</span> y luego aplica la parte (a).</li>
</ol>
<p>2.16 <strong>Correlación y estadísticas <span class="math inline">\(t\)</span>.</strong> Usa los siguientes pasos para establecer una relación entre el coeficiente de correlación y el estadístico <span class="math inline">\(t\)</span> para la pendiente.</p>
<ol style="list-style-type: lower-alpha">
<li><p>Usa álgebra para verificar que
<span class="math display">\[\begin{equation*}
R^2=1-\frac{n-2}{n-1}\frac{s^2}{s_y^2}.
\end{equation*}\]</span></p></li>
<li><p>Usa la parte (a) para establecer la siguiente fórmula rápida para <span class="math inline">\(s\)</span>,
<span class="math display">\[\begin{equation*}s = s_y \sqrt{(1-r^2)\frac{n-1}{n-2}}.\end{equation*}\]</span></p></li>
<li><p>Usa la parte (b) para mostrar que
<span class="math display">\[\begin{equation*}
t(b_1) = \sqrt{n-2}\frac{r}{\sqrt{1-r^2}}.
\end{equation*}\]</span></p></li>
</ol>
<hr />
<p>2.17 <strong>Efectos de un punto inusual.</strong> Estás analizando un conjunto de datos de tamaño <span class="math inline">\(n=100\)</span>. Has realizado un análisis de regresión usando una variable predictora y notas que el residuo para la décima observación es inusualmente grande.</p>
<ol style="list-style-type: lower-alpha">
<li>Supón que, de hecho, resulta que <span class="math inline">\(e_{10}=8s\)</span>. ¿Qué porcentaje de la suma de cuadrados de los errores, <span class="math inline">\(Error~SS\)</span>, se debe a la décima observación?<br />
</li>
<li>Supón que <span class="math inline">\(e_{10}=4s\)</span>. ¿Qué porcentaje de la suma de cuadrados de errores, <span class="math inline">\(Error~SS\)</span>, se debe a la décima observación?<br />
</li>
<li>Supón que reduces el conjunto de datos a tamaño <span class="math inline">\(n=20\)</span>. Después de realizar la regresión, resulta que todavía tenemos <span class="math inline">\(e_{10}=4s\)</span>. ¿Qué porcentaje de la suma de cuadrados de errores, <span class="math inline">\(Error~SS\)</span>, se debe a la décima observación?</li>
</ol>
<p>2.18 Considera un conjunto de datos de 20 observaciones con las siguientes estadísticas resumen: <span class="math inline">\(\overline{x}=0\)</span>, <span class="math inline">\(\overline{y}=9\)</span>, <span class="math inline">\(s_x=1\)</span> y <span class="math inline">\(s_y=10\)</span>. Realizas una regresión usando una variable y determinas que <span class="math inline">\(s=7\)</span>. Determina el error estándar de una predicción en <span class="math inline">\(x_{\ast}=1.\)</span></p>
<p>2.19 <strong>Las estadísticas resumen pueden ocultar relaciones importantes.</strong> Los datos en <a href="C2BasicLR.html#Table29">Tabla 2.9</a> son de Anscombe (1973). El propósito de este ejercicio es demostrar cómo
graficar los datos puede revelar información importante que no es evidente en las estadísticas numéricas resumen.</p>
<p><a id=Table29></a></p>
<p><span id="Table29">Tabla 2.9</span>. <strong>Datos de Anscombe (1973)</strong></p>
<p><span class="math display">\[
{\small
\begin{array}{c|rrrrrr}
\hline
obs &amp;  &amp;  &amp;  &amp;  &amp;  &amp;  \\
num &amp; x_1 &amp; y_1 &amp; y_2 &amp; y_3 &amp; x_2 &amp; y_4 \\
\hline 1 &amp; 10 &amp; 8.04 &amp; 9.14 &amp; 7.46 &amp; 8 &amp;
6.58 \\
2 &amp; 8 &amp; 6.95 &amp;  8.14 &amp; 6.77 &amp; 8 &amp;
5.76 \\
3 &amp; 13 &amp; 7.58 &amp; 8.74 &amp; 12.74 &amp; 8 &amp;
7.71 \\
4 &amp; 9 &amp; 8.81 &amp; 8.77 &amp; 7.11 &amp; 8 &amp;
8.84 \\
5 &amp; 11 &amp; 8.33 &amp; 9.26 &amp; 7.81 &amp; 8 &amp;
8.47 \\
6 &amp; 14 &amp; 9.96 &amp; 8.10 &amp; 8.84 &amp; 8 &amp;
7.04 \\
7 &amp; 6 &amp; 7.24 &amp; 6.13 &amp; 6.08 &amp; 8 &amp;
5.25 \\
8 &amp; 4 &amp; 4.26 &amp; 3.10 &amp; 5.39 &amp; 8 &amp;
5.56 \\
9 &amp; 12 &amp; 10.84 &amp; 9.13 &amp; 8.15 &amp; 8 &amp;
7.91 \\
10 &amp; 7 &amp; 4.82 &amp; 7.26 &amp; 6.42 &amp; 8 &amp;
6.89 \\
11 &amp; 5 &amp; 5.68 &amp; 4.74 &amp; 5.73 &amp; 19 &amp; 12.50 \\
\hline
\end{array}
}
\]</span></p>
<ol style="list-style-type: lower-alpha">
<li><p>Calcula los promedios y desviaciones estándar de cada columna de datos. Verifica que los promedios y desviaciones estándar de cada una de las columnas <span class="math inline">\(x\)</span> son iguales, dentro de dos decimales, y de manera similar para cada una de las columnas <span class="math inline">\(y\)</span>.</p></li>
<li><p>Realiza cuatro regresiones, (1) <span class="math inline">\(y_{1}\)</span> sobre <span class="math inline">\(x_{1}\)</span>, (2) <span class="math inline">\(y_2\)</span> sobre <span class="math inline">\(x_{1}\)</span>, (3) <span class="math inline">\(y_{3}\)</span> sobre <span class="math inline">\(x_{1}\)</span> y (4) <span class="math inline">\(y_{4}\)</span> sobre <span class="math inline">\(x_2\)</span>. Verifica, para cada uno de los cuatro ajustes de regresión, que <span class="math inline">\(b_0\approx 3.0\)</span>, <span class="math inline">\(b_{1}\approx 0.5\)</span>, <span class="math inline">\(s\approx 1.237\)</span> y <span class="math inline">\(R^2\approx 0.677\)</span>, dentro de dos decimales.<br />
</p></li>
<li><p>Produce diagramas de dispersión para cada uno de los cuatro modelos de regresión que ajustaste en el apartado (b).<br />
</p></li>
<li><p>Discute el hecho de que los modelos de regresión ajustados en el apartado (b) implican que los cuatro conjuntos de datos son similares, aunque los cuatro diagramas de dispersión producidos en el apartado (c) muestran una historia dramáticamente diferente.</p></li>
</ol>
<p>2.20 <strong>Utilización de Hogares de Cuidado.</strong> Este ejercicio considera los datos de hogares de cuidado proporcionados por el Departamento de Salud y Servicios Familiares de Wisconsin (DHFS) y descritos en el Ejercicio 1.2 y 2.10.</p>
<p>Decides examinar la relación entre los años totales de pacientes (LOGTPY) y el número de camas (LOGNUMBED), ambos en unidades logarítmicas, usando datos del año 2001.</p>
<ol style="list-style-type: lower-alpha">
<li><p>Estadísticas descriptivas. Crea estadísticas descriptivas básicas para cada variable. Resume la relación mediante un estadístico de correlación y un diagrama de dispersión.</p></li>
<li><p>Ajusta el modelo lineal básico. Cita las estadísticas descriptivas básicas, incluye el coeficiente de determinación, el coeficiente de regresión para LOGNUMBED y el estadístico <span class="math inline">\(t\)</span> correspondiente.</p></li>
<li><p><strong>Pruebas de hipótesis.</strong> Prueba las siguientes hipótesis al nivel de significancia del 5% usando un estadístico <span class="math inline">\(t\)</span>. También calcula el valor <span class="math inline">\(p\)</span> correspondiente.</p>
<p>c(i). Prueba <span class="math inline">\(H_0: \beta_1 = 0\)</span> frente a <span class="math inline">\(H_a: \beta_1 \neq 0\)</span>. <br>
c(ii). Prueba <span class="math inline">\(H_0: \beta_1 = 1\)</span> frente a <span class="math inline">\(H_a: \beta_1 \neq 1\)</span>. <br>
c(iii). Prueba <span class="math inline">\(H_0: \beta_1 = 1\)</span> frente a <span class="math inline">\(H_a: \beta_1 &gt; 1\)</span>. <br>
c(iv). Prueba <span class="math inline">\(H_0: \beta_1 = 1\)</span> frente a <span class="math inline">\(H_a: \beta_1 &lt; 1\)</span>. <br></p></li>
<li><p>Estás interesado en el efecto que un cambio marginal en LOGNUMBED tiene sobre el valor esperado de LOGTPY.</p>
<p>d(i). Supón que hay un cambio marginal en LOGNUMBED de 2. Proporciona una estimación puntual del cambio esperado en LOGTPY. <br>
d(ii). Proporciona un intervalo de confianza del 95% correspondiente a la estimación puntual en la parte d(i). <br>
d(iii). Proporciona un intervalo de confianza del 99% correspondiente a la estimación puntual en la parte d(i). <br></p></li>
<li><p>En un número especificado de camas estimado en <span class="math inline">\(x_{*} = 100\)</span>, haz lo siguiente:</p>
<p>e(i). Encuentra el valor predicho de LOGTPY. <br>
e(ii). Obtén el error estándar de la predicción. <br>
e(iii). Obtén un intervalo de predicción del 95% para tu predicción. <br>
e(iv). Convierte la predicción puntual en la parte e(i) y el intervalo de predicción obtenido en la parte e(iii) en años totales de personas (mediante exponenciación). <br>
e(v). Obtén un intervalo de predicción como en la parte e(iv), correspondiente a un nivel del 90% (en lugar del 95%).</p></li>
</ol>
<p>2.21 <strong>Ofertas Públicas Iniciales.</strong> Como analista financiero, deseas convencer a un cliente de las ventajas de invertir en empresas que acaban de ingresar a una bolsa de valores, en una OPI (oferta pública inicial). Por lo tanto, reúnes datos de 116 empresas que fijaron precios durante el período de seis meses del 1 de enero de 1998 al 1 de junio de 1998. Al mirar estos datos históricos recientes, puedes calcular RETURN, el retorno de la empresa en un año (en porcentaje).</p>
<p>También estás interesado en observar características financieras de la empresa que puedan ayudarte a entender (y predecir) el retorno. Inicialmente examinas REVENUE, los ingresos de la empresa en 1997 en millones de dólares. Desafortunadamente, esta variable no estaba disponible para seis empresas. Por lo tanto, las estadísticas a continuación son para las 110 empresas que tienen tanto REVENUE como RETURN. Además, la Tabla <a href="C2BasicLR.html#tab:IPOSumStats">2.9</a> proporciona información sobre los ingresos logarítmicos (naturales), denominados como LnREV, y el precio inicial de la acción, denominado PRICEIPO.</p>
<table class=" lightable-classic table table-striped table-condensed" style="font-size: 12px; font-family: Cambria; width: auto !important; margin-left: auto; margin-right: auto; margin-left: auto; margin-right: auto;">
<caption style="font-size: initial !important;">
<span id="tab:IPOSumStats">Tabla 2.9: </span><strong>Estadísticas Resumen de Cada Variable</strong>
</caption>
<thead>
<tr>
<th style="text-align:left;">
</th>
<th style="text-align:right;">
Media
</th>
<th style="text-align:right;">
Mediana
</th>
<th style="text-align:right;">
Desviación Estándar
</th>
<th style="text-align:right;">
Mínimo
</th>
<th style="text-align:right;">
Máximo
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;width: 2.5cm; border-right:1px solid;">
RETURN
</td>
<td style="text-align:right;width: 1.6cm; ">
0.106
</td>
<td style="text-align:right;width: 1.6cm; ">
-0.130
</td>
<td style="text-align:right;width: 1.6cm; ">
0.824
</td>
<td style="text-align:right;width: 1.6cm; ">
-0.938
</td>
<td style="text-align:right;width: 1.6cm; ">
4.333
</td>
</tr>
<tr>
<td style="text-align:left;width: 2.5cm; border-right:1px solid;">
REV
</td>
<td style="text-align:right;width: 1.6cm; ">
134.487
</td>
<td style="text-align:right;width: 1.6cm; ">
39.971
</td>
<td style="text-align:right;width: 1.6cm; ">
261.881
</td>
<td style="text-align:right;width: 1.6cm; ">
0.099
</td>
<td style="text-align:right;width: 1.6cm; ">
1455.761
</td>
</tr>
<tr>
<td style="text-align:left;width: 2.5cm; border-right:1px solid;">
LnREV
</td>
<td style="text-align:right;width: 1.6cm; ">
3.686
</td>
<td style="text-align:right;width: 1.6cm; ">
3.688
</td>
<td style="text-align:right;width: 1.6cm; ">
1.698
</td>
<td style="text-align:right;width: 1.6cm; ">
-2.316
</td>
<td style="text-align:right;width: 1.6cm; ">
7.283
</td>
</tr>
<tr>
<td style="text-align:left;width: 2.5cm; border-right:1px solid;">
PRICEIPO
</td>
<td style="text-align:right;width: 1.6cm; ">
13.195
</td>
<td style="text-align:right;width: 1.6cm; ">
13.000
</td>
<td style="text-align:right;width: 1.6cm; ">
4.694
</td>
<td style="text-align:right;width: 1.6cm; ">
4.000
</td>
<td style="text-align:right;width: 1.6cm; ">
29.000
</td>
</tr>
</tbody>
</table>
<ol style="list-style-type: lower-alpha">
<li><p>Hipotetizas que las empresas más grandes, medida por ingresos, son más estables y, por lo tanto, deberían tener mayores retornos. Has determinado que la correlación entre RETURN y REVENUE es -0.0175.</p>
<p>a(i). Calcula el ajuste de mínimos cuadrados usando REVENUE para predecir RETURN. Determina <span class="math inline">\(b_0\)</span> y <span class="math inline">\(b_1\)</span>. <br>
a(ii). Para Hyperion Telecommunications, los ingresos son 95.55 (millones de dólares). Calcula el RETURN ajustado usando el ajuste de regresión en la parte a(i). <br></p></li>
</ol>
<p><a id=Table211></a></p>
<p><span id="Table211">Tabla 2.11</span>. <strong>Resultados de la Regresión con Ingresos Logarítmicos</strong></p>
<p><span class="math display">\[
{\small
\begin{array}{l|rrr}
\hline
&amp;  &amp; \text{Error} &amp;  \\
\text{Variable} &amp; \text{Coeficiente} &amp; \text{Estándar} &amp; t-\text{estadístico} \\
\hline
\text{INTERCEPTO} &amp; 0.438 &amp; 0.186 &amp; 2.35\\
\text{LnREV}  &amp; -0.090 &amp; 0.046 &amp; -1.97 \\
\hline s = 0.8136, &amp; R^2 = 0.03452 \\ \hline
\end{array}
}
\]</span></p>
<ol start="2" style="list-style-type: lower-alpha">
<li><p>Ingresos logarítmicos y retornos. <br></p>
<p>b(i). Supón que usas LnREV para predecir RETURN. Calcula el RETURN ajustado bajo este modelo de regresión. ¿Es igual a tu respuesta en la parte a(ii)? <br>
b(ii) ¿Afectan significativamente los ingresos logarítmicos a los retornos? Para ello, proporciona una prueba formal de hipótesis. Expón tus hipótesis nula y alternativa, el criterio de toma de decisiones y la regla de toma de decisiones. Usa un nivel de significancia del 10%. <br>
b(iii). Hipotetizas que, manteniendo todo constante, las empresas con mayores ingresos serán más estables y, por lo tanto, tendrán un mayor retorno inicial. Por lo tanto, deseas considerar la hipótesis nula de ninguna relación entre LnREV y RETURN frente a la hipótesis alternativa de que hay una relación positiva entre LnREV y RETURN. Para ello, proporciona una prueba formal de hipótesis. Expón tus hipótesis nula y alternativa, el criterio de toma de decisiones y la regla de toma de decisiones. Usa un nivel de significancia del 10%. <br></p></li>
<li><p>Determina la correlación entre LnREV y RETURN. Asegúrate de indicar si esta correlación es positiva, negativa o cero.</p></li>
<li><p>Estás considerando invertir en una empresa que tiene LnREV = 2 (por lo que los ingresos son <span class="math inline">\(e^2\)</span> = 7.389 millones de dólares).</p>
<p>d(i). Usando el modelo de regresión ajustado, determina la predicción puntual de mínimos cuadrados. <br>
d(ii). Determina el intervalo de predicción del 95% correspondiente a tu predicción en la parte d(i). <br></p></li>
<li><p>El <span class="math inline">\(R^2\)</span> del modelo de regresión ajustado es un decepcionante 3.5%. Parte de la dificultad se debe a la observación número 59, la Corporación Inktomi. Las ventas de Inktomi están en el 12º lugar más bajo del conjunto de datos, con LnREV = 1.76 (por lo que los ingresos son <span class="math inline">\(e^{1.76} = 5.79\)</span> millones de dólares), pero tiene el mayor retorno en el primer año, con RETURN = 433.33.</p>
<p>e(i). Calcula el residuo para esta observación. <br>
e(ii). ¿Qué proporción de la variabilidad no explicada (suma de cuadrados de errores) representa esta observación? <br>
e(iii). Define la idea de una observación de alto apalancamiento. <br>
e(iv). ¿Se consideraría esta observ</p></li>
</ol>
<p>ación como una observación de alto apalancamiento? Justifica tu respuesta.</p>
<p>2.22 <strong>Esperanzas de Vida Nacionales.</strong> Continuamos el análisis iniciado en el Ejercicio 1.7 examinando la relación entre <span class="math inline">\(y= LIFEEXP\)</span> y <span class="math inline">\(x=FERTILITY\)</span>, mostrado en la Figura @ref(fig:Fig2.12). Ajusta un modelo de regresión lineal de <span class="math inline">\(LIFEEXP\)</span> usando la variable explicativa <span class="math inline">\(x=FERTILITY\)</span>.</p>
<p>(ref:Fig2.12) <strong>Gráfico de FERTILITY versus LIFEEXP.</strong></p>
<div class="figure" style="text-align: center">
<img src="RegressionMarkdown_files/figure-html/Fig2.12-1.png" alt="(ref:Fig2.12)" width="60%" />
<p class="caption">
(#fig:Fig2.12)(ref:Fig2.12)
</p>
</div>
<ol style="list-style-type: lower-alpha">
<li><p>EE.UU. tiene una tasa de FERTILITY de 2.0. Determina la esperanza de vida ajustada.</p></li>
<li><p>La nación insular Dominica no reportó una tasa de FERTILITY y, por lo tanto, no se incluyó en la regresión. Supón que su tasa de FERTILITY es 2.0. Proporciona un intervalo de predicción del 95% para la esperanza de vida en Dominica.</p></li>
<li><p>China tiene una tasa de FERTILITY de 1.7 y una esperanza de vida de 72.5. Determina el residuo bajo el modelo. ¿Cuántos múltiplos de <span class="math inline">\(s\)</span> está este residuo alejado de cero?</p></li>
<li><p>Supón que tu hipótesis previa es que la pendiente de FERTILITY es -6.0 y deseas probar la hipótesis nula de que la pendiente ha aumentado (es decir, la pendiente es mayor que -6.0). Prueba esta hipótesis al nivel de significancia del 5%. También calcula un valor <span class="math inline">\(p\)</span> aproximado.</p></li>
</ol>
</div>
</div>
<div id="Sec211" class="section level2 hasAnchor" number="2.11">
<h2><span class="header-section-number">2.11</span> Suplemento Técnico - Elementos del Álgebra de Matrices<a href="C2BasicLR.html#Sec211" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Los ejemplos son una herramienta excelente para introducir temas técnicos como la regresión. Sin embargo, este capítulo también ha utilizado álgebra, así como probabilidad y estadística básica, para darte una comprensión más profunda del análisis de regresión. A partir de ahora, estudiaremos relaciones multivariantes. Con muchas cosas ocurriendo simultáneamente en varias dimensiones, el álgebra ya no es útil para proporcionar información. En cambio, necesitaremos el álgebra de <em>matrices</em>. Este suplemento ofrece una breve introducción al álgebra de matrices para que puedas estudiar los capítulos de regresión lineal de este texto. El Apéndice A3 define conceptos adicionales de matrices.</p>
<div id="Sec2111" class="section level3 hasAnchor" number="2.11.1">
<h3><span class="header-section-number">2.11.1</span> Definiciones Básicas<a href="C2BasicLR.html#Sec2111" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Una <em>matriz</em> es una tabla rectangular de números organizados en filas y columnas (el plural de matriz es matrices). Por ejemplo, considera los ingresos y la edad de 3 personas.</p>
<p><span class="math display">\[\begin{equation*}
\mathbf{A}=
\begin{array}{c}
Fila~1 \\
Fila~2 \\
Fila~3
\end{array}
\overset{
\begin{array}{cc}
~~~Col~1~ &amp; Col~2
\end{array}
}{\left(
\begin{array}{cc}
6,000 &amp; 23 \\
13,000 &amp; 47 \\
11,000 &amp; 35
\end{array}
\right) }
\end{equation*}\]</span></p>
<p>Aquí, la columna 1 representa el ingreso y la columna 2 representa la edad. Cada fila corresponde a un individuo. Por ejemplo, el primer individuo tiene 23 años y un ingreso de $6,000.</p>
<p>El número de filas y columnas se llama la <em>dimensión</em> de la matriz. Por ejemplo, la dimensión de la matriz <span class="math inline">\(\mathbf{A}\)</span> anterior es <span class="math inline">\(3\times 2\)</span> (se lee 3 “por” 2). Esto significa 3 filas y 2 columnas. Si quisiéramos representar los ingresos y la edad de 100 personas, entonces la dimensión de la matriz sería <span class="math inline">\(100\times 2\)</span>.</p>
<p>Es conveniente representar una matriz usando la notación</p>
<p><span class="math display">\[\begin{equation*}
\mathbf{A}=\left(
\begin{array}{cc}
a_{11} &amp; a_{12} \\
a_{21} &amp; a_{22} \\
a_{31} &amp; a_{32}
\end{array}
\right) .
\end{equation*}\]</span></p>
<p>Aquí, <span class="math inline">\(a_{ij}\)</span> es el símbolo para el número en la <span class="math inline">\(i\)</span>-ésima fila y <span class="math inline">\(j\)</span>-ésima columna de <span class="math inline">\(\mathbf{A}\)</span>. En general, trabajamos con matrices de la forma</p>
<p><span class="math display">\[\begin{equation*}
\mathbf{A}=\left(
\begin{array}{cccc}
a_{11} &amp; a_{12} &amp; \cdots &amp; a_{1k} \\
\vdots &amp; \vdots &amp; \ddots &amp; \vdots \\
a_{n1} &amp; a_{n2} &amp; \cdots &amp; a_{nk}
\end{array}
\right) .
\end{equation*}\]</span></p>
<p>En este caso, la matriz <span class="math inline">\(\mathbf{A}\)</span> tiene dimensión <span class="math inline">\(n\times k\)</span>.</p>
<p>Un <em>vector</em> es una matriz especial. Un <em>vector fila</em> es una matriz que contiene solo 1 fila (<span class="math inline">\(k=1\)</span>). Un <em>vector columna</em> es una matriz que contiene solo 1 columna (<span class="math inline">\(n=1\)</span>). Por ejemplo,</p>
<p><span class="math display">\[\begin{equation*}
\text{vector columna}\rightarrow \left(
\begin{array}{c}
2 \\
3 \\
4 \\
5 \\
6
\end{array}
\right) ~~~~\text{vector fila}\rightarrow \left(
\begin{array}{ccccc}
2 &amp; 3 &amp; 4 &amp; 5 &amp; 6
\end{array}
\right) .
\end{equation*}\]</span></p>
<p>Observa que el vector fila ocupa mucho menos espacio en una página impresa que el vector columna correspondiente. Una operación básica que relaciona estas dos cantidades es la <em>transposición</em>. La transposición de una matriz <span class="math inline">\(\mathbf{A}\)</span> se define intercambiando las filas y columnas y se denota por <span class="math inline">\(\mathbf{A }^{\prime }\)</span> (o <span class="math inline">\(\mathbf{A}^{T}\)</span>). Por ejemplo,</p>
<p><span class="math display">\[\begin{equation*}
\mathbf{A}=\left(
\begin{array}{cc}
6,000 &amp; 23 \\
13,000 &amp; 47 \\
11,000 &amp; 35
\end{array}
\right) ~~~\mathbf{A}^{\prime }=\left(
\begin{array}{ccc}
6,000 &amp; 13,000 &amp; 11,000 \\
23 &amp; 47 &amp; 35
\end{array}
\right) .
\end{equation*}\]</span></p>
<p>Así, si <span class="math inline">\(\mathbf{A}\)</span> tiene dimensión <span class="math inline">\(n\times k\)</span>, entonces <span class="math inline">\(\mathbf{A}^{\prime }\)</span> tiene dimensiones <span class="math inline">\(k\times n\)</span>.</p>
</div>
<div id="Sec2112" class="section level3 hasAnchor" number="2.11.2">
<h3><span class="header-section-number">2.11.2</span> Algunas Matrices Especiales<a href="C2BasicLR.html#Sec2112" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<ul>
<li><p>Una <em>matriz cuadrada</em> es una matriz donde el número de filas es igual al número de columnas, es decir, <span class="math inline">\(n=k\)</span>.</p></li>
<li><p>Los <em>números diagonales</em> de una matriz cuadrada son los números en una matriz donde el número de fila es igual al número de columna, por ejemplo, <span class="math inline">\(a_{11}\)</span>, <span class="math inline">\(a_{22}\)</span>, y así sucesivamente. Una <em>matriz diagonal</em> es una matriz cuadrada en la que todos los números no diagonales son iguales a 0. Por ejemplo,
<span class="math display">\[\begin{equation*}
\mathbf{A}=\left(
\begin{array}{ccc}
-1 &amp; 0 &amp; 0 \\
0 &amp; 2 &amp; 0 \\
0 &amp; 0 &amp; 3
\end{array}
\right) .
\end{equation*}\]</span></p></li>
<li><p>Una <em>matriz identidad</em> es una matriz diagonal donde todos los números diagonales son iguales a 1. Esta matriz especial se denota a menudo por <span class="math inline">\(\mathbf{I}\)</span>.</p></li>
<li><p>Una <em>matriz simétrica</em> es una matriz cuadrada <span class="math inline">\(\mathbf{A}\)</span> tal que la matriz permanece sin cambios si intercambiamos las filas y las columnas. Más formalmente, una matriz <span class="math inline">\(\mathbf{A}\)</span> es simétrica si <span class="math inline">\(\mathbf{A=A} ^{\prime }\)</span>. Por ejemplo,
<span class="math display">\[\begin{equation*}
\mathbf{A}=\left(
\begin{array}{ccc}
1 &amp; 2 &amp; 3 \\
2 &amp; 4 &amp; 5 \\
3 &amp; 5 &amp; 10
\end{array}
\right) \mathbf{=A}^{\prime }.
\end{equation*}\]</span>
Observa que una matriz diagonal es una matriz simétrica.</p></li>
</ul>
</div>
<div id="Sec2113" class="section level3 hasAnchor" number="2.11.3">
<h3><span class="header-section-number">2.11.3</span> Operaciones Básicas<a href="C2BasicLR.html#Sec2113" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<div id="multiplicación-por-un-escalar" class="section level4 unnumbered hasAnchor">
<h4>Multiplicación por un Escalar<a href="C2BasicLR.html#multiplicación-por-un-escalar" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>Sea <span class="math inline">\(\mathbf{A}\)</span> una matriz de <span class="math inline">\(n\times k\)</span> y sea <span class="math inline">\(c\)</span> un número real. Es decir, un número real es una matriz de <span class="math inline">\(1\times 1\)</span> y también se llama <em>escalar</em>. Multiplicar un escalar <span class="math inline">\(c\)</span> por una matriz <span class="math inline">\(\mathbf{A}\)</span> se denota por <span class="math inline">\(c\mathbf{A}\)</span> y se define por
<span class="math display">\[\begin{equation*}
c\mathbf{A}=\left(
\begin{array}{cccc}
ca_{11} &amp; ca_{12} &amp; \cdots &amp; ca_{1k} \\
\vdots &amp; \vdots &amp; \ddots &amp; \vdots \\
ca_{n1} &amp; ca_{n2} &amp; \cdots &amp; ca_{nk}
\end{array}
\right) .
\end{equation*}\]</span>
Por ejemplo, supongamos que <span class="math inline">\(c=10\)</span> y
<span class="math display">\[\begin{equation*}
\mathbf{A}=\left(
\begin{array}{cc}
1 &amp; 2 \\
6 &amp; 8
\end{array}
\right) ~~~~~\text{entonces} ~~~~\mathbf{B}=c\mathbf{A}=\left(
\begin{array}{cc}
10 &amp; 20 \\
60 &amp; 80
\end{array}
\right) .
\end{equation*}\]</span>
Observa que <span class="math inline">\(c\mathbf{A}=\mathbf{A}c\)</span>.</p>
</div>
<div id="suma-y-resta-de-matrices" class="section level4 unnumbered hasAnchor">
<h4>Suma y Resta de Matrices<a href="C2BasicLR.html#suma-y-resta-de-matrices" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>Sean <span class="math inline">\(\mathbf{A}\)</span> y <span class="math inline">\(\mathbf{B}\)</span> matrices con dimensiones <span class="math inline">\(n\times k\)</span>. Utiliza <span class="math inline">\(a_{ij}\)</span> y <span class="math inline">\(b_{ij}\)</span> para denotar los números en la <span class="math inline">\(i\)</span>-ésima fila y <span class="math inline">\(j\)</span>-ésima columna de <span class="math inline">\(\mathbf{A}\)</span> y <span class="math inline">\(\mathbf{B}\)</span>, respectivamente. Entonces, la matriz <span class="math inline">\(\mathbf{C}=\mathbf{A}+\mathbf{B}\)</span> se define como la matriz con <span class="math inline">\((a_{ij}+b_{ij})\)</span> en la <span class="math inline">\(i\)</span>-ésima fila y <span class="math inline">\(j\)</span>-ésima columna. De manera similar, la matriz <span class="math inline">\(\mathbf{C}=\mathbf{A}-\mathbf{B}\)</span> se define como la matriz con <span class="math inline">\((a_{ij}-b_{ij})\)</span> en la <span class="math inline">\(i\)</span>-ésima fila y <span class="math inline">\(j\)</span>-ésima columna. Simbólicamente, escribimos esto como sigue.
<span class="math display">\[\begin{equation*}
\text{Si   }\mathbf{A=}\left( a_{ij}\right) _{ij}\text{    y
   } \mathbf{B=}\left( b_{ij}\right) _{ij}\text{, entonces}
\end{equation*}\]</span>
<span class="math display">\[\begin{equation*}
\mathbf{C}=\mathbf{A}+\mathbf{B=}\left( a_{ij}+b_{ij}\right)
_{ij}\text{    y    }\mathbf{C}=\mathbf{A}-\mathbf{B=}\left(
a_{ij}-b_{ij}\right) _{ij}.
\end{equation*}\]</span>
Por ejemplo, considera
<span class="math display">\[\begin{equation*}
\mathbf{A}=\left(
\begin{array}{cc} 2 &amp; 5 \\ 4 &amp; 1 \end{array}
\right) ~~~\mathbf{B}=\left(
\begin{array}{cc} 4 &amp; 6 \\ 8 &amp; 1 \end{array}
\right).
\end{equation*}\]</span>
Entonces
<span class="math display">\[\begin{equation*}
\mathbf{A}+\mathbf{B}=\left(
\begin{array}{cc} 6 &amp; 11 \\ 12 &amp; 2 \end{array}
\right) ~~~\mathbf{A}-\mathbf{B}=\left(
\begin{array}{cc} -2 &amp; -1 \\ -4 &amp; 0 \end{array}
\right) .
\end{equation*}\]</span></p>
<hr />
<p><strong>Ejemplo Básico de Regresión Lineal de Suma y Resta</strong>. Ahora, recuerda que el modelo básico de regresión lineal puede escribirse como <span class="math inline">\(n\)</span> ecuaciones:
<span class="math display">\[\begin{equation*}
\begin{array}{c}
y_1=\beta_0+\beta_1x_1+\varepsilon_1 \\
\vdots \\
y_n=\beta_0+\beta_1x_n+\varepsilon_n.
\end{array}
\end{equation*}\]</span>
Podemos definir
<span class="math display">\[\begin{equation*}
\mathbf{y}=\left(
\begin{array}{c} y_1 \\ \vdots \\ y_n \end{array}
\right)
~~~\boldsymbol \varepsilon =
\left(
\begin{array}{c} \varepsilon_1 \\ \vdots \\ \varepsilon_n \end{array}
\right)
~~~\text{y}~~~
\mathrm{E~}\mathbf{y} =\left(
\begin{array}{c} \beta_0+\beta_1 x_1 \\ \vdots \\ \beta_0 + \beta_1 x_n \end{array}
\right) .
\end{equation*}\]</span>
Con esta notación, podemos expresar las <span class="math inline">\(n\)</span> ecuaciones de manera más compacta como <span class="math inline">\(\mathbf{y} = \mathrm{E~}\mathbf{y}+\boldsymbol \varepsilon\)</span>.</p>
</div>
<div id="multiplicación-de-matrices" class="section level4 unnumbered hasAnchor">
<h4>Multiplicación de Matrices<a href="C2BasicLR.html#multiplicación-de-matrices" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>En general, si <span class="math inline">\(\mathbf{A}\)</span> es una matriz de dimensión <span class="math inline">\(n\times c\)</span> y <span class="math inline">\(\mathbf{B}\)</span> es una matriz de dimensión <span class="math inline">\(c\times k\)</span>, entonces <span class="math inline">\(\mathbf{C}=\mathbf{AB}\)</span> es una matriz de dimensión <span class="math inline">\(n\times k\)</span> y se define por
<span class="math display">\[\begin{equation*}
\mathbf{C}=\mathbf{AB}=\left( \sum_{s=1}^{c}a_{is}b_{sj}\right)_{ij}.
\end{equation*}\]</span>
Por ejemplo, considera las matrices <span class="math inline">\(2\times 2\)</span>
<span class="math display">\[\begin{equation*}
\mathbf{A}=\left(
\begin{array}{cc}
2 &amp; 5 \\
4 &amp; 1
\end{array}
\right) ~~~\mathbf{B}=\left(
\begin{array}{cc}
4 &amp; 6 \\
8 &amp; 1
\end{array}
\right) .
\end{equation*}\]</span>
La matriz <span class="math inline">\(\mathbf{AB}\)</span> tiene dimensión <span class="math inline">\(2\times 2\)</span>. Para ilustrar el cálculo, considera el número en la primera fila y segunda columna de <span class="math inline">\(\mathbf{AB}\)</span>. Según la regla presentada arriba, con <span class="math inline">\(i=1\)</span> y <span class="math inline">\(j=2\)</span>, el elemento correspondiente de <span class="math inline">\(\mathbf{AB}\)</span> es <span class="math inline">\(\sum_{s=1}^2a_{1s}b_{s2}=a_{11}b_{12}+a_{12}b_{22}=2(6)+5(1)=17\)</span>. Los otros cálculos se resumen como
<span class="math display">\[\begin{equation*}
\mathbf{AB}=\left(
\begin{array}{cc}
2(4)+5(8) &amp; 2(6)+5(1) \\
4(4)+1(8) &amp; 4(6)+1(1)
\end{array}
\right) =\left(
\begin{array}{cc}
48 &amp; 17 \\
24 &amp; 25
\end{array}
\right) .
\end{equation*}\]</span>
Como otro ejemplo, supongamos
<span class="math display">\[\begin{equation*}
\mathbf{A}=\left(
\begin{array}{ccc}
1 &amp; 2 &amp; 4 \\
0 &amp; 5 &amp; 8
\end{array}
\right) ~~~\mathbf{B}=\left(
\begin{array}{c}
3 \\
5 \\
2
\end{array}
\right) .
\end{equation*}\]</span>
Como <span class="math inline">\(\mathbf{A}\)</span> tiene dimensión <span class="math inline">\(2\times 3\)</span> y <span class="math inline">\(\mathbf{B}\)</span> tiene dimensión <span class="math inline">\(3\times 1\)</span>, esto significa que el producto <span class="math inline">\(\mathbf{AB}\)</span> tiene dimensión <span class="math inline">\(2\times 1\)</span>. Los cálculos se resumen como
<span class="math display">\[\begin{equation*}
\mathbf{AB}=\left(
\begin{array}{c}
1(3)+2(5)+4(2) \\
0(3)+5(5)+8(2)
\end{array}
\right) =\left(
\begin{array}{c}
21 \\
41
\end{array}
\right) .
\end{equation*}\]</span>
Para algunos ejemplos adicionales, tenemos
<span class="math display">\[\begin{equation*}
\left(
\begin{array}{cc}
4 &amp; 2 \\
5 &amp; 8
\end{array}
\right) \left(
\begin{array}{c}
a_1 \\
a_2
\end{array}
\right) =\left(
\begin{array}{c}
4a_1+2a_2 \\
5a_1+8a_2
\end{array}
\right) .
\end{equation*}\]</span>
<span class="math display">\[\begin{equation*}
\left(
\begin{array}{ccc}
2 &amp; 3 &amp; 5
\end{array}
\right) \left(
\begin{array}{c}
2 \\
3 \\
5
\end{array}
\right) =2^2+3^2+5^2=38~~~\left(
\begin{array}{c}
2 \\
3 \\
5
\end{array}
\right) \left(
\begin{array}{ccc}
2 &amp; 3 &amp; 5
\end{array}
\right) =\left(
\begin{array}{ccc}
4 &amp; 6 &amp; 10 \\
6 &amp; 9 &amp; 15 \\
10 &amp; 15 &amp; 25
\end{array}
\right) .
\end{equation*}\]</span>
En general, observa que <span class="math inline">\(\mathbf{AB}\neq \mathbf{BA}\)</span> en la multiplicación de matrices, a diferencia de la multiplicación de escalares (números reales). Además, observamos que la matriz identidad cumple el papel de “uno” en la multiplicación de matrices, ya que <span class="math inline">\(\mathbf{AI=A}\)</span> y <span class="math inline">\(\mathbf{IA=A}\)</span> para cualquier matriz <span class="math inline">\(\mathbf{A}\)</span>, siempre que las dimensiones sean compatibles para permitir la multiplicación de matrices.</p>
<p><strong>Ejemplo Básico de Regresión Lineal de Multiplicación de Matrices</strong>. Define
<span class="math display">\[\begin{equation*}
\mathbf{X}=\left(
\begin{array}{cc}
1 &amp; x_1 \\
\vdots &amp; \vdots \\
1 &amp; x_n
\end{array}
\right) \text{   y   } \boldsymbol \beta =\left(
\begin{array}{c}
\beta_0 \\
\beta_1
\end{array}
\right) \text{, para obtener } \mathbf{X} \boldsymbol{\beta} =\left(
\begin{array}{c}
\beta_0+\beta_1x_1 \\
\vdots \\
\beta_0+\beta_1x_n
\end{array}
\right) =\mathbf{\mathrm{E~}\mathbf{y}}.
\end{equation*}\]</span>
Así, se obtiene la expresión matricial familiar del modelo de regresión, <span class="math inline">\(\mathbf{y}=\mathbf{X} \boldsymbol{\beta} + \boldsymbol{\varepsilon}\)</span>. Otras cantidades útiles incluyen
<span class="math display">\[\begin{equation*}
\mathbf{y}^{\prime }\mathbf{y}=\left(
\begin{array}{ccc}
y_1 &amp; \cdots &amp; y_n
\end{array}
\right) \left(
\begin{array}{c}
y_1 \\
\vdots \\
y_n
\end{array}
\right) =y_1^2+\cdots +y_n^2=\sum_{i=1}^{n}y_i^2,
\end{equation*}\]</span>
<span class="math display">\[\begin{equation*}
\mathbf{X}^{\prime }\mathbf{y}=\left(
\begin{array}{ccc}
1 &amp; \cdots &amp; 1 \\
x_1 &amp; \cdots &amp; x_n
\end{array}
\right) \left(
\begin{array}{c}
y_1 \\
\vdots \\
y_n
\end{array}
\right) =\left(
\begin{array}{c}
\sum_{i=1}^{n}y_i \\
\sum_{i=1}^{n}x_iy_i
\end{array}
\right)
\end{equation*}\]</span>
y
<span class="math display">\[\begin{equation*}
\mathbf{X}^{\prime }\mathbf{X}=\left(
\begin{array}{ccc}
1 &amp; \cdots &amp; 1 \\
x_1 &amp; \cdots &amp; x_n
\end{array}
\right) \left(
\begin{array}{cc}
1 &amp; x_1 \\
\vdots &amp; \vdots \\
1 &amp; x_n
\end{array}
\right) =\left(
\begin{array}{cc}
n &amp; \sum_{i=1}^{n}x_i \\
\sum_{i=1}^{n}x_i &amp; \sum_{i=1}^{n} x_i^2
\end{array}
\right) .
\end{equation*}\]</span>
Observa que <span class="math inline">\(\mathbf{X}^{\prime }\mathbf{X}\)</span> es una matriz simétrica.</p>
</div>
<div id="inversas-de-matrices" class="section level4 unnumbered hasAnchor">
<h4>Inversas de Matrices<a href="C2BasicLR.html#inversas-de-matrices" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>En álgebra de matrices, no existe el concepto de “división.” En su lugar, extendemos el concepto de “recíprocos” de los números reales. Para comenzar, supongamos que <span class="math inline">\(\mathbf{A}\)</span> es una matriz cuadrada de dimensión <span class="math inline">\(k \times k\)</span> y que <span class="math inline">\(\mathbf{I}\)</span> es la matriz identidad de dimensión <span class="math inline">\(k \times k\)</span>. Si existe una matriz <span class="math inline">\(k \times k\)</span> llamada <span class="math inline">\(\mathbf{B}\)</span> tal que <span class="math inline">\(\mathbf{AB}=\mathbf{I}=\mathbf{BA}\)</span>, entonces <span class="math inline">\(\mathbf{B}\)</span> se llama <em>inversa</em> de <span class="math inline">\(\mathbf{A}\)</span> y se escribe como
<span class="math display">\[\begin{equation*}
\mathbf{B}=\mathbf{A}^{-1}.
\end{equation*}\]</span>
No todas las matrices cuadradas tienen inversas. Además, incluso cuando existe una inversa, puede no ser fácil de calcular manualmente. Una excepción a esta regla son las matrices diagonales. Supongamos que <span class="math inline">\(\mathbf{A}\)</span> es una matriz diagonal de la forma
<span class="math display">\[\begin{equation*}
\mathbf{A}=\left(
\begin{array}{ccc}
a_{11} &amp; \cdots &amp; 0 \\
\vdots &amp; \ddots &amp; \vdots \\
0 &amp; \cdots &amp; a_{kk}
\end{array}
\right). \text{   Entonces   } \mathbf{A}^{-1}=\left(
\begin{array}{ccc}
\frac{1}{a_{11}} &amp; \cdots &amp; 0 \\
\vdots &amp; \ddots &amp; \vdots \\
0 &amp; \cdots &amp; \frac{1}{a_{kk}}
\end{array}
\right).
\end{equation*}\]</span>
Por ejemplo,
<span class="math display">\[\begin{equation*}
\begin{array}{cccc}
\left(
\begin{array}{cc}
2 &amp; 0 \\
0 &amp; -19
\end{array}
\right) &amp; \left(
\begin{array}{cc}
\frac{1}{2} &amp; 0 \\
0 &amp; -\frac{1}{19}
\end{array}
\right) &amp; = &amp; \left(
\begin{array}{cc}
1 &amp; 0 \\
0 &amp; 1
\end{array}
\right) \\
\mathbf{A} &amp; \mathbf{A}^{-1} &amp; = &amp; \mathbf{I}
\end{array}
.
\end{equation*}\]</span>
En el caso de una matriz de dimensión <span class="math inline">\(2\times 2\)</span>, el procedimiento de inversión se puede realizar manualmente incluso cuando la matriz no es diagonal. En el caso de <span class="math inline">\(2\times 2\)</span>, supongamos que si
<span class="math display">\[\begin{equation*}
\mathbf{A}=\left(
\begin{array}{cc}
a &amp; b \\
c &amp; d
\end{array}
\right), \text{    entonces  } \mathbf{A}^{-1}=\frac{1}{ad-bc}\left(
\begin{array}{cc}
d &amp; -b \\
-c &amp; a
\end{array}
\right) \text{.}
\end{equation*}\]</span>
Así, por ejemplo, si
<span class="math display">\[\begin{equation*}
\mathbf{A}=\left(
\begin{array}{cc}
2 &amp; 2 \\
3 &amp; 4
\end{array}
\right) \text{  entonces   } \mathbf{A}^{-1}=\frac{1}{2(4)-2(3)} \left(
\begin{array}{cc}
4 &amp; -2 \\
-3 &amp; 2
\end{array}
\right) =\left(
\begin{array}{cc}
2 &amp; -1 \\
-3/2 &amp; 1
\end{array}
\right) \text{.}
\end{equation*}\]</span>
Como verificación, tenemos
<span class="math display">\[\begin{equation*}
\mathbf{A}\mathbf{A}^{-1}=\left(
\begin{array}{cc}
2 &amp; 2 \\
3 &amp; 4
\end{array}
\right) \left(
\begin{array}{cc}
2 &amp; -1 \\
-3/2 &amp; 1
\end{array}
\right) =\left(
\begin{array}{cc}
2(2)-2(3/2) &amp; 2(-1)+2(1) \\
3(2)-4(3/2) &amp; 3(-1)+4(1)
\end{array}
\right) =\left(
\begin{array}{cc}
1 &amp; 0 \\
0 &amp; 1
\end{array}
\right) =\mathbf{I}\text{.}
\end{equation*}\]</span></p>
<hr />
<p><strong>Ejemplo Básico de Regresión Lineal de Inversas de Matrices.</strong> Con
<span class="math display">\[\begin{equation*}
\mathbf{X}^{\prime }\mathbf{X}=\left(
\begin{array}{cc}
n &amp; \sum\limits_{i=1}^{n}x_i \\
\sum\limits_{i=1}^{n}x_i &amp; \sum\limits_{i=1}^{n}x_i^2
\end{array}
\right),
\end{equation*}\]</span>
tenemos
<span class="math display">\[\begin{equation*}
\left( \mathbf{X}^{\prime }\mathbf{X}\right)^{-1}=\frac{1}{n\sum_{i=1}^{n}x_i^2-\left( \sum_{i=1}^{n}x_i\right) ^2}\left(
\begin{array}{cc}
\sum\limits_{i=1}^{n}x_i^2 &amp; -\sum\limits_{i=1}^{n}x_i \\
-\sum\limits_{i=1}^{n}x_i &amp; n
\end{array}
\right).
\end{equation*}\]</span>
Para simplificar esta expresión, recuerda que <span class="math inline">\(\overline{x}=n^{-1} \sum_{i=1}^{n}x_i\)</span>. Así,
<span class="math display" id="eq:eq29">\[\begin{equation}
\left( \mathbf{X}^{\prime }\mathbf{X}\right)^{-1}=\frac{1}{ \sum_{i=1}^{n}x_i^2-n\overline{x}^2}\left(
\begin{array}{cc}
n^{-1}\sum\limits_{i=1}^{n}x_i^2 &amp; -\overline{x} \\
-\overline{x} &amp; 1
\end{array}
\right) .
\tag{2.9}
\end{equation}\]</span></p>
<p>La Sección 3.1 discutirá la relación <span class="math inline">\(\mathbf{b}=\left( \mathbf{X}^{\prime}\mathbf{X}\right)^{-1}\mathbf{X}^{\prime}\mathbf{y}\)</span>. Para ilustrar el cálculo, tenemos
<span class="math display">\[\begin{eqnarray*}
\mathbf{b} &amp;=&amp;\left( \mathbf{X}^{\prime }\mathbf{X}\right)^{-1}\mathbf{X} ^{\prime }\mathbf{y}=\frac{1}{\sum_{i=1}^{n}x_i^2-n\overline{x}^2} \left(
\begin{array}{cc}
n^{-1}\sum\limits_{i=1}^{n}x_i^2 &amp; -\overline{x} \\
-\overline{x} &amp; 1
\end{array}
\right) \left(
\begin{array}{c}
\sum\limits_{i=1}^{n}y_i \\
\sum\limits_{i=1}^{n}x_iy_i
\end{array}
\right) \\
&amp;=&amp;\frac{1}{\sum_{i=1}^{n}x_i^2-n\overline{x}^2}\left(
\begin{array}{c}
\sum\limits_{i=1}^{n}\left( \overline{y}x_i^2-\overline{x} x_iy_i\right) \\
\sum\limits_{i=1}^{n}x_iy_i-n\overline{x}\overline{y}
\end{array}
\right) =\left(
\begin{array}{c}
b_0 \\
b_1
\end{array}
\right) .
\end{eqnarray*}\]</span>
De esta expresión, podemos ver
<span class="math display">\[\begin{equation*}
b_1=\frac{\sum\limits_{i=1}^{n}x_iy_i-n\overline{x}\overline{y}}{\sum\limits_{i=1}^{n}x_i^2-n\overline{x}^2}
\end{equation*}\]</span>
y
<span class="math display">\[\begin{equation*}
b_0=\frac{\overline{y}\sum\limits_{i=1}^{n}x_i^2-\overline{x} \sum\limits_{i=1}^{n}x_iy_i}{\sum\limits_{i=1}^{n}x_i^2-n\overline{x}^2}=\frac{\overline{y}\left( \sum\limits_{i=1}^{n}x_i^2-n\overline{x} ^2\right) -\overline{x}\left( \sum\limits_{i=1}^{n}

x_i y_i - n\overline{x} \overline{y}\right) }{\sum\limits_{i=1}^{n}x_i^2-n\overline{x}^2}=\overline{y}-b_1\overline{x}.
\end{equation*}\]</span>
Estas son las expresiones usuales para la pendiente <span class="math inline">\(b_1\)</span> (Ejercicio 2A.8) y el intercepto <span class="math inline">\(b_0\)</span>.</p>
<hr />
</div>
</div>
<div id="Sec2114" class="section level3 hasAnchor" number="2.11.4">
<h3><span class="header-section-number">2.11.4</span> Matrices Aleatorias<a href="C2BasicLR.html#Sec2114" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p><strong>Esperanzas.</strong> Consideremos una matriz de variables aleatorias
<span class="math display">\[\begin{equation*}
\mathbf{U=}\left(
\begin{array}{cccc}
u_{11} &amp;  u_{12}  &amp; \cdots &amp; u_{1c}  \\
u_{21} &amp;  u_{22}  &amp; \cdots &amp; u_{2c}  \\
\vdots &amp;  \vdots  &amp; \ddots &amp; \vdots  \\
u_{n1} &amp;  u_{n2}  &amp; \cdots &amp; u_{nc}
\end{array}
\right).
\end{equation*}\]</span>
Cuando escribimos la esperanza de una matriz, esto es una forma abreviada para la matriz de esperanzas. Específicamente, supongamos que la función de probabilidad conjunta de <span class="math inline">\({u_{11}, u_{12}, ..., u_{1c}, ..., u_{n1}, ..., u_{nc}}\)</span> está disponible para definir el operador de esperanza. Entonces definimos
<span class="math display">\[\begin{equation*}
\mathrm{E} ~ \mathbf{U} = \left(
\begin{array}{cccc}
\mathrm{E }u_{11} &amp;  \mathrm{E }u_{12}  &amp; \cdots &amp; \mathrm{E }u_{1c}  \\
\mathrm{E }u_{21} &amp;  \mathrm{E }u_{22}  &amp; \cdots &amp; \mathrm{E }u_{2c}  \\
\vdots &amp;  \vdots  &amp; \ddots &amp; \vdots  \\
\mathrm{E }u_{n1} &amp;  \mathrm{E }u_{n2}  &amp; \cdots &amp; \mathrm{E }u_{nc}
\end{array}
\right).
\end{equation*}\]</span>
Como un caso especial importante, consideremos la función de probabilidad conjunta para las variables aleatorias <span class="math inline">\(y_1, \ldots, y_n\)</span> y el operador de expectativas correspondiente. Entonces
<span class="math display">\[\begin{equation*}
\mathrm{E}~ \mathbf{y=} \mathrm{E } \left(
\begin{array}{cccc}
y_1   \\
\vdots \\
y_n
\end{array}
\right) =  \left(
\begin{array}{cccc}
\mathrm{E }y_1  \\
\vdots   \\
\mathrm{E }y_n
\end{array}
\right).
\end{equation*}\]</span>
Por la linealidad de las esperanzas, para una matriz no aleatoria <strong>A</strong> y un vector , tenemos <span class="math inline">\(\mathrm{E} (\textbf{A y} + \textbf{B}) = \textbf{A} \mathrm{E} \textbf{y + B}\)</span>.</p>
<p><strong>Varianzas.</strong> También podemos trabajar con los segundos momentos de vectores aleatorios. La varianza de un vector de variables aleatorias se llama <em>matriz de varianza-covarianza</em>. Se define como
<span class="math display" id="eq:eq210">\[\begin{equation}
\mathrm{Var} ~ \mathbf{y}  =  \mathrm{E} ( (\mathbf{y} - \mathrm{E} \mathbf{y})(\mathbf{y} - \mathrm{E} \mathbf{y})^{\prime} ).
\tag{2.10}
\end{equation}\]</span>
Es decir, podemos expresar
<span class="math display">\[\begin{equation*}
\mathrm{Var}~\mathbf{y=} \mathrm{E } \left( \left( \begin{array}{c}
y_1 -\mathrm{E } y_1    \\
\vdots \\
y_n -\mathrm{E } y_n
\end{array}\right)
\left(\begin{array}{ccc} y_1 - \mathrm{E } y_1   &amp; \cdots &amp; y_n -
\mathrm{E } y_n
\end{array}\right) \right)
\end{equation*}\]</span>
<span class="math display">\[\begin{equation*}
= \left( \begin{array}{cccc}
\mathrm{Var}~y_1 &amp; \mathrm{Cov}(y_1, y_2) &amp; \cdots &amp;\mathrm{Cov}(y_1, y_n)   \\
\mathrm{Cov}(y_2, y_1) &amp; \mathrm{Var}~y_2 &amp; \cdots &amp; \mathrm{Cov}(y_2, y_n)   \\
\vdots  &amp; \vdots &amp; \ddots &amp; \vdots\\
\mathrm{Cov}(y_n, y_1) &amp; \mathrm{Cov}(y_n, y_2) &amp; \cdots &amp; \mathrm{Var}~y_n   \\
\end{array}\right),
\end{equation*}\]</span>
porque <span class="math inline">\(\mathrm{E} ( (y_i - \mathrm{E} y_i)(y_j - \mathrm{E} y_j) ) = \mathrm{Cov}(y_i, y_j)\)</span> para <span class="math inline">\(i \neq j\)</span> y <span class="math inline">\(\mathrm{Cov}(y_i, y_i) = \mathrm{Var}~y_i\)</span>.</p>
<p>En el caso de que <span class="math inline">\(y_1, \ldots, y_n\)</span> sean mutuamente no correlacionados, tenemos que <span class="math inline">\(\mathrm{Cov}(y_i, y_j)=0\)</span> para <span class="math inline">\(i \neq j\)</span> y así
<span class="math display">\[\begin{equation*}
\mathrm{Var}~\mathbf{y=} \left( \begin{array}{cccc}
\mathrm{Var}~y_1 &amp; 0 &amp; \cdots &amp; 0   \\
0 &amp; \mathrm{Var}~y_2 &amp; \cdots &amp; 0   \\
\vdots  &amp; \vdots &amp; \ddots &amp; \vdots\\
0 &amp; 0 &amp; \cdots &amp; \mathrm{Var}~y_n   \\
\end{array}\right).
\end{equation*}\]</span>
Además, si las varianzas son idénticas, de modo que <span class="math inline">\(\mathrm{Var}~y_i=\sigma ^2\)</span>, entonces podemos escribir <span class="math inline">\(\mathrm{Var} ~\mathbf{y} = \sigma ^2 \mathbf{I}\)</span>, donde <strong>I</strong> es la matriz identidad <span class="math inline">\(n \times n\)</span>. Por ejemplo, si <span class="math inline">\(y_1, \ldots, y_n\)</span> son i.i.d., entonces <span class="math inline">\(\mathrm{Var} ~\mathbf{y} = \sigma ^2 \mathbf{I}\)</span>.</p>
<p>A partir de la ecuación <a href="C2BasicLR.html#eq:eq210">(2.10)</a>, se puede demostrar que
<span class="math display" id="eq:eq211">\[\begin{equation}
\mathrm{Var}\left( \mathbf{Ay +B} \right) = \mathrm{Var}\left(
\mathbf{Ay} \right) = \mathbf{A} \left( \mathrm{Var}~\mathbf{y}
\right) \mathbf{A}^{\prime}.
\tag{2.11}
\end{equation}\]</span>
Por ejemplo, si <span class="math inline">\(\mathbf{A} = (a_1, a_2, \ldots,a_n)= \mathbf{a}^{\prime}\)</span> y <strong>B = 0</strong>, entonces la ecuación <a href="C2BasicLR.html#eq:eq211">(2.11)</a> se reduce a
<span class="math display">\[\begin{equation*}
\mathrm{Var}\left( \sum_{i=1}^n a_i y_i \right) = \mathrm{Var}
\left( \mathbf{a^{\prime} y}  \right) = \mathbf{a^{\prime}} \left(
\mathrm{Var} ~\mathbf{y} \right) \mathbf{a} = (a_1, a_2, \ldots,a_n)
\left( \mathrm{Var} ~\mathbf{y} \right) \left(\begin{array}{c} a_1 \\
\vdots \\ a_n \end{array}\right)
\end{equation*}\]</span>
<span class="math display">\[\begin{equation*}
= \sum_{i=1}^n a_i^2 \mathrm{Var} ~y_i ~+~2 \sum_{i=2}^n
\sum_{j=1}^{i-1} a_i a_j \mathrm{Cov}(y_i, y_j).
\end{equation*}\]</span></p>
<p><strong>Definición - Distribución Normal Multivariante.</strong> Un vector de variables aleatorias <span class="math inline">\(\mathbf{y} = \left(y_1, \ldots, y_n \right)^{\prime}\)</span> se dice que es <em>normal multivariante</em> si todas las combinaciones lineales de la forma <span class="math inline">\(\sum_{i=1}^n a_i y_i\)</span> están distribuidas normalmente. En este caso, escribimos <span class="math inline">\(\mathbf{y} \sim N (\mathbf{\boldsymbol \mu}, \mathbf{\Sigma} )\)</span>, donde <span class="math inline">\(\mathbf{\boldsymbol \mu} = \mathrm{E}~ \mathbf{y}\)</span> es el valor esperado de <strong>y</strong> y <span class="math inline">\(\mathbf{\Sigma}= \mathrm{Var}~\mathbf{y}\)</span> es la matriz de varianza-covarianza de <strong>y</strong>. Según la definición, tenemos que <span class="math inline">\(\mathbf{y}\sim N (\mathbf{\boldsymbol \mu}, \mathbf{\Sigma} )\)</span> implica que <span class="math inline">\(\mathbf{a^{\prime}y}\sim N (\mathbf{a^{\prime} \boldsymbol \mu}, \mathbf{a^{\prime}\Sigma a})\)</span>. Así, si <span class="math inline">\(y_i\)</span> son i.i.d., entonces <span class="math inline">\(\sum_{i=1}^n a_i y_i\)</span> está distribuido normalmente con media
<span class="math inline">\(\mu \sum_{i=1}^n a_i\)</span> y varianza <span class="math inline">\(\sigma ^2 \sum_{i=1}^n a_i ^2\)</span>.</p>

<!-- # Chap 1 -->
<!-- # Chap 2 -->
</div>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="regresión-y-la-distribución-normal.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="C3BasicMLR.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": null,
"search": {
"engine": "fuse",
"options": null
},
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/latest.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
