#  FILENAME IS Chap20.txt  ;

setwd("c://BOOK3//CUPBook//Chapter20ReportWriting")
#setwd("R://BOOK3//CUPBook//Chapter20ReportWriting")
library(HH)

#  SINGAPORE DATA
Swedish = read.csv(choose.files(),  quote = "",header=TRUE)

#  CHECK THE NAMES, DIMENSION IN THE FILE AND LIST THE FIRST 8 OBSERVATIONS  ;
names(Swedish)
dim(Swedish)
Swedish[1:8,]
attach(Swedish)
sum(Insured);sum(Claims);sum(Payment)


par(mfrow=c(1, 2))
plot(Insured,Claims, xlab="Policyholder Years")
plot(Claims,Payment)
export.eps("F20ScatterPlots.eps", width=8,height=4) 
dev.off()

AveClmNumber=Claims/Insured
AveSeverity=Payment/Claims

#  TABLE SUMMARY STATISTICS
options(digits=10)
Xymat <- data.frame(cbind(Insured,Claims,Payment,AveClmNumber,AveSeverity))   
meanSummary <- sapply(Xymat, mean,  na.rm=TRUE) 
sdSummary   <- sapply(Xymat, sd,    na.rm=TRUE) 
minSummary  <- sapply(Xymat, min,   na.rm=TRUE) 
maxSummary  <- sapply(Xymat, max,   na.rm=TRUE) 
medSummary  <- sapply(Xymat, median,na.rm=TRUE) 
summvar <- cbind(meanSummary, medSummary, sdSummary, minSummary, maxSummary)
summvar
write.csv(summvar, file = "summvar.csv")

#  NUMBER OF ZERO'S AND MAX PAYMENTS
Numzero <- 1*(Claims==0);sum(Numzero)
NumMaxPay <- 1*(AveSeverity == 31442);sum(NumMaxPay,  na.rm=TRUE)
Swedish$Bonus1 = Swedish$Bonus - 1

#  FOR PLOTTING FREQUENCY, REMOVE LARGE CLAIMS PER INSURED
library(HH)
Swedish2 = subset(Swedish, Claims/Insured < 1 )
par(mfrow=c(2, 2))
boxplot(Claims/Insured ~ Kilometres, data=Swedish2,
   ylab="Average Claim Number",xlab="Distance Driven")
boxplot(Claims/Insured ~ Zone, data=Swedish2,
   ylab="Average Claim Number",xlab="Geographic Zone")
boxplot(Claims/Insured ~ Bonus1, data=Swedish2,
   ylab="Average Claim Number",xlab="Accident Free Years")
boxplot(Claims/Insured ~ Make, data=Swedish2,
   ylab="Average Claim Number",xlab="Auto Make")
export.eps("F20BoxFREQ.eps", width=6,height=6) 
dev.off()

#  FOR PLOTTING AVERAGE SEVERITY, REMOVE ZEROS AND MAXIMUMS
Swedish2 = subset(Swedish, Claims>0, Payment/Claims<31000 )
Swedish2 = subset(Swedish2, Payment/Claims<31000 )
par(mfrow=c(2, 2))
boxplot(Payment/Claims ~ Kilometres, data=Swedish2,
   ylab="Average Claim Amount",xlab="Distance Driven")
boxplot(Payment/Claims ~ Zone, data=Swedish2,
   ylab="Average Claim Amount",xlab="Geographic Zone")
boxplot(Payment/Claims ~ Bonus1, data=Swedish2,
   ylab="Average Claim Amount",xlab="Accident Free Years")
boxplot(Payment/Claims ~ Make, data=Swedish2,
   ylab="Average Claim Amount",xlab="Auto Make")
export.eps("F20BoxSEV.eps", width=6,height=6) 
dev.off()

Swedish2 = subset(Swedish, Claims>0 )
AveClmNumber2 <- Swedish2$Claims/Swedish2$Insured
hist(AveClmNumber2 , freq=FALSE,  main="", xlab="Average Claim Number")

#  SUMMARY STATS 
library(Hmisc)
options(digits=3)
t1 <- summarize(AveClmNumber, Kilometres, mean)
t2 <- summarize(AveClmNumber, Zone, mean) 
t3 <- summarize(AveClmNumber, Bonus, mean) 
t4 <- summarize(AveClmNumber, Make, mean)  
tableout <- c(t1[2],t2[2],t3[2],t4[2]);tableout

#  FREQUENCY MODELING
CountPoisson1<-glm(Claims ~ 1, 
   offset=log(Insured),poisson(link=log))
summary(CountPoisson1)

CountPoisson2<-glm(Claims ~ factor(Kilometres)+factor(Zone)+factor(Bonus)
   +factor(Make), offset=log(Insured),poisson(link=log))
summary(CountPoisson2)
anova(CountPoisson2,test="Chisq")
hist(residuals(CountPoisson2,type=c("deviance")),xlab="Deviance Residuals"
   ,main="")
export.eps("F20Resids.eps", width=4,height=4)
dev.off() 

temp1 <- coefficients(CountPoisson2)
temp2 <- temp1/sqrt(diag(summary(CountPoisson2)$cov.scaled))
temp3 <- cbind(temp1,temp2)
write.csv(temp3, file = "tempFreq.csv")

#  CHECK OUT THE QUASI - POISSON MODEL FIT
CountPoisson3<-glm(Claims ~ factor(Kilometres)+factor(Zone)+factor(Bonus)
   +factor(Make), offset=lnInsured,quasipoisson(link = "log"))
summary(CountPoisson3)

#help(package=MASS)
library(MASS)
# FIT A NEGATIVE BINOMIAL MODEL;
CountNB1<-glm.nb(Claims ~ factor(Kilometres)+factor(Zone)+factor(Bonus)
   +factor(Make)+ offset(log(Insured)),link=log)#offset=log(Insured),
summary(CountNB1)

#  INDIVIDUAL PEARSON CHI-SQUARE STATISTIC
temp <- (Claims - CountPoisson1$fitted.values)
PearsonIt <- sum(temp*temp/CountPoisson1$fitted.values);PearsonIt

#  MAKE THIS STATISTIC ROUTINE TO SAVE WORK
PearsonI <- function(y){
temp <- (Swedish$Claims - y)
PearsonIp <- sum(temp*temp/y);PearsonIp}

#  COMPARISON USING INDIVIDUAL PEARSON CHI-SQUARE
tp1 <- PearsonI(CountPoisson1$fitted.values)
tp2 <- PearsonI(CountPoisson2$fitted.values)
tp3 <- PearsonI(CountNB1$fitted.values)
#  INDIVIDUAL WEIGHTED PEARSON CHI-SQUARE STATISTIC
temp <- (Claims - CountPoisson1$fitted.values)*sqrt(Insured)
PearsonWIt <- sum(temp*temp/CountPoisson1$fitted.values);PearsonWIt
#  MAKE THIS STATISTIC ROUTINE TO SAVE WORK
PearsonWI <- function(y){
temp <- (Swedish$Claims - y)*sqrt(Insured)
PearsonWIp <- sum(temp*temp/y);PearsonWIp}
#  COMPARISON USING INDIVIDUAL WEIGHTED PEARSON CHI-SQUARE
tp4 <- PearsonWI(CountPoisson1$fitted.values)
tp5 <- PearsonWI(CountPoisson2$fitted.values)
tp6 <- PearsonWI(CountNB1$fitted.values)
tableout1 <- cbind(c(tp1,tp2,tp3),c(tp4,tp5,tp6)/1000000);tableout1


#  USE LIKELIHOOD RATIO TEST TO TEST SIGNIFICANCE
anova(CountPoisson1,CountPoisson2)
anova(CountPoisson2,CountNB1) 

#  SEVERITY MODELING
Swedish3 = subset(Swedish, Claims>0 )
detach(Swedish)
attach(Swedish3)
rm(AveSeverity)
AveSeverity=Payment/Claims
Weight=1/sqrt(Claims)
Gotland <- 1*(Zone==7)
Safe <- 1*(Bonus ==7)


# LOGNORMALITY IS ONE POSSIBILITY
hist(AveSeverity)
lnAveSever <- log(AveSeverity)
hist(lnAveSever)

SeverityLN1<-lm(lnAveSever  ~ factor(Kilometres)+factor(Zone)+factor(Bonus)
   +factor(Make))
summary(SeverityLN1)
anova(SeverityLN1,test="F")
plot(Weight,residuals(SeverityLN1))
Wresids <- residuals(SeverityLN1)/Weight
plot(Weight,Wresids)
qqnorm(Wresids,main="")
qqline(Wresids)
export.eps("F20QQplot.eps", width=4,height=4)
dev.off() 
#  STILL A POOR FIT IN THE TAILS

# LOOK TO THE GAMMA MODEL
SeverityGAM1<-glm(Payment  ~ factor(Kilometres)+factor(Zone)+factor(Bonus)
   +factor(Make), Gamma(link=log))
summary(SeverityGAM1)
anova(SeverityGAM1,test="Chisq")
resids <- residuals(SeverityGAM1,type=c("deviance"))
hist(resids)
plot(Weight,resids)
Wresids <- resids/Weight
plot(Weight,Wresids)

# LOOK TO THE GAMMA MODEL WITH OFFSET
SeverityGAM2<-glm(Payment  ~ factor(Kilometres)+factor(Zone)+factor(Bonus)
   +factor(Make),  offset=log(Claims),Gamma(link=log))
summary(SeverityGAM2)
anova(SeverityGAM2,test="Chisq")
resids <- residuals(SeverityGAM2,type=c("deviance"))
hist(resids)
plot(Weight,resids)
Wresids <- resids/Weight
plot(Weight,Wresids)
#  MUCH BETTER

#  FINAL MODEL FORM
SeverityGAM3<-glm(Payment  ~ factor(Kilometres)+factor(Zone)+factor(Bonus)
   +factor(Make),  offset=log(Claims),weights=Weight,Gamma(link=log))
summary(SeverityGAM3)
anova(SeverityGAM3,test="Chisq")
resids <- residuals(SeverityGAM3,type=c("deviance"))
hist(resids)

#  REMOVE BONUS AND KILOMETRES - FINAL MODEL
SeverityGAM4<-glm(Payment  ~ factor(Zone)
   +factor(Make),  offset=log(Claims),weights=Weight,Gamma(link=log))
summary(SeverityGAM4)
anova(SeverityGAM4,test="Chisq")
resids <- residuals(SeverityGAM3,type=c("deviance"))
hist(resids)


temp1S <- coefficients(SeverityGAM4)
temp2S <- temp1S/sqrt(diag(summary(SeverityGAM4)$cov.scaled))
temp3S <- cbind(temp1S,temp2S)
write.csv(temp3S, file = "tempSeverity.csv")


