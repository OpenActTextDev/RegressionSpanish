<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapter 8 Autocorrelations and Autoregressive Models | Regression Modeling with Actuarial and Financial Applications</title>
  <meta name="description" content="HTML version of ‘Regression Modeling with Actuarial and Financial Applications’" />
  <meta name="generator" content="bookdown 0.39 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapter 8 Autocorrelations and Autoregressive Models | Regression Modeling with Actuarial and Financial Applications" />
  <meta property="og:type" content="book" />
  
  <meta property="og:description" content="HTML version of ‘Regression Modeling with Actuarial and Financial Applications’" />
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 8 Autocorrelations and Autoregressive Models | Regression Modeling with Actuarial and Financial Applications" />
  
  <meta name="twitter:description" content="HTML version of ‘Regression Modeling with Actuarial and Financial Applications’" />
  

<meta name="author" content="Edward (Jed) Frees, University of Wisconsin - Madison, Australian National University" />



  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="C7Trends.html"/>
<link rel="next" href="C9Forecast.html"/>
<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/anchor-sections-1.1.0/anchor-sections.css" rel="stylesheet" />
<link href="libs/anchor-sections-1.1.0/anchor-sections-hash.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.1.0/anchor-sections.js"></script>
<script src="libs/kePrint-0.0.1/kePrint.js"></script>
<link href="libs/lightable-0.0.1/lightable.css" rel="stylesheet" />
<link href="libs/bsTable-3.3.7/bootstrapTable.min.css" rel="stylesheet" />
<script src="libs/bsTable-3.3.7/bootstrapTable.js"></script>

<!-- Mathjax Version 2-->
<script type='text/x-mathjax-config'>
		MathJax.Hub.Config({
			extensions: ['tex2jax.js'],
			jax: ['input/TeX', 'output/HTML-CSS'],
			tex2jax: {
				inlineMath: [ ['$','$'], ['\\(','\\)'] ],
				displayMath: [ ['$$','$$'], ['\\[','\\]'] ],
				processEscapes: true
			},
			'HTML-CSS': { availableFonts: ['TeX'] }
		});
</script>

<script type="text/javascript"  src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/MathJax.js?config=TeX-AMS_HTML"> </script>

<script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
<script type="text/javascript" src="https://unpkg.com/survey-jquery/survey.jquery.min.js"></script>
<link href="https://unpkg.com/survey-jquery/modern.min.css" type="text/css" rel="stylesheet">
<script src="https://unpkg.com/showdown/dist/showdown.min.js"></script>


<!-- Various toggle functions used throughout --> 
<script language="javascript">
function toggle(id1,id2) {
	var ele = document.getElementById(id1); var text = document.getElementById(id2);
	if (ele.style.display == "block") {ele.style.display = "none"; text.innerHTML = "Show Solution";}
		else {ele.style.display = "block"; text.innerHTML = "Hide Solution";}}
function togglecode(id1,id2) {
   var ele = document.getElementById(id1); var text = document.getElementById(id2);
   if (ele.style.display == "block") {ele.style.display = "none"; text.innerHTML = "Show R Code";}
      else {ele.style.display = "block"; text.innerHTML = "Hide R Code";}}
function toggleEX(id1,id2) {
   var ele = document.getElementById(id1); var text = document.getElementById(id2);
   if (ele.style.display == "block") {ele.style.display = "none"; text.innerHTML = "Show Example";}
      else {ele.style.display = "block"; text.innerHTML = "Hide Example";}}
function toggleTheory(id1,id2) {
   var ele = document.getElementById(id1); var text = document.getElementById(id2);
   if (ele.style.display == "block") {ele.style.display = "none"; text.innerHTML = "Show Theory";}
      else {ele.style.display = "block"; text.innerHTML = "Hide Theory";}}
function toggleSolution(id1,id2) {
   var ele = document.getElementById(id1); var text = document.getElementById(id2);
   if (ele.style.display == "block") {ele.style.display = "none"; text.innerHTML = "Show Solution";}
      else {ele.style.display = "block"; text.innerHTML = "Hide Solution";}}      
function toggleQuiz(id1,id2) {
   var ele = document.getElementById(id1); var text = document.getElementById(id2);
   if (ele.style.display == "block") {ele.style.display = "none"; text.innerHTML = "Show Quiz Solution";}
      else {ele.style.display = "block"; text.innerHTML = "Hide Quiz Solution";}}      
</script>

<!-- A few functions for revealing definitions -->
<script language="javascript">
<!--   $( function() {
    $("#tabs").tabs();
  } ); -->

$(document).ready(function(){
    $('[data-toggle="tooltip"]').tooltip();
});

$(document).ready(function(){
    $('[data-toggle="popover"]').popover(); 
});
</script>

<script language="javascript">
function openTab(evt, tabName) {
    var i, tabcontent, tablinks;
    tabcontent = document.getElementsByClassName("tabcontent");
    for (i = 0; i < tabcontent.length; i++) {
        tabcontent[i].style.display = "none";
    }
    tablinks = document.getElementsByClassName("tablinks");
    for (i = 0; i < tablinks.length; i++) {
        tablinks[i].className = tablinks[i].className.replace(" active", "");
    }
    document.getElementById(tabName).style.display = "block";
    evt.currentTarget.className += " active";
}

// Get the element with id="defaultOpen" and click on it
document.getElementById("defaultOpen").click();
</script>



<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { color: #008000; } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { color: #008000; font-weight: bold; } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<style type="text/css">
  
  div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Regression Modeling With Actuarial and Financial Applications</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Preface</a>
<ul>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#forward"><i class="fa fa-check"></i>Forward</a>
<ul>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#who-is-this-book-for"><i class="fa fa-check"></i>Who Is This Book For?</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#what-is-this-book-about"><i class="fa fa-check"></i>What Is This Book About?</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#how-does-this-book-deliver-its-message"><i class="fa fa-check"></i>How Does This Book Deliver Its Message?</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#acknowledgements"><i class="fa fa-check"></i>Acknowledgements</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#dedication"><i class="fa fa-check"></i>Dedication</a></li>
</ul></li>
<li class="chapter" data-level="1" data-path="regression-and-the-normal-distribution.html"><a href="regression-and-the-normal-distribution.html"><i class="fa fa-check"></i><b>1</b> Regression and the Normal Distribution</a>
<ul>
<li class="chapter" data-level="1.1" data-path="regression-and-the-normal-distribution.html"><a href="regression-and-the-normal-distribution.html#Sec11"><i class="fa fa-check"></i><b>1.1</b> What is Regression Analysis?</a></li>
<li class="chapter" data-level="1.2" data-path="regression-and-the-normal-distribution.html"><a href="regression-and-the-normal-distribution.html#Sec12"><i class="fa fa-check"></i><b>1.2</b> Fitting Data to a Normal Distribution</a></li>
<li class="chapter" data-level="1.3" data-path="regression-and-the-normal-distribution.html"><a href="regression-and-the-normal-distribution.html#Sec13"><i class="fa fa-check"></i><b>1.3</b> Power Transforms</a></li>
<li class="chapter" data-level="1.4" data-path="regression-and-the-normal-distribution.html"><a href="regression-and-the-normal-distribution.html#Sec14"><i class="fa fa-check"></i><b>1.4</b> Sampling and the Role of Normality</a></li>
<li class="chapter" data-level="1.5" data-path="regression-and-the-normal-distribution.html"><a href="regression-and-the-normal-distribution.html#Sec15"><i class="fa fa-check"></i><b>1.5</b> Regression and Sampling Designs</a></li>
<li class="chapter" data-level="1.6" data-path="regression-and-the-normal-distribution.html"><a href="regression-and-the-normal-distribution.html#Sec16"><i class="fa fa-check"></i><b>1.6</b> Actuarial Applications of Regression</a></li>
<li class="chapter" data-level="1.7" data-path="regression-and-the-normal-distribution.html"><a href="regression-and-the-normal-distribution.html#Sec17"><i class="fa fa-check"></i><b>1.7</b> Further Reading and References</a></li>
<li class="chapter" data-level="1.8" data-path="regression-and-the-normal-distribution.html"><a href="regression-and-the-normal-distribution.html#Sec18"><i class="fa fa-check"></i><b>1.8</b> Exercises</a></li>
<li class="chapter" data-level="1.9" data-path="regression-and-the-normal-distribution.html"><a href="regression-and-the-normal-distribution.html#Sec19"><i class="fa fa-check"></i><b>1.9</b> Technical Supplement - Central Limit Theorem</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="C2BasicLR.html"><a href="C2BasicLR.html"><i class="fa fa-check"></i><b>2</b> Basic Linear Regression</a>
<ul>
<li class="chapter" data-level="2.1" data-path="C2BasicLR.html"><a href="C2BasicLR.html#Sec21"><i class="fa fa-check"></i><b>2.1</b> Correlations and Least Squares</a></li>
<li class="chapter" data-level="2.2" data-path="C2BasicLR.html"><a href="C2BasicLR.html#Sec22"><i class="fa fa-check"></i><b>2.2</b> Basic Linear Regression Model</a></li>
<li class="chapter" data-level="2.3" data-path="C2BasicLR.html"><a href="C2BasicLR.html#Sec23"><i class="fa fa-check"></i><b>2.3</b> Is the Model Useful? Some Basic Summary Measures</a>
<ul>
<li class="chapter" data-level="2.3.1" data-path="C2BasicLR.html"><a href="C2BasicLR.html#Sec231"><i class="fa fa-check"></i><b>2.3.1</b> Partitioning the Variability</a></li>
<li class="chapter" data-level="2.3.2" data-path="C2BasicLR.html"><a href="C2BasicLR.html#Sec232"><i class="fa fa-check"></i><b>2.3.2</b> The Size of a Typical Deviation: <em>s</em></a></li>
</ul></li>
<li class="chapter" data-level="2.4" data-path="C2BasicLR.html"><a href="C2BasicLR.html#Sec24"><i class="fa fa-check"></i><b>2.4</b> Properties of Regression Coefficient Estimators</a></li>
<li class="chapter" data-level="2.5" data-path="C2BasicLR.html"><a href="C2BasicLR.html#Sec25"><i class="fa fa-check"></i><b>2.5</b> Statistical Inference</a>
<ul>
<li class="chapter" data-level="2.5.1" data-path="C2BasicLR.html"><a href="C2BasicLR.html#Sec251"><i class="fa fa-check"></i><b>2.5.1</b> Is the Explanatory Variable Important?: The <em>t</em>-Test</a></li>
<li class="chapter" data-level="2.5.2" data-path="C2BasicLR.html"><a href="C2BasicLR.html#Sec252"><i class="fa fa-check"></i><b>2.5.2</b> Confidence Intervals</a></li>
<li class="chapter" data-level="2.5.3" data-path="C2BasicLR.html"><a href="C2BasicLR.html#Sec253"><i class="fa fa-check"></i><b>2.5.3</b> Prediction Intervals</a></li>
</ul></li>
<li class="chapter" data-level="2.6" data-path="C2BasicLR.html"><a href="C2BasicLR.html#Sec26"><i class="fa fa-check"></i><b>2.6</b> Building a Better Model: Residual Analysis</a></li>
<li class="chapter" data-level="2.7" data-path="C2BasicLR.html"><a href="C2BasicLR.html#Sec27"><i class="fa fa-check"></i><b>2.7</b> Application: Capital Asset Pricing Model</a></li>
<li class="chapter" data-level="2.8" data-path="C2BasicLR.html"><a href="C2BasicLR.html#Sec28"><i class="fa fa-check"></i><b>2.8</b> Illustrative Regression Computer Output</a></li>
<li class="chapter" data-level="2.9" data-path="C2BasicLR.html"><a href="C2BasicLR.html#Sec29"><i class="fa fa-check"></i><b>2.9</b> Further Reading and References</a></li>
<li class="chapter" data-level="2.10" data-path="C2BasicLR.html"><a href="C2BasicLR.html#Sec210"><i class="fa fa-check"></i><b>2.10</b> Exercises</a></li>
<li class="chapter" data-level="2.11" data-path="C2BasicLR.html"><a href="C2BasicLR.html#Sec211"><i class="fa fa-check"></i><b>2.11</b> Technical Supplement - Elements of Matrix Algebra</a>
<ul>
<li class="chapter" data-level="2.11.1" data-path="C2BasicLR.html"><a href="C2BasicLR.html#Sec2111"><i class="fa fa-check"></i><b>2.11.1</b> Basic Definitions</a></li>
<li class="chapter" data-level="2.11.2" data-path="C2BasicLR.html"><a href="C2BasicLR.html#Sec2112"><i class="fa fa-check"></i><b>2.11.2</b> Some Special Matrices</a></li>
<li class="chapter" data-level="2.11.3" data-path="C2BasicLR.html"><a href="C2BasicLR.html#Sec2113"><i class="fa fa-check"></i><b>2.11.3</b> Basic Operations</a></li>
<li class="chapter" data-level="2.11.4" data-path="C2BasicLR.html"><a href="C2BasicLR.html#Sec2114"><i class="fa fa-check"></i><b>2.11.4</b> Random Matrices</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="3" data-path="C3BasicMLR.html"><a href="C3BasicMLR.html"><i class="fa fa-check"></i><b>3</b> Multiple Linear Regression - I</a>
<ul>
<li class="chapter" data-level="3.1" data-path="C3BasicMLR.html"><a href="C3BasicMLR.html#Sec31"><i class="fa fa-check"></i><b>3.1</b> Method of Least Squares</a></li>
<li class="chapter" data-level="3.2" data-path="C3BasicMLR.html"><a href="C3BasicMLR.html#Sec32"><i class="fa fa-check"></i><b>3.2</b> Linear Regression Model and Properties of Estimators</a>
<ul>
<li class="chapter" data-level="3.2.1" data-path="C3BasicMLR.html"><a href="C3BasicMLR.html#Sec321"><i class="fa fa-check"></i><b>3.2.1</b> Regression Function</a></li>
<li class="chapter" data-level="3.2.2" data-path="C3BasicMLR.html"><a href="C3BasicMLR.html#Sec322"><i class="fa fa-check"></i><b>3.2.2</b> Regression Coefficient Interpretation</a></li>
<li class="chapter" data-level="3.2.3" data-path="C3BasicMLR.html"><a href="C3BasicMLR.html#Sec323"><i class="fa fa-check"></i><b>3.2.3</b> Model Assumptions</a></li>
<li class="chapter" data-level="3.2.4" data-path="C3BasicMLR.html"><a href="C3BasicMLR.html#Sec324"><i class="fa fa-check"></i><b>3.2.4</b> Properties of Regression Coefficient Estimators</a></li>
</ul></li>
<li class="chapter" data-level="3.3" data-path="C3BasicMLR.html"><a href="C3BasicMLR.html#Sec33"><i class="fa fa-check"></i><b>3.3</b> Estimation and Goodness of Fit</a></li>
<li class="chapter" data-level="3.4" data-path="C3BasicMLR.html"><a href="C3BasicMLR.html#Sec34"><i class="fa fa-check"></i><b>3.4</b> Statistical Inference for a Single Coefficient</a>
<ul>
<li class="chapter" data-level="3.4.1" data-path="C3BasicMLR.html"><a href="C3BasicMLR.html#Sec341"><i class="fa fa-check"></i><b>3.4.1</b> The <em>t</em>-Test</a></li>
<li class="chapter" data-level="3.4.2" data-path="C3BasicMLR.html"><a href="C3BasicMLR.html#Sec342"><i class="fa fa-check"></i><b>3.4.2</b> Confidence Intervals</a></li>
<li class="chapter" data-level="3.4.3" data-path="C3BasicMLR.html"><a href="C3BasicMLR.html#Sec343"><i class="fa fa-check"></i><b>3.4.3</b> Added Variable Plots</a></li>
<li class="chapter" data-level="3.4.4" data-path="C3BasicMLR.html"><a href="C3BasicMLR.html#Sec344"><i class="fa fa-check"></i><b>3.4.4</b> Partial Correlation Coefficients</a></li>
</ul></li>
<li class="chapter" data-level="3.5" data-path="C3BasicMLR.html"><a href="C3BasicMLR.html#Sec35"><i class="fa fa-check"></i><b>3.5</b> Some Special Explanatory Variables</a>
<ul>
<li class="chapter" data-level="3.5.1" data-path="C3BasicMLR.html"><a href="C3BasicMLR.html#Sec351"><i class="fa fa-check"></i><b>3.5.1</b> Binary Variables</a></li>
<li class="chapter" data-level="3.5.2" data-path="C3BasicMLR.html"><a href="C3BasicMLR.html#Sec352"><i class="fa fa-check"></i><b>3.5.2</b> Transforming Explanatory Variables</a></li>
<li class="chapter" data-level="3.5.3" data-path="C3BasicMLR.html"><a href="C3BasicMLR.html#Sec353"><i class="fa fa-check"></i><b>3.5.3</b> Interaction Terms</a></li>
</ul></li>
<li class="chapter" data-level="3.6" data-path="C3BasicMLR.html"><a href="C3BasicMLR.html#Sec36"><i class="fa fa-check"></i><b>3.6</b> Further Reading and References</a></li>
<li class="chapter" data-level="3.7" data-path="C3BasicMLR.html"><a href="C3BasicMLR.html#Sec37"><i class="fa fa-check"></i><b>3.7</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="C4MLRANOVA.html"><a href="C4MLRANOVA.html"><i class="fa fa-check"></i><b>4</b> Multiple Linear Regression - II</a>
<ul>
<li class="chapter" data-level="4.1" data-path="C4MLRANOVA.html"><a href="C4MLRANOVA.html#Sec41"><i class="fa fa-check"></i><b>4.1</b> The Role of Binary Variables</a></li>
<li class="chapter" data-level="4.2" data-path="C4MLRANOVA.html"><a href="C4MLRANOVA.html#Sec42"><i class="fa fa-check"></i><b>4.2</b> Statistical Inference for Several Coefficients</a>
<ul>
<li class="chapter" data-level="4.2.1" data-path="C4MLRANOVA.html"><a href="C4MLRANOVA.html#Sec421"><i class="fa fa-check"></i><b>4.2.1</b> Sets of Regression Coefficients</a></li>
<li class="chapter" data-level="4.2.2" data-path="C4MLRANOVA.html"><a href="C4MLRANOVA.html#Sec422"><i class="fa fa-check"></i><b>4.2.2</b> The General Linear Hypothesis</a></li>
<li class="chapter" data-level="4.2.3" data-path="C4MLRANOVA.html"><a href="C4MLRANOVA.html#Sec423"><i class="fa fa-check"></i><b>4.2.3</b> Estimating and Predicting Several Coefficients</a></li>
</ul></li>
<li class="chapter" data-level="4.3" data-path="C4MLRANOVA.html"><a href="C4MLRANOVA.html#Sec43"><i class="fa fa-check"></i><b>4.3</b> One Factor ANOVA Model</a></li>
<li class="chapter" data-level="4.4" data-path="C4MLRANOVA.html"><a href="C4MLRANOVA.html#Sec44"><i class="fa fa-check"></i><b>4.4</b> Combining Categorical and Continuous Explanatory Variables</a></li>
<li class="chapter" data-level="4.5" data-path="C4MLRANOVA.html"><a href="C4MLRANOVA.html#Sec45"><i class="fa fa-check"></i><b>4.5</b> Further Reading and References</a></li>
<li class="chapter" data-level="4.6" data-path="C4MLRANOVA.html"><a href="C4MLRANOVA.html#Sec46"><i class="fa fa-check"></i><b>4.6</b> Exercises</a></li>
<li class="chapter" data-level="4.7" data-path="C4MLRANOVA.html"><a href="C4MLRANOVA.html#Sec47"><i class="fa fa-check"></i><b>4.7</b> Technical Supplement - Matrix Expressions</a>
<ul>
<li class="chapter" data-level="4.7.1" data-path="C4MLRANOVA.html"><a href="C4MLRANOVA.html#Sec471"><i class="fa fa-check"></i><b>4.7.1</b> Expressing Models with Categorical Variables in Matrix Form</a></li>
<li class="chapter" data-level="4.7.2" data-path="C4MLRANOVA.html"><a href="C4MLRANOVA.html#Sec472"><i class="fa fa-check"></i><b>4.7.2</b> Calculating Least Squares Recursively</a></li>
<li class="chapter" data-level="4.7.3" data-path="C4MLRANOVA.html"><a href="C4MLRANOVA.html#Sec473"><i class="fa fa-check"></i><b>4.7.3</b> General Linear Model</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="5" data-path="C5VarSelect.html"><a href="C5VarSelect.html"><i class="fa fa-check"></i><b>5</b> Variable Selection</a>
<ul>
<li class="chapter" data-level="5.1" data-path="C5VarSelect.html"><a href="C5VarSelect.html#Sec51"><i class="fa fa-check"></i><b>5.1</b> An Iterative Approach to Data Analysis and Modeling</a></li>
<li class="chapter" data-level="5.2" data-path="C5VarSelect.html"><a href="C5VarSelect.html#Sec52"><i class="fa fa-check"></i><b>5.2</b> Automatic Variable Selection Procedures</a></li>
<li class="chapter" data-level="5.3" data-path="C5VarSelect.html"><a href="C5VarSelect.html#Sec53"><i class="fa fa-check"></i><b>5.3</b> Residual Analysis</a>
<ul>
<li class="chapter" data-level="5.3.1" data-path="C5VarSelect.html"><a href="C5VarSelect.html#Sec531"><i class="fa fa-check"></i><b>5.3.1</b> Residuals</a></li>
<li class="chapter" data-level="5.3.2" data-path="C5VarSelect.html"><a href="C5VarSelect.html#Sec532"><i class="fa fa-check"></i><b>5.3.2</b> Using Residuals to Identify Outliers</a></li>
<li class="chapter" data-level="5.3.3" data-path="C5VarSelect.html"><a href="C5VarSelect.html#Sec533"><i class="fa fa-check"></i><b>5.3.3</b> Using Residuals to Select Explanatory Variables</a></li>
</ul></li>
<li class="chapter" data-level="5.4" data-path="C5VarSelect.html"><a href="C5VarSelect.html#Sec54"><i class="fa fa-check"></i><b>5.4</b> Influential Points</a>
<ul>
<li class="chapter" data-level="5.4.1" data-path="C5VarSelect.html"><a href="C5VarSelect.html#Sec541"><i class="fa fa-check"></i><b>5.4.1</b> Leverage</a></li>
<li class="chapter" data-level="5.4.2" data-path="C5VarSelect.html"><a href="C5VarSelect.html#Sec542"><i class="fa fa-check"></i><b>5.4.2</b> Cook’s Distance</a></li>
</ul></li>
<li class="chapter" data-level="5.5" data-path="C5VarSelect.html"><a href="C5VarSelect.html#Sec55"><i class="fa fa-check"></i><b>5.5</b> Collinearity</a>
<ul>
<li class="chapter" data-level="5.5.1" data-path="C5VarSelect.html"><a href="C5VarSelect.html#Sec551"><i class="fa fa-check"></i><b>5.5.1</b> What is Collinearity?</a></li>
<li class="chapter" data-level="5.5.2" data-path="C5VarSelect.html"><a href="C5VarSelect.html#Sec552"><i class="fa fa-check"></i><b>5.5.2</b> Variance Inflation Factors</a></li>
<li class="chapter" data-level="5.5.3" data-path="C5VarSelect.html"><a href="C5VarSelect.html#Sec553"><i class="fa fa-check"></i><b>5.5.3</b> Collinearity and Leverage</a></li>
<li class="chapter" data-level="5.5.4" data-path="C5VarSelect.html"><a href="C5VarSelect.html#Sec554"><i class="fa fa-check"></i><b>5.5.4</b> Suppressor Variables</a></li>
<li class="chapter" data-level="5.5.5" data-path="C5VarSelect.html"><a href="C5VarSelect.html#Sec555"><i class="fa fa-check"></i><b>5.5.5</b> Orthogonal Variables</a></li>
</ul></li>
<li class="chapter" data-level="5.6" data-path="C5VarSelect.html"><a href="C5VarSelect.html#Sec56"><i class="fa fa-check"></i><b>5.6</b> Selection Criteria</a>
<ul>
<li class="chapter" data-level="5.6.1" data-path="C5VarSelect.html"><a href="C5VarSelect.html#Sec561"><i class="fa fa-check"></i><b>5.6.1</b> Goodness of Fit</a></li>
<li class="chapter" data-level="5.6.2" data-path="C5VarSelect.html"><a href="C5VarSelect.html#Sec562"><i class="fa fa-check"></i><b>5.6.2</b> Model Validation</a></li>
<li class="chapter" data-level="5.6.3" data-path="C5VarSelect.html"><a href="C5VarSelect.html#Sec563"><i class="fa fa-check"></i><b>5.6.3</b> Cross-Validation</a></li>
</ul></li>
<li class="chapter" data-level="5.7" data-path="C5VarSelect.html"><a href="C5VarSelect.html#Sec57"><i class="fa fa-check"></i><b>5.7</b> Heteroscedasticity</a>
<ul>
<li class="chapter" data-level="5.7.1" data-path="C5VarSelect.html"><a href="C5VarSelect.html#Sec571"><i class="fa fa-check"></i><b>5.7.1</b> Detecting Heteroscedasticity</a></li>
<li class="chapter" data-level="5.7.2" data-path="C5VarSelect.html"><a href="C5VarSelect.html#Sec572"><i class="fa fa-check"></i><b>5.7.2</b> Heteroscedasticity-Consistent Standard Errors</a></li>
<li class="chapter" data-level="5.7.3" data-path="C5VarSelect.html"><a href="C5VarSelect.html#Sec573"><i class="fa fa-check"></i><b>5.7.3</b> Weighted Least Squares</a></li>
<li class="chapter" data-level="5.7.4" data-path="C5VarSelect.html"><a href="C5VarSelect.html#Sec574"><i class="fa fa-check"></i><b>5.7.4</b> Transformations</a></li>
</ul></li>
<li class="chapter" data-level="5.8" data-path="C5VarSelect.html"><a href="C5VarSelect.html#Sec58"><i class="fa fa-check"></i><b>5.8</b> Further Reading and References</a></li>
<li class="chapter" data-level="5.9" data-path="C5VarSelect.html"><a href="C5VarSelect.html#Sec59"><i class="fa fa-check"></i><b>5.9</b> Exercises</a></li>
<li class="chapter" data-level="5.10" data-path="C5VarSelect.html"><a href="C5VarSelect.html#Sec510"><i class="fa fa-check"></i><b>5.10</b> Technical Supplements for Chapter 5</a>
<ul>
<li class="chapter" data-level="5.10.1" data-path="C5VarSelect.html"><a href="C5VarSelect.html#Sec5101"><i class="fa fa-check"></i><b>5.10.1</b> Projection Matrix</a></li>
<li class="chapter" data-level="5.10.2" data-path="C5VarSelect.html"><a href="C5VarSelect.html#Sec5102"><i class="fa fa-check"></i><b>5.10.2</b> Leave One Out Statistics</a></li>
<li class="chapter" data-level="5.10.3" data-path="C5VarSelect.html"><a href="C5VarSelect.html#Sec5103"><i class="fa fa-check"></i><b>5.10.3</b> Omitting Variables</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="6" data-path="interpreting-regression-results.html"><a href="interpreting-regression-results.html"><i class="fa fa-check"></i><b>6</b> Interpreting Regression Results</a>
<ul>
<li class="chapter" data-level="6.1" data-path="interpreting-regression-results.html"><a href="interpreting-regression-results.html#Sec61"><i class="fa fa-check"></i><b>6.1</b> What the Modeling Process Tells Us</a>
<ul>
<li class="chapter" data-level="6.1.1" data-path="interpreting-regression-results.html"><a href="interpreting-regression-results.html#Sec611"><i class="fa fa-check"></i><b>6.1.1</b> Interpreting Individual Effects</a></li>
<li class="chapter" data-level="6.1.2" data-path="interpreting-regression-results.html"><a href="interpreting-regression-results.html#Sec612"><i class="fa fa-check"></i><b>6.1.2</b> Other Interpretations</a></li>
</ul></li>
<li class="chapter" data-level="6.2" data-path="interpreting-regression-results.html"><a href="interpreting-regression-results.html#Sec62"><i class="fa fa-check"></i><b>6.2</b> The Importance of Variable Selection</a>
<ul>
<li class="chapter" data-level="6.2.1" data-path="interpreting-regression-results.html"><a href="interpreting-regression-results.html#Sec621"><i class="fa fa-check"></i><b>6.2.1</b> Overfitting the Model</a></li>
<li class="chapter" data-level="6.2.2" data-path="interpreting-regression-results.html"><a href="interpreting-regression-results.html#Sec622"><i class="fa fa-check"></i><b>6.2.2</b> Underfitting the Model</a></li>
</ul></li>
<li class="chapter" data-level="6.3" data-path="interpreting-regression-results.html"><a href="interpreting-regression-results.html#Sec63"><i class="fa fa-check"></i><b>6.3</b> The Importance of Data Collection</a>
<ul>
<li class="chapter" data-level="6.3.1" data-path="interpreting-regression-results.html"><a href="interpreting-regression-results.html#Sec631"><i class="fa fa-check"></i><b>6.3.1</b> Sampling Frame Error and Adverse Selection</a></li>
<li class="chapter" data-level="6.3.2" data-path="interpreting-regression-results.html"><a href="interpreting-regression-results.html#Sec632"><i class="fa fa-check"></i><b>6.3.2</b> Limited Sampling Regions</a></li>
<li class="chapter" data-level="6.3.3" data-path="interpreting-regression-results.html"><a href="interpreting-regression-results.html#Sec633"><i class="fa fa-check"></i><b>6.3.3</b> Limited Dependent Variables, Censoring and Truncation</a></li>
<li class="chapter" data-level="6.3.4" data-path="interpreting-regression-results.html"><a href="interpreting-regression-results.html#Sec634"><i class="fa fa-check"></i><b>6.3.4</b> Omitted and Endogenous Variables</a></li>
<li class="chapter" data-level="6.3.5" data-path="interpreting-regression-results.html"><a href="interpreting-regression-results.html#Sec635"><i class="fa fa-check"></i><b>6.3.5</b> Missing Data</a></li>
</ul></li>
<li class="chapter" data-level="6.4" data-path="interpreting-regression-results.html"><a href="interpreting-regression-results.html#Sec64"><i class="fa fa-check"></i><b>6.4</b> Missing Data Models</a>
<ul>
<li class="chapter" data-level="6.4.1" data-path="interpreting-regression-results.html"><a href="interpreting-regression-results.html#Sec641"><i class="fa fa-check"></i><b>6.4.1</b> Missing at Random</a></li>
<li class="chapter" data-level="6.4.2" data-path="interpreting-regression-results.html"><a href="interpreting-regression-results.html#Sec642"><i class="fa fa-check"></i><b>6.4.2</b> Non-Ignorable Missing Data</a></li>
</ul></li>
<li class="chapter" data-level="6.5" data-path="interpreting-regression-results.html"><a href="interpreting-regression-results.html#Sec65"><i class="fa fa-check"></i><b>6.5</b> Application: Risk Managers’ Cost Effectiveness</a></li>
<li class="chapter" data-level="6.6" data-path="interpreting-regression-results.html"><a href="interpreting-regression-results.html#Sec66"><i class="fa fa-check"></i><b>6.6</b> Further Reading and References</a></li>
<li class="chapter" data-level="6.7" data-path="interpreting-regression-results.html"><a href="interpreting-regression-results.html#Sec67"><i class="fa fa-check"></i><b>6.7</b> Exercises</a></li>
<li class="chapter" data-level="6.8" data-path="interpreting-regression-results.html"><a href="interpreting-regression-results.html#Sec68"><i class="fa fa-check"></i><b>6.8</b> Technical Supplements for Chapter 6</a>
<ul>
<li class="chapter" data-level="6.8.1" data-path="interpreting-regression-results.html"><a href="interpreting-regression-results.html#Sec681"><i class="fa fa-check"></i><b>6.8.1</b> Effects of Model Misspecification</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="7" data-path="C7Trends.html"><a href="C7Trends.html"><i class="fa fa-check"></i><b>7</b> Modeling Trends</a>
<ul>
<li class="chapter" data-level="7.1" data-path="C7Trends.html"><a href="C7Trends.html#introduction-1"><i class="fa fa-check"></i><b>7.1</b> Introduction</a>
<ul>
<li class="chapter" data-level="" data-path="C7Trends.html"><a href="C7Trends.html#time-series-and-stochastic-processes"><i class="fa fa-check"></i>Time Series and Stochastic Processes</a></li>
<li class="chapter" data-level="" data-path="C7Trends.html"><a href="C7Trends.html#time-series-versus-causal-models"><i class="fa fa-check"></i>Time Series versus Causal Models</a></li>
</ul></li>
<li class="chapter" data-level="7.2" data-path="C7Trends.html"><a href="C7Trends.html#S7:Trends"><i class="fa fa-check"></i><b>7.2</b> Fitting Trends in Time</a>
<ul>
<li class="chapter" data-level="" data-path="C7Trends.html"><a href="C7Trends.html#understanding-patterns-over-time"><i class="fa fa-check"></i>Understanding Patterns over Time</a></li>
<li class="chapter" data-level="" data-path="C7Trends.html"><a href="C7Trends.html#fitting-trends-in-time"><i class="fa fa-check"></i>Fitting Trends in Time</a></li>
<li class="chapter" data-level="" data-path="C7Trends.html"><a href="C7Trends.html#fitting-seasonal-trends"><i class="fa fa-check"></i>Fitting Seasonal Trends</a></li>
<li class="chapter" data-level="" data-path="C7Trends.html"><a href="C7Trends.html#reliability-of-time-series-forecasts"><i class="fa fa-check"></i>Reliability of Time Series Forecasts</a></li>
</ul></li>
<li class="chapter" data-level="7.3" data-path="C7Trends.html"><a href="C7Trends.html#S7:RandomWalk"><i class="fa fa-check"></i><b>7.3</b> Stationarity and Random Walk Models</a>
<ul>
<li class="chapter" data-level="" data-path="C7Trends.html"><a href="C7Trends.html#white-noise"><i class="fa fa-check"></i>White Noise</a></li>
<li class="chapter" data-level="" data-path="C7Trends.html"><a href="C7Trends.html#random-walk"><i class="fa fa-check"></i>Random Walk</a></li>
</ul></li>
<li class="chapter" data-level="7.4" data-path="C7Trends.html"><a href="C7Trends.html#inference-using-random-walk-models"><i class="fa fa-check"></i><b>7.4</b> Inference using Random Walk Models</a>
<ul>
<li class="chapter" data-level="" data-path="C7Trends.html"><a href="C7Trends.html#model-properties"><i class="fa fa-check"></i>Model Properties</a></li>
<li class="chapter" data-level="" data-path="C7Trends.html"><a href="C7Trends.html#forecasting"><i class="fa fa-check"></i>Forecasting</a></li>
<li class="chapter" data-level="" data-path="C7Trends.html"><a href="C7Trends.html#identifying-stationarity"><i class="fa fa-check"></i>Identifying Stationarity</a></li>
<li class="chapter" data-level="" data-path="C7Trends.html"><a href="C7Trends.html#identifying-random-walks"><i class="fa fa-check"></i>Identifying Random Walks</a></li>
<li class="chapter" data-level="" data-path="C7Trends.html"><a href="C7Trends.html#random-walk-versus-linear-trend-in-time-models"><i class="fa fa-check"></i>Random Walk versus Linear Trend in Time Models</a></li>
</ul></li>
<li class="chapter" data-level="7.5" data-path="C7Trends.html"><a href="C7Trends.html#filtering-to-achieve-stationarity"><i class="fa fa-check"></i><b>7.5</b> Filtering to Achieve Stationarity</a>
<ul>
<li class="chapter" data-level="" data-path="C7Trends.html"><a href="C7Trends.html#transformations"><i class="fa fa-check"></i>Transformations</a></li>
</ul></li>
<li class="chapter" data-level="7.6" data-path="C7Trends.html"><a href="C7Trends.html#forecast-evaluation"><i class="fa fa-check"></i><b>7.6</b> Forecast Evaluation</a></li>
<li class="chapter" data-level="7.7" data-path="C7Trends.html"><a href="C7Trends.html#further-reading-and-references"><i class="fa fa-check"></i><b>7.7</b> Further Reading and References</a></li>
<li class="chapter" data-level="7.8" data-path="C7Trends.html"><a href="C7Trends.html#exercises"><i class="fa fa-check"></i><b>7.8</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="C8AR.html"><a href="C8AR.html"><i class="fa fa-check"></i><b>8</b> Autocorrelations and Autoregressive Models</a>
<ul>
<li class="chapter" data-level="8.1" data-path="C8AR.html"><a href="C8AR.html#S8:Autocorrs"><i class="fa fa-check"></i><b>8.1</b> Autocorrelations</a>
<ul>
<li class="chapter" data-level="" data-path="C8AR.html"><a href="C8AR.html#application-inflation-bond-returns"><i class="fa fa-check"></i>Application: Inflation Bond Returns</a></li>
</ul></li>
<li class="chapter" data-level="8.2" data-path="C8AR.html"><a href="C8AR.html#autoregressive-models-of-order-one"><i class="fa fa-check"></i><b>8.2</b> Autoregressive Models of Order One</a></li>
<li class="chapter" data-level="8.3" data-path="C8AR.html"><a href="C8AR.html#S8:Estimation"><i class="fa fa-check"></i><b>8.3</b> Estimation and Diagnostic Checking</a></li>
<li class="chapter" data-level="8.4" data-path="C8AR.html"><a href="C8AR.html#S8:AR1Smooth"><i class="fa fa-check"></i><b>8.4</b> Smoothing and Prediction</a></li>
<li class="chapter" data-level="8.5" data-path="C8AR.html"><a href="C8AR.html#S8:BoxJenkins"><i class="fa fa-check"></i><b>8.5</b> Box-Jenkins Modeling and Forecasting</a>
<ul>
<li class="chapter" data-level="8.5.1" data-path="C8AR.html"><a href="C8AR.html#models"><i class="fa fa-check"></i><b>8.5.1</b> Models</a></li>
<li class="chapter" data-level="8.5.2" data-path="C8AR.html"><a href="C8AR.html#forecasting-1"><i class="fa fa-check"></i><b>8.5.2</b> Forecasting</a></li>
</ul></li>
<li class="chapter" data-level="8.6" data-path="C8AR.html"><a href="C8AR.html#application-hong-kong-exchange-rates"><i class="fa fa-check"></i><b>8.6</b> Application: Hong Kong Exchange Rates</a></li>
<li class="chapter" data-level="8.7" data-path="C8AR.html"><a href="C8AR.html#further-reading-and-references-1"><i class="fa fa-check"></i><b>8.7</b> Further Reading and References</a></li>
<li class="chapter" data-level="8.8" data-path="C8AR.html"><a href="C8AR.html#exercises-1"><i class="fa fa-check"></i><b>8.8</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="9" data-path="C9Forecast.html"><a href="C9Forecast.html"><i class="fa fa-check"></i><b>9</b> Forecasting and Time Series Models</a>
<ul>
<li class="chapter" data-level="9.1" data-path="C9Forecast.html"><a href="C9Forecast.html#smoothing-with-moving-averages"><i class="fa fa-check"></i><b>9.1</b> Smoothing with Moving Averages</a></li>
<li class="chapter" data-level="9.2" data-path="C9Forecast.html"><a href="C9Forecast.html#S9:ExponSmooth"><i class="fa fa-check"></i><b>9.2</b> Exponential Smoothing</a></li>
<li class="chapter" data-level="9.3" data-path="C9Forecast.html"><a href="C9Forecast.html#S9:SeasonalTSModels"><i class="fa fa-check"></i><b>9.3</b> Seasonal Time Series Models</a></li>
<li class="chapter" data-level="9.4" data-path="C9Forecast.html"><a href="C9Forecast.html#unit-root-tests"><i class="fa fa-check"></i><b>9.4</b> Unit Root Tests</a></li>
<li class="chapter" data-level="9.5" data-path="C9Forecast.html"><a href="C9Forecast.html#archgarch-models"><i class="fa fa-check"></i><b>9.5</b> ARCH/GARCH Models</a></li>
<li class="chapter" data-level="9.6" data-path="C9Forecast.html"><a href="C9Forecast.html#further-reading-and-references-2"><i class="fa fa-check"></i><b>9.6</b> Further Reading and References</a></li>
</ul></li>
<li class="chapter" data-level="10" data-path="C10Panel.html"><a href="C10Panel.html"><i class="fa fa-check"></i><b>10</b> Longitudinal and Panel Data Models</a>
<ul>
<li class="chapter" data-level="10.1" data-path="C10Panel.html"><a href="C10Panel.html#S10:Intro"><i class="fa fa-check"></i><b>10.1</b> What are Longitudinal and Panel Data?</a></li>
<li class="chapter" data-level="10.2" data-path="C10Panel.html"><a href="C10Panel.html#S10:Visual"><i class="fa fa-check"></i><b>10.2</b> Visualizing Longitudinal and Panel Data</a></li>
<li class="chapter" data-level="10.3" data-path="C10Panel.html"><a href="C10Panel.html#S10:FEModels"><i class="fa fa-check"></i><b>10.3</b> Basic Fixed Effects Models</a></li>
<li class="chapter" data-level="10.4" data-path="C10Panel.html"><a href="C10Panel.html#S10:FEModels2"><i class="fa fa-check"></i><b>10.4</b> Extended Fixed Effects Models</a></li>
<li class="chapter" data-level="10.5" data-path="C10Panel.html"><a href="C10Panel.html#S10:REModels"><i class="fa fa-check"></i><b>10.5</b> Random Effects Models</a></li>
<li class="chapter" data-level="10.6" data-path="C10Panel.html"><a href="C10Panel.html#S10:References"><i class="fa fa-check"></i><b>10.6</b> Further Reading and References</a></li>
</ul></li>
<li class="chapter" data-level="11" data-path="C11Binary.html"><a href="C11Binary.html"><i class="fa fa-check"></i><b>11</b> Categorical Dependent Variables</a>
<ul>
<li class="chapter" data-level="11.1" data-path="C11Binary.html"><a href="C11Binary.html#S:Sec111"><i class="fa fa-check"></i><b>11.1</b> Binary Dependent Variables</a></li>
<li class="chapter" data-level="11.2" data-path="C11Binary.html"><a href="C11Binary.html#S:Sec112"><i class="fa fa-check"></i><b>11.2</b> Logistic and Probit Regression Models</a>
<ul>
<li class="chapter" data-level="11.2.1" data-path="C11Binary.html"><a href="C11Binary.html#S:Sec1121"><i class="fa fa-check"></i><b>11.2.1</b> Using Nonlinear Functions of Explanatory Variables</a></li>
<li class="chapter" data-level="11.2.2" data-path="C11Binary.html"><a href="C11Binary.html#S:Sec1122"><i class="fa fa-check"></i><b>11.2.2</b> Threshold Interpretation</a></li>
<li class="chapter" data-level="11.2.3" data-path="C11Binary.html"><a href="C11Binary.html#S:Sec1123"><i class="fa fa-check"></i><b>11.2.3</b> Random Utility Interpretation</a></li>
<li class="chapter" data-level="11.2.4" data-path="C11Binary.html"><a href="C11Binary.html#S:Sec1124"><i class="fa fa-check"></i><b>11.2.4</b> Logistic Regression</a></li>
</ul></li>
<li class="chapter" data-level="11.3" data-path="C11Binary.html"><a href="C11Binary.html#S:Sec113"><i class="fa fa-check"></i><b>11.3</b> Inference for Logistic and Probit Regression Models</a>
<ul>
<li class="chapter" data-level="11.3.1" data-path="C11Binary.html"><a href="C11Binary.html#parameter-estimation"><i class="fa fa-check"></i><b>11.3.1</b> Parameter Estimation</a></li>
<li class="chapter" data-level="11.3.2" data-path="C11Binary.html"><a href="C11Binary.html#additional-inference"><i class="fa fa-check"></i><b>11.3.2</b> Additional Inference</a></li>
</ul></li>
<li class="chapter" data-level="11.4" data-path="C11Binary.html"><a href="C11Binary.html#S:Sec114"><i class="fa fa-check"></i><b>11.4</b> Application: Medical Expenditures</a></li>
<li class="chapter" data-level="11.5" data-path="C11Binary.html"><a href="C11Binary.html#S:Sec115"><i class="fa fa-check"></i><b>11.5</b> Nominal Dependent Variables</a>
<ul>
<li class="chapter" data-level="11.5.1" data-path="C11Binary.html"><a href="C11Binary.html#S:Sec1151"><i class="fa fa-check"></i><b>11.5.1</b> Generalized Logit</a></li>
<li class="chapter" data-level="11.5.2" data-path="C11Binary.html"><a href="C11Binary.html#S:Sec1152"><i class="fa fa-check"></i><b>11.5.2</b> Multinomial Logit</a></li>
<li class="chapter" data-level="11.5.3" data-path="C11Binary.html"><a href="C11Binary.html#S:Sec1153"><i class="fa fa-check"></i><b>11.5.3</b> Nested Logit</a></li>
</ul></li>
<li class="chapter" data-level="11.6" data-path="C11Binary.html"><a href="C11Binary.html#S:Sec116"><i class="fa fa-check"></i><b>11.6</b> Ordinal Dependent Variables</a>
<ul>
<li class="chapter" data-level="11.6.1" data-path="C11Binary.html"><a href="C11Binary.html#cumulative-logit"><i class="fa fa-check"></i><b>11.6.1</b> Cumulative Logit</a></li>
<li class="chapter" data-level="11.6.2" data-path="C11Binary.html"><a href="C11Binary.html#cumulative-probit"><i class="fa fa-check"></i><b>11.6.2</b> Cumulative Probit</a></li>
</ul></li>
<li class="chapter" data-level="11.7" data-path="C11Binary.html"><a href="C11Binary.html#S:Sec117"><i class="fa fa-check"></i><b>11.7</b> Further Reading and References</a></li>
<li class="chapter" data-level="11.8" data-path="C11Binary.html"><a href="C11Binary.html#S:Sec118"><i class="fa fa-check"></i><b>11.8</b> Exercises</a></li>
<li class="chapter" data-level="11.9" data-path="C11Binary.html"><a href="C11Binary.html#S:Sec119"><i class="fa fa-check"></i><b>11.9</b> Technical Supplements - Likelihood-Based Inference</a>
<ul>
<li class="chapter" data-level="11.9.1" data-path="C11Binary.html"><a href="C11Binary.html#S:Sec1191"><i class="fa fa-check"></i><b>11.9.1</b> Properties of Likelihood Functions</a></li>
<li class="chapter" data-level="11.9.2" data-path="C11Binary.html"><a href="C11Binary.html#S:Sec1192"><i class="fa fa-check"></i><b>11.9.2</b> Maximum Likelihood Estimators</a></li>
<li class="chapter" data-level="11.9.3" data-path="C11Binary.html"><a href="C11Binary.html#S:Sec1193"><i class="fa fa-check"></i><b>11.9.3</b> Hypothesis Tests</a></li>
<li class="chapter" data-level="11.9.4" data-path="C11Binary.html"><a href="C11Binary.html#S:Sec1194"><i class="fa fa-check"></i><b>11.9.4</b> Information Criteria</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="12" data-path="C12Count.html"><a href="C12Count.html"><i class="fa fa-check"></i><b>12</b> Count Dependent Variables</a>
<ul>
<li class="chapter" data-level="12.1" data-path="C12Count.html"><a href="C12Count.html#S:Sec121"><i class="fa fa-check"></i><b>12.1</b> Poisson Regression</a>
<ul>
<li class="chapter" data-level="12.1.1" data-path="C12Count.html"><a href="C12Count.html#S:Sec1211"><i class="fa fa-check"></i><b>12.1.1</b> Poisson Distribution</a></li>
<li class="chapter" data-level="12.1.2" data-path="C12Count.html"><a href="C12Count.html#S:Sec1212"><i class="fa fa-check"></i><b>12.1.2</b> Regression Model</a></li>
<li class="chapter" data-level="12.1.3" data-path="C12Count.html"><a href="C12Count.html#S:Sec1213"><i class="fa fa-check"></i><b>12.1.3</b> Estimation</a></li>
<li class="chapter" data-level="12.1.4" data-path="C12Count.html"><a href="C12Count.html#S:Sec1214"><i class="fa fa-check"></i><b>12.1.4</b> Additional Inference</a></li>
</ul></li>
<li class="chapter" data-level="12.2" data-path="C12Count.html"><a href="C12Count.html#S:Sec122"><i class="fa fa-check"></i><b>12.2</b> Application: Singapore Automobile Insurance</a></li>
<li class="chapter" data-level="12.3" data-path="C12Count.html"><a href="C12Count.html#S:Sec123"><i class="fa fa-check"></i><b>12.3</b> Overdispersion and Negative Binomial Models</a></li>
<li class="chapter" data-level="12.4" data-path="C12Count.html"><a href="C12Count.html#S:Sec124"><i class="fa fa-check"></i><b>12.4</b> Other Count Models</a>
<ul>
<li class="chapter" data-level="12.4.1" data-path="C12Count.html"><a href="C12Count.html#zero-inflated-models"><i class="fa fa-check"></i><b>12.4.1</b> Zero-Inflated Models</a></li>
<li class="chapter" data-level="12.4.2" data-path="C12Count.html"><a href="C12Count.html#hurdle-models"><i class="fa fa-check"></i><b>12.4.2</b> Hurdle Models</a></li>
<li class="chapter" data-level="12.4.3" data-path="C12Count.html"><a href="C12Count.html#heterogeneity-models"><i class="fa fa-check"></i><b>12.4.3</b> Heterogeneity Models</a></li>
<li class="chapter" data-level="12.4.4" data-path="C12Count.html"><a href="C12Count.html#latent-class-models"><i class="fa fa-check"></i><b>12.4.4</b> Latent Class Models</a></li>
</ul></li>
<li class="chapter" data-level="12.5" data-path="C12Count.html"><a href="C12Count.html#S:Sec125"><i class="fa fa-check"></i><b>12.5</b> Further Reading and References</a></li>
<li class="chapter" data-level="12.6" data-path="C12Count.html"><a href="C12Count.html#S:Sec126"><i class="fa fa-check"></i><b>12.6</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="13" data-path="C13GLM.html"><a href="C13GLM.html"><i class="fa fa-check"></i><b>13</b> Generalized Linear Models</a>
<ul>
<li class="chapter" data-level="13.1" data-path="C13GLM.html"><a href="C13GLM.html#S:Sec131"><i class="fa fa-check"></i><b>13.1</b> Introduction</a></li>
<li class="chapter" data-level="13.2" data-path="C13GLM.html"><a href="C13GLM.html#S:Sec132"><i class="fa fa-check"></i><b>13.2</b> GLM Model</a>
<ul>
<li class="chapter" data-level="13.2.1" data-path="C13GLM.html"><a href="C13GLM.html#S:Sec1321"><i class="fa fa-check"></i><b>13.2.1</b> Linear Exponential Family of Distributions</a></li>
<li class="chapter" data-level="13.2.2" data-path="C13GLM.html"><a href="C13GLM.html#S:Sec1322"><i class="fa fa-check"></i><b>13.2.2</b> Link Functions</a></li>
</ul></li>
<li class="chapter" data-level="13.3" data-path="C13GLM.html"><a href="C13GLM.html#S:Sec133"><i class="fa fa-check"></i><b>13.3</b> Estimation</a>
<ul>
<li class="chapter" data-level="13.3.1" data-path="C13GLM.html"><a href="C13GLM.html#S:Sec1331"><i class="fa fa-check"></i><b>13.3.1</b> Maximum Likelihood Estimation for Canonical Links</a></li>
<li class="chapter" data-level="13.3.2" data-path="C13GLM.html"><a href="C13GLM.html#overdispersion"><i class="fa fa-check"></i><b>13.3.2</b> Overdispersion</a></li>
<li class="chapter" data-level="13.3.3" data-path="C13GLM.html"><a href="C13GLM.html#S:Sec1333"><i class="fa fa-check"></i><b>13.3.3</b> Goodness of Fit Statistics</a></li>
</ul></li>
<li class="chapter" data-level="13.4" data-path="C13GLM.html"><a href="C13GLM.html#S:Sec134"><i class="fa fa-check"></i><b>13.4</b> Application: Medical Expenditures</a></li>
<li class="chapter" data-level="13.5" data-path="C13GLM.html"><a href="C13GLM.html#S:Sec135"><i class="fa fa-check"></i><b>13.5</b> Residuals</a></li>
<li class="chapter" data-level="13.6" data-path="C13GLM.html"><a href="C13GLM.html#S:Sec136"><i class="fa fa-check"></i><b>13.6</b> Tweedie Distribution</a></li>
<li class="chapter" data-level="13.7" data-path="C13GLM.html"><a href="C13GLM.html#S:Sec137"><i class="fa fa-check"></i><b>13.7</b> Further Reading and References</a></li>
<li class="chapter" data-level="13.8" data-path="C13GLM.html"><a href="C13GLM.html#S:Sec138"><i class="fa fa-check"></i><b>13.8</b> Exercises</a></li>
<li class="chapter" data-level="13.9" data-path="C13GLM.html"><a href="C13GLM.html#S:Sec139"><i class="fa fa-check"></i><b>13.9</b> Technical Supplements - Exponential Family</a>
<ul>
<li class="chapter" data-level="13.9.1" data-path="C13GLM.html"><a href="C13GLM.html#S:Sec1391"><i class="fa fa-check"></i><b>13.9.1</b> Linear Exponential Family of Distributions</a></li>
<li class="chapter" data-level="13.9.2" data-path="C13GLM.html"><a href="C13GLM.html#S:Sec1392"><i class="fa fa-check"></i><b>13.9.2</b> Moments</a></li>
<li class="chapter" data-level="13.9.3" data-path="C13GLM.html"><a href="C13GLM.html#S:Sec1393"><i class="fa fa-check"></i><b>13.9.3</b> Maximum Likelihood Estimation for General Links</a></li>
<li class="chapter" data-level="13.9.4" data-path="C13GLM.html"><a href="C13GLM.html#S:Sec1394"><i class="fa fa-check"></i><b>13.9.4</b> Iterated Reweighted Least Squares</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="14" data-path="C14Survival.html"><a href="C14Survival.html"><i class="fa fa-check"></i><b>14</b> Survival Models</a>
<ul>
<li class="chapter" data-level="14.1" data-path="C14Survival.html"><a href="C14Survival.html#introduction-2"><i class="fa fa-check"></i><b>14.1</b> Introduction</a></li>
<li class="chapter" data-level="14.2" data-path="C14Survival.html"><a href="C14Survival.html#S:Sec142"><i class="fa fa-check"></i><b>14.2</b> Censoring and Truncation</a>
<ul>
<li class="chapter" data-level="14.2.1" data-path="C14Survival.html"><a href="C14Survival.html#definitions-and-examples"><i class="fa fa-check"></i><b>14.2.1</b> Definitions and Examples</a></li>
<li class="chapter" data-level="14.2.2" data-path="C14Survival.html"><a href="C14Survival.html#likelihood-inference"><i class="fa fa-check"></i><b>14.2.2</b> Likelihood Inference</a></li>
<li class="chapter" data-level="14.2.3" data-path="C14Survival.html"><a href="C14Survival.html#product-limit-estimator"><i class="fa fa-check"></i><b>14.2.3</b> Product-Limit Estimator</a></li>
</ul></li>
<li class="chapter" data-level="14.3" data-path="C14Survival.html"><a href="C14Survival.html#S:Sec143"><i class="fa fa-check"></i><b>14.3</b> Accelerated Failure Time Model</a></li>
<li class="chapter" data-level="14.4" data-path="C14Survival.html"><a href="C14Survival.html#S:Sec144"><i class="fa fa-check"></i><b>14.4</b> Proportional Hazards Model</a>
<ul>
<li class="chapter" data-level="14.4.1" data-path="C14Survival.html"><a href="C14Survival.html#S:Sec1441"><i class="fa fa-check"></i><b>14.4.1</b> Proportional Hazards</a></li>
<li class="chapter" data-level="14.4.2" data-path="C14Survival.html"><a href="C14Survival.html#S:Sec1442"><i class="fa fa-check"></i><b>14.4.2</b> Inference</a></li>
</ul></li>
<li class="chapter" data-level="14.5" data-path="C14Survival.html"><a href="C14Survival.html#S:Sec145"><i class="fa fa-check"></i><b>14.5</b> Recurrent Events</a></li>
<li class="chapter" data-level="14.6" data-path="C14Survival.html"><a href="C14Survival.html#S:Sec146"><i class="fa fa-check"></i><b>14.6</b> Further Reading and References</a></li>
</ul></li>
<li class="chapter" data-level="15" data-path="C15Misc.html"><a href="C15Misc.html"><i class="fa fa-check"></i><b>15</b> Miscellaneous Regression Topics</a>
<ul>
<li class="chapter" data-level="15.1" data-path="C15Misc.html"><a href="C15Misc.html#S:Sec151"><i class="fa fa-check"></i><b>15.1</b> Mixed Linear Models</a>
<ul>
<li class="chapter" data-level="15.1.1" data-path="C15Misc.html"><a href="C15Misc.html#weighted-least-squares-2"><i class="fa fa-check"></i><b>15.1.1</b> Weighted Least Squares</a></li>
<li class="chapter" data-level="15.1.2" data-path="C15Misc.html"><a href="C15Misc.html#S:Sec1512"><i class="fa fa-check"></i><b>15.1.2</b> Variance Components Estimation</a></li>
<li class="chapter" data-level="15.1.3" data-path="C15Misc.html"><a href="C15Misc.html#best-linear-unbiased-prediction"><i class="fa fa-check"></i><b>15.1.3</b> Best Linear Unbiased Prediction</a></li>
</ul></li>
<li class="chapter" data-level="15.2" data-path="C15Misc.html"><a href="C15Misc.html#bayesian-regression"><i class="fa fa-check"></i><b>15.2</b> Bayesian Regression</a></li>
<li class="chapter" data-level="15.3" data-path="C15Misc.html"><a href="C15Misc.html#S:Sec153"><i class="fa fa-check"></i><b>15.3</b> Density Estimation and Scatterplot Smoothing}</a></li>
<li class="chapter" data-level="15.4" data-path="C15Misc.html"><a href="C15Misc.html#S:Sec154"><i class="fa fa-check"></i><b>15.4</b> Generalized Additive Models</a></li>
<li class="chapter" data-level="15.5" data-path="C15Misc.html"><a href="C15Misc.html#bootstrapping"><i class="fa fa-check"></i><b>15.5</b> Bootstrapping</a></li>
<li class="chapter" data-level="15.6" data-path="C15Misc.html"><a href="C15Misc.html#further-reading-and-references-3"><i class="fa fa-check"></i><b>15.6</b> Further Reading and References</a></li>
</ul></li>
<li class="chapter" data-level="16" data-path="C16FreqSev.html"><a href="C16FreqSev.html"><i class="fa fa-check"></i><b>16</b> Frequency-Severity Models</a>
<ul>
<li class="chapter" data-level="16.1" data-path="C16FreqSev.html"><a href="C16FreqSev.html#S:Sec161"><i class="fa fa-check"></i><b>16.1</b> Introduction</a></li>
<li class="chapter" data-level="16.2" data-path="C16FreqSev.html"><a href="C16FreqSev.html#S:Sec162"><i class="fa fa-check"></i><b>16.2</b> Tobit Model</a></li>
<li class="chapter" data-level="16.3" data-path="C16FreqSev.html"><a href="C16FreqSev.html#S:Sec163"><i class="fa fa-check"></i><b>16.3</b> Application: Medical Expenditures</a></li>
<li class="chapter" data-level="16.4" data-path="C16FreqSev.html"><a href="C16FreqSev.html#S:Sec164"><i class="fa fa-check"></i><b>16.4</b> Two-Part Model</a></li>
<li class="chapter" data-level="16.5" data-path="C16FreqSev.html"><a href="C16FreqSev.html#S:Sec165"><i class="fa fa-check"></i><b>16.5</b> Aggregate Loss Model</a></li>
<li class="chapter" data-level="16.6" data-path="C16FreqSev.html"><a href="C16FreqSev.html#S:Sec166"><i class="fa fa-check"></i><b>16.6</b> Further Reading and References</a></li>
<li class="chapter" data-level="16.7" data-path="C16FreqSev.html"><a href="C16FreqSev.html#S:Sec167"><i class="fa fa-check"></i><b>16.7</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="17" data-path="C17Fat.html"><a href="C17Fat.html"><i class="fa fa-check"></i><b>17</b> Fat-Tailed Regression Models</a>
<ul>
<li class="chapter" data-level="17.1" data-path="C17Fat.html"><a href="C17Fat.html#introduction-3"><i class="fa fa-check"></i><b>17.1</b> Introduction</a></li>
<li class="chapter" data-level="17.2" data-path="C17Fat.html"><a href="C17Fat.html#S:Sec172"><i class="fa fa-check"></i><b>17.2</b> Transformations</a></li>
<li class="chapter" data-level="17.3" data-path="C17Fat.html"><a href="C17Fat.html#S:Sec173"><i class="fa fa-check"></i><b>17.3</b> Generalized Linear Models</a>
<ul>
<li class="chapter" data-level="17.3.1" data-path="C17Fat.html"><a href="C17Fat.html#S:Sec1731"><i class="fa fa-check"></i><b>17.3.1</b> What is “Fat-Tailed?”</a></li>
<li class="chapter" data-level="17.3.2" data-path="C17Fat.html"><a href="C17Fat.html#S:Sec1732"><i class="fa fa-check"></i><b>17.3.2</b> Application: Wisconsin Nursing Homes</a></li>
</ul></li>
<li class="chapter" data-level="17.4" data-path="C17Fat.html"><a href="C17Fat.html#S:Sec174"><i class="fa fa-check"></i><b>17.4</b> Generalized Distributions</a>
<ul>
<li class="chapter" data-level="" data-path="C17Fat.html"><a href="C17Fat.html#application-wisconsin-nursing-homes"><i class="fa fa-check"></i>Application: Wisconsin Nursing Homes</a></li>
</ul></li>
<li class="chapter" data-level="17.5" data-path="C17Fat.html"><a href="C17Fat.html#S:Sec175"><i class="fa fa-check"></i><b>17.5</b> Quantile Regression</a></li>
<li class="chapter" data-level="17.6" data-path="C17Fat.html"><a href="C17Fat.html#S:Sec176"><i class="fa fa-check"></i><b>17.6</b> Extreme Value Models</a></li>
<li class="chapter" data-level="17.7" data-path="C17Fat.html"><a href="C17Fat.html#further-reading-and-references-4"><i class="fa fa-check"></i><b>17.7</b> Further Reading and References</a></li>
<li class="chapter" data-level="17.8" data-path="C17Fat.html"><a href="C17Fat.html#exercises-2"><i class="fa fa-check"></i><b>17.8</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="18" data-path="C18Cred.html"><a href="C18Cred.html"><i class="fa fa-check"></i><b>18</b> Credibility and Bonus-Malus</a>
<ul>
<li class="chapter" data-level="18.1" data-path="C18Cred.html"><a href="C18Cred.html#risk-classification-and-experience-rating"><i class="fa fa-check"></i><b>18.1</b> Risk Classification and Experience Rating</a></li>
<li class="chapter" data-level="18.2" data-path="C18Cred.html"><a href="C18Cred.html#S:Sec182"><i class="fa fa-check"></i><b>18.2</b> Credibility</a>
<ul>
<li class="chapter" data-level="18.2.1" data-path="C18Cred.html"><a href="C18Cred.html#S:Sec1821"><i class="fa fa-check"></i><b>18.2.1</b> Limited Fluctuation Credibility</a></li>
<li class="chapter" data-level="18.2.2" data-path="C18Cred.html"><a href="C18Cred.html#S:Sec1822"><i class="fa fa-check"></i><b>18.2.2</b> Greatest Accuracy Credibility</a></li>
</ul></li>
<li class="chapter" data-level="18.3" data-path="C18Cred.html"><a href="C18Cred.html#S:Sec183"><i class="fa fa-check"></i><b>18.3</b> Credibility and Regression</a>
<ul>
<li class="chapter" data-level="18.3.1" data-path="C18Cred.html"><a href="C18Cred.html#one-way-random-effects-model"><i class="fa fa-check"></i><b>18.3.1</b> One-Way Random Effects Model</a></li>
<li class="chapter" data-level="18.3.2" data-path="C18Cred.html"><a href="C18Cred.html#longitudinal-models"><i class="fa fa-check"></i><b>18.3.2</b> Longitudinal Models</a></li>
</ul></li>
<li class="chapter" data-level="18.4" data-path="C18Cred.html"><a href="C18Cred.html#S:Sec184"><i class="fa fa-check"></i><b>18.4</b> Bonus-Malus</a></li>
</ul></li>
<li class="chapter" data-level="19" data-path="C19Triangles.html"><a href="C19Triangles.html"><i class="fa fa-check"></i><b>19</b> Claims Triangles</a>
<ul>
<li class="chapter" data-level="19.1" data-path="C19Triangles.html"><a href="C19Triangles.html#introduction-4"><i class="fa fa-check"></i><b>19.1</b> Introduction</a>
<ul>
<li class="chapter" data-level="19.1.1" data-path="C19Triangles.html"><a href="C19Triangles.html#S:Sec1911"><i class="fa fa-check"></i><b>19.1.1</b> Claims Evolution</a></li>
<li class="chapter" data-level="19.1.2" data-path="C19Triangles.html"><a href="C19Triangles.html#S:Sec1912"><i class="fa fa-check"></i><b>19.1.2</b> Claims Triangles</a></li>
<li class="chapter" data-level="19.1.3" data-path="C19Triangles.html"><a href="C19Triangles.html#S:Sec1913"><i class="fa fa-check"></i><b>19.1.3</b> Chain Ladder Method</a></li>
</ul></li>
<li class="chapter" data-level="19.2" data-path="C19Triangles.html"><a href="C19Triangles.html#S:Sec192"><i class="fa fa-check"></i><b>19.2</b> Regression Using Functions of Time as Explanatory Variables</a>
<ul>
<li class="chapter" data-level="19.2.1" data-path="C19Triangles.html"><a href="C19Triangles.html#S:Sec1921"><i class="fa fa-check"></i><b>19.2.1</b> Lognormal Model</a></li>
<li class="chapter" data-level="19.2.2" data-path="C19Triangles.html"><a href="C19Triangles.html#S:Sec1922"><i class="fa fa-check"></i><b>19.2.2</b> Hoerl Curve</a></li>
<li class="chapter" data-level="19.2.3" data-path="C19Triangles.html"><a href="C19Triangles.html#S:Sec1923"><i class="fa fa-check"></i><b>19.2.3</b> Poisson Models</a></li>
</ul></li>
<li class="chapter" data-level="19.3" data-path="C19Triangles.html"><a href="C19Triangles.html#S:Sec193"><i class="fa fa-check"></i><b>19.3</b> Using Past Developments</a>
<ul>
<li class="chapter" data-level="19.3.1" data-path="C19Triangles.html"><a href="C19Triangles.html#S:Sec1931"><i class="fa fa-check"></i><b>19.3.1</b> Mack Model</a></li>
<li class="chapter" data-level="19.3.2" data-path="C19Triangles.html"><a href="C19Triangles.html#S:Sec1932"><i class="fa fa-check"></i><b>19.3.2</b> Distributional Models</a></li>
</ul></li>
<li class="chapter" data-level="19.4" data-path="C19Triangles.html"><a href="C19Triangles.html#further-reading-and-references-5"><i class="fa fa-check"></i><b>19.4</b> Further Reading and References</a></li>
<li class="chapter" data-level="19.5" data-path="C19Triangles.html"><a href="C19Triangles.html#exercises-3"><i class="fa fa-check"></i><b>19.5</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="20" data-path="C20Report.html"><a href="C20Report.html"><i class="fa fa-check"></i><b>20</b> Report Writing: Communicating Data Analysis Results</a>
<ul>
<li class="chapter" data-level="20.1" data-path="C20Report.html"><a href="C20Report.html#S20:Overview"><i class="fa fa-check"></i><b>20.1</b> Overview</a></li>
<li class="chapter" data-level="20.2" data-path="C20Report.html"><a href="C20Report.html#S20:Methods"><i class="fa fa-check"></i><b>20.2</b> Methods for Communicating Data</a>
<ul>
<li class="chapter" data-level="" data-path="C20Report.html"><a href="C20Report.html#within-text-data"><i class="fa fa-check"></i>Within Text Data</a></li>
<li class="chapter" data-level="" data-path="C20Report.html"><a href="C20Report.html#graphs"><i class="fa fa-check"></i>Graphs</a></li>
</ul></li>
<li class="chapter" data-level="20.3" data-path="C20Report.html"><a href="C20Report.html#S20:Organize"><i class="fa fa-check"></i><b>20.3</b> How to Organize</a>
<ul>
<li class="chapter" data-level="" data-path="C20Report.html"><a href="C20Report.html#title-and-abstract"><i class="fa fa-check"></i>Title and Abstract</a></li>
<li class="chapter" data-level="" data-path="C20Report.html"><a href="C20Report.html#introduction-5"><i class="fa fa-check"></i>Introduction</a></li>
<li class="chapter" data-level="" data-path="C20Report.html"><a href="C20Report.html#model-selection-and-interpretation"><i class="fa fa-check"></i>Model Selection and Interpretation</a></li>
<li class="chapter" data-level="" data-path="C20Report.html"><a href="C20Report.html#references-and-appendix"><i class="fa fa-check"></i>References and Appendix</a></li>
</ul></li>
<li class="chapter" data-level="20.4" data-path="C20Report.html"><a href="C20Report.html#further-suggestions-for-report-writing"><i class="fa fa-check"></i><b>20.4</b> Further Suggestions for Report Writing</a></li>
<li class="chapter" data-level="20.5" data-path="C20Report.html"><a href="C20Report.html#case-study-swedish-automobile-claims"><i class="fa fa-check"></i><b>20.5</b> Case Study: Swedish Automobile Claims</a></li>
<li class="chapter" data-level="20.6" data-path="C20Report.html"><a href="C20Report.html#further-reading-and-references-6"><i class="fa fa-check"></i><b>20.6</b> Further Reading and References</a></li>
<li class="chapter" data-level="20.7" data-path="C20Report.html"><a href="C20Report.html#exercise"><i class="fa fa-check"></i><b>20.7</b> Exercise</a></li>
</ul></li>
<li class="chapter" data-level="21" data-path="C21Design.html"><a href="C21Design.html"><i class="fa fa-check"></i><b>21</b> Designing Effective Graphs</a>
<ul>
<li class="chapter" data-level="21.1" data-path="C21Design.html"><a href="C21Design.html#S21:Intro"><i class="fa fa-check"></i><b>21.1</b> Introduction</a></li>
<li class="chapter" data-level="21.2" data-path="C21Design.html"><a href="C21Design.html#S21:GDesign"><i class="fa fa-check"></i><b>21.2</b> Graphic Design Choices Make a Difference</a></li>
<li class="chapter" data-level="21.3" data-path="C21Design.html"><a href="C21Design.html#S21:DesignGuide"><i class="fa fa-check"></i><b>21.3</b> Design Guidelines</a>
<ul>
<li class="chapter" data-level="" data-path="C21Design.html"><a href="C21Design.html#guideline-one-avoid-chartjunk"><i class="fa fa-check"></i>Guideline One: Avoid Chartjunk</a></li>
<li class="chapter" data-level="" data-path="C21Design.html"><a href="C21Design.html#guideline-two-use-small-multiples-to-promote-comparisons-and-assess-change"><i class="fa fa-check"></i>Guideline Two: Use Small Multiples to Promote Comparisons and Assess Change</a></li>
<li class="chapter" data-level="" data-path="C21Design.html"><a href="C21Design.html#guideline-three-use-complex-graphs-to-portray-complex-patterns"><i class="fa fa-check"></i>Guideline Three: Use Complex Graphs to Portray Complex Patterns</a></li>
<li class="chapter" data-level="" data-path="C21Design.html"><a href="C21Design.html#guideline-four-relate-graph-size-to-information-content"><i class="fa fa-check"></i>Guideline Four: Relate Graph Size to Information Content</a></li>
<li class="chapter" data-level="" data-path="C21Design.html"><a href="C21Design.html#guideline-five-use-graphical-forms-that-promote-comparisons"><i class="fa fa-check"></i>Guideline Five: Use Graphical Forms That Promote Comparisons</a></li>
<li class="chapter" data-level="" data-path="C21Design.html"><a href="C21Design.html#guideline-six-integrate-graphs-and-text"><i class="fa fa-check"></i>Guideline Six: Integrate Graphs and Text</a></li>
<li class="chapter" data-level="" data-path="C21Design.html"><a href="C21Design.html#guideline-seven-demonstrate-an-important-message"><i class="fa fa-check"></i>Guideline Seven: Demonstrate an Important Message</a></li>
<li class="chapter" data-level="" data-path="C21Design.html"><a href="C21Design.html#guideline-eight-know-your-audience"><i class="fa fa-check"></i>Guideline Eight: Know Your Audience</a></li>
</ul></li>
<li class="chapter" data-level="21.4" data-path="C21Design.html"><a href="C21Design.html#S21:EmpiricalFoundations"><i class="fa fa-check"></i><b>21.4</b> Empirical Foundations For Guidelines</a>
<ul>
<li class="chapter" data-level="21.4.1" data-path="C21Design.html"><a href="C21Design.html#graphs-as-units-of-study"><i class="fa fa-check"></i><b>21.4.1</b> Graphs as Units of Study</a></li>
</ul></li>
<li class="chapter" data-level="21.5" data-path="C21Design.html"><a href="C21Design.html#S21:Conclude"><i class="fa fa-check"></i><b>21.5</b> Concluding Remarks</a></li>
<li class="chapter" data-level="21.6" data-path="C21Design.html"><a href="C21Design.html#S21:References"><i class="fa fa-check"></i><b>21.6</b> Further Reading and References</a></li>
</ul></li>
<li class="chapter" data-level="22" data-path="appendices.html"><a href="appendices.html"><i class="fa fa-check"></i><b>22</b> Appendices</a>
<ul>
<li class="chapter" data-level="" data-path="appendices.html"><a href="appendices.html#appendix-a1.-basic-statistical-inference"><i class="fa fa-check"></i>Appendix A1. Basic Statistical Inference</a>
<ul>
<li class="chapter" data-level="" data-path="appendices.html"><a href="appendices.html#distributions-of-functions-of-random-variables"><i class="fa fa-check"></i>Distributions of Functions of Random Variables</a></li>
<li class="chapter" data-level="" data-path="appendices.html"><a href="appendices.html#estimation-and-prediction"><i class="fa fa-check"></i>Estimation and Prediction</a></li>
<li class="chapter" data-level="" data-path="appendices.html"><a href="appendices.html#testing-hypotheses"><i class="fa fa-check"></i>Testing Hypotheses</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="appendices.html"><a href="appendices.html#appendix-a2.-matrix-algebra"><i class="fa fa-check"></i>Appendix A2. Matrix Algebra</a>
<ul>
<li class="chapter" data-level="" data-path="appendices.html"><a href="appendices.html#basic-definitions"><i class="fa fa-check"></i>Basic Definitions</a></li>
<li class="chapter" data-level="" data-path="appendices.html"><a href="appendices.html#review-of-basic-operations"><i class="fa fa-check"></i>Review of Basic Operations</a></li>
<li class="chapter" data-level="" data-path="appendices.html"><a href="appendices.html#further-definitions"><i class="fa fa-check"></i>Further Definitions</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="appendices.html"><a href="appendices.html#appendix-a3.-probability-tables"><i class="fa fa-check"></i>Appendix A3. Probability Tables</a>
<ul>
<li class="chapter" data-level="" data-path="appendices.html"><a href="appendices.html#normal-distribution"><i class="fa fa-check"></i>Normal Distribution</a></li>
<li class="chapter" data-level="" data-path="appendices.html"><a href="appendices.html#chi-square-distribution"><i class="fa fa-check"></i>Chi-Square Distribution</a></li>
<li class="chapter" data-level="" data-path="appendices.html"><a href="appendices.html#t-distribution"><i class="fa fa-check"></i><em>t</em>-Distribution</a></li>
<li class="chapter" data-level="" data-path="appendices.html"><a href="appendices.html#f-distribution"><i class="fa fa-check"></i><em>F</em>-Distribution</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="" data-path="brief-answers-to-selected-exercises.html"><a href="brief-answers-to-selected-exercises.html"><i class="fa fa-check"></i>Brief Answers to Selected Exercises</a></li>
</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Regression Modeling with Actuarial and Financial Applications</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="C8AR" class="section level1 hasAnchor" number="8">
<h1><span class="header-section-number">Chapter 8</span> Autocorrelations and Autoregressive Models<a href="C8AR.html#C8AR" class="anchor-section" aria-label="Anchor link to header"></a></h1>
<p><em>Chapter Preview</em>. This chapter continues our study
of time series data. Chapter 7 introduced techniques for determining
major patterns that provide a good first step for forecasting.
Chapter 8 provides techniques for detecting subtle trends in time
and models to accommodate these trends. These techniques detect and
model relationships between the current and past values of a series
using regression concepts.</p>
<div id="S8:Autocorrs" class="section level2 hasAnchor" number="8.1">
<h2><span class="header-section-number">8.1</span> Autocorrelations<a href="C8AR.html#S8:Autocorrs" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<div id="application-inflation-bond-returns" class="section level3 unnumbered hasAnchor">
<h3>Application: Inflation Bond Returns<a href="C8AR.html#application-inflation-bond-returns" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>To motivate the methods introduced in this chapter, we work in the
context of the inflation bond return series. Beginning in January of
2003, the US Treasury Department established an inflation bond index
that summarizes the returns on long-term bonds offered by the
Treasury Department that are inflation-indexed. For a Treasury
inflation protected security (TIPS), the principal of the bond is
indexed by the (three month lagged) value of the (non-seasonally
adjusted) consumer price index. The bond then pays a semi-annual
coupon at a rate determined at auction when the bond is issued. The
index that we examine is the unweighted average of bid yields for
all TIPS with remaining terms to maturity of 10 or more years.</p>
<p>Monthly values of the index from January 2003 through March 2007 are
considered, for a total of <span class="math inline">\(T=51\)</span> returns. A time series plot of the
data is presented in Figure <a href="C8AR.html#fig:Fig81">8.1</a>. This plot suggests
that the series is stationary and so it is useful to examine the
distribution of the series through summary statistics that appear in
<a href="C8AR.html#Tab81">Table 8.1</a>.</p>

<div class="figure" style="text-align: center"><span style="display:block;" id="fig:Fig81"></span>
<img src="RegressionMarkdown_files/figure-html/Fig81-1.png" alt="Time Series Plot of the Inflation Bond Index. Monthly values over January 2003 to March 2007, inclusive." width="60%" />
<p class="caption">
Figure 8.1: <strong>Time Series Plot of the Inflation Bond Index.</strong> Monthly values over January 2003 to March 2007, inclusive.
</p>
</div>
<p><a id=Tab81></a></p>
<p><span id="Tab81">Table 8.1</span>. <strong>Summary Statistics of the Inflation Bond Index</strong></p>
<p><span class="math display">\[
\small{
\begin{array}{lccccc}
\hline
&amp;  &amp;  &amp; \text{Standard} &amp;  &amp;  \\
\text{Variable} &amp; \text{Mean} &amp; \text{Median} &amp; \text{Deviation} &amp; \text{Minimum} &amp; \text{Maximum} \\ \hline
\text{INDEX} &amp; 2.245 &amp; 2.26 &amp; 0.259 &amp; 1.77 &amp; 2.80 \\
\hline ~~~Source: \text{US Treasury}
\end{array}
}
\]</span></p>
<h5 style="text-align: center;">
<a id="displayCode.Fig81.Hide" href="javascript:togglecode('toggleCode.Fig81.Hide','displayCode.Fig81.Hide');"><i><strong>R Code to Produce Figure 8.1 and Table 8.1</strong></i></a>
</h5>
<div id="toggleCode.Fig81.Hide" style="display: none">
<div class="sourceCode" id="cb67"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb67-1"><a href="C8AR.html#cb67-1" tabindex="-1"></a><span class="co"># Figure 81</span></span>
<span id="cb67-2"><a href="C8AR.html#cb67-2" tabindex="-1"></a></span>
<span id="cb67-3"><a href="C8AR.html#cb67-3" tabindex="-1"></a>inflation  <span class="ot">&lt;-</span> <span class="fu">read.csv</span>(<span class="st">&quot;CSVData/InflationBond.csv&quot;</span>, <span class="at">header=</span><span class="cn">TRUE</span>)</span>
<span id="cb67-4"><a href="C8AR.html#cb67-4" tabindex="-1"></a><span class="co">#inflation  &lt;- read.csv(&quot;../../CSVData/InflationBond.csv&quot;, header=TRUE)</span></span>
<span id="cb67-5"><a href="C8AR.html#cb67-5" tabindex="-1"></a></span>
<span id="cb67-6"><a href="C8AR.html#cb67-6" tabindex="-1"></a>index<span class="ot">&lt;-</span> inflation<span class="sc">$</span>INFBOND</span>
<span id="cb67-7"><a href="C8AR.html#cb67-7" tabindex="-1"></a></span>
<span id="cb67-8"><a href="C8AR.html#cb67-8" tabindex="-1"></a>foo  <span class="ot">&lt;-</span> <span class="fu">ts</span>(index, <span class="at">freq =</span> <span class="dv">12</span>, <span class="at">start =</span> <span class="fu">c</span>(<span class="dv">2003</span>,<span class="dv">1</span>),<span class="at">end=</span><span class="fu">c</span>(<span class="dv">2007</span>,<span class="dv">3</span>))</span>
<span id="cb67-9"><a href="C8AR.html#cb67-9" tabindex="-1"></a><span class="fu">ts.plot</span>(foo,<span class="at">ylab=</span><span class="st">&quot;Index&quot;</span>, <span class="at">xlab=</span><span class="st">&quot;Year&quot;</span>,<span class="at">type=</span><span class="st">&quot;o&quot;</span>,<span class="at">ylim=</span><span class="fu">c</span>(<span class="fl">1.5</span>,<span class="fl">3.0</span>),</span>
<span id="cb67-10"><a href="C8AR.html#cb67-10" tabindex="-1"></a>        <span class="at">gpars=</span><span class="fu">list</span>(<span class="at">pch=</span><span class="dv">16</span>))</span></code></pre></div>
<div class="sourceCode" id="cb68"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb68-1"><a href="C8AR.html#cb68-1" tabindex="-1"></a>Tab81 <span class="ot">&lt;-</span> <span class="fu">cbind</span>(<span class="at">Mean=</span><span class="fu">mean</span>(index),<span class="at">Median=</span><span class="fu">median</span>(index),</span>
<span id="cb68-2"><a href="C8AR.html#cb68-2" tabindex="-1"></a>                 <span class="at">Std=</span><span class="fu">sd</span>(index),<span class="at">Minimum=</span><span class="fu">min</span>(index),<span class="at">Maximum=</span><span class="fu">max</span>(index))</span>
<span id="cb68-3"><a href="C8AR.html#cb68-3" tabindex="-1"></a>knitr<span class="sc">::</span><span class="fu">kable</span>(Tab81, <span class="at">digits =</span> <span class="dv">4</span>)</span></code></pre></div>
<table>
<thead>
<tr class="header">
<th align="right">Mean</th>
<th align="right">Median</th>
<th align="right">Std</th>
<th align="right">Minimum</th>
<th align="right">Maximum</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="right">2.2449</td>
<td align="right">2.26</td>
<td align="right">0.2589</td>
<td align="right">1.77</td>
<td align="right">2.8</td>
</tr>
</tbody>
</table>
</div>
<p>Our goal is to detect patterns in the data and provide models to
represent these patterns. Although Figure <a href="C8AR.html#fig:Fig81">8.1</a> shows a
stationary series with no major tendencies, a few subtle patterns
are evident. Beginning in mid 2003 and then in the beginning of
2004, we see large increases followed by a series of declines in the
index. Beginning in 2005, a pattern of increase with some cyclical
behavior seems to be occurring. Although it is not clear what
economic phenomenon these patterns represent, they are not what we
would expect to see with a white noise process. For a white noise
process, a series may increase or decrease randomly from one period
to the next, producing a non-smooth, “jagged” series over time.</p>
<p>To help understand these patterns, Figure <a href="C8AR.html#fig:Fig82">8.2</a>
presents a scatter plot of the series (<span class="math inline">\(y_t\)</span>) versus its lagged
value (<span class="math inline">\(y_{t-1}\)</span>). Because this is a crucial step to understanding
this chapter, <a href="C8AR.html#Tab82">Table 8.2</a> presents a small subset of
the data so that you can see exactly what each point on the scatter
plot represents. Figure <a href="C8AR.html#fig:Fig82">8.2</a> shows a strong
relationship between <span class="math inline">\(y_t\)</span> and <span class="math inline">\(y_{t-1}\)</span>; we will model this
relationship in the next section.</p>

<div class="figure" style="text-align: center"><span style="display:block;" id="fig:Fig82"></span>
<img src="RegressionMarkdown_files/figure-html/Fig82-1.png" alt="Inflation Bond versus Lagged Value. This scatter plot reveals a linear relationship between the index and its lagged value" width="60%" />
<p class="caption">
Figure 8.2: <strong>Inflation Bond versus Lagged Value.</strong> This scatter plot reveals a linear relationship between the index and its lagged value
</p>
</div>
<p><a id=Tab82></a></p>
<p><span id="Tab82">Table 8.2</span>. <strong>Index and Lagged Index for the First Five of <span class="math inline">\(T=51\)</span> Values</strong></p>
<p><span class="math display">\[
\small{
\begin{array}{l|crrrr}
\hline
t &amp; 1~~ &amp; 2~~ &amp; 3~~ &amp; 4~~ &amp; 5~~ \\ \hline
\text{Index }(y_t) &amp; 2.72 &amp; 2.50 &amp;  2.52 &amp;  2.72 &amp; 2.40 \\
\text{Lagged Index } (y_{t-1}) &amp; * &amp;  2.72   &amp;  2.50   &amp;  2.52  &amp; 2.72
\\ \hline
\end{array}
}
\]</span></p>
<h5 style="text-align: center;">
<a id="displayCode.Fig82.Hide" href="javascript:togglecode('toggleCode.Fig82.Hide','displayCode.Fig82.Hide');"><i><strong>R Code to Produce Figure 8.2</strong></i></a>
</h5>
<div id="toggleCode.Fig82.Hide" style="display: none">
<div class="sourceCode" id="cb69"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb69-1"><a href="C8AR.html#cb69-1" tabindex="-1"></a><span class="co"># Figure 82</span></span>
<span id="cb69-2"><a href="C8AR.html#cb69-2" tabindex="-1"></a><span class="co">#inflation  &lt;- read.csv(&quot;CSVData/InflationBond.csv&quot;, header=TRUE)</span></span>
<span id="cb69-3"><a href="C8AR.html#cb69-3" tabindex="-1"></a><span class="co">#inflation  &lt;- read.csv(&quot;../../CSVData/InflationBond.csv&quot;, header=TRUE)</span></span>
<span id="cb69-4"><a href="C8AR.html#cb69-4" tabindex="-1"></a><span class="co">#index&lt;- inflation$INFBOND</span></span>
<span id="cb69-5"><a href="C8AR.html#cb69-5" tabindex="-1"></a></span>
<span id="cb69-6"><a href="C8AR.html#cb69-6" tabindex="-1"></a>n <span class="ot">&lt;-</span> <span class="fu">length</span>(index)</span>
<span id="cb69-7"><a href="C8AR.html#cb69-7" tabindex="-1"></a><span class="fu">plot</span>(index[<span class="sc">-</span><span class="dv">1</span>],index[<span class="sc">-</span>n],<span class="at">xlim=</span><span class="fu">c</span>(<span class="fl">1.5</span>,<span class="fl">3.0</span>),<span class="at">ylim=</span><span class="fu">c</span>(<span class="fl">1.5</span>,<span class="fl">3.0</span>),</span>
<span id="cb69-8"><a href="C8AR.html#cb69-8" tabindex="-1"></a>     <span class="at">xlab=</span><span class="st">&quot;Lagged Index&quot;</span>, <span class="at">ylab=</span><span class="st">&quot;Infation Bond Index&quot;</span>)</span></code></pre></div>
</div>
<div id="autocorrelations" class="section level4 unnumbered hasAnchor">
<h4>Autocorrelations<a href="C8AR.html#autocorrelations" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>Scatter plots are useful because they graphically display nonlinear,
as well as linear, relationships between two variables. As we
established in Chapter 2, correlations can be used to measure the
linear relation between two variables. Recall that when dealing with
cross-sectional data, we summarized
relations between {<span class="math inline">\(y_t\)</span>} and {<span class="math inline">\(x_t\)</span>} using the correlation statistic
<span class="math display">\[
r = \frac{1}{(T-1)s_{x}s_y} \sum_{t=1}^{T} \left( x_t -
\overline{x}\right) \left( y_t-\overline{y} \right) .
\]</span>
We now mimic this statistic using the series {<span class="math inline">\(y_{t-1}\)</span>} in place
of {<span class="math inline">\(x_t\)</span>}. With this replacement, use <span class="math inline">\(\overline{y}\)</span> in place of
<span class="math inline">\(\overline{x}\)</span> and, for the denominator, use <span class="math inline">\(s_y\)</span> in place of
<span class="math inline">\(s_x\)</span>. With this last substitution, we have <span class="math inline">\((T-1) s_y^2 = \sum_{t=1}^{T}(y_t-\overline{y} )^2\)</span>. Our resulting correlation
statistic is</p>
<p><span class="math display">\[
r_1 = \frac{\sum_{t=2}^{T} \left( y_{t-1}-\overline{y}\right) \left(
y_t- \overline{y}\right) }{\sum_{t=1}^{T} (y_t-\overline{y})^2}.
\]</span>
This statistic is referred to as an <em>autocorrelation</em>, that is,
a correlation of the series upon itself. This statistic summarizes
the linear relationship between {<span class="math inline">\(y_t\)</span>} and {<span class="math inline">\(y_{t-1}\)</span>}, that
is, observations that are one time unit apart. It will also be
useful to summarize the linear relationship between observations
that are <span class="math inline">\(k\)</span> time units apart, {<span class="math inline">\(y_t\)</span>} and {<span class="math inline">\(y_{t-k}\)</span>}, as
follows.</p>
<div class="blackbox">
<p><strong>Definition.</strong> The <em>lag k autocorrelation statistic</em> is</p>
<p><span class="math display">\[
r_k = \frac{\sum_{t=k+1}^{T}\left( y_{t-k}-\overline{y}\right) \left( y_t-
\overline{y}\right) }{\sum_{t=1}^{T}(y_t-\overline{y})^2},
~~~~k=1,2, \ldots
\]</span></p>
</div>
<p>Properties of autocorrelations are similar to correlations. Just as
with the usual correlation statistic <span class="math inline">\(r\)</span>, the denominator,
<span class="math inline">\(\sum_{t=1}^{T}(y_t - \overline{y})^2\)</span>, is always nonnegative and
hence does not change the sign of the numerator. We use this
rescaling device so that <span class="math inline">\(r_k\)</span> always lies within the interval [-1,
1]. Thus, when we interpret <span class="math inline">\(r_k\)</span>, a value near -1, 0 and 1, means,
respectively, a strong negative, near null or strong positive
relationship between <span class="math inline">\(y_t\)</span> and <span class="math inline">\(y_{t-k}\)</span>. If there is a positive
relationship between  <span class="math inline">\(y_t\)</span> and <span class="math inline">\(y_{t-1}\)</span>, then <span class="math inline">\(r_1 &gt; 0\)</span> and the
process is said to be <em>positively autocorrelated</em>. For example,
in <a href="C8AR.html#Tab83">Table 8.3</a> are the first five
autocorrelations of the inflation bond series. These
autocorrelations indicate that there is a positive relationship
between adjacent observations.</p>
<p><a id=Tab83></a></p>
<p><span id="Tab83">Table 8.3</span>. <strong>Autocorrelations for the Inflation Bond Series</strong></p>
<p><span class="math display">\[
\small{
\begin{array}{l|ccccc}
\hline
\text{Lag } k &amp; 1 &amp; 2 &amp; 3 &amp; 4 &amp; 5 \\ \hline
\text{Autocorrelation } r_k &amp; 0.814 &amp; 0.632 &amp; 0.561 &amp; 0.447 &amp; 0.367 \\
\hline
\end{array}
}
\]</span></p>
<h5 style="text-align: center;">
<a id="displayCode.Tab83.Hide" href="javascript:togglecode('toggleCode.Tab83.Hide','displayCode.Tab83.Hide');"><i><strong>R Code to Produce Table 8.3</strong></i></a>
</h5>
<div id="toggleCode.Tab83.Hide" style="display: none">
<div class="sourceCode" id="cb70"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb70-1"><a href="C8AR.html#cb70-1" tabindex="-1"></a>temp <span class="ot">&lt;-</span> <span class="fu">acf</span>(index, <span class="at">plot =</span> <span class="cn">FALSE</span>)</span>
<span id="cb70-2"><a href="C8AR.html#cb70-2" tabindex="-1"></a>Tab83 <span class="ot">&lt;-</span> temp<span class="sc">$</span>acf[<span class="dv">1</span><span class="sc">:</span><span class="dv">6</span>]</span>
<span id="cb70-3"><a href="C8AR.html#cb70-3" tabindex="-1"></a>knitr<span class="sc">::</span><span class="fu">kable</span>(Tab83, <span class="at">digits =</span> <span class="dv">3</span>)</span></code></pre></div>
<table>
<thead>
<tr class="header">
<th align="right">x</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="right">1.000</td>
</tr>
<tr class="even">
<td align="right">0.814</td>
</tr>
<tr class="odd">
<td align="right">0.632</td>
</tr>
<tr class="even">
<td align="right">0.561</td>
</tr>
<tr class="odd">
<td align="right">0.447</td>
</tr>
<tr class="even">
<td align="right">0.367</td>
</tr>
</tbody>
</table>
</div>
<div class="blackboxvideo">
<p><strong>Video: Section Summary</strong></p>
</div>
<center>
<iframe id="kaltura_player" src="https://cdnapisec.kaltura.com/p/1660902/embedPlaykitJs/uiconf_id/55063162?iframeembed=true&amp;entry_id=1_tjn86ji6&amp;config%5Bprovider%5D=%7B%22widgetId%22%3A%221_qcrvixwo%22%7D&amp;config%5Bplayback%5D=%7B%22startTime%22%3A0%7D" style="width: 576px;height: 324px;border: 0;" allowfullscreen webkitallowfullscreen mozAllowFullScreen allow="autoplay *; fullscreen *; encrypted-media *" title="8.1 Autocorrelations">
</iframe>
</center>
</div>
</div>
</div>
<div id="autoregressive-models-of-order-one" class="section level2 hasAnchor" number="8.2">
<h2><span class="header-section-number">8.2</span> Autoregressive Models of Order One<a href="C8AR.html#autoregressive-models-of-order-one" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<div id="model-definition-and-properties" class="section level4 unnumbered hasAnchor">
<h4>Model Definition and Properties<a href="C8AR.html#model-definition-and-properties" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>In Figure <a href="C8AR.html#fig:Fig82">8.2</a> we noted the strong relationship
between the immediate past and current values of the inflation bond
index. This suggests using <span class="math inline">\(y_{t-1}\)</span> to explain <span class="math inline">\(y_t\)</span> in a
regression model. Using previous values of a series to predict
current values of a series is termed, not surprisingly, an
<em>autoregression</em>. When only the immediate past is used as a
predictor, we use the following model.</p>
<div class="blackbox">
<p><strong>Definition.</strong> The <em>autoregressive model of order one</em>, denoted
by <span class="math inline">\(AR(1)\)</span>, is written as
<span class="math display" id="eq:eq81">\[\begin{equation}
y_t = \beta_0 + \beta_1 y_{t-1} + \varepsilon_t, ~~~ t=2,\ldots,T,
\tag{8.1}
\end{equation}\]</span>
where {<span class="math inline">\(\varepsilon_t\)</span>} is a white noise process such that
<span class="math inline">\(\mathrm{Cov}(\varepsilon_{t+k}, y_t)=0\)</span> for <span class="math inline">\(k&gt;0\)</span> and <span class="math inline">\(\beta_0\)</span> and
<span class="math inline">\(\beta_1\)</span> are unknown parameters.</p>
</div>
<p>In the <span class="math inline">\(AR\)</span>(1) model, the parameter <span class="math inline">\(\beta_0\)</span> may be any fixed
constant. However, the parameter <span class="math inline">\(\beta_1\)</span> is restricted to be
between -1 and 1. By making this restriction, it can be established
that the <span class="math inline">\(AR\)</span>(1) series {<span class="math inline">\(y_t\)</span>} is stationary. Note that if
<span class="math inline">\(\beta_1 = 1\)</span>, then the model is a random walk and hence is
nonstationary. This is because, if <span class="math inline">\(\beta_1 = 1\)</span>, then equation
<a href="C8AR.html#eq:eq81">(8.1)</a> may be rewritten as
<span class="math display">\[
y_t - y_{t-1} = \beta_0 + \varepsilon_t.
\]</span>
If the difference of a series forms a white noise process, then the series
itself must be a random walk.</p>
<p>The equation <a href="C8AR.html#eq:eq81">(8.1)</a> is useful in the discussion of model
properties. We can view an <span class="math inline">\(AR\)</span>(1) model as a generalization of both
a white noise process and a random walk model. If <span class="math inline">\(\beta_1=0\)</span>, then
equation <a href="C8AR.html#eq:eq81">(8.1)</a> reduces to a white noise process. If
<span class="math inline">\(\beta_1 = 1,\)</span> then equation <a href="C8AR.html#eq:eq81">(8.1)</a> is a random walk.</p>
<p>A stationary process where there is a linear relationship between
<span class="math inline">\(y_{t-2}\)</span> and <span class="math inline">\(y_t\)</span> is said to be <em>autoregressive of order 2</em>,
and similarly for higher order processes. Discussion of higher order
processes is in Section <a href="C8AR.html#S8:BoxJenkins">8.5</a>.</p>
</div>
<div id="model-selection" class="section level4 unnumbered hasAnchor">
<h4>Model Selection<a href="C8AR.html#model-selection" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>When examining the data, how does one recognize that an
autoregressive model may be a suitable candidate model? First, an
autoregressive model is stationary and thus a control chart is a
good device to examine graphically the data to search for stability.
Second, adjacent realizations of an <span class="math inline">\(AR\)</span>(1) model should be related;
this can be detected visually by a scatter plot of current versus
immediate past values of the series. Third, we can recognize an
<span class="math inline">\(AR\)</span>(1) model through its autocorrelation structure, as follows.</p>
<p>A useful property of the <span class="math inline">\(AR\)</span>(1) model is that the correlation
between points <span class="math inline">\(k\)</span> time units apart turns out to be <span class="math inline">\(\beta_1^{k}\)</span>.
Stated another way,
<span class="math display" id="eq:eq82">\[\begin{equation}
\rho_k = \mathrm{Corr}(y_t,y_{t-k}) =
\frac{\mathrm{Cov}(y_t,y_{t-k})}{\sqrt{\mathrm{Var}(y_t)\mathrm{Var}(y_{t-k})}}
= \frac{\mathrm{Cov}(y_t,y_{t-k})}{\sigma_y^2} = \beta_1^k.
\tag{8.2}
\end{equation}\]</span></p>
<p>The first two equalities are definitions and the third is
due to the stationarity. The reader is asked to check the fourth
equality in the exercises. Hence, the absolute values of the
autocorrelations of an <span class="math inline">\(AR\)</span>(1) process become smaller as the lag
time <span class="math inline">\(k\)</span> increases. In fact, they decrease at a geometric rate. We
remark that for a white noise process, we have <span class="math inline">\(\beta_1 = 0\)</span>, and
thus <span class="math inline">\(\rho_k\)</span> should be equal to zero for all lags <span class="math inline">\(k\)</span>.</p>
<p>As an aid in model identification, we use the idea of matching the
observed autocorrelations <span class="math inline">\(r_k\)</span> to quantities that we expect from
the theory, <span class="math inline">\(\rho_k\)</span>. For white noise, the sample autocorrelation
coefficient should be approximately zero for each lag <span class="math inline">\(k\)</span>. Even
though <span class="math inline">\(r_k\)</span> is algebraically bounded by -1 and 1, the question
arises, how large does <span class="math inline">\(r_k\)</span> need to be, in absolute value, to be
considered significantly different from zero? The answer to this
type of question is given in terms of the statistic’s standard
error. Under the hypothesis of no autocorrelation, a good
approximation to the standard error of the lag <span class="math inline">\(k\)</span> autocorrelation
statistic is
<span class="math display">\[
se(r_k) = \frac{1}{\sqrt{T}}.
\]</span>
Our rule of thumb is that if <span class="math inline">\(r_k\)</span> exceeds <span class="math inline">\(2 \times se(r_k)\)</span> in
absolute value, it may be considered to be significantly non-zero.
This rule is based on a 5% level of significance.</p>
<hr />
<p><strong>Example: Inflation Index Bonds - Continued.</strong> Is a white
noise process model a good candidate to represent this series? The
autocorrelations are given in <a href="C8AR.html#Tab82">Table 8.2</a>. For a
white noise process model, we expect each autocorrelation <span class="math inline">\(r_k\)</span> to
be close to zero but note that, for example, <span class="math inline">\(r_1=0.814\)</span>. Because
there are <span class="math inline">\(T=51\)</span> returns available, the approximate standard error
of each autocorrelation is
<span class="math display">\[
se(r_k) = \frac{1}{\sqrt{51}} = 0.140.
\]</span>
Thus, <span class="math inline">\(r_1\)</span> is 0.814 / 0.140 = 5.81 standard errors above zero.
Using the normal distribution as a reference base, this difference
is significant, implying that a white noise process is not a
suitable candidate model.</p>
<p>Is the autoregressive model of order one a suitable choice? Well,
because <span class="math inline">\(\rho_k\)</span> = <span class="math inline">\(\beta_1^{k}\)</span>, a good estimate of
<span class="math inline">\(\beta_1\)</span>=<span class="math inline">\(\rho_1\)</span> is <span class="math inline">\(r_1=0.814\)</span>. If this is the case, then under
the <span class="math inline">\(AR\)</span>(1) model, another estimate of <span class="math inline">\(\rho_k\)</span> is <span class="math inline">\((0.814)^{k}\)</span>.
Thus, we have two estimates of <span class="math inline">\(\rho_k\)</span>; (i) <span class="math inline">\(r_k\)</span>, an empirical
estimate that does not depend on a parametric model and (ii)
<span class="math inline">\((r_1)^{k}\)</span>, that depends on the <span class="math inline">\(AR\)</span>(1) model. To illustrate, see
<a href="C8AR.html#Tab84">Table 8.4</a>.</p>
<p><a id=Tab84></a></p>
<p><span id="Tab84">Table 8.4</span>. <strong>Comparison of Empirical Autocorrelations to Estimated under the <span class="math inline">\(AR\)</span>(1) model</strong></p>
<p><span class="math display">\[
\small{
\begin{array}{l|ccccc}
\hline
\text{Lag } k &amp; 1 &amp; 2 &amp; 3 &amp; 4 &amp; 5 \\ \hline
\text{Estimated } \rho_k \text{ under the } AR(1) \text{ model} &amp; 0.814 &amp; (0.814)^2 &amp;
(0.814)^{3} &amp; (0.814)^{4} &amp; (0.814)^{5} \\
&amp;  &amp; =.66 &amp;
=.54 &amp; =.44 &amp; =.36 \\
\text{Autocorrelation } r_k &amp; 0.814 &amp; 0.632 &amp; 0.561 &amp; 0.447 &amp; 0.367 \\
\hline
\end{array}
}
\]</span></p>
<p>Given that the approximate standard error is <span class="math inline">\(se(r_k) = 0.14\)</span>, there
seems to be a good match between the two sets of autocorrelations.
Because of this match, in Section <a href="C8AR.html#S8:Estimation">8.3</a> we will
discuss how to fit the <span class="math inline">\(AR\)</span>(1) model to this set of data.</p>
<hr />
</div>
<div id="meandering-process" class="section level4 unnumbered hasAnchor">
<h4>Meandering Process<a href="C8AR.html#meandering-process" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>Many processes display the pattern of adjacent points being related
to one another. Thinking of a process evolving as a river, Roberts
(1991) picturesquely describes such processes as <em>meandering</em>.
To supplement this intuitive notion, we say that a process is
meandering if the lag one autocorrelation of the series is positive.
For example, from the plots in Figures <a href="C8AR.html#fig:Fig81">8.1</a> and
<a href="C8AR.html#fig:Fig82">8.2</a>, it seems clear that the Inflation Bond Index is
a good example of a meandering series. Indeed, an <span class="math inline">\(AR\)</span>(1) model with
a positive slope coefficient is a meandering process.</p>
<p>What about the case when the slope coefficient approaches one,
resulting in a random walk? Consider the Hong Kong Exchange Rates
example given in Chapter 7. Although introduced as a quadratic trend
in time model, an exercise shows that the series can more
appropriately be modeled as a random walk. It seems clear that any
point in the process is highly related to each adjacent point in the
process. To emphasize this point, Figure <a href="C8AR.html#fig:Fig83">8.3</a> shows a
strong linear relationship between the current and immediate past
value of exchange rates. Because of the strong linear relationship
in Figure <a href="C8AR.html#fig:Fig83">8.3</a>, we will use the terminology “meandering
process” for a data set that may be modeled using a random walk.</p>

<div class="figure" style="text-align: center"><span style="display:block;" id="fig:Fig83"></span>
<img src="RegressionMarkdown_files/figure-html/Fig83-1.png" alt="Hong Kong Daily Exchange Rates versus Lagged Values." width="60%" />
<p class="caption">
Figure 8.3: <strong>Hong Kong Daily Exchange Rates versus Lagged Values.</strong>
</p>
</div>
<h5 style="text-align: center;">
<a id="displayCode.Fig83.Hide" href="javascript:togglecode('toggleCode.Fig83.Hide','displayCode.Fig83.Hide');"><i><strong>R Code to Produce Figure 8.3</strong></i></a>
</h5>
<div id="toggleCode.Fig83.Hide" style="display: none">
<div class="sourceCode" id="cb71"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb71-1"><a href="C8AR.html#cb71-1" tabindex="-1"></a><span class="co"># Figure 83</span></span>
<span id="cb71-2"><a href="C8AR.html#cb71-2" tabindex="-1"></a></span>
<span id="cb71-3"><a href="C8AR.html#cb71-3" tabindex="-1"></a>exchange  <span class="ot">&lt;-</span> <span class="fu">read.csv</span>(<span class="st">&quot;CSVData/HKExchange.csv&quot;</span>, <span class="at">header=</span><span class="cn">TRUE</span>)</span>
<span id="cb71-4"><a href="C8AR.html#cb71-4" tabindex="-1"></a><span class="co">#exchange  &lt;- read.csv(&quot;../../CSVData/HKExchange.csv&quot;, header=TRUE)</span></span>
<span id="cb71-5"><a href="C8AR.html#cb71-5" tabindex="-1"></a></span>
<span id="cb71-6"><a href="C8AR.html#cb71-6" tabindex="-1"></a>EXHKUS <span class="ot">&lt;-</span> exchange<span class="sc">$</span>EXHKUS</span>
<span id="cb71-7"><a href="C8AR.html#cb71-7" tabindex="-1"></a><span class="fu">plot</span>(EXHKUS[<span class="sc">-</span><span class="fu">length</span>(EXHKUS)], EXHKUS[<span class="sc">-</span><span class="dv">1</span>], <span class="at">xlab=</span><span class="st">&quot;Lagged Exchange Rate&quot;</span>,</span>
<span id="cb71-8"><a href="C8AR.html#cb71-8" tabindex="-1"></a>     <span class="at">ylab=</span><span class="st">&quot;Exchange Rage&quot;</span>, <span class="at">xlim=</span><span class="fu">c</span>(<span class="fl">7.75</span>,<span class="fl">7.82</span>),<span class="at">ylim=</span><span class="fu">c</span>(<span class="fl">7.75</span>,<span class="fl">7.82</span>))</span></code></pre></div>
</div>
<div class="blackboxvideo">
<p><strong>Video: Section Summary</strong></p>
</div>
<center>
<iframe id="kaltura_player" src="https://cdnapisec.kaltura.com/p/1660902/embedPlaykitJs/uiconf_id/55063162?iframeembed=true&amp;entry_id=1_m3val3ha&amp;config%5Bprovider%5D=%7B%22widgetId%22%3A%221_f5c8omi2%22%7D&amp;config%5Bplayback%5D=%7B%22startTime%22%3A0%7D" style="width: 576px;height: 324px;border: 0;" allowfullscreen webkitallowfullscreen mozAllowFullScreen allow="autoplay *; fullscreen *; encrypted-media *" title="8.2 AR1Model">
</iframe>
</center>
</div>
</div>
<div id="S8:Estimation" class="section level2 hasAnchor" number="8.3">
<h2><span class="header-section-number">8.3</span> Estimation and Diagnostic Checking<a href="C8AR.html#S8:Estimation" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Having identified a tentative model, the task now at hand is to
estimate values of <span class="math inline">\(\beta_0\)</span> and <span class="math inline">\(\beta_1\)</span>. In this section, we use
the <em>method of conditional least squares</em> to determine the
estimates, denoted as <span class="math inline">\(b_0\)</span> and <span class="math inline">\(b_1\)</span>, respectively. This approach
is based on the least squares method that was introduced in Section
2.1. Specifically, we now use the least squares to find estimates
that best fit an observation <em>conditional</em> on the previous
observation.</p>
<p>Formulas for the conditional least squares estimates are determined
from the usual least squares procedures, using the lagged value of
<span class="math inline">\(y\)</span> for the explanatory variable. It is easy to see that conditional
least squares estimates are closely approximated by
<span class="math display">\[
b_1 \approx r_1  \ \ \ \ \ \ \text{and} \ \ \ \ \ \ b_0 \approx
\overline{y}(1-r_1).
\]</span>
Differences between these approximations and the conditional least
squares estimates arise because we have no explanatory variable for
<span class="math inline">\(y_1\)</span>, the first observation. These differences are typically small
in most series and diminish as the series length increases.</p>
<p>Residuals of an <span class="math inline">\(AR\)</span>(1) model are defined as
<span class="math display">\[
e_t = y_t - \left( b_0 + b_1 y_{t-1} \right).
\]</span>
As we have seen, patterns in the residuals may reveal ways to
improve the model specification. One can use a control chart of the
residuals to assess the stationarity and compute the autocorrelation
function of residuals to verify the lack of milder patterns through
time.</p>
<p>The residuals also play an important role in estimating standard
errors associated with model parameter estimates. From equation
<a href="C8AR.html#eq:eq81">(8.1)</a>, we see that the unobserved errors are driving the
updating of the new observations. Thus, it makes sense to focus on
the variance of the errors and, as in cross-sectional data, we
define <span class="math inline">\(\sigma^2=\sigma_{\varepsilon }^2=\)</span> <span class="math inline">\(\mathrm{Var}~\varepsilon_t.\)</span></p>
<p>In cross-sectional regression, because the predictor variables were
non-stochastic, the variance of the response (<span class="math inline">\(\sigma_y^2\)</span>) equals
the variance of the errors (<span class="math inline">\(\sigma^2\)</span>). This is not generally true
in time series models that use stochastic predictors. For the
<span class="math inline">\(AR\)</span>(1) model, taking variances of both sides of equation
<a href="C8AR.html#eq:eq81">(8.1)</a> establishes
<span class="math display">\[
\sigma_y^2 (1-\beta_1^2) = \sigma^2 ,
\]</span>
so that <span class="math inline">\(\sigma_y^2 &gt; \sigma^2\)</span>.</p>
<p>To estimate <span class="math inline">\(\sigma^2\)</span>, we define
<span class="math display" id="eq:eq83">\[\begin{equation}
s^2 = \frac{1}{T-3}\sum_{t=2}^{T} \left( e_t - \overline{e}\right)^2.
\tag{8.3}
\end{equation}\]</span>
In equation <a href="C8AR.html#eq:eq83">(8.3)</a> the first residual, <span class="math inline">\(e_1\)</span>, is not
available because <span class="math inline">\(y_{t-1}\)</span> is not available when <span class="math inline">\(t=1\)</span> and so the
number of residuals is <span class="math inline">\(T-1\)</span>. Without the first residual, the
average of the residuals is no longer automatically zero and thus is
included in the sum of squares. Further, the denominator in the
right hand side of equation <a href="C8AR.html#eq:eq83">(8.3)</a> is still the number of
observations minus the number of parameters, keeping in mind the
conditions that the “number of observations” is <span class="math inline">\(T-1\)</span> and the
“number of parameters” is two. As in the cross-sectional
regression context, we refer to <span class="math inline">\(s^2\)</span> as the <em>mean square error (MSE)</em>.</p>
<hr />
<p><strong>Example: Inflation Index Bonds - Continued.</strong> The inflation
index was fit using an <span class="math inline">\(AR\)</span>(1) model. The estimated equation turns
out to be
<span class="math display">\[
\begin{array}{llllrl}
\widehat{INDEX}_t &amp; = &amp; 0.40849 &amp; + &amp; 0.81384 &amp; INDEX_{t-1} \\
{\small std~errors} &amp;  &amp; {\small (0.16916)} &amp;  &amp; {\small (0.07486)} &amp;
\end{array}
\]</span>
with <span class="math inline">\(s = 0.14\)</span>. This is smaller than the standard deviation of the
original series (0.259 from <a href="C8AR.html#Tab81">Table 8.1</a>),
indicating a better fit to the data than a white noise model. The
standard errors, given in parentheses, were computed using the
method of conditional least squares. For example, the <span class="math inline">\(t\)</span>-ratio for
<span class="math inline">\(\beta_1\)</span> is <span class="math inline">\(0.8727/0.0736=14.9\)</span>, indicating that the immediate
past response is an important predictor of the current response.</p>
<p>Residuals were computed as <span class="math inline">\(e_t = INDEX_t - (0.2923+0.8727INDEX_{t-1})\)</span>. The control chart of the residuals in
Figure <a href="C8AR.html#fig:Fig84">8.4</a> reveals no apparent patterns. Several
autocorrelations of residuals are presented in
<a href="C8AR.html#Tab85">Table 8.5</a>. With <span class="math inline">\(T=51\)</span> observations, the approximate
standard error is <span class="math inline">\(se(r_k) = 1/ \sqrt{51} = 0.14\)</span>. The second lag
autocorrelation is approximately -2.3 standard errors from zero and
the others are smaller, in absolute value. These values are lower
than those in <a href="C8AR.html#Tab83">Table 8.3</a>, indicating that we
have removed some of the temporal patterns with the <span class="math inline">\(AR\)</span>(1)
specification. The statistically significant autocorrelation at lag
2 indicates that there is still some potential for model
improvement.</p>

<div class="figure" style="text-align: center"><span style="display:block;" id="fig:Fig84"></span>
<img src="RegressionMarkdown_files/figure-html/Fig84-1.png" alt="Control Chart of Residuals from an \(AR\)(1) Fit of the Inflation Index Series. The dashed lines mark the upper and lower control limits which are the mean plus and minus three standard deviations." width="60%" />
<p class="caption">
Figure 8.4: <strong>Control Chart of Residuals from an <span class="math inline">\(AR\)</span>(1) Fit of the Inflation Index Series.</strong> The dashed lines mark the upper and lower control limits which are the mean plus and minus three standard deviations.
</p>
</div>
<p><a id=Tab85></a></p>
<p><span id="Tab85">Table 8.5</span>. <strong>Residual Autocorrelations from the <span class="math inline">\(AR\)</span>(1) model</strong></p>
<p><span class="math display">\[
\small{
\begin{array}{l|ccccc}
\hline
\text{Lag }k &amp; 1 &amp; 2 &amp; 3 &amp; 4 &amp; 5 \\ \hline
\text{Residual Autocorrelation }r_k &amp; 0.157 &amp;-0.289 &amp; 0.059 &amp; 0.073&amp; -0.124 \\
\hline
\end{array}
}
\]</span></p>
<h5 style="text-align: center;">
<a id="displayCode.Fig84.Hide" href="javascript:togglecode('toggleCode.Fig84.Hide','displayCode.Fig84.Hide');"><i><strong>R Code to Produce Figure 8.4 and Table 8.5</strong></i></a>
</h5>
<div id="toggleCode.Fig84.Hide" style="display: none">
<div class="sourceCode" id="cb72"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb72-1"><a href="C8AR.html#cb72-1" tabindex="-1"></a><span class="co"># Figure 84</span></span>
<span id="cb72-2"><a href="C8AR.html#cb72-2" tabindex="-1"></a><span class="co">#inflation  &lt;- read.csv(&quot;CSVData/InflationBond.csv&quot;, header=TRUE)</span></span>
<span id="cb72-3"><a href="C8AR.html#cb72-3" tabindex="-1"></a><span class="co">#inflation  &lt;- read.csv(&quot;../../CSVData/InflationBond.csv&quot;, header=TRUE)</span></span>
<span id="cb72-4"><a href="C8AR.html#cb72-4" tabindex="-1"></a><span class="co">#index&lt;- inflation$INFBOND</span></span>
<span id="cb72-5"><a href="C8AR.html#cb72-5" tabindex="-1"></a></span>
<span id="cb72-6"><a href="C8AR.html#cb72-6" tabindex="-1"></a>lagind  <span class="ot">&lt;-</span> index[<span class="sc">-</span><span class="fu">length</span>(index)]</span>
<span id="cb72-7"><a href="C8AR.html#cb72-7" tabindex="-1"></a>AR1  <span class="ot">&lt;-</span> <span class="fu">lm</span>(index[<span class="sc">-</span><span class="dv">1</span>] <span class="sc">~</span> lagind )</span>
<span id="cb72-8"><a href="C8AR.html#cb72-8" tabindex="-1"></a><span class="co">#summary(AR1)</span></span>
<span id="cb72-9"><a href="C8AR.html#cb72-9" tabindex="-1"></a>e  <span class="ot">&lt;-</span> index[<span class="sc">-</span><span class="dv">1</span>] <span class="sc">-</span> <span class="fu">as.numeric</span>(AR1<span class="sc">$</span>fitted)</span>
<span id="cb72-10"><a href="C8AR.html#cb72-10" tabindex="-1"></a>s  <span class="ot">&lt;-</span> <span class="fu">sqrt</span>(<span class="fu">sum</span>((e<span class="sc">-</span><span class="fu">mean</span>(e))<span class="sc">^</span><span class="dv">2</span>)<span class="sc">/</span>(<span class="fu">length</span>(index[<span class="sc">-</span><span class="dv">1</span>])<span class="sc">-</span><span class="dv">2</span>))</span>
<span id="cb72-11"><a href="C8AR.html#cb72-11" tabindex="-1"></a><span class="co">#  = sd(e)*sqrt(49/48)</span></span>
<span id="cb72-12"><a href="C8AR.html#cb72-12" tabindex="-1"></a><span class="fu">plot</span>(<span class="fu">c</span>(<span class="dv">1</span><span class="sc">:</span><span class="dv">50</span>), e, <span class="at">xlim=</span><span class="fu">c</span>(<span class="dv">0</span>,<span class="dv">50</span>), <span class="at">ylim=</span><span class="fu">c</span>(<span class="sc">-</span><span class="fl">0.6</span>,<span class="fl">0.6</span>), <span class="at">xlab=</span><span class="st">&quot;TIME&quot;</span>,</span>
<span id="cb72-13"><a href="C8AR.html#cb72-13" tabindex="-1"></a>     <span class="at">ylab=</span><span class="st">&quot;&quot;</span>, <span class="at">type=</span><span class="st">&quot;o&quot;</span>, <span class="at">pch=</span><span class="dv">16</span>,<span class="at">axes=</span>F)</span>
<span id="cb72-14"><a href="C8AR.html#cb72-14" tabindex="-1"></a><span class="fu">abline</span>(<span class="at">h=</span><span class="dv">0</span>, <span class="at">lty=</span><span class="dv">1</span>)</span>
<span id="cb72-15"><a href="C8AR.html#cb72-15" tabindex="-1"></a><span class="fu">abline</span>(<span class="at">h=</span><span class="fu">c</span>(<span class="sc">-</span><span class="dv">3</span><span class="sc">*</span>s,<span class="dv">3</span><span class="sc">*</span>s), <span class="at">lty=</span><span class="dv">2</span>)</span>
<span id="cb72-16"><a href="C8AR.html#cb72-16" tabindex="-1"></a>xat  <span class="ot">&lt;-</span> <span class="fu">seq</span>(<span class="dv">0</span>,<span class="dv">50</span>,<span class="at">by=</span><span class="dv">10</span>)</span>
<span id="cb72-17"><a href="C8AR.html#cb72-17" tabindex="-1"></a>yat  <span class="ot">&lt;-</span> <span class="fu">seq</span>(<span class="sc">-</span><span class="fl">0.6</span>,<span class="fl">0.6</span>,<span class="at">by=</span><span class="fl">0.3</span>)</span>
<span id="cb72-18"><a href="C8AR.html#cb72-18" tabindex="-1"></a><span class="fu">axis</span>(<span class="dv">1</span>,<span class="at">at=</span>xat,<span class="at">labels=</span><span class="fu">as.character</span>(xat),<span class="at">las=</span><span class="dv">1</span>)</span>
<span id="cb72-19"><a href="C8AR.html#cb72-19" tabindex="-1"></a><span class="fu">axis</span>(<span class="dv">2</span>,<span class="at">at=</span>yat,<span class="at">labels=</span><span class="fu">as.character</span>(yat),<span class="at">las=</span><span class="dv">1</span>)</span>
<span id="cb72-20"><a href="C8AR.html#cb72-20" tabindex="-1"></a><span class="fu">box</span>()</span></code></pre></div>
<div class="sourceCode" id="cb73"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb73-1"><a href="C8AR.html#cb73-1" tabindex="-1"></a><span class="co"># Table 8.5</span></span>
<span id="cb73-2"><a href="C8AR.html#cb73-2" tabindex="-1"></a>temp <span class="ot">&lt;-</span> <span class="fu">acf</span>(e, <span class="at">plot =</span> <span class="cn">FALSE</span>, <span class="at">demean =</span> <span class="cn">FALSE</span>, <span class="at">lag.max =</span> <span class="dv">6</span>)</span>
<span id="cb73-3"><a href="C8AR.html#cb73-3" tabindex="-1"></a>Tab85 <span class="ot">&lt;-</span> temp<span class="sc">$</span>acf[<span class="dv">1</span><span class="sc">:</span><span class="dv">6</span>]</span>
<span id="cb73-4"><a href="C8AR.html#cb73-4" tabindex="-1"></a>knitr<span class="sc">::</span><span class="fu">kable</span>(Tab85, <span class="at">digits =</span> <span class="dv">3</span>)</span></code></pre></div>
<table>
<thead>
<tr class="header">
<th align="right">x</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="right">1.000</td>
</tr>
<tr class="even">
<td align="right">0.157</td>
</tr>
<tr class="odd">
<td align="right">-0.289</td>
</tr>
<tr class="even">
<td align="right">0.059</td>
</tr>
<tr class="odd">
<td align="right">0.073</td>
</tr>
<tr class="even">
<td align="right">-0.124</td>
</tr>
</tbody>
</table>
</div>
<div class="blackboxvideo">
<p><strong>Video: Section Summary</strong></p>
</div>
<center>
<iframe id="kaltura_player" src="https://cdnapisec.kaltura.com/p/1660902/embedPlaykitJs/uiconf_id/55063162?iframeembed=true&amp;entry_id=1_7c8y60z9&amp;config%5Bprovider%5D=%7B%22widgetId%22%3A%221_vyd7h8qa%22%7D&amp;config%5Bplayback%5D=%7B%22startTime%22%3A0%7D" style="width: 576px;height: 324px;border: 0;" allowfullscreen webkitallowfullscreen mozAllowFullScreen allow="autoplay *; fullscreen *; encrypted-media *" title="8.3 EstimationDiagChecking">
</iframe>
</center>
</div>
<div id="S8:AR1Smooth" class="section level2 hasAnchor" number="8.4">
<h2><span class="header-section-number">8.4</span> Smoothing and Prediction<a href="C8AR.html#S8:AR1Smooth" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Having identified, fit, and checked the identification of the model, we now
proceed to basic inference. Recall that by inference we mean the process of
using the data set to make statements about the nature of the world. To make
statements about the series, analysts often examine the values fitted under
the model, called the <em>smoothed series</em>. The smoothed series is the
estimated expected value of the series given the past. For the <span class="math inline">\(AR\)</span>(1)
model, the smoothed series is
<span class="math display">\[
\widehat{y}_t=b_0+b_1y_{t-1}.
\]</span></p>
<p>In Figure <a href="C8AR.html#fig:Fig85">8.5</a>, an open circle represents the
actual Inflation Bond Index and an opaque circle represents the
corresponding smoothed series. Because the smoothed series is the
actual series with the estimated noise component removed, the
smoothed series is sometimes interpreted to represent the “real”
value of the series.</p>

<div class="figure" style="text-align: center"><span style="display:block;" id="fig:Fig85"></span>
<img src="RegressionMarkdown_files/figure-html/Fig85-1.png" alt="Inflation Bond Index with a Smoothed Series Superimposed. The index is given by the open plotting symbols, the smoothed series is represented by the opaque symbols." width="60%" />
<p class="caption">
Figure 8.5: <strong>Inflation Bond Index with a Smoothed Series Superimposed.</strong> The index is given by the open plotting symbols, the smoothed series is represented by the opaque symbols.
</p>
</div>
<h5 style="text-align: center;">
<a id="displayCode.Fig85.Hide" href="javascript:togglecode('toggleCode.Fig85.Hide','displayCode.Fig85.Hide');"><i><strong>R Code to Produce Figure 8.5</strong></i></a>
</h5>
<div id="toggleCode.Fig85.Hide" style="display: none">
<div class="sourceCode" id="cb74"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb74-1"><a href="C8AR.html#cb74-1" tabindex="-1"></a><span class="co"># Figure 85</span></span>
<span id="cb74-2"><a href="C8AR.html#cb74-2" tabindex="-1"></a><span class="co">#inflation  &lt;- read.csv(&quot;CSVData/InflationBond.csv&quot;, header=TRUE)</span></span>
<span id="cb74-3"><a href="C8AR.html#cb74-3" tabindex="-1"></a><span class="co">#inflation  &lt;- read.csv(&quot;../../CSVData/InflationBond.csv&quot;, header=TRUE)</span></span>
<span id="cb74-4"><a href="C8AR.html#cb74-4" tabindex="-1"></a><span class="co">#index&lt;- inflation$INFBOND</span></span>
<span id="cb74-5"><a href="C8AR.html#cb74-5" tabindex="-1"></a><span class="co">#foo  &lt;- ts(index, freq = 12, start = c(2003,1),end=c(2007,3))</span></span>
<span id="cb74-6"><a href="C8AR.html#cb74-6" tabindex="-1"></a><span class="co">#AR1  &lt;- lm(index[-1] ~ lagind )</span></span>
<span id="cb74-7"><a href="C8AR.html#cb74-7" tabindex="-1"></a></span>
<span id="cb74-8"><a href="C8AR.html#cb74-8" tabindex="-1"></a><span class="fu">ts.plot</span>(foo,<span class="at">ylab=</span><span class="st">&quot;Index&quot;</span>, <span class="at">xlab=</span><span class="st">&quot;YEAR&quot;</span>,<span class="at">ylim=</span><span class="fu">c</span>(<span class="fl">1.5</span>,<span class="fl">3.0</span>),</span>
<span id="cb74-9"><a href="C8AR.html#cb74-9" tabindex="-1"></a>        <span class="at">gpars=</span><span class="fu">list</span>(<span class="at">pch=</span><span class="dv">16</span>,<span class="at">type=</span><span class="st">&quot;o&quot;</span>))</span>
<span id="cb74-10"><a href="C8AR.html#cb74-10" tabindex="-1"></a>pred  <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="cn">NA</span>,<span class="fu">as.numeric</span>(AR1<span class="sc">$</span>fitted))</span>
<span id="cb74-11"><a href="C8AR.html#cb74-11" tabindex="-1"></a><span class="fu">par</span>(<span class="at">new=</span><span class="cn">TRUE</span>)</span>
<span id="cb74-12"><a href="C8AR.html#cb74-12" tabindex="-1"></a>foopred  <span class="ot">&lt;-</span> <span class="fu">ts</span>(pred, <span class="at">freq =</span> <span class="dv">12</span>, <span class="at">start =</span> <span class="fu">c</span>(<span class="dv">2003</span>,<span class="dv">2</span>),<span class="at">end=</span><span class="fu">c</span>(<span class="dv">2007</span>,<span class="dv">3</span>))</span>
<span id="cb74-13"><a href="C8AR.html#cb74-13" tabindex="-1"></a><span class="fu">ts.plot</span>(foopred,<span class="at">gpars=</span><span class="fu">list</span>(<span class="at">pch=</span><span class="dv">1</span>,<span class="at">type=</span><span class="st">&quot;o&quot;</span>,<span class="at">axes=</span>F),<span class="at">ylim=</span><span class="fu">c</span>(<span class="fl">1.5</span>,<span class="fl">3.0</span>),</span>
<span id="cb74-14"><a href="C8AR.html#cb74-14" tabindex="-1"></a>        <span class="at">xlab=</span><span class="st">&quot;&quot;</span>,<span class="at">ylab=</span><span class="st">&quot;&quot;</span>)</span>
<span id="cb74-15"><a href="C8AR.html#cb74-15" tabindex="-1"></a><span class="fu">legend</span>(<span class="dv">2006</span>,<span class="fl">2.9</span>,<span class="at">legend=</span><span class="fu">c</span>(<span class="st">&quot;INFBOND&quot;</span>,<span class="st">&quot;SMOOTH&quot;</span>),<span class="at">pch=</span><span class="fu">c</span>(<span class="dv">16</span>,<span class="dv">1</span>),<span class="at">bty=</span><span class="st">&quot;n&quot;</span>)</span></code></pre></div>
</div>
<p>Typically, the most important application of time series modeling is
the forecasting of future values of the series. From equation
<a href="C8AR.html#eq:eq81">(8.1)</a>, the immediate future value of the series is <span class="math inline">\(y_{T+1} = \beta_0 + \beta_1 y_T + \varepsilon_{T+1}\)</span>. Because the series
{<span class="math inline">\(\varepsilon_t\)</span>} is random, a natural forecast of
<span class="math inline">\(\varepsilon_{T+1}\)</span> is its mean, zero. Thus, if the estimates <span class="math inline">\(b_0\)</span>
and <span class="math inline">\(b_1\)</span> are close to the true parameters <span class="math inline">\(\beta_0\)</span> and <span class="math inline">\(\beta_1\)</span>,
then a desirable estimate of the series at time <span class="math inline">\(T+1\)</span> is
<span class="math inline">\(\widehat{y}_{T+1} = b_0 + b_1 y_T\)</span>. Similarly, one can recursively
compute an estimate for the series <span class="math inline">\(k\)</span> time points in the future,
<span class="math inline">\(y_{T+k}\)</span>.</p>
<div class="blackbox">
<p><strong>Definition.</strong> The <span class="math inline">\(k\)</span>-step ahead forecast of
<span class="math inline">\(y_{T+k}\)</span> for an <span class="math inline">\(AR\)</span> (1) model is recursively determined by
<span class="math display" id="eq:eq84">\[\begin{equation}
\widehat{y}_{T+k} = b_0 + b_1 \widehat{y}_{T+k-1}.
\tag{8.4}
\end{equation}\]</span>
This is sometimes known as the <em>chain rule of forecasting</em>.</p>
</div>
<p>To get an idea of the error in using <span class="math inline">\(\widehat{y}_{T+1}\)</span> to predict
<span class="math inline">\(y_{T+1}\)</span>, assume for the moment that the error in using <span class="math inline">\(b_0\)</span> and
<span class="math inline">\(b_1\)</span> to estimate <span class="math inline">\(\beta_0\)</span> and <span class="math inline">\(\beta_1\)</span> is negligible. With this
assumption, the forecast error is
<span class="math display">\[
y_{T+1}-\widehat{y}_{T+1} = \beta_0 + \beta_1 y_t +
\varepsilon_{T+1} - \left( b_0 + b_1 y_t\right) \approx
\varepsilon_{T+1}.
\]</span>
Thus, the variance of this forecast error is approximately
<span class="math inline">\(\sigma^2\)</span>. Similarly, it can be shown that the approximate variance
of the forecast error <span class="math inline">\(y_{T+k}-\widehat{y}_{T+k}\)</span> is <span class="math inline">\(\sigma^2(1 + \beta_1^2 \ldots + \beta_1^{2(k-1)})\)</span>. From this variance
calculation and the approximate normality, we have the following
prediction interval.</p>
<div class="blackbox">
<p><strong>Definition.</strong> The <span class="math inline">\(k\)</span>-step ahead forecast interval of
<span class="math inline">\(y_{T+k}\)</span> for an <span class="math inline">\(AR\)</span>(1) model is
<span class="math display">\[
\widehat{y}_{T+k} \pm (t-value)~s \sqrt{1 + b_1^2+ \ldots +
b_1^{2(k-1)}}.
\]</span>
Here, the <span class="math inline">\(t\)</span>-value is a percentile from the <span class="math inline">\(t\)</span>-curve using <span class="math inline">\(df=T-3\)</span>
degrees of freedom. The percentile is 1 - (prediction level)/2.</p>
</div>
<p>For example, for 95% prediction intervals, we would have <span class="math inline">\(t\)</span>-value <span class="math inline">\(\approx\)</span> 2. Thus, one- and two-step 95% prediction intervals are:
<span class="math display">\[
\begin{array}{lc}
\text{one-step:} &amp; \widehat{y}_{T+1}\pm \ 2s \\
\text{two-step:} &amp; \widehat{y}_{T+2}\pm \ 2s(1+b_1^2)^{1/2}.
\end{array}
\]</span></p>
<p>Figure <a href="C8AR.html#fig:Fig86">8.6</a> illustrates forecasts of the inflation
bond index. The forecast intervals widen as the number of steps into
the future increases; this reflects our increasing uncertainty as we
forecast further into the future.</p>

<div class="figure" style="text-align: center"><span style="display:block;" id="fig:Fig86"></span>
<img src="RegressionMarkdown_files/figure-html/Fig86-1.png" alt="Forecast Intervals for the Inflation Bond Series." width="60%" />
<p class="caption">
Figure 8.6: <strong>Forecast Intervals for the Inflation Bond Series.</strong>
</p>
</div>
<h5 style="text-align: center;">
<a id="displayCode.Fig86.Hide" href="javascript:togglecode('toggleCode.Fig86.Hide','displayCode.Fig86.Hide');"><i><strong>R Code to Produce Figure 8.6</strong></i></a>
</h5>
<div id="toggleCode.Fig86.Hide" style="display: none">
<div class="sourceCode" id="cb75"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb75-1"><a href="C8AR.html#cb75-1" tabindex="-1"></a><span class="co"># Figure 86</span></span>
<span id="cb75-2"><a href="C8AR.html#cb75-2" tabindex="-1"></a><span class="co">#inflation  &lt;- read.csv(&quot;CSVData/InflationBond.csv&quot;, header=TRUE)</span></span>
<span id="cb75-3"><a href="C8AR.html#cb75-3" tabindex="-1"></a><span class="co">#inflation  &lt;- read.csv(&quot;../../CSVData/InflationBond.csv&quot;, header=TRUE)</span></span>
<span id="cb75-4"><a href="C8AR.html#cb75-4" tabindex="-1"></a><span class="co">#index&lt;- inflation$INFBOND</span></span>
<span id="cb75-5"><a href="C8AR.html#cb75-5" tabindex="-1"></a><span class="co">#AR1  &lt;- lm(index[-1] ~ lagind )</span></span>
<span id="cb75-6"><a href="C8AR.html#cb75-6" tabindex="-1"></a></span>
<span id="cb75-7"><a href="C8AR.html#cb75-7" tabindex="-1"></a>fore  <span class="ot">&lt;-</span> index</span>
<span id="cb75-8"><a href="C8AR.html#cb75-8" tabindex="-1"></a>b0    <span class="ot">&lt;-</span> <span class="fu">as.numeric</span>(AR1<span class="sc">$</span>coef[<span class="dv">1</span>])</span>
<span id="cb75-9"><a href="C8AR.html#cb75-9" tabindex="-1"></a>b1    <span class="ot">&lt;-</span> <span class="fu">as.numeric</span>(AR1<span class="sc">$</span>coef[<span class="dv">2</span>])</span>
<span id="cb75-10"><a href="C8AR.html#cb75-10" tabindex="-1"></a><span class="cf">for</span>(i <span class="cf">in</span> <span class="dv">52</span><span class="sc">:</span><span class="dv">57</span>) {fore  <span class="ot">&lt;-</span> <span class="fu">c</span>(fore,fore[<span class="fu">length</span>(fore)]<span class="sc">*</span>b1 <span class="sc">+</span> b0)}</span>
<span id="cb75-11"><a href="C8AR.html#cb75-11" tabindex="-1"></a></span>
<span id="cb75-12"><a href="C8AR.html#cb75-12" tabindex="-1"></a>crit  <span class="ot">&lt;-</span> <span class="fu">qt</span>(<span class="fl">0.025</span>,<span class="dv">48</span>,<span class="at">lower.tail=</span>F)</span>
<span id="cb75-13"><a href="C8AR.html#cb75-13" tabindex="-1"></a>temp  <span class="ot">&lt;-</span> b1<span class="sc">^</span>((<span class="fu">c</span>(<span class="dv">1</span><span class="sc">:</span><span class="dv">6</span>)<span class="sc">-</span><span class="dv">1</span>)<span class="sc">*</span><span class="dv">2</span>)</span>
<span id="cb75-14"><a href="C8AR.html#cb75-14" tabindex="-1"></a>wid   <span class="ot">&lt;-</span> <span class="cn">NULL</span></span>
<span id="cb75-15"><a href="C8AR.html#cb75-15" tabindex="-1"></a><span class="cf">for</span>(k <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span><span class="dv">6</span>) {wid[k]  <span class="ot">&lt;-</span> <span class="fu">sqrt</span>(<span class="fu">sum</span>(temp[<span class="dv">1</span><span class="sc">:</span>k]))<span class="sc">*</span>s<span class="sc">*</span>crit}</span>
<span id="cb75-16"><a href="C8AR.html#cb75-16" tabindex="-1"></a>lower  <span class="ot">&lt;-</span> <span class="fu">c</span>(index,fore[<span class="dv">52</span><span class="sc">:</span><span class="dv">57</span>]<span class="sc">-</span>wid)</span>
<span id="cb75-17"><a href="C8AR.html#cb75-17" tabindex="-1"></a>upper  <span class="ot">&lt;-</span> <span class="fu">c</span>(index,fore[<span class="dv">52</span><span class="sc">:</span><span class="dv">57</span>]<span class="sc">+</span>wid)</span>
<span id="cb75-18"><a href="C8AR.html#cb75-18" tabindex="-1"></a></span>
<span id="cb75-19"><a href="C8AR.html#cb75-19" tabindex="-1"></a>foofore  <span class="ot">&lt;-</span> <span class="fu">ts</span>(fore, <span class="at">freq =</span> <span class="dv">12</span>, <span class="at">start =</span> <span class="fu">c</span>(<span class="dv">2003</span>,<span class="dv">2</span>),<span class="at">end=</span><span class="fu">c</span>(<span class="dv">2007</span>,<span class="dv">9</span>))</span>
<span id="cb75-20"><a href="C8AR.html#cb75-20" tabindex="-1"></a><span class="fu">ts.plot</span>(foofore,<span class="at">gpars=</span><span class="fu">list</span>(<span class="at">type=</span><span class="st">&quot;o&quot;</span>,<span class="at">pch=</span><span class="dv">16</span>),<span class="at">ylim=</span><span class="fu">c</span>(<span class="fl">1.5</span>,<span class="fl">3.0</span>),</span>
<span id="cb75-21"><a href="C8AR.html#cb75-21" tabindex="-1"></a>        <span class="at">xlab=</span><span class="st">&quot;Year&quot;</span>,<span class="at">ylab=</span><span class="st">&quot;Bond Index&quot;</span>,<span class="at">xlim=</span><span class="fu">c</span>(<span class="dv">2003</span>,<span class="dv">2008</span>))</span>
<span id="cb75-22"><a href="C8AR.html#cb75-22" tabindex="-1"></a><span class="fu">par</span>(<span class="at">new=</span><span class="cn">TRUE</span>)</span>
<span id="cb75-23"><a href="C8AR.html#cb75-23" tabindex="-1"></a>foolower  <span class="ot">&lt;-</span> <span class="fu">ts</span>(lower, <span class="at">freq =</span> <span class="dv">12</span>, <span class="at">start =</span> <span class="fu">c</span>(<span class="dv">2003</span>,<span class="dv">2</span>),<span class="at">end=</span><span class="fu">c</span>(<span class="dv">2007</span>,<span class="dv">9</span>))</span>
<span id="cb75-24"><a href="C8AR.html#cb75-24" tabindex="-1"></a><span class="fu">ts.plot</span>(foolower,<span class="at">gpars=</span><span class="fu">list</span>(<span class="at">type=</span><span class="st">&quot;l&quot;</span>,<span class="at">lty=</span><span class="dv">1</span>),<span class="at">ylim=</span><span class="fu">c</span>(<span class="fl">1.5</span>,<span class="fl">3.0</span>),</span>
<span id="cb75-25"><a href="C8AR.html#cb75-25" tabindex="-1"></a>        <span class="at">xlab=</span><span class="st">&quot;&quot;</span>,<span class="at">ylab=</span><span class="st">&quot;&quot;</span>,<span class="at">axes=</span>F,<span class="at">xlim=</span><span class="fu">c</span>(<span class="dv">2003</span>,<span class="dv">2008</span>))</span>
<span id="cb75-26"><a href="C8AR.html#cb75-26" tabindex="-1"></a><span class="fu">par</span>(<span class="at">new=</span><span class="cn">TRUE</span>)</span>
<span id="cb75-27"><a href="C8AR.html#cb75-27" tabindex="-1"></a>fooupper  <span class="ot">&lt;-</span> <span class="fu">ts</span>(upper, <span class="at">freq =</span> <span class="dv">12</span>, <span class="at">start =</span> <span class="fu">c</span>(<span class="dv">2003</span>,<span class="dv">2</span>),<span class="at">end=</span><span class="fu">c</span>(<span class="dv">2007</span>,<span class="dv">9</span>))</span>
<span id="cb75-28"><a href="C8AR.html#cb75-28" tabindex="-1"></a><span class="fu">ts.plot</span>(fooupper,<span class="at">gpars=</span><span class="fu">list</span>(<span class="at">type=</span><span class="st">&quot;l&quot;</span>,<span class="at">lty=</span><span class="dv">3</span>),<span class="at">ylim=</span><span class="fu">c</span>(<span class="fl">1.5</span>,<span class="fl">3.0</span>),</span>
<span id="cb75-29"><a href="C8AR.html#cb75-29" tabindex="-1"></a>        <span class="at">xlab=</span><span class="st">&quot;&quot;</span>,<span class="at">ylab=</span><span class="st">&quot;&quot;</span>,<span class="at">axes=</span>F,<span class="at">xlim=</span><span class="fu">c</span>(<span class="dv">2003</span>,<span class="dv">2008</span>))</span></code></pre></div>
</div>
<div class="blackboxvideo">
<p><strong>Video: Section Summary</strong></p>
</div>
<center>
<iframe id="kaltura_player" src="https://cdnapisec.kaltura.com/p/1660902/embedPlaykitJs/uiconf_id/55063162?iframeembed=true&amp;entry_id=1_r1ki8b07&amp;config%5Bprovider%5D=%7B%22widgetId%22%3A%221_fb8z17pi%22%7D&amp;config%5Bplayback%5D=%7B%22startTime%22%3A0%7D" style="width: 576px;height: 324px;border: 0;" allowfullscreen webkitallowfullscreen mozAllowFullScreen allow="autoplay *; fullscreen *; encrypted-media *" title="8.4 SmoothingPrediction">
</iframe>
</center>
</div>
<div id="S8:BoxJenkins" class="section level2 hasAnchor" number="8.5">
<h2><span class="header-section-number">8.5</span> Box-Jenkins Modeling and Forecasting<a href="C8AR.html#S8:BoxJenkins" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Sections 8.1 through 8.4 introduced
the <span class="math inline">\(AR(1)\)</span> model, including model properties, identification
methods and forecasting. We now introduce a broader class of models
known as <em>autoregressive integrated moving average (ARIMA) models</em>, due to George Box and Gwilym Jenkins, see Box, Jenkins and Reinsel (1994).</p>
<div id="models" class="section level3 hasAnchor" number="8.5.1">
<h3><span class="header-section-number">8.5.1</span> Models<a href="C8AR.html#models" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<div id="arp-models" class="section level4 unnumbered hasAnchor">
<h4><span class="math inline">\(AR(p)\)</span> Models<a href="C8AR.html#arp-models" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>The autoregressive model of order one allows us to relate the
current behavior of an observation directly to its immediate past
value. Moreover, in some applications, there are also important
effects of observations that are more distant in the past than
simply the immediate preceding observation. To quantify this, we
have already introduced the lag <span class="math inline">\(k\)</span> autocorrelation <span class="math inline">\(\rho_k\)</span> that
captures the linear relationship between <span class="math inline">\(y_t\)</span> and <span class="math inline">\(y_{t-k}\)</span>. To
incorporate this feature into a forecasting framework, we have the
<em>autoregressive model of order p</em>, denoted by <span class="math inline">\(AR(p).\)</span> The
model equation is
<span class="math display" id="eq:eq85">\[\begin{equation}
y_t = \beta_0 + \beta_1 y_{t-1} + \ldots + \beta_p y_{t-p} +
\varepsilon_t, ~~~~ t=p+1,\ldots ,T,
\tag{8.5}
\end{equation}\]</span>
where {<span class="math inline">\(\varepsilon_t\)</span>} is a white noise process such that
<span class="math inline">\(\mathrm{Cov}(\varepsilon_{t+k}, y_t)=0\)</span> for <span class="math inline">\(k&gt;0\)</span> and <span class="math inline">\(\beta_0\)</span>,
<span class="math inline">\(\beta_1,\ldots,\beta_p\)</span> are unknown parameters.</p>
<p>As a convention, when data analysts specify an <span class="math inline">\(AR\)</span>(<span class="math inline">\(p\)</span>)
model, they include not only <span class="math inline">\(y_{t-p}\)</span> as a predictor variable, but
also the intervening lags, <span class="math inline">\(y_{t-1}, \ldots, y_{t-p+1}\)</span>. The
exceptions to this convention are the seasonal autoregressive
models, that will be introduced in Section 9.4. Also by convention,
the <span class="math inline">\(AR(p)\)</span> is a model of a stationary, stochastic process. Thus,
certain restrictions on the parameters <span class="math inline">\(\beta_1, \ldots, \beta_p\)</span>
are necessary to ensure (weak) stationarity. These restrictions are
developed in the following subsection.</p>
</div>
<div id="backshift-notation" class="section level4 unnumbered hasAnchor">
<h4>Backshift Notation<a href="C8AR.html#backshift-notation" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>The <em>backshift, or backwards-shift, operator</em> <span class="math inline">\(\mathrm{B}\)</span> is
defined by <span class="math inline">\(\mathrm{B}y_t\)</span> = <span class="math inline">\(y_{t-1}\)</span>. The notation
<span class="math inline">\(\mathrm{B}^{k}\)</span> means apply the operator <span class="math inline">\(k\)</span> times, that is,
<span class="math display">\[
\mathrm{B}^{k}~y_t = \mathrm{BB \cdots B~} y_t = \mathrm{B}
^{k-1}~y_{t-1} = \cdots = y_{t-k}.
\]</span>
This operator is linear in the sense that <span class="math inline">\(\mathrm{B} (a_1 y_t + a_2 y_{t-1}) = a_1 y_{t-1} + a_2 y_{t-2}\)</span>, where <span class="math inline">\(a_1\)</span> and <span class="math inline">\(a_2\)</span> are
constants. Thus, we can express the <span class="math inline">\(AR(p)\)</span> model as
<span class="math display">\[\begin{eqnarray*}
\beta_0 + \varepsilon_t &amp;=&amp; y_t - \left( \beta_1 y_{t-1} + \ldots +
\beta_p y_{t-p}\right)  \\
&amp;=&amp; \left(1-\beta_1 \mathrm{B} - \ldots - \beta_p
\mathrm{B}^{p}\right) y_t = \Phi \left( \mathrm{B}\right) y_t.
\end{eqnarray*}\]</span>
If <span class="math inline">\(x\)</span> is a scalar, then <span class="math inline">\(\Phi \left( x\right) = 1 - \beta_1 x - \ldots - \beta_p x^p\)</span> is a <span class="math inline">\(p\)</span>th order polynomial in <span class="math inline">\(x\)</span>. Thus,
there exist <span class="math inline">\(p\)</span> roots of the equation <span class="math inline">\(\Phi \left( x\right) =0\)</span>.
These roots, say, <span class="math inline">\(g_1,..,g_p\)</span> , may or may not be complex numbers.
It can be shown, see Box, Jenkins and Reinsel (1994), that for
stationarity, all roots lie strictly outside the unit circle. To
illustrate, for <span class="math inline">\(p=1\)</span>, we have <span class="math inline">\(\Phi \left( x\right) = 1 - \beta_1 x\)</span>. The root of this equation is <span class="math inline">\(g_1 = \beta_1^{-1}\)</span>. Thus, we
require <span class="math inline">\(|g_1|&gt;1\)</span>, or <span class="math inline">\(|\beta_1|&lt;1\)</span>, for stationarity.</p>
</div>
<div id="maq-models" class="section level4 unnumbered hasAnchor">
<h4><span class="math inline">\(MA(q)\)</span> Models<a href="C8AR.html#maq-models" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>One interpretation of the model <span class="math inline">\(y_t=\beta_0+\varepsilon_t\)</span> is that
the disturbance <span class="math inline">\(\varepsilon_t\)</span> perturbs the measure of the
true, expected value of <span class="math inline">\(y_t.\)</span>
Similarly, we can consider the model <span class="math inline">\(y_t=\beta_0 + \varepsilon _t-\theta_1\varepsilon_{t-1}\)</span>, where <span class="math inline">\(\theta_1 \varepsilon_{t-1}\)</span> is
the perturbation from the previous time period. Extending this line
of thought, we introduce the <em>moving average model of order q</em>,
denoted by <span class="math inline">\(MA(q)\)</span>. The model equation is
<span class="math display" id="eq:eq86">\[\begin{equation}
y_t = \beta_0 + \varepsilon_t - \theta_1 \varepsilon_{t-1} - \ldots
- \theta_q \varepsilon_{t-q},
\tag{8.6}
\end{equation}\]</span>
where the process {<span class="math inline">\(\varepsilon_t\)</span>} is a white noise process such
that <span class="math inline">\(\mathrm{Cov}(\varepsilon_{t+k}, y_t)=0\)</span> for <span class="math inline">\(k&gt;0\)</span> and
<span class="math inline">\(\beta_0\)</span>, <span class="math inline">\(\theta_1, \ldots, \theta_q\)</span> are unknown parameters.</p>
<p>With equation <a href="C8AR.html#eq:eq86">(8.6)</a> it is easy to see that <span class="math inline">\(\mathrm{Cov} (y_{t+k},y_t)=0\)</span> for <span class="math inline">\(k&gt;q\)</span>. Thus, <span class="math inline">\(\rho_k =0\)</span> for <span class="math inline">\(k&gt;q\)</span>. Unlike the
<span class="math inline">\(AR(p)\)</span> model, the <span class="math inline">\(MA(q)\)</span> process is stationary for any finite
values of the parameters <span class="math inline">\(\beta_0\)</span>, <span class="math inline">\(\theta_1, \ldots, \theta_q\)</span>. It
is convenient to write the <span class="math inline">\(MA(q)\)</span> using backshift notation, as
follows:
<span class="math display">\[
y_t - \beta_0 = \left( 1-\theta_1\mathrm{B} - \ldots - \theta_q
\mathrm{B}^q\right) \varepsilon_t = \Theta \left( \mathrm{B}\right)
\varepsilon_t.
\]</span>
As with <span class="math inline">\(\Phi \left( x\right)\)</span>, if <span class="math inline">\(x\)</span> is a scalar, then <span class="math inline">\(\Theta \left( x\right) = 1 - \theta_1 x - \ldots - \theta_q x^q\)</span> is a <span class="math inline">\(q\)</span>th
order polynomial in <span class="math inline">\(x\)</span>. It is unfortunate that the phrase “moving
average” is used for the model defined by equation <a href="C8AR.html#eq:eq86">(8.6)</a>
and the estimate defined in Section 9.2. We will attempt to clarify
the usage as it arises.</p>
</div>
<div id="arma-and-arima-models" class="section level4 unnumbered hasAnchor">
<h4><span class="math inline">\(ARMA\)</span> and <span class="math inline">\(ARIMA\)</span> Models<a href="C8AR.html#arma-and-arima-models" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>Combining the <span class="math inline">\(AR(p)\)</span> and the <span class="math inline">\(MA(q)\)</span> models yields the
<em>autoregressive moving average model</em> of order <span class="math inline">\(p\)</span> and <span class="math inline">\(q\)</span>, or
<span class="math inline">\(ARMA(p,q)\)</span>,
<span class="math display" id="eq:eq87">\[\begin{equation}
y_t - \beta_1 y_{t-1} - \ldots - \beta_p y_{t-p} = \beta_0 +
\varepsilon _t - \theta_1 \varepsilon_{t-1} - \ldots - \theta_q
\varepsilon_{t-q},
\tag{8.7}
\end{equation}\]</span>
which can be represented as
<span class="math display" id="eq:eq88">\[\begin{equation}
\Phi \left( \mathrm{B}\right) y_t = \beta_0 + \Theta \left(
\mathrm{B} \right) \varepsilon_t.
\tag{8.8}
\end{equation}\]</span></p>
<p>In many applications, the data requires differencing to exhibit
stationarity. We assume that the data are differenced <span class="math inline">\(d\)</span> times to
yield
<span class="math display" id="eq:eq89">\[\begin{equation}
w_t = \left( 1-\mathrm{B}\right)^d y_t = \left( 1-\mathrm{B}\right)
^{d-1}\left( y_t-y_{t-1}\right) = \left( 1-\mathrm{B}\right)
^{d-2}\left( y_t-y_{t-1}-\left( y_{t-1}-y_{t-2}\right) \right) =
\ldots
\tag{8.9}
\end{equation}\]</span>
In practice, <span class="math inline">\(d\)</span> is typically zero, one or two. With this, the
<em>autoregressive integrated moving average model</em> of order
<span class="math inline">\((p,d,q)\)</span>, denoted by <span class="math inline">\(ARIMA(p,d,q)\)</span>, is
<span class="math display" id="eq:eq810">\[\begin{equation}
\Phi \left( \mathrm{B}\right) w_t = \beta_0+\Theta \left( \mathrm{B}
\right) \varepsilon_t.
\tag{8.10}
\end{equation}\]</span>
Often, <span class="math inline">\(\beta_0\)</span> is zero for <span class="math inline">\(d&gt;0\)</span>.</p>
<p>Several procedures are available for estimating model parameters including
maximum likelihood estimation, and conditional and unconditional least
squares estimation. In most cases, these procedures require iterative
fitting procedures. See Abraham and Ledolter (1983) for further information.</p>
<hr />
<p><strong>Example: Forecasting Mortality Rates</strong>. To quantify values in life insurance and
annuities, actuaries need forecasts of age-specific mortality rates.
Since its publication, the method proposed by Lee and Carter (1992)
has proved to be a popular method to forecast mortality. For
example, Li and Chan (2007) used these methods to produce forecasts
of 1921-2000 Canadian population rates and 1900-2000 U.S. rates.
They showed how to modify the basic methodology to incorporate
atypical events including wars and pandemic events such as influenza
and pneumonia.</p>
<p>The Lee-Carter method is usually based on central death rates at age
<span class="math inline">\(x\)</span> at time <span class="math inline">\(t\)</span>, denoted by <span class="math inline">\(m_{x,t}\)</span>. The model equation is
<span class="math display" id="eq:eq811">\[\begin{equation}
m_{x,t} = \alpha_x + \beta_x \kappa_t + \varepsilon_{x,t} .
\tag{8.11}
\end{equation}\]</span>
Here, the intercept (<span class="math inline">\(\alpha_x\)</span>) and slope (<span class="math inline">\(\beta_x\)</span>) depend only
on age <span class="math inline">\(x\)</span>, not on time <span class="math inline">\(t\)</span>. The parameter <span class="math inline">\(\kappa_t\)</span> captures the
important time effects (except for those in the disturbance term
<span class="math inline">\(\varepsilon_{x,t}\)</span>).</p>
<p>At first glance, the Lee-Carter model appears to be a linear
regression with one explanatory variable. However, the term
<span class="math inline">\(\kappa_t\)</span> is not observed and so different techniques are required
for model estimation. Different algorithms are available, including
the singular value decomposition proposed by Lee and Carter, the
principal components approach and a Poisson regression model; see Li
and Chan (2007) for references.</p>
<p>The time-varying term <span class="math inline">\(\kappa_t\)</span> is typically represented using an
<span class="math inline">\(ARIMA\)</span> model. Li and Chan found that a random walk (with
adjustments for unusual events) was a suitable model for Canadian
and U.S. rates (with different coefficients), reinforcing the
findings of Lee and Carter.</p>
<hr />
</div>
</div>
<div id="forecasting-1" class="section level3 hasAnchor" number="8.5.2">
<h3><span class="header-section-number">8.5.2</span> Forecasting<a href="C8AR.html#forecasting-1" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<div id="optimal-point-forecasts" class="section level4 unnumbered hasAnchor">
<h4>Optimal Point Forecasts<a href="C8AR.html#optimal-point-forecasts" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>Similar to forecasts that were introduced in Section
<a href="C8AR.html#S8:AR1Smooth">8.4</a>, it is common to provide forecasts that are
estimates of conditional expectations of the predictive
distribution. Specifically, assume we have available a realization
of {<span class="math inline">\(y_1, y_2, \ldots, y_T\)</span>} and would like to forecast <span class="math inline">\(y_{T+l}\)</span>,
the value of the series “<span class="math inline">\(l\)</span>” lead time units in the future. If
the parameters of the process were known, then we would use
<span class="math inline">\(\mathrm{E}(y_{T+l}|y_T,y_{T-1},y_{T-2},\ldots)\)</span>, that is, the
conditional expectation of <span class="math inline">\(y_{T+l}\)</span> given the value of the series
up to and including time <span class="math inline">\(T\)</span>. We use the notation <span class="math inline">\(\mathrm{E}_T\)</span> for
this conditional expectation.</p>
<p>To illustrate, taking <span class="math inline">\(t=T+l\)</span> and applying <span class="math inline">\(\mathrm{E}_T\)</span> to both
sides of equation <a href="C8AR.html#eq:eq87">(8.7)</a> yields
<span class="math display" id="eq:eq812">\[\begin{equation}
y_T(l) - \beta_1 y_T(l-1) - \ldots - \beta_p y_T(l-p) = \beta_0 +
\mathrm{E}_T\left( \varepsilon_{T+l} - \theta_1 \varepsilon_{T+l-1}
- \ldots - \theta _q \varepsilon_{T+l-q}\right) ,
\tag{8.12}
\end{equation}\]</span>
using the notation <span class="math inline">\(y_T(k) = \mathrm{E}_T\left( y_{T+k}\right)\)</span>.
For <span class="math inline">\(k \leq 0\)</span>, <span class="math inline">\(\mathrm{E}_T\left( y_{T+k}\right) =y_{T+k}\)</span>, as the
value of <span class="math inline">\(y_{T+k}\)</span> is known at time <span class="math inline">\(T\)</span>. Further,
<span class="math inline">\(\mathrm{E}_T\left( \varepsilon_{T+k}\right) =0\)</span> for <span class="math inline">\(k&gt;0\)</span> as
disturbance terms in the future are assumed to be uncorrelated with
current and past values of the series. Thus, equation
<a href="C8AR.html#eq:eq812">(8.12)</a> provides the basis of the
<em>chain rule of forecasting</em>, where we recursively provide
forecasts at lead time <span class="math inline">\(l\)</span> based on prior forecasts and realizations
of the series. To implement equation
<a href="C8AR.html#eq:eq812">(8.12)</a>, we substitute estimates for
parameters and residuals for disturbance terms.</p>
<p><strong>Special Case - MA(1) Model</strong>. We have already seen the forecasting chain rule for the <span class="math inline">\(AR(1)\)</span> model in Section <a href="C8AR.html#S8:AR1Smooth">8.4</a>. For the <span class="math inline">\(MA(1)\)</span> model, note that for <span class="math inline">\(l\geq 2\)</span>,
we have <span class="math inline">\(y_T(l)=\mathrm{E}_T\left( y_{T+l}\right)\)</span>
<span class="math inline">\(=\mathrm{E}_T\left( \beta_0+\varepsilon_{T+l}-\theta_1\varepsilon_{T+l-1}\right) =\beta_0\)</span>, because <span class="math inline">\(\varepsilon_{T+l}\)</span> and <span class="math inline">\(\varepsilon _{T+l-1}\)</span> are in the future at time <span class="math inline">\(T\)</span>. For <span class="math inline">\(l=1\)</span>, we have <span class="math inline">\(y_T(1)= \mathrm{E}_T\left( \beta_0+\varepsilon_{T+1}-\theta _1\varepsilon_T\right)\)</span> <span class="math inline">\(=\beta_0-\theta_1\mathrm{E}_T\left( \varepsilon_T\right)\)</span>. Typically, one would estimate the term <span class="math inline">\(\mathrm{E}_T\left( \varepsilon_T\right)\)</span> using the residual at time <span class="math inline">\(T\)</span>.</p>
</div>
<div id="psi-coefficient-representation" class="section level4 unnumbered hasAnchor">
<h4><span class="math inline">\(\psi\)</span>-Coefficient Representation<a href="C8AR.html#psi-coefficient-representation" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>Any <span class="math inline">\(ARIMA(p,d,q)\)</span> model can be expressed as
<span class="math display">\[
y_t=\beta_0^{\ast }+\varepsilon_t+\psi_1 \varepsilon_{t-1}+\psi
_2\varepsilon_{t-2}+\ldots=\beta_0^{\ast }+\sum_{k=0}^{\infty }\psi
_{k}\varepsilon_{t-k},
\]</span>
called the <span class="math inline">\(\psi\)</span><em>-coefficient representation</em>. That is, the
current value of a process can be expressed as a constant plus a
linear combination of the current and previous disturbances. Values
of {<span class="math inline">\(\psi_{k}\)</span>} depend on the linear parameters of the <span class="math inline">\(ARIMA\)</span>
process and can be determined via straightforward recursive
substitution. To illustrate, for the <span class="math inline">\(AR(1)\)</span> model, we have
<span class="math display">\[\begin{eqnarray*}
y_t &amp;=&amp;\beta_0+\varepsilon_t+\beta_1y_{t-1}=\beta_0+\varepsilon
_t+\beta_1\left( \beta_0+\varepsilon
_{t-1}+\beta_1y_{t-2}\right) =\ldots \\
&amp;=&amp;\frac{\beta_0}{1-\beta_1}+\varepsilon_t+\beta_1\varepsilon
_{t-1}+\beta_1^2\varepsilon_{t-2}+\ldots=\frac{\beta_0}{1-\beta_1}
+\sum_{k=0}^{\infty }\beta_1^{k}\varepsilon_{t-k}.
\end{eqnarray*}\]</span>
That is, <span class="math inline">\(\psi_{k}=\beta_1^{k}\)</span>.</p>
</div>
<div id="forecast-interval" class="section level4 unnumbered hasAnchor">
<h4>Forecast Interval<a href="C8AR.html#forecast-interval" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>Using the <span class="math inline">\(\psi\)</span>-coefficient representation, we can express the
conditional expectation of <span class="math inline">\(y_{T+l}\)</span> as
<span class="math display">\[
\mathrm{E}_T\left( y_{T+l}\right) =\beta_0^{\ast
}+\sum_{k=0}^{\infty }\psi_{k}\mathrm{E}_T\left( \varepsilon
_{T+l-k}\right) =\beta_0^{\ast }+\sum_{k=l}^{\infty }\psi
_{k}\mathrm{E}_T\left( \varepsilon_{T+l-k}\right) .
\]</span>
This is because, at time <span class="math inline">\(T\)</span>, the errors <span class="math inline">\(\varepsilon_T,\varepsilon _{T-1},\ldots\)</span>, have been determined by the realization of the
process. However, the errors
<span class="math inline">\(\varepsilon_{T+1},\ldots,\varepsilon_{T+l}\)</span> have not been realized
and hence have conditional expectation zero. Thus, the <span class="math inline">\(l\)</span>-step
forecast error is
<span class="math display">\[
y_{T+l}-\mathrm{E}_T\left( y_{T+l}\right) =\beta_0^{\ast
}+\sum_{k=0}^{\infty }\psi_{k}\varepsilon_{T+l-k}-\left(
\beta_0^{\ast }+\sum_{k=l}^{\infty }\psi_{k}\mathrm{E}_T\left(
\varepsilon _{T+l-k}\right) \right)
=\sum_{k=0}^{l-1}\psi_{k}\varepsilon _{T+l-k}.
\]</span></p>
<p>We focus on the variability of the forecasts errors. That is,
straightforward calculations yield <span class="math inline">\(\mathrm{Var}\left( y_{T+l}-\mathrm{E}_T \left( y_{T+l}\right) \right) =\sigma^2\sum_{k=1}^{l-1}\psi_{k}^2\)</span>. Thus, assuming normality of
the errors, a <span class="math inline">\(100(1-\alpha)\)</span> forecast interval for <span class="math inline">\(y_{T+l}\)</span> is
<span class="math display">\[
\widehat{y}_{T+l} \pm (t-value) s \sqrt{\sum_{k=0}^{l-1}
\widehat{\psi}_k^2} .
\]</span>
where <span class="math inline">\(t\)</span>-value is the <span class="math inline">\((1-\alpha /2)^{th}\)</span> percentile from a
<span class="math inline">\(t\)</span>-distribution with <span class="math inline">\(df=T-(number~of~linear~parameters)\)</span>. If <span class="math inline">\(y_t\)</span>
is an <span class="math inline">\(ARIMA(p,d,q)\)</span> process, then <span class="math inline">\(\psi_{k}\)</span> is a function of
<span class="math inline">\(\beta_1,\ldots,\beta_p,\theta_1,\ldots,\theta_q\)</span> and the number of
linear parameters is <span class="math inline">\(1+p+q\)</span>.</p>
<div class="blackboxvideo">
<p><strong>Video: Section Summary</strong></p>
</div>
<center>
<iframe id="kaltura_player" src="https://cdnapisec.kaltura.com/p/1660902/embedPlaykitJs/uiconf_id/55063162?iframeembed=true&amp;entry_id=1_jy9bl2am&amp;config%5Bprovider%5D=%7B%22widgetId%22%3A%221_esmjwwlx%22%7D&amp;config%5Bplayback%5D=%7B%22startTime%22%3A0%7D" style="width: 576px;height: 324px;border: 0;" allowfullscreen webkitallowfullscreen mozAllowFullScreen allow="autoplay *; fullscreen *; encrypted-media *" title="8.5 ARIMAModels">
</iframe>
</center>
</div>
</div>
</div>
<div id="application-hong-kong-exchange-rates" class="section level2 hasAnchor" number="8.6">
<h2><span class="header-section-number">8.6</span> Application: Hong Kong Exchange Rates<a href="C8AR.html#application-hong-kong-exchange-rates" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Section 7.2 introduced the Hong Kong Exchange Rate series, based on
<span class="math inline">\(T=502\)</span> daily observations for the period April 1, 2005 through Mary
31, 2007. A quadratic trend was fit to the model that produced an
<span class="math inline">\(R^2=86.2\)</span> with a residual standard deviation of <span class="math inline">\(s=0.0068\)</span>. We
now show how to improve on this fit using <span class="math inline">\(ARIMA\)</span> modeling.</p>
<p>To begin, Figure <a href="C8AR.html#fig:Fig87">8.7</a> shows a time series plot of
residuals from the quadratic trend time model. This plot displays a
meandering pattern, suggesting that there is information in the
residuals that can be exploited.</p>

<div class="figure" style="text-align: center"><span style="display:block;" id="fig:Fig87"></span>
<img src="RegressionMarkdown_files/figure-html/Fig87-1.png" alt="Residuals from a Quadratic Trend in Time Model of the Hong Kong Exchange Rates." width="60%" />
<p class="caption">
Figure 8.7: <strong>Residuals from a Quadratic Trend in Time Model of the Hong Kong Exchange Rates.</strong>
</p>
</div>
<h5 style="text-align: center;">
<a id="displayCode.Fig87.Hide" href="javascript:togglecode('toggleCode.Fig87.Hide','displayCode.Fig87.Hide');"><i><strong>R Code to Produce Figure 8.7</strong></i></a>
</h5>
<div id="toggleCode.Fig87.Hide" style="display: none">
<div class="sourceCode" id="cb76"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb76-1"><a href="C8AR.html#cb76-1" tabindex="-1"></a><span class="co"># Figure 87</span></span>
<span id="cb76-2"><a href="C8AR.html#cb76-2" tabindex="-1"></a><span class="co"># exchange  &lt;- read.csv(&quot;CSVData/HKExchange.csv&quot;, header=TRUE)</span></span>
<span id="cb76-3"><a href="C8AR.html#cb76-3" tabindex="-1"></a><span class="co"># #exchange  &lt;- read.csv(&quot;../../CSVData/HKExchange.csv&quot;, header=TRUE)</span></span>
<span id="cb76-4"><a href="C8AR.html#cb76-4" tabindex="-1"></a><span class="co"># EXHKUS &lt;- exchange$EXHKUS</span></span>
<span id="cb76-5"><a href="C8AR.html#cb76-5" tabindex="-1"></a></span>
<span id="cb76-6"><a href="C8AR.html#cb76-6" tabindex="-1"></a>t <span class="ot">&lt;-</span> <span class="dv">1</span><span class="sc">:</span><span class="fu">length</span>(EXHKUS)</span>
<span id="cb76-7"><a href="C8AR.html#cb76-7" tabindex="-1"></a>qtrend <span class="ot">&lt;-</span> <span class="fu">lm</span>(EXHKUS<span class="sc">~</span>t<span class="sc">+</span><span class="fu">I</span>(t<span class="sc">^</span><span class="dv">2</span>)) </span>
<span id="cb76-8"><a href="C8AR.html#cb76-8" tabindex="-1"></a><span class="co">#summary(qtrend)</span></span>
<span id="cb76-9"><a href="C8AR.html#cb76-9" tabindex="-1"></a></span>
<span id="cb76-10"><a href="C8AR.html#cb76-10" tabindex="-1"></a><span class="fu">plot</span>( (<span class="dv">1</span><span class="sc">:</span><span class="fu">length</span>(EXHKUS)), qtrend<span class="sc">$</span>resid, <span class="at">type=</span><span class="st">&quot;o&quot;</span>, </span>
<span id="cb76-11"><a href="C8AR.html#cb76-11" tabindex="-1"></a>      <span class="at">xlab=</span><span class="st">&quot;Index&quot;</span>, <span class="at">ylab=</span><span class="st">&quot;Residuals&quot;</span>)</span></code></pre></div>
</div>
<p>Further evidence of these patterns is in the table of
autocorrelations in <a href="C8AR.html#Tab86">Table 8.6</a>. Here, we see large
residual autocorrelations that do not decrease quickly as the lag
<span class="math inline">\(k\)</span> increases. A similar pattern is also evident for the original
series, EXHKUS. This confirms the nonstationarity that we observed
in Section 7.2.</p>
<p>As an alternative transform, we differenced the series, producing
DIFFHKUS. This differenced series has a standard deviation of
<span class="math inline">\(s_{DIFF}=0.0020\)</span>, suggesting that it is more stable than the
original series or the residuals from the quadratic trend in time
model. <a href="C8AR.html#Tab86">Table 8.6</a> presents the autocorrelations from
the differenced series, indicating mild patterns. However, these
autocorrelations are still significantly different from zero. For
<span class="math inline">\(T=501\)</span> differences, we may use as an approximate standard error for
autocorrelations <span class="math inline">\(1/\sqrt{501}\approx 0.0447.\)</span> With this, we see
that the lag 2 autocorrelation is <span class="math inline">\(0.151/0.0447\approx 3.38\)</span>
standard errors below zero, which is statistically significant. This
suggests introducing another model to take advantage of the
information in the time series patterns.</p>
<p><a id=Tab86></a></p>
<p><span id="Tab86">Table 8.6</span>. <strong>Autocorrelations of Hong Kong Exchange Rates</strong></p>
<p><span class="math display">\[
\small{
\begin{array}{l|cccccccccc}
\hline
\text{Lag }&amp; 1 &amp; 2 &amp; 3 &amp; 4 &amp; 5 &amp; 6 &amp; 7 &amp; 8 &amp; 9 &amp; 10 \\ \hline
\text{Residuals from the} &amp; 0.958 &amp; 0.910 &amp; 0.876 &amp; 0.847 &amp; 0.819 &amp; 0.783 &amp; 0.748 &amp; 0.711 &amp; 0.677 &amp; 0.636 \\
\ \ \text{Quadratic Model} &amp;  &amp;  &amp;  &amp;  &amp;  &amp;  &amp;  &amp;  &amp;  &amp;  \\
\text{EXHKUS}  &amp; 0.988 &amp; 0.975 &amp; 0.963 &amp; 0.952 &amp; 0.942 &amp; 0.930 &amp; 0.919 &amp; 0.907 &amp; 0.895 &amp; 0.882 \\
\ \ \text{(Original Series)} &amp;  &amp;  &amp;  &amp;  &amp;  &amp;  &amp;  &amp;  &amp;  &amp;  \\
\text{DIFFHKUS} &amp; 0.078 &amp; -0.151 &amp; -0.038 &amp; -0.001 &amp; 0.095 &amp; -0.005 &amp; 0.051 &amp; -0.012 &amp; 0.084 &amp; -0.001 \\ \hline
\end{array}
}
\]</span></p>
<h5 style="text-align: center;">
<a id="displayCode.Tab86.Hide" href="javascript:togglecode('toggleCode.Tab86.Hide','displayCode.Tab86.Hide');"><i><strong>R Code to Produce Table 8.6</strong></i></a>
</h5>
<div id="toggleCode.Tab86.Hide" style="display: none">
<div class="sourceCode" id="cb77"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb77-1"><a href="C8AR.html#cb77-1" tabindex="-1"></a><span class="co"># Table 8.6</span></span>
<span id="cb77-2"><a href="C8AR.html#cb77-2" tabindex="-1"></a><span class="co"># exchange  &lt;- read.csv(&quot;CSVData/HKExchange.csv&quot;, header=TRUE)</span></span>
<span id="cb77-3"><a href="C8AR.html#cb77-3" tabindex="-1"></a><span class="co"># #exchange  &lt;- read.csv(&quot;../../CSVData/HKExchange.csv&quot;, header=TRUE)</span></span>
<span id="cb77-4"><a href="C8AR.html#cb77-4" tabindex="-1"></a><span class="co"># EXHKUS &lt;- exchange$EXHKUS</span></span>
<span id="cb77-5"><a href="C8AR.html#cb77-5" tabindex="-1"></a></span>
<span id="cb77-6"><a href="C8AR.html#cb77-6" tabindex="-1"></a><span class="co"># t &lt;- 1:length(EXHKUS)</span></span>
<span id="cb77-7"><a href="C8AR.html#cb77-7" tabindex="-1"></a><span class="co"># qtrend &lt;- lm(EXHKUS~t+I(t^2)) </span></span>
<span id="cb77-8"><a href="C8AR.html#cb77-8" tabindex="-1"></a></span>
<span id="cb77-9"><a href="C8AR.html#cb77-9" tabindex="-1"></a>diffrate <span class="ot">&lt;-</span> EXHKUS[<span class="sc">-</span><span class="dv">1</span>]<span class="sc">-</span>EXHKUS[<span class="sc">-</span><span class="fu">length</span>(EXHKUS)]</span>
<span id="cb77-10"><a href="C8AR.html#cb77-10" tabindex="-1"></a><span class="co">#sd(diffrate)</span></span>
<span id="cb77-11"><a href="C8AR.html#cb77-11" tabindex="-1"></a>auto.qtrend <span class="ot">&lt;-</span> <span class="fu">as.numeric</span>(<span class="fu">acf</span>(qtrend<span class="sc">$</span>resid,<span class="at">lag.max=</span><span class="dv">10</span>,<span class="at">plot=</span>F)<span class="sc">$</span>acf)</span>
<span id="cb77-12"><a href="C8AR.html#cb77-12" tabindex="-1"></a>auto.orig   <span class="ot">&lt;-</span> <span class="fu">as.numeric</span>(<span class="fu">acf</span>(EXHKUS,      <span class="at">lag.max=</span><span class="dv">10</span>,<span class="at">plot=</span>F)<span class="sc">$</span>acf)</span>
<span id="cb77-13"><a href="C8AR.html#cb77-13" tabindex="-1"></a>auto.diff   <span class="ot">&lt;-</span> <span class="fu">as.numeric</span>(<span class="fu">acf</span>(diffrate,    <span class="at">lag.max=</span><span class="dv">10</span>,<span class="at">plot=</span>F)<span class="sc">$</span>acf)</span>
<span id="cb77-14"><a href="C8AR.html#cb77-14" tabindex="-1"></a></span>
<span id="cb77-15"><a href="C8AR.html#cb77-15" tabindex="-1"></a>Tab86 <span class="ot">&lt;-</span> <span class="fu">rbind</span>(auto.qtrend, auto.orig, auto.diff)</span>
<span id="cb77-16"><a href="C8AR.html#cb77-16" tabindex="-1"></a>knitr<span class="sc">::</span><span class="fu">kable</span>(Tab86, <span class="at">digits =</span> <span class="dv">3</span>)</span></code></pre></div>
<table>
<colgroup>
<col width="14%" />
<col width="3%" />
<col width="7%" />
<col width="8%" />
<col width="8%" />
<col width="8%" />
<col width="7%" />
<col width="8%" />
<col width="7%" />
<col width="8%" />
<col width="7%" />
<col width="8%" />
</colgroup>
<tbody>
<tr class="odd">
<td align="left">auto.qtrend</td>
<td align="right">1</td>
<td align="right">0.958</td>
<td align="right">0.910</td>
<td align="right">0.876</td>
<td align="right">0.847</td>
<td align="right">0.819</td>
<td align="right">0.783</td>
<td align="right">0.748</td>
<td align="right">0.711</td>
<td align="right">0.677</td>
<td align="right">0.636</td>
</tr>
<tr class="even">
<td align="left">auto.orig</td>
<td align="right">1</td>
<td align="right">0.988</td>
<td align="right">0.975</td>
<td align="right">0.963</td>
<td align="right">0.952</td>
<td align="right">0.942</td>
<td align="right">0.930</td>
<td align="right">0.919</td>
<td align="right">0.907</td>
<td align="right">0.895</td>
<td align="right">0.882</td>
</tr>
<tr class="odd">
<td align="left">auto.diff</td>
<td align="right">1</td>
<td align="right">0.078</td>
<td align="right">-0.151</td>
<td align="right">-0.038</td>
<td align="right">-0.001</td>
<td align="right">0.095</td>
<td align="right">-0.005</td>
<td align="right">0.051</td>
<td align="right">-0.012</td>
<td align="right">0.084</td>
<td align="right">-0.001</td>
</tr>
</tbody>
</table>
</div>
<div id="model-selection-and-partial-autocorrelations" class="section level4 unnumbered hasAnchor">
<h4>Model Selection and Partial Autocorrelations<a href="C8AR.html#model-selection-and-partial-autocorrelations" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>For all stationary autoregressive models, it can be shown that the
absolute values of the autocorrelations become small as the lag <span class="math inline">\(k\)</span>
increases. In the case that the autocorrelations decrease
approximately like a geometric series, an <span class="math inline">\(AR\)</span>(1) model may
be identified. Unfortunately, for other types of autoregressive
series, the rules of thumb for identifying the series from the
autocorrelations become more cloudy. One device that is useful for
identifying the order of an autoregressive series is the
<em>partial autocorrelation function</em>.</p>
<p>Just like autocorrelations, we now define a <em>partial autocorrelation</em> at a specific lag <span class="math inline">\(k\)</span>. Consider the model equation
<span class="math display">\[
y_t=\beta_{0,k}+\beta_{1,k} y_{t-1}+\ldots+\beta_{k,k} y_{t-k} +
\varepsilon_t.
\]</span>
Here, {<span class="math inline">\(\varepsilon_t\)</span>} is a stationary error that may or may not
be a white noise process. The second subscript on the <span class="math inline">\(\beta\)</span>’s,
“<span class="math inline">\(,k\)</span>”, is there to remind us that the value of each <span class="math inline">\(\beta\)</span> may
change when the order of the model, <span class="math inline">\(k\)</span>, changes. With this model
specification, we can interpret <span class="math inline">\(\beta_{k,k}\)</span> as the correlation
between <span class="math inline">\(y_t\)</span> and <span class="math inline">\(y_{t-k}\)</span> after the effects of the intervening
variables, <span class="math inline">\(y_{t-1},\ldots,y_{t-k+1}\)</span>, have been removed. This is
the same idea as the partial correlation coefficient, introduced in
Section 4.4. Estimates of partial correlation coefficients,
<span class="math inline">\(b_{k,k}\)</span>, can then be calculated using conditional least squares or
other techniques. As with other correlations, we may use
<span class="math inline">\(1/\sqrt{T}\)</span> as an approximate standard error for detecting
significant differences from zero.</p>
<p>Partial autocorrelations are used in model identification in the following
way. First calculate the first several estimates, <span class="math inline">\(b_{1,1},b_{2,2},b_{3,3}\)</span>,
and so on. Then, choose the order of the autoregressive model to be the
largest <span class="math inline">\(k\)</span> so that the estimate <span class="math inline">\(b_{k,k}\)</span> is significantly different from
zero.</p>
<p>To see how this applies in the Hong Kong Exchange Rate example,
recall that the approximate standard error for correlations is
<span class="math inline">\(1/\sqrt{501}\approx 0.0447\)</span>. <a href="C8AR.html#Tab87">Table 8.7</a> provides
the first ten partial autocorrelations for the rates and for their
differences. Using twice the standard error as our cut-off rule, we
see that the second partial autocorrelation of the differences
exceeds <span class="math inline">\(2\times 0.0447=0.0894\)</span> in absolute value. This would
suggest using an <span class="math inline">\(AR(2)\)</span> as a tentative first model choice.
Alternatively, the reader may wish to argue that because the fifth
and ninth partial autocorrelations are also statistically
significant, suggesting a more complex <span class="math inline">\(AR(5)\)</span> or <span class="math inline">\(AR(9)\)</span> would be
more appropriate. The philosophy is to “use the simplest model
possible, but no simpler.” We prefer to employ simpler models and
thus fit these first and then test to see whether or not they
capture the important aspects of the data.</p>
<p>Finally, you may be interested to see what happens to partial
autocorrelations calculated on a non-stationary series.
<a href="C8AR.html#Tab87">Table 8.7</a> provides partial autocorrelations for the
original series (EXHKUS). Note how large the first partial
autocorrelation is. That is, yet another way of identifying a series
as nonstationary is to examine the partial autocorrelation function
and look for a large lag one partial autocorrelation.</p>
<p><a id=Tab87></a></p>
<p><span id="Tab87">Table 8.7</span>. <strong>Partial Autocorrelations of EXHKUS and DIFFHKUS</strong></p>
<p><span class="math display">\[
\small{
\begin{array}{l|cccccccccc}
\hline
\text{Lag} &amp; 1 &amp; 2 &amp; 3 &amp; 4 &amp; 5 &amp; 6 &amp; 7 &amp; 8 &amp; 9 &amp; 10 \\ \hline
\text{EXHKUS} &amp; 0.988 &amp; -0.034 &amp; 0.051 &amp; 0.019 &amp; -0.001 &amp; -0.023 &amp; 0.010 &amp;
-0.047 &amp; -0.013 &amp; -0.049 \\
\text{DIFFHKUS} &amp; 0.078 &amp; -0.158 &amp; -0.013 &amp; -0.021 &amp; 0.092 &amp; -0.026 &amp; 0.085 &amp; -0.027 &amp; 0.117 &amp; -0.036 \\ \hline
\end{array}
}
\]</span></p>
<h5 style="text-align: center;">
<a id="displayCode.Tab87.Hide" href="javascript:togglecode('toggleCode.Tab87.Hide','displayCode.Tab87.Hide');"><i><strong>R Code to Produce Table 8.7</strong></i></a>
</h5>
<div id="toggleCode.Tab87.Hide" style="display: none">
<div class="sourceCode" id="cb78"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb78-1"><a href="C8AR.html#cb78-1" tabindex="-1"></a><span class="co"># Table 8.7</span></span>
<span id="cb78-2"><a href="C8AR.html#cb78-2" tabindex="-1"></a><span class="co"># exchange  &lt;- read.csv(&quot;CSVData/HKExchange.csv&quot;, header=TRUE)</span></span>
<span id="cb78-3"><a href="C8AR.html#cb78-3" tabindex="-1"></a><span class="co"># #exchange  &lt;- read.csv(&quot;../../CSVData/HKExchange.csv&quot;, header=TRUE)</span></span>
<span id="cb78-4"><a href="C8AR.html#cb78-4" tabindex="-1"></a><span class="co"># EXHKUS &lt;- exchange$EXHKUS</span></span>
<span id="cb78-5"><a href="C8AR.html#cb78-5" tabindex="-1"></a><span class="co">#diffrate &lt;- EXHKUS[-1]-EXHKUS[-length(EXHKUS)]</span></span>
<span id="cb78-6"><a href="C8AR.html#cb78-6" tabindex="-1"></a></span>
<span id="cb78-7"><a href="C8AR.html#cb78-7" tabindex="-1"></a>pauto.orig <span class="ot">&lt;-</span> <span class="fu">as.numeric</span>(<span class="fu">pacf</span>(EXHKUS,<span class="at">lag.max=</span><span class="dv">10</span>,<span class="at">plot=</span>F)<span class="sc">$</span>acf)</span>
<span id="cb78-8"><a href="C8AR.html#cb78-8" tabindex="-1"></a>pauto.diff <span class="ot">&lt;-</span> <span class="fu">as.numeric</span>(<span class="fu">pacf</span>(diffrate,<span class="at">lag.max=</span><span class="dv">10</span>,<span class="at">plot=</span>F)<span class="sc">$</span>acf)</span>
<span id="cb78-9"><a href="C8AR.html#cb78-9" tabindex="-1"></a></span>
<span id="cb78-10"><a href="C8AR.html#cb78-10" tabindex="-1"></a>Tab87 <span class="ot">&lt;-</span> <span class="fu">rbind</span>(pauto.orig, pauto.diff)</span>
<span id="cb78-11"><a href="C8AR.html#cb78-11" tabindex="-1"></a>knitr<span class="sc">::</span><span class="fu">kable</span>(Tab87, <span class="at">digits =</span> <span class="dv">3</span>)</span></code></pre></div>
<table>
<colgroup>
<col width="13%" />
<col width="7%" />
<col width="8%" />
<col width="8%" />
<col width="8%" />
<col width="8%" />
<col width="8%" />
<col width="7%" />
<col width="8%" />
<col width="8%" />
<col width="8%" />
</colgroup>
<tbody>
<tr class="odd">
<td align="left">pauto.orig</td>
<td align="right">0.988</td>
<td align="right">-0.034</td>
<td align="right">0.051</td>
<td align="right">0.019</td>
<td align="right">-0.001</td>
<td align="right">-0.023</td>
<td align="right">0.010</td>
<td align="right">-0.047</td>
<td align="right">-0.013</td>
<td align="right">-0.049</td>
</tr>
<tr class="even">
<td align="left">pauto.diff</td>
<td align="right">0.078</td>
<td align="right">-0.158</td>
<td align="right">-0.013</td>
<td align="right">-0.021</td>
<td align="right">0.092</td>
<td align="right">-0.026</td>
<td align="right">0.085</td>
<td align="right">-0.027</td>
<td align="right">0.117</td>
<td align="right">-0.036</td>
</tr>
</tbody>
</table>
</div>
</div>
<div id="residual-checking" class="section level4 unnumbered hasAnchor">
<h4>Residual Checking<a href="C8AR.html#residual-checking" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>Having identified and fit a model, residual checking is still an important
part of determining a model’s validity. For the <span class="math inline">\(ARMA(p,q)\)</span> model, we
compute fitted values as</p>
<p><span class="math display" id="eq:eq813">\[\begin{equation}
\widehat{y}_t = b_0 + b_1 y_{t-1} + \ldots + b_p y_{t-p} -
\widehat{\theta}_1 e_{t-1}- \ldots - \widehat{\theta }_q e_{t-q}.
\tag{8.13}
\end{equation}\]</span>
Here, <span class="math inline">\(\widehat{\theta}_1, \ldots, \widehat{\theta}_q\)</span> are estimates
of <span class="math inline">\(\theta_1,\ldots, \theta_q\)</span>. The residuals may be computed in the
usual fashion, that is, as <span class="math inline">\(e_t=y_t-\widehat{y}_t\)</span>. Without further
approximations, note that the initial residuals are missing because
fitted values before time <span class="math inline">\(t=\max (p,q)\)</span> can not be calculated using
equation <a href="C8AR.html#eq:eq813">(8.13)</a>. To check for patterns, use the
devices described in Section <a href="C8AR.html#S8:Estimation">8.3</a>, such as the
control chart to check for stationarity and the autocorrelation
function to check for lagged variable relationships.</p>
</div>
<div id="residual-autocorrelation" class="section level4 unnumbered hasAnchor">
<h4>Residual Autocorrelation<a href="C8AR.html#residual-autocorrelation" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>Residuals from the fitted model should resemble white noise and
hence, display few discernible patterns. In particular, we expect
<span class="math inline">\(r_k(e)\)</span>, the lag <span class="math inline">\(k\)</span> autocorrelation of residuals, to be
approximately zero. To assess this, we have that <span class="math inline">\(se\left( r_k(e) \right) \approx 1/\sqrt{T}\)</span>. More precisely, MacLeod (1977, 1978)
has given approximations for a broad class of <span class="math inline">\(ARMA\)</span> models. It
turns out that the <span class="math inline">\(1/\sqrt{T}\)</span> can be improved for small values of
<span class="math inline">\(k\)</span>. (These improved values can be seen in the output of most
statistical packages.) The improvement depends on the model that is
being fit. To illustrate, suppose that an <span class="math inline">\(AR(1)\)</span> model with
autoregressive parameter <span class="math inline">\(\beta_1\)</span> is fit to the data. Then, the
approximate standard error of the lag one residual autocorrelation
is <span class="math inline">\(|\beta_1|/\sqrt{T}\)</span> . This standard error can be much smaller
than <span class="math inline">\(1/\sqrt{T}\)</span>, depending on the value of <span class="math inline">\(\beta_1\)</span>.</p>
</div>
<div id="testing-several-lags" class="section level4 unnumbered hasAnchor">
<h4>Testing Several Lags<a href="C8AR.html#testing-several-lags" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>To test whether there is significant residual autocorrelation at a
specific lag <span class="math inline">\(k\)</span>, we use <span class="math inline">\(r_k(e) /se\left( r_k(e) \right)\)</span>. Further,
to check whether residuals resemble a white noise process, we might
test whether <span class="math inline">\(r_k(e)\)</span> is close to zero for several values of <span class="math inline">\(k\)</span>. To
test whether the first <span class="math inline">\(K\)</span> residual autocorrelation are zero, use
the Box and Pierce (1970) chi-square statistic
<span class="math display">\[
Q_{BP} = T \sum_{k=1}^{K} r_k \left( e \right)^2.
\]</span>
Here, <span class="math inline">\(K\)</span> is an integer that is user-specified. If there is no real
autocorrelation, then we expect <span class="math inline">\(Q_{BP}\)</span> to be small; more
precisely, Box and Pierce showed that <span class="math inline">\(Q_{BP}\)</span> follows an
approximate <span class="math inline">\(\chi^2\)</span> distribution with
<span class="math inline">\(df=K-(number~of~linear~parameters)\)</span>. For an <span class="math inline">\(ARMA(p,q)\)</span> model, the
number of linear parameters is <span class="math inline">\(1+p+q.\)</span> Another widely used
statistic is
<span class="math display">\[
Q_{LB}=T(T+2)\sum_{k=1}^{K}\frac{r_k \left( e\right)^2}{T-k}.
\]</span></p>
<p>due to Ljung and Box (1978). This statistic performs
better in small samples than the <span class="math inline">\(BP\)</span> statistic. Under the
hypothesis of no residual autocorrelation, <span class="math inline">\(Q_{LB}\)</span> follows the same
<span class="math inline">\(\chi^2\)</span> distribution as <span class="math inline">\(Q_{BP}\)</span>. Thus, for each statistic, we
reject <span class="math inline">\(H_{0}\)</span>: No Residual Autocorrelation if the statistic exceeds
<span class="math inline">\(chi\)</span>-value, a <span class="math inline">\(1-\alpha\)</span> percentile from a <span class="math inline">\(\chi^2\)</span> distribution. A
convenient rule of thumb is to use <span class="math inline">\(chi\)</span>-value = 1.5
<span class="math inline">\(df.\)</span></p>
<hr />
<p><strong>Example: Hong Kong Exchange Rate - Continued.</strong> Two models
were fit, the <span class="math inline">\(ARIMA(2,1,0)\)</span> and the <span class="math inline">\(ARIMA(0,1,2)\)</span>; these are the
<span class="math inline">\(AR(2)\)</span> and <span class="math inline">\(MA(2)\)</span> models after taking differences. Using {<span class="math inline">\(y_t\)</span>}
for the differences, the estimated <span class="math inline">\(AR(2)\)</span> model is:
<span class="math display">\[
\begin{array}{clllrllll}
\widehat{y}_t &amp; = &amp; 0.0000317 &amp; + &amp; 0.0900 &amp; y_{t-1} &amp; - &amp;
0.158 &amp; y_{t-2} \\
{\small t-statistic} &amp;  &amp;
{\small [0.37]} &amp;  &amp; {\small [2.03]} &amp;  &amp; &amp; {\small [-3.57]} &amp;
\end{array}
\]</span>
with a residual standard error of <span class="math inline">\(s=0.00193.\)</span> The estimated <span class="math inline">\(MA(2)\)</span>
is:
<span class="math display">\[
\begin{array}{clllrllll}
\widehat{y}_t &amp; = &amp; 0.0000297 &amp; - &amp; 0.0920 &amp; e_{t-1} &amp; + &amp; 0.162 &amp; e_{t-2} \\
{\small t-statistic} &amp;  &amp; {\small [0.37]} &amp; &amp;{\small [-2.08]} &amp; &amp;  &amp; {\small [3.66]} &amp;
\end{array}
\]</span>
with the same residual standard error of <span class="math inline">\(s=0.00193.\)</span> These
statistics indicate that the models are roughly comparable. The
Ljung-Box statistic in <a href="C8AR.html#Tab88">Table 8.8</a> also indicates a
great deal of similarity for the models.</p>
<p><a id=Tab88></a></p>
<p><span id="Tab88">Table 8.8</span>. <strong>Ljung-Box Statistics <span class="math inline">\(Q_{LB}\)</span> for Hong Kong Exchange Rate Models</strong></p>
<p><span class="math display">\[
\small{
\begin{array}{l|ccccc}
\hline
&amp;&amp;&amp; \text{Lag }K \\
\text{Model}  &amp; 2 &amp; 4 &amp; 6 &amp; 8 &amp; 10 \\  \hline
AR(2) &amp; 0.0065 &amp; 0.5674 &amp; 6.3496 &amp; 10.4539 &amp; 16.3258 \\
MA(2) &amp; 0.0110 &amp; 0.2872 &amp; 6.6557 &amp; 11.3361 &amp; 17.6882 \\ \hline
\end{array}
}
\]</span></p>
<h5 style="text-align: center;">
<a id="displayCode.Tab88.Hide" href="javascript:togglecode('toggleCode.Tab88.Hide','displayCode.Tab88.Hide');"><i><strong>R Code to Produce Table 8.8</strong></i></a>
</h5>
<div id="toggleCode.Tab88.Hide" style="display: none">
<div class="sourceCode" id="cb79"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb79-1"><a href="C8AR.html#cb79-1" tabindex="-1"></a><span class="co"># Table 8.8</span></span>
<span id="cb79-2"><a href="C8AR.html#cb79-2" tabindex="-1"></a><span class="co"># exchange  &lt;- read.csv(&quot;CSVData/HKExchange.csv&quot;, header=TRUE)</span></span>
<span id="cb79-3"><a href="C8AR.html#cb79-3" tabindex="-1"></a><span class="co"># #exchange  &lt;- read.csv(&quot;../../CSVData/HKExchange.csv&quot;, header=TRUE)</span></span>
<span id="cb79-4"><a href="C8AR.html#cb79-4" tabindex="-1"></a><span class="co"># EXHKUS &lt;- exchange$EXHKUS</span></span>
<span id="cb79-5"><a href="C8AR.html#cb79-5" tabindex="-1"></a><span class="co">#diffrate &lt;- EXHKUS[-1]-EXHKUS[-length(EXHKUS)]</span></span>
<span id="cb79-6"><a href="C8AR.html#cb79-6" tabindex="-1"></a></span>
<span id="cb79-7"><a href="C8AR.html#cb79-7" tabindex="-1"></a><span class="co"># Fit ARIMA models</span></span>
<span id="cb79-8"><a href="C8AR.html#cb79-8" tabindex="-1"></a>AR2 <span class="ot">&lt;-</span> <span class="fu">arima</span>(diffrate, <span class="at">order =</span> <span class="fu">c</span>(<span class="dv">2</span>,<span class="dv">0</span>,<span class="dv">0</span>))</span>
<span id="cb79-9"><a href="C8AR.html#cb79-9" tabindex="-1"></a><span class="co">#AR2$coef/sqrt(diag(AR2$var.coef))</span></span>
<span id="cb79-10"><a href="C8AR.html#cb79-10" tabindex="-1"></a></span>
<span id="cb79-11"><a href="C8AR.html#cb79-11" tabindex="-1"></a><span class="co"># Comment: different intercept values</span></span>
<span id="cb79-12"><a href="C8AR.html#cb79-12" tabindex="-1"></a><span class="co">#sqrt(AR2$sigma2)</span></span>
<span id="cb79-13"><a href="C8AR.html#cb79-13" tabindex="-1"></a></span>
<span id="cb79-14"><a href="C8AR.html#cb79-14" tabindex="-1"></a>MA2 <span class="ot">&lt;-</span> <span class="fu">arima</span>(diffrate, <span class="at">order =</span> <span class="fu">c</span>(<span class="dv">0</span>,<span class="dv">0</span>,<span class="dv">2</span>))</span>
<span id="cb79-15"><a href="C8AR.html#cb79-15" tabindex="-1"></a><span class="co">#MA2$coef/sqrt(diag(MA2$var.coef))</span></span>
<span id="cb79-16"><a href="C8AR.html#cb79-16" tabindex="-1"></a></span>
<span id="cb79-17"><a href="C8AR.html#cb79-17" tabindex="-1"></a><span class="co">#sqrt(MA2$sigma2)</span></span>
<span id="cb79-18"><a href="C8AR.html#cb79-18" tabindex="-1"></a></span>
<span id="cb79-19"><a href="C8AR.html#cb79-19" tabindex="-1"></a>LB1 <span class="ot">&lt;-</span> LB2 <span class="ot">&lt;-</span> <span class="cn">NULL</span></span>
<span id="cb79-20"><a href="C8AR.html#cb79-20" tabindex="-1"></a><span class="cf">for</span>(k <span class="cf">in</span> <span class="fu">seq</span>(<span class="dv">2</span>,<span class="dv">10</span>, <span class="at">by=</span><span class="dv">2</span>)){ </span>
<span id="cb79-21"><a href="C8AR.html#cb79-21" tabindex="-1"></a>  LB1 <span class="ot">&lt;-</span> <span class="fu">c</span>(LB1,<span class="fu">as.numeric</span>(<span class="fu">Box.test</span>(AR2<span class="sc">$</span>residuals,<span class="at">lag=</span>k, </span>
<span id="cb79-22"><a href="C8AR.html#cb79-22" tabindex="-1"></a>                                <span class="at">type=</span><span class="st">&quot;Ljung&quot;</span>,<span class="at">fitdf =</span> <span class="dv">3</span>)<span class="sc">$</span>statistic))</span>
<span id="cb79-23"><a href="C8AR.html#cb79-23" tabindex="-1"></a>  LB2 <span class="ot">&lt;-</span> <span class="fu">c</span>(LB2,<span class="fu">as.numeric</span>(<span class="fu">Box.test</span>(MA2<span class="sc">$</span>residuals,<span class="at">lag=</span>k, </span>
<span id="cb79-24"><a href="C8AR.html#cb79-24" tabindex="-1"></a>                                <span class="at">type=</span><span class="st">&quot;Ljung&quot;</span>,<span class="at">fitdf =</span> <span class="dv">3</span>)<span class="sc">$</span>statistic))</span>
<span id="cb79-25"><a href="C8AR.html#cb79-25" tabindex="-1"></a>  }</span>
<span id="cb79-26"><a href="C8AR.html#cb79-26" tabindex="-1"></a></span>
<span id="cb79-27"><a href="C8AR.html#cb79-27" tabindex="-1"></a>Tab88 <span class="ot">&lt;-</span> <span class="fu">rbind</span>(LB1,LB2)</span>
<span id="cb79-28"><a href="C8AR.html#cb79-28" tabindex="-1"></a><span class="fu">rownames</span>(Tab88)<span class="ot">=</span><span class="fu">c</span>(<span class="st">&quot;AR(2)&quot;</span>,<span class="st">&quot;MA(2)&quot;</span>)</span>
<span id="cb79-29"><a href="C8AR.html#cb79-29" tabindex="-1"></a><span class="fu">colnames</span>(Tab88)<span class="ot">=</span><span class="fu">paste</span>(<span class="st">&quot;Lag&quot;</span>,<span class="fu">c</span>(<span class="dv">2</span>,<span class="dv">4</span>,<span class="dv">6</span>,<span class="dv">8</span>,<span class="dv">10</span>))    </span>
<span id="cb79-30"><a href="C8AR.html#cb79-30" tabindex="-1"></a></span>
<span id="cb79-31"><a href="C8AR.html#cb79-31" tabindex="-1"></a>knitr<span class="sc">::</span><span class="fu">kable</span>(Tab88, <span class="at">digits =</span> <span class="dv">4</span>)</span></code></pre></div>
<table>
<thead>
<tr class="header">
<th align="left"></th>
<th align="right">Lag 2</th>
<th align="right">Lag 4</th>
<th align="right">Lag 6</th>
<th align="right">Lag 8</th>
<th align="right">Lag 10</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">AR(2)</td>
<td align="right">0.0065</td>
<td align="right">0.5674</td>
<td align="right">6.3496</td>
<td align="right">10.4539</td>
<td align="right">16.3258</td>
</tr>
<tr class="even">
<td align="left">MA(2)</td>
<td align="right">0.0110</td>
<td align="right">0.2872</td>
<td align="right">6.6557</td>
<td align="right">11.3361</td>
<td align="right">17.6882</td>
</tr>
</tbody>
</table>
</div>
<p>The fitted <span class="math inline">\(MA\)</span>(2) and <span class="math inline">\(AR\)</span>(2) models are roughly similar. We
present the <span class="math inline">\(AR\)</span>(2) model for forecasting only because
autoregressive models are typically easier to interpret. Figure
<a href="C8AR.html#fig:Fig88">8.8</a>} summarizes the predictions, calculated for ten
days. Note the widening forecast intervals, typical of forecasts for
nonstationary series.</p>

<div class="figure" style="text-align: center"><span style="display:block;" id="fig:Fig88"></span>
<img src="RegressionMarkdown_files/figure-html/Fig88-1.png" alt="Ten Day Forecasts and Forecast Intervals of the Hong Kong Exchange Rates. Forecasts are based on the \(ARIMA(2,1,0)\) model." width="60%" />
<p class="caption">
Figure 8.8: <strong>Ten Day Forecasts and Forecast Intervals of the Hong Kong Exchange Rates.</strong> Forecasts are based on the <span class="math inline">\(ARIMA(2,1,0)\)</span> model.
</p>
</div>
<h5 style="text-align: center;">
<a id="displayCode.Fig88.Hide" href="javascript:togglecode('toggleCode.Fig88.Hide','displayCode.Fig88.Hide');"><i><strong>R Code to Produce Figure 8.8</strong></i></a>
</h5>
<div id="toggleCode.Fig88.Hide" style="display: none">
<div class="sourceCode" id="cb80"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb80-1"><a href="C8AR.html#cb80-1" tabindex="-1"></a><span class="co"># Figure 88</span></span>
<span id="cb80-2"><a href="C8AR.html#cb80-2" tabindex="-1"></a><span class="co"># exchange  &lt;- read.csv(&quot;CSVData/HKExchange.csv&quot;, header=TRUE)</span></span>
<span id="cb80-3"><a href="C8AR.html#cb80-3" tabindex="-1"></a><span class="co"># #exchange  &lt;- read.csv(&quot;../../CSVData/HKExchange.csv&quot;, header=TRUE)</span></span>
<span id="cb80-4"><a href="C8AR.html#cb80-4" tabindex="-1"></a><span class="co"># EXHKUS &lt;- exchange$EXHKUS</span></span>
<span id="cb80-5"><a href="C8AR.html#cb80-5" tabindex="-1"></a>date <span class="ot">&lt;-</span> exchange<span class="sc">$</span>DATE</span>
<span id="cb80-6"><a href="C8AR.html#cb80-6" tabindex="-1"></a></span>
<span id="cb80-7"><a href="C8AR.html#cb80-7" tabindex="-1"></a>modelAR <span class="ot">&lt;-</span> <span class="fu">arima</span>(EXHKUS,<span class="at">order=</span><span class="fu">c</span>(<span class="dv">2</span>,<span class="dv">1</span>,<span class="dv">0</span>))</span>
<span id="cb80-8"><a href="C8AR.html#cb80-8" tabindex="-1"></a>pred10  <span class="ot">&lt;-</span> <span class="fu">predict</span>(modelAR,<span class="dv">10</span>)</span>
<span id="cb80-9"><a href="C8AR.html#cb80-9" tabindex="-1"></a>pred    <span class="ot">&lt;-</span> <span class="fu">c</span>(EXHKUS, pred10<span class="sc">$</span>pred)</span>
<span id="cb80-10"><a href="C8AR.html#cb80-10" tabindex="-1"></a>lower   <span class="ot">&lt;-</span> <span class="fu">c</span>(EXHKUS, pred10<span class="sc">$</span>pred<span class="dv">-2</span><span class="sc">*</span>pred10<span class="sc">$</span>se)</span>
<span id="cb80-11"><a href="C8AR.html#cb80-11" tabindex="-1"></a>upper   <span class="ot">&lt;-</span> <span class="fu">c</span>(EXHKUS, pred10<span class="sc">$</span>pred<span class="sc">+</span><span class="dv">2</span><span class="sc">*</span>pred10<span class="sc">$</span>se)</span>
<span id="cb80-12"><a href="C8AR.html#cb80-12" tabindex="-1"></a><span class="fu">plot</span>(<span class="fu">c</span>(<span class="dv">1</span><span class="sc">:</span><span class="fu">length</span>(pred)), pred, <span class="at">xlim=</span><span class="fu">c</span>(<span class="dv">0</span>,<span class="dv">510</span>),<span class="at">ylim=</span><span class="fu">c</span>(<span class="fl">7.74</span>,<span class="fl">7.832</span>),</span>
<span id="cb80-13"><a href="C8AR.html#cb80-13" tabindex="-1"></a>     <span class="at">xlab=</span><span class="st">&quot;Time&quot;</span>, <span class="at">ylab=</span><span class="st">&quot;EXHKUS&quot;</span>,<span class="at">type=</span><span class="st">&quot;o&quot;</span>)</span>
<span id="cb80-14"><a href="C8AR.html#cb80-14" tabindex="-1"></a><span class="fu">lines</span>(<span class="fu">c</span>(<span class="dv">1</span><span class="sc">:</span><span class="fu">length</span>(pred)),lower)</span>
<span id="cb80-15"><a href="C8AR.html#cb80-15" tabindex="-1"></a><span class="fu">lines</span>(<span class="fu">c</span>(<span class="dv">1</span><span class="sc">:</span><span class="fu">length</span>(pred)),upper)</span></code></pre></div>
</div>
</div>
</div>
<div id="further-reading-and-references-1" class="section level2 hasAnchor" number="8.7">
<h2><span class="header-section-number">8.7</span> Further Reading and References<a href="C8AR.html#further-reading-and-references-1" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>The classic book-long introduction to Box-Jenkins time series is
Box, Jenkins and Reinsel (1994).</p>
<p><strong>Chapter References</strong></p>
<ul>
<li>Abraham, Bovas and Johannes Ledolter (1983). <em>Statistical Methods for Forecasting</em>. John Wiley &amp; Sons, New York.</li>
<li>Box, George E. P., Gwilym M. Jenkins and Gregory C. Reinsel (1994). <em>Time Series Analysis: Forecasting and Control</em>, Third Edition, Prentice-Hall, Englewood Cliffs, New Jersey.</li>
<li>Box, George E. P., and D. A. Pierce (1970). Distribution of residual autocorrelations in autoregressive moving average time series models. <em>Journal of the American Statistical Association</em> 65, 1509-1526.</li>
<li>Chan, Wai-Sum and Siu-Hang Li (2007). The Lee-Carter model for forecasting mortality, revisited. <em>North American Actuarial Journal</em> 11(1), 68-89.</li>
<li>Lee, Ronald D. and Lawrence R. Carter (1992). Modelling and forecasting U.S. mortality. <em>Journal of the American Statistical Association</em> 87, 659-671.</li>
<li>Ljung, G. M. and George E. P. Box (1978). On a measure of lack of fit in time series models. <em>Biometrika</em> 65, 297-303.</li>
<li>MacLeod, A. I. (1977). Improved Box-Jenkins estimators. <em>Biometrika</em> 64, 531-534.</li>
<li>MacLeod, A. I. (1978). On the distribution of residual autocorrelations in Box-Jenkins models. <em>Journal of the Royal Statistical Society B</em> 40, 296-302.</li>
<li>Miller, Robert B. and Dean W. Wichern (1977). <em>Intermediate Business Statistics: Analysis of Variance, Regression and Time Series</em>. Holt, Rinehart and Winston, New York.</li>
<li>Roberts, Harry V. (1991). <em>Data Analysis for Managers with MINITAB</em>. Scientific Press, South San Francisco, CA.</li>
</ul>
</div>
<div id="exercises-1" class="section level2 hasAnchor" number="8.8">
<h2><span class="header-section-number">8.8</span> Exercises<a href="C8AR.html#exercises-1" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p><strong>8.1</strong>. A mutual fund has provided investment yield rates for five consecutive years as follows:</p>
<p><span class="math display">\[
\begin{array}{l|ccccc}
  \hline
\text{Year} &amp; 1 &amp; 2 &amp; 3 &amp; 4 &amp; 5 \\ \hline
\text{Yield} &amp; 0.09 &amp; 0.08 &amp; 0.09 &amp; 0.12 &amp; -0.03 \\
  \hline
\end{array}
\]</span></p>
<p>Determine <span class="math inline">\(r_1\)</span> and <span class="math inline">\(r_2\)</span>, the lag 1 and lag 2 autocorrelation coefficients.</p>
<p><strong>8.2</strong>. The <em>Durbin-Watson</em> statistic is designed to detect autocorrelation and is defined by:
<span class="math display">\[
DW = \frac {\sum_{t=2}^T (y_t - y_{t-1})^2} {\sum_{t=1}^T (y_t -
\bar{y})^2}.
\]</span></p>
<ol style="list-style-type: lower-alpha">
<li><p>Derive the approximate relationship between <span class="math inline">\(DW\)</span> and the lag 1
autocorrelation coefficient <span class="math inline">\(r_1\)</span>.</p></li>
<li><p>Suppose that <span class="math inline">\(r_1 = 0.4\)</span>. What is the approximate value of <span class="math inline">\(DW\)</span>?</p></li>
</ol>
<p><strong>8.3</strong>. Consider the Chapter 2 linear regression model formulas with
<span class="math inline">\(y_{t-1}\)</span> in place of <span class="math inline">\(x_t\)</span>, for <span class="math inline">\(t=2, \ldots, T\)</span>.</p>
<ol style="list-style-type: lower-alpha">
<li><p>Provide an exact expression for <span class="math inline">\(b_1\)</span>.</p></li>
<li><p>Provide an exact expression for <span class="math inline">\(b_0\)</span>.</p></li>
<li><p>Show that <span class="math inline">\(b_0 \approx \bar{y} (1-r_1)\)</span>.</p></li>
</ol>
<p><strong>8.4</strong>. Begin with the <span class="math inline">\(AR\)</span>(1) model as in equation <a href="C8AR.html#eq:eq81">(8.1)</a>.</p>
<ol style="list-style-type: lower-alpha">
<li><p>Take variances of each side of equation <a href="C8AR.html#eq:eq81">(8.1)</a> to show
that <span class="math inline">\(\sigma_y^2(1-\beta_1^2) = \sigma^2,\)</span> where <span class="math inline">\(\sigma_y^2 = \mathrm{Var}~y_t\)</span> and <span class="math inline">\(\sigma^2 = \mathrm{Var}~\varepsilon_t\)</span>.</p></li>
<li><p>Show that <span class="math inline">\(\mathrm{Cov}(y_t,y_{t-1}) = \beta_1 \sigma_y^2.\)</span></p></li>
<li><p>Show that <span class="math inline">\(\mathrm{Cov}(y_t,y_{t-k}) = \beta_1^k \sigma_y^2.\)</span></p></li>
<li><p>Use part (c) to establish equation <a href="C8AR.html#eq:eq82">(8.2)</a>.</p></li>
</ol>
<p><strong>8.5</strong>. Consider forecasting with the <span class="math inline">\(AR\)</span>(1) model.</p>
<ol style="list-style-type: lower-alpha">
<li><p>Use the forecasting chain rule in equation <a href="C8AR.html#eq:eq84">(8.4)</a> to show
<span class="math display">\[
y_{T+k}-\widehat{y}_{T+k} \approx \varepsilon_{T+k} + \beta_1
\varepsilon_{T+k-1} + \cdots + \beta_1^{k-1} \varepsilon_{T+1}.
\]</span></p></li>
<li><p>From part (a), show that the approximate variance of the forecast
error is <span class="math inline">\(\sigma^2 \sum_{l=0}^{k-1} \beta_1^{2l}.\)</span></p></li>
</ol>
<p><strong>8.6</strong>. These data consist of the 503 daily returns for the calendar
years 2005 and 2006 of the Standard and Poor’s (S&amp;P) value weighted
index. (The data file contains additional years - this exercise uses
only 2005 and 2006 data.) Each year, there are about 250 days on
which the exchange is open and stocks were traded - on weekends and
holidays it is closed. There are several indices to measure the
market’s overall performance. The <em>value weighted index</em> is
created by assuming that the amount invested in each stock is
proportional to its market capitalization. Here, the market
capitalization is simply the beginning price per share times the
number of outstanding shares. An alternative is the <em>equally weighted index</em>, created by taking a simple average of the closing,
or last, price of stocks that form the S&amp;P on that trading day.</p>
<p>Financial economic theory states that if the market were predictable, many
investors would attempt to take advantage of these predictions, thus forcing
unpredictability. For example, suppose a statistical model reliably
predicted mutual fund A to increase two-fold over the next 18 months. Then,
the no arbitrage principle in financial economics states that several alert
investors, armed with information from the statistical model, would bid to
buy mutual fund A, thus causing the price to increase because demand is
increasing. These alert investors would continue to purchase until the price
of mutual fund A rose to the point where the return was equivalent to other
investment opportunities in the same risk class. Thus, any advantages
produced by the statistical model would disappear rapidly, thus eliminating
this advantage.</p>
<p>Thus, financial economic theory states that for liquid markets such
as stocks represented through the S&amp;P index there should be no
detectable patterns, resulting in a white noise process. In
practice, it has been found that cost of buying and selling equities
(called transactions costs) are large enough so as to prevent us
from taking advantage of these slight tendencies in the swings of
the market. This illustrates a point known as <em>statistically
significant but not practically important</em>. This is not to suggest
that statistics is not practical (heavens forbid!). Instead,
statistics in and of itself does not explicitly recognize factors,
such as economic, psychological and so on, that may be extremely
important in any given situation. It is up to the analyst to
interpret the statistical analysis in light of these
factors.</p>

<div class="figure" style="text-align: center"><span style="display:block;" id="fig:Fig89"></span>
<img src="RegressionMarkdown_files/figure-html/Fig89-1.png" alt="Time Series Plot of the S &amp; P Daily Market Return, 2005-2006." width="60%" />
<p class="caption">
Figure 8.9: <strong>Time Series Plot of the S &amp; P Daily Market Return, 2005-2006.</strong>
</p>
</div>
<h5 style="text-align: center;">
<a id="displayCode.Fig89.Hide" href="javascript:togglecode('toggleCode.Fig89.Hide','displayCode.Fig89.Hide');"><i><strong>R Code to Produce Figure 8.9</strong></i></a>
</h5>
<div id="toggleCode.Fig89.Hide" style="display: none">
<div class="sourceCode" id="cb81"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb81-1"><a href="C8AR.html#cb81-1" tabindex="-1"></a><span class="co"># Figure 89</span></span>
<span id="cb81-2"><a href="C8AR.html#cb81-2" tabindex="-1"></a></span>
<span id="cb81-3"><a href="C8AR.html#cb81-3" tabindex="-1"></a>spdaily  <span class="ot">&lt;-</span> <span class="fu">read.csv</span>(<span class="st">&quot;CSVData/SP500Daily.csv&quot;</span>, <span class="at">header=</span><span class="cn">TRUE</span>)</span>
<span id="cb81-4"><a href="C8AR.html#cb81-4" tabindex="-1"></a><span class="co">#spdaily &lt;- read.csv(&quot;../../CSVData/SP500Daily.csv&quot;, header=TRUE)</span></span>
<span id="cb81-5"><a href="C8AR.html#cb81-5" tabindex="-1"></a></span>
<span id="cb81-6"><a href="C8AR.html#cb81-6" tabindex="-1"></a>sub56<span class="ot">&lt;-</span>spdaily[<span class="fu">c</span>(<span class="dv">1257</span><span class="sc">:</span><span class="dv">1759</span>),]</span>
<span id="cb81-7"><a href="C8AR.html#cb81-7" tabindex="-1"></a><span class="fu">plot</span>(<span class="fu">c</span>(<span class="dv">1</span><span class="sc">:</span><span class="fu">dim</span>(sub56)[<span class="dv">1</span>]),sub56<span class="sc">$</span>vwretd,<span class="at">type=</span><span class="st">&quot;o&quot;</span>,<span class="at">pch=</span><span class="dv">16</span>,</span>
<span id="cb81-8"><a href="C8AR.html#cb81-8" tabindex="-1"></a>     <span class="at">xlab=</span><span class="st">&quot;Index&quot;</span>,<span class="at">ylab=</span><span class="st">&quot;Value Weighted Return&quot;</span>, <span class="at">xlim=</span><span class="fu">c</span>(<span class="dv">0</span>,<span class="dv">500</span>))</span></code></pre></div>
</div>
<ol style="list-style-type: lower-alpha">
<li><p>The time series plot in Figure <a href="C8AR.html#fig:Fig89">8.9</a> gives a
preliminary idea of the characteristics of the sequence. Comment on
the stationarity of the sequence.</p></li>
<li><p>Calculate summary statistics of the sequence. Suppose that you assume a
white noise model for the the sequence. Compute 1, 2 and 3 step ahead
forecasts for the daily returns for the first three trading days of 2007.</p></li>
<li><p>Calculate the autocorrelations for the lags 1 through 10. Do you detect
any autocorrelations that are statistically significantly different from
zero?</p></li>
</ol>

<!-- # Chap 1 -->
<!-- # Chap 2 -->
<!-- # Chap 3 -->
<!-- # Chap 4 -->
<!-- # Chap 5 -->
<!-- # Chap 6 -->
<!-- # Chap 7 -->
<!-- # Chap 8 -->
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="C7Trends.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="C9Forecast.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": null,
"search": {
"engine": "fuse",
"options": null
},
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/latest.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
