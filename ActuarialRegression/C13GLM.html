<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapter 13 Generalized Linear Models | Regression Modeling with Actuarial and Financial Applications</title>
  <meta name="description" content="HTML version of ‘Regression Modeling with Actuarial and Financial Applications’" />
  <meta name="generator" content="bookdown 0.39 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapter 13 Generalized Linear Models | Regression Modeling with Actuarial and Financial Applications" />
  <meta property="og:type" content="book" />
  
  <meta property="og:description" content="HTML version of ‘Regression Modeling with Actuarial and Financial Applications’" />
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 13 Generalized Linear Models | Regression Modeling with Actuarial and Financial Applications" />
  
  <meta name="twitter:description" content="HTML version of ‘Regression Modeling with Actuarial and Financial Applications’" />
  

<meta name="author" content="Edward (Jed) Frees, University of Wisconsin - Madison, Australian National University" />



  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="C12Count.html"/>
<link rel="next" href="C14Survival.html"/>
<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/anchor-sections-1.1.0/anchor-sections.css" rel="stylesheet" />
<link href="libs/anchor-sections-1.1.0/anchor-sections-hash.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.1.0/anchor-sections.js"></script>
<script src="libs/kePrint-0.0.1/kePrint.js"></script>
<link href="libs/lightable-0.0.1/lightable.css" rel="stylesheet" />
<link href="libs/bsTable-3.3.7/bootstrapTable.min.css" rel="stylesheet" />
<script src="libs/bsTable-3.3.7/bootstrapTable.js"></script>

<!-- Mathjax Version 2-->
<script type='text/x-mathjax-config'>
		MathJax.Hub.Config({
			extensions: ['tex2jax.js'],
			jax: ['input/TeX', 'output/HTML-CSS'],
			tex2jax: {
				inlineMath: [ ['$','$'], ['\\(','\\)'] ],
				displayMath: [ ['$$','$$'], ['\\[','\\]'] ],
				processEscapes: true
			},
			'HTML-CSS': { availableFonts: ['TeX'] }
		});
</script>

<script type="text/javascript"  src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/MathJax.js?config=TeX-AMS_HTML"> </script>

<script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
<script type="text/javascript" src="https://unpkg.com/survey-jquery/survey.jquery.min.js"></script>
<link href="https://unpkg.com/survey-jquery/modern.min.css" type="text/css" rel="stylesheet">
<script src="https://unpkg.com/showdown/dist/showdown.min.js"></script>


<!-- Various toggle functions used throughout --> 
<script language="javascript">
function toggle(id1,id2) {
	var ele = document.getElementById(id1); var text = document.getElementById(id2);
	if (ele.style.display == "block") {ele.style.display = "none"; text.innerHTML = "Show Solution";}
		else {ele.style.display = "block"; text.innerHTML = "Hide Solution";}}
function togglecode(id1,id2) {
   var ele = document.getElementById(id1); var text = document.getElementById(id2);
   if (ele.style.display == "block") {ele.style.display = "none"; text.innerHTML = "Show R Code";}
      else {ele.style.display = "block"; text.innerHTML = "Hide R Code";}}
function toggleEX(id1,id2) {
   var ele = document.getElementById(id1); var text = document.getElementById(id2);
   if (ele.style.display == "block") {ele.style.display = "none"; text.innerHTML = "Show Example";}
      else {ele.style.display = "block"; text.innerHTML = "Hide Example";}}
function toggleTheory(id1,id2) {
   var ele = document.getElementById(id1); var text = document.getElementById(id2);
   if (ele.style.display == "block") {ele.style.display = "none"; text.innerHTML = "Show Theory";}
      else {ele.style.display = "block"; text.innerHTML = "Hide Theory";}}
function toggleSolution(id1,id2) {
   var ele = document.getElementById(id1); var text = document.getElementById(id2);
   if (ele.style.display == "block") {ele.style.display = "none"; text.innerHTML = "Show Solution";}
      else {ele.style.display = "block"; text.innerHTML = "Hide Solution";}}      
function toggleQuiz(id1,id2) {
   var ele = document.getElementById(id1); var text = document.getElementById(id2);
   if (ele.style.display == "block") {ele.style.display = "none"; text.innerHTML = "Show Quiz Solution";}
      else {ele.style.display = "block"; text.innerHTML = "Hide Quiz Solution";}}      
</script>

<!-- A few functions for revealing definitions -->
<script language="javascript">
<!--   $( function() {
    $("#tabs").tabs();
  } ); -->

$(document).ready(function(){
    $('[data-toggle="tooltip"]').tooltip();
});

$(document).ready(function(){
    $('[data-toggle="popover"]').popover(); 
});
</script>

<script language="javascript">
function openTab(evt, tabName) {
    var i, tabcontent, tablinks;
    tabcontent = document.getElementsByClassName("tabcontent");
    for (i = 0; i < tabcontent.length; i++) {
        tabcontent[i].style.display = "none";
    }
    tablinks = document.getElementsByClassName("tablinks");
    for (i = 0; i < tablinks.length; i++) {
        tablinks[i].className = tablinks[i].className.replace(" active", "");
    }
    document.getElementById(tabName).style.display = "block";
    evt.currentTarget.className += " active";
}

// Get the element with id="defaultOpen" and click on it
document.getElementById("defaultOpen").click();
</script>



<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { color: #008000; } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { color: #008000; font-weight: bold; } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<style type="text/css">
  
  div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Regression Modeling With Actuarial and Financial Applications</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Preface</a>
<ul>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#dedication"><i class="fa fa-check"></i>Dedication</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#forward"><i class="fa fa-check"></i>Forward</a>
<ul>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#who-is-this-book-for"><i class="fa fa-check"></i>Who Is This Book For?</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#what-is-this-book-about"><i class="fa fa-check"></i>What Is This Book About?</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#how-does-this-book-deliver-its-message"><i class="fa fa-check"></i>How Does This Book Deliver Its Message?</a></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#acknowledgements"><i class="fa fa-check"></i>Acknowledgements</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="1" data-path="regression-and-the-normal-distribution.html"><a href="regression-and-the-normal-distribution.html"><i class="fa fa-check"></i><b>1</b> Regression and the Normal Distribution</a>
<ul>
<li class="chapter" data-level="1.1" data-path="regression-and-the-normal-distribution.html"><a href="regression-and-the-normal-distribution.html#Sec11"><i class="fa fa-check"></i><b>1.1</b> What is Regression Analysis?</a></li>
<li class="chapter" data-level="1.2" data-path="regression-and-the-normal-distribution.html"><a href="regression-and-the-normal-distribution.html#Sec12"><i class="fa fa-check"></i><b>1.2</b> Fitting Data to a Normal Distribution</a></li>
<li class="chapter" data-level="1.3" data-path="regression-and-the-normal-distribution.html"><a href="regression-and-the-normal-distribution.html#Sec13"><i class="fa fa-check"></i><b>1.3</b> Power Transforms</a></li>
<li class="chapter" data-level="1.4" data-path="regression-and-the-normal-distribution.html"><a href="regression-and-the-normal-distribution.html#Sec14"><i class="fa fa-check"></i><b>1.4</b> Sampling and the Role of Normality</a></li>
<li class="chapter" data-level="1.5" data-path="regression-and-the-normal-distribution.html"><a href="regression-and-the-normal-distribution.html#Sec15"><i class="fa fa-check"></i><b>1.5</b> Regression and Sampling Designs</a></li>
<li class="chapter" data-level="1.6" data-path="regression-and-the-normal-distribution.html"><a href="regression-and-the-normal-distribution.html#Sec16"><i class="fa fa-check"></i><b>1.6</b> Actuarial Applications of Regression</a></li>
<li class="chapter" data-level="1.7" data-path="regression-and-the-normal-distribution.html"><a href="regression-and-the-normal-distribution.html#Sec17"><i class="fa fa-check"></i><b>1.7</b> Further Reading and References</a></li>
<li class="chapter" data-level="1.8" data-path="regression-and-the-normal-distribution.html"><a href="regression-and-the-normal-distribution.html#Sec18"><i class="fa fa-check"></i><b>1.8</b> Exercises</a></li>
<li class="chapter" data-level="1.9" data-path="regression-and-the-normal-distribution.html"><a href="regression-and-the-normal-distribution.html#Sec19"><i class="fa fa-check"></i><b>1.9</b> Technical Supplement - Central Limit Theorem</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="C2BasicLR.html"><a href="C2BasicLR.html"><i class="fa fa-check"></i><b>2</b> Basic Linear Regression</a>
<ul>
<li class="chapter" data-level="2.1" data-path="C2BasicLR.html"><a href="C2BasicLR.html#Sec21"><i class="fa fa-check"></i><b>2.1</b> Correlations and Least Squares</a></li>
<li class="chapter" data-level="2.2" data-path="C2BasicLR.html"><a href="C2BasicLR.html#Sec22"><i class="fa fa-check"></i><b>2.2</b> Basic Linear Regression Model</a></li>
<li class="chapter" data-level="2.3" data-path="C2BasicLR.html"><a href="C2BasicLR.html#Sec23"><i class="fa fa-check"></i><b>2.3</b> Is the Model Useful? Some Basic Summary Measures</a>
<ul>
<li class="chapter" data-level="2.3.1" data-path="C2BasicLR.html"><a href="C2BasicLR.html#Sec231"><i class="fa fa-check"></i><b>2.3.1</b> Partitioning the Variability</a></li>
<li class="chapter" data-level="2.3.2" data-path="C2BasicLR.html"><a href="C2BasicLR.html#Sec232"><i class="fa fa-check"></i><b>2.3.2</b> The Size of a Typical Deviation: <em>s</em></a></li>
</ul></li>
<li class="chapter" data-level="2.4" data-path="C2BasicLR.html"><a href="C2BasicLR.html#Sec24"><i class="fa fa-check"></i><b>2.4</b> Properties of Regression Coefficient Estimators</a></li>
<li class="chapter" data-level="2.5" data-path="C2BasicLR.html"><a href="C2BasicLR.html#Sec25"><i class="fa fa-check"></i><b>2.5</b> Statistical Inference</a>
<ul>
<li class="chapter" data-level="2.5.1" data-path="C2BasicLR.html"><a href="C2BasicLR.html#Sec251"><i class="fa fa-check"></i><b>2.5.1</b> Is the Explanatory Variable Important?: The <em>t</em>-Test</a></li>
<li class="chapter" data-level="2.5.2" data-path="C2BasicLR.html"><a href="C2BasicLR.html#Sec252"><i class="fa fa-check"></i><b>2.5.2</b> Confidence Intervals</a></li>
<li class="chapter" data-level="2.5.3" data-path="C2BasicLR.html"><a href="C2BasicLR.html#Sec253"><i class="fa fa-check"></i><b>2.5.3</b> Prediction Intervals</a></li>
</ul></li>
<li class="chapter" data-level="2.6" data-path="C2BasicLR.html"><a href="C2BasicLR.html#Sec26"><i class="fa fa-check"></i><b>2.6</b> Building a Better Model: Residual Analysis</a></li>
<li class="chapter" data-level="2.7" data-path="C2BasicLR.html"><a href="C2BasicLR.html#Sec27"><i class="fa fa-check"></i><b>2.7</b> Application: Capital Asset Pricing Model</a></li>
<li class="chapter" data-level="2.8" data-path="C2BasicLR.html"><a href="C2BasicLR.html#Sec28"><i class="fa fa-check"></i><b>2.8</b> Illustrative Regression Computer Output</a></li>
<li class="chapter" data-level="2.9" data-path="C2BasicLR.html"><a href="C2BasicLR.html#Sec29"><i class="fa fa-check"></i><b>2.9</b> Further Reading and References</a></li>
<li class="chapter" data-level="2.10" data-path="C2BasicLR.html"><a href="C2BasicLR.html#Sec210"><i class="fa fa-check"></i><b>2.10</b> Exercises</a></li>
<li class="chapter" data-level="2.11" data-path="C2BasicLR.html"><a href="C2BasicLR.html#Sec211"><i class="fa fa-check"></i><b>2.11</b> Technical Supplement - Elements of Matrix Algebra</a>
<ul>
<li class="chapter" data-level="2.11.1" data-path="C2BasicLR.html"><a href="C2BasicLR.html#Sec2111"><i class="fa fa-check"></i><b>2.11.1</b> Basic Definitions</a></li>
<li class="chapter" data-level="2.11.2" data-path="C2BasicLR.html"><a href="C2BasicLR.html#Sec2112"><i class="fa fa-check"></i><b>2.11.2</b> Some Special Matrices</a></li>
<li class="chapter" data-level="2.11.3" data-path="C2BasicLR.html"><a href="C2BasicLR.html#Sec2113"><i class="fa fa-check"></i><b>2.11.3</b> Basic Operations</a></li>
<li class="chapter" data-level="2.11.4" data-path="C2BasicLR.html"><a href="C2BasicLR.html#Sec2114"><i class="fa fa-check"></i><b>2.11.4</b> Random Matrices</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="3" data-path="C3BasicMLR.html"><a href="C3BasicMLR.html"><i class="fa fa-check"></i><b>3</b> Multiple Linear Regression - I</a>
<ul>
<li class="chapter" data-level="3.1" data-path="C3BasicMLR.html"><a href="C3BasicMLR.html#Sec31"><i class="fa fa-check"></i><b>3.1</b> Method of Least Squares</a>
<ul>
<li class="chapter" data-level="3.1.1" data-path="C3BasicMLR.html"><a href="C3BasicMLR.html#Sec311"><i class="fa fa-check"></i><b>3.1.1</b> Least Squares Method</a></li>
<li class="chapter" data-level="3.1.2" data-path="C3BasicMLR.html"><a href="C3BasicMLR.html#Sec312"><i class="fa fa-check"></i><b>3.1.2</b> General Case with <em>k</em> Explanatory Variables</a></li>
</ul></li>
<li class="chapter" data-level="3.2" data-path="C3BasicMLR.html"><a href="C3BasicMLR.html#Sec32"><i class="fa fa-check"></i><b>3.2</b> Linear Regression Model and Properties of Estimators</a>
<ul>
<li class="chapter" data-level="3.2.1" data-path="C3BasicMLR.html"><a href="C3BasicMLR.html#Sec321"><i class="fa fa-check"></i><b>3.2.1</b> Regression Function</a></li>
<li class="chapter" data-level="3.2.2" data-path="C3BasicMLR.html"><a href="C3BasicMLR.html#Sec322"><i class="fa fa-check"></i><b>3.2.2</b> Regression Coefficient Interpretation</a></li>
<li class="chapter" data-level="3.2.3" data-path="C3BasicMLR.html"><a href="C3BasicMLR.html#Sec323"><i class="fa fa-check"></i><b>3.2.3</b> Model Assumptions</a></li>
<li class="chapter" data-level="3.2.4" data-path="C3BasicMLR.html"><a href="C3BasicMLR.html#Sec324"><i class="fa fa-check"></i><b>3.2.4</b> Properties of Regression Coefficient Estimators</a></li>
</ul></li>
<li class="chapter" data-level="3.3" data-path="C3BasicMLR.html"><a href="C3BasicMLR.html#Sec33"><i class="fa fa-check"></i><b>3.3</b> Estimation and Goodness of Fit</a></li>
<li class="chapter" data-level="3.4" data-path="C3BasicMLR.html"><a href="C3BasicMLR.html#Sec34"><i class="fa fa-check"></i><b>3.4</b> Statistical Inference for a Single Coefficient</a>
<ul>
<li class="chapter" data-level="3.4.1" data-path="C3BasicMLR.html"><a href="C3BasicMLR.html#Sec341"><i class="fa fa-check"></i><b>3.4.1</b> The <em>t</em>-Test</a></li>
<li class="chapter" data-level="3.4.2" data-path="C3BasicMLR.html"><a href="C3BasicMLR.html#Sec342"><i class="fa fa-check"></i><b>3.4.2</b> Confidence Intervals</a></li>
<li class="chapter" data-level="3.4.3" data-path="C3BasicMLR.html"><a href="C3BasicMLR.html#Sec343"><i class="fa fa-check"></i><b>3.4.3</b> Added Variable Plots</a></li>
<li class="chapter" data-level="3.4.4" data-path="C3BasicMLR.html"><a href="C3BasicMLR.html#Sec344"><i class="fa fa-check"></i><b>3.4.4</b> Partial Correlation Coefficients</a></li>
</ul></li>
<li class="chapter" data-level="3.5" data-path="C3BasicMLR.html"><a href="C3BasicMLR.html#Sec35"><i class="fa fa-check"></i><b>3.5</b> Some Special Explanatory Variables</a>
<ul>
<li class="chapter" data-level="3.5.1" data-path="C3BasicMLR.html"><a href="C3BasicMLR.html#Sec351"><i class="fa fa-check"></i><b>3.5.1</b> Binary Variables</a></li>
<li class="chapter" data-level="3.5.2" data-path="C3BasicMLR.html"><a href="C3BasicMLR.html#Sec352"><i class="fa fa-check"></i><b>3.5.2</b> Transforming Explanatory Variables</a></li>
<li class="chapter" data-level="3.5.3" data-path="C3BasicMLR.html"><a href="C3BasicMLR.html#Sec353"><i class="fa fa-check"></i><b>3.5.3</b> Interaction Terms</a></li>
</ul></li>
<li class="chapter" data-level="3.6" data-path="C3BasicMLR.html"><a href="C3BasicMLR.html#Sec36"><i class="fa fa-check"></i><b>3.6</b> Further Reading and References</a></li>
<li class="chapter" data-level="3.7" data-path="C3BasicMLR.html"><a href="C3BasicMLR.html#Sec37"><i class="fa fa-check"></i><b>3.7</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="C4MLRANOVA.html"><a href="C4MLRANOVA.html"><i class="fa fa-check"></i><b>4</b> Multiple Linear Regression - II</a>
<ul>
<li class="chapter" data-level="4.1" data-path="C4MLRANOVA.html"><a href="C4MLRANOVA.html#Sec41"><i class="fa fa-check"></i><b>4.1</b> The Role of Binary Variables</a></li>
<li class="chapter" data-level="4.2" data-path="C4MLRANOVA.html"><a href="C4MLRANOVA.html#Sec42"><i class="fa fa-check"></i><b>4.2</b> Statistical Inference for Several Coefficients</a>
<ul>
<li class="chapter" data-level="4.2.1" data-path="C4MLRANOVA.html"><a href="C4MLRANOVA.html#Sec421"><i class="fa fa-check"></i><b>4.2.1</b> Sets of Regression Coefficients</a></li>
<li class="chapter" data-level="4.2.2" data-path="C4MLRANOVA.html"><a href="C4MLRANOVA.html#Sec422"><i class="fa fa-check"></i><b>4.2.2</b> The General Linear Hypothesis</a></li>
<li class="chapter" data-level="4.2.3" data-path="C4MLRANOVA.html"><a href="C4MLRANOVA.html#Sec423"><i class="fa fa-check"></i><b>4.2.3</b> Estimating and Predicting Several Coefficients</a></li>
</ul></li>
<li class="chapter" data-level="4.3" data-path="C4MLRANOVA.html"><a href="C4MLRANOVA.html#Sec43"><i class="fa fa-check"></i><b>4.3</b> One Factor ANOVA Model</a></li>
<li class="chapter" data-level="4.4" data-path="C4MLRANOVA.html"><a href="C4MLRANOVA.html#Sec44"><i class="fa fa-check"></i><b>4.4</b> Combining Categorical and Continuous Explanatory Variables</a></li>
<li class="chapter" data-level="4.5" data-path="C4MLRANOVA.html"><a href="C4MLRANOVA.html#Sec45"><i class="fa fa-check"></i><b>4.5</b> Further Reading and References</a></li>
<li class="chapter" data-level="4.6" data-path="C4MLRANOVA.html"><a href="C4MLRANOVA.html#Sec46"><i class="fa fa-check"></i><b>4.6</b> Exercises</a></li>
<li class="chapter" data-level="4.7" data-path="C4MLRANOVA.html"><a href="C4MLRANOVA.html#Sec47"><i class="fa fa-check"></i><b>4.7</b> Technical Supplement - Matrix Expressions</a>
<ul>
<li class="chapter" data-level="4.7.1" data-path="C4MLRANOVA.html"><a href="C4MLRANOVA.html#Sec471"><i class="fa fa-check"></i><b>4.7.1</b> Expressing Models with Categorical Variables in Matrix Form</a></li>
<li class="chapter" data-level="4.7.2" data-path="C4MLRANOVA.html"><a href="C4MLRANOVA.html#Sec472"><i class="fa fa-check"></i><b>4.7.2</b> Calculating Least Squares Recursively</a></li>
<li class="chapter" data-level="4.7.3" data-path="C4MLRANOVA.html"><a href="C4MLRANOVA.html#Sec473"><i class="fa fa-check"></i><b>4.7.3</b> General Linear Model</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="5" data-path="C5VarSelect.html"><a href="C5VarSelect.html"><i class="fa fa-check"></i><b>5</b> Variable Selection</a>
<ul>
<li class="chapter" data-level="5.1" data-path="C5VarSelect.html"><a href="C5VarSelect.html#Sec51"><i class="fa fa-check"></i><b>5.1</b> An Iterative Approach to Data Analysis and Modeling</a></li>
<li class="chapter" data-level="5.2" data-path="C5VarSelect.html"><a href="C5VarSelect.html#Sec52"><i class="fa fa-check"></i><b>5.2</b> Automatic Variable Selection Procedures</a></li>
<li class="chapter" data-level="5.3" data-path="C5VarSelect.html"><a href="C5VarSelect.html#Sec53"><i class="fa fa-check"></i><b>5.3</b> Residual Analysis</a>
<ul>
<li class="chapter" data-level="5.3.1" data-path="C5VarSelect.html"><a href="C5VarSelect.html#Sec531"><i class="fa fa-check"></i><b>5.3.1</b> Residuals</a></li>
<li class="chapter" data-level="5.3.2" data-path="C5VarSelect.html"><a href="C5VarSelect.html#Sec532"><i class="fa fa-check"></i><b>5.3.2</b> Using Residuals to Identify Outliers</a></li>
<li class="chapter" data-level="5.3.3" data-path="C5VarSelect.html"><a href="C5VarSelect.html#Sec533"><i class="fa fa-check"></i><b>5.3.3</b> Using Residuals to Select Explanatory Variables</a></li>
</ul></li>
<li class="chapter" data-level="5.4" data-path="C5VarSelect.html"><a href="C5VarSelect.html#Sec54"><i class="fa fa-check"></i><b>5.4</b> Influential Points</a>
<ul>
<li class="chapter" data-level="5.4.1" data-path="C5VarSelect.html"><a href="C5VarSelect.html#Sec541"><i class="fa fa-check"></i><b>5.4.1</b> Leverage</a></li>
<li class="chapter" data-level="5.4.2" data-path="C5VarSelect.html"><a href="C5VarSelect.html#Sec542"><i class="fa fa-check"></i><b>5.4.2</b> Cook’s Distance</a></li>
</ul></li>
<li class="chapter" data-level="5.5" data-path="C5VarSelect.html"><a href="C5VarSelect.html#Sec55"><i class="fa fa-check"></i><b>5.5</b> Collinearity</a>
<ul>
<li class="chapter" data-level="5.5.1" data-path="C5VarSelect.html"><a href="C5VarSelect.html#Sec551"><i class="fa fa-check"></i><b>5.5.1</b> What is Collinearity?</a></li>
<li class="chapter" data-level="5.5.2" data-path="C5VarSelect.html"><a href="C5VarSelect.html#Sec552"><i class="fa fa-check"></i><b>5.5.2</b> Variance Inflation Factors</a></li>
<li class="chapter" data-level="5.5.3" data-path="C5VarSelect.html"><a href="C5VarSelect.html#Sec553"><i class="fa fa-check"></i><b>5.5.3</b> Collinearity and Leverage</a></li>
<li class="chapter" data-level="5.5.4" data-path="C5VarSelect.html"><a href="C5VarSelect.html#Sec554"><i class="fa fa-check"></i><b>5.5.4</b> Suppressor Variables</a></li>
<li class="chapter" data-level="5.5.5" data-path="C5VarSelect.html"><a href="C5VarSelect.html#Sec555"><i class="fa fa-check"></i><b>5.5.5</b> Orthogonal Variables</a></li>
</ul></li>
<li class="chapter" data-level="5.6" data-path="C5VarSelect.html"><a href="C5VarSelect.html#Sec56"><i class="fa fa-check"></i><b>5.6</b> Selection Criteria</a>
<ul>
<li class="chapter" data-level="5.6.1" data-path="C5VarSelect.html"><a href="C5VarSelect.html#Sec561"><i class="fa fa-check"></i><b>5.6.1</b> Goodness of Fit</a></li>
<li class="chapter" data-level="5.6.2" data-path="C5VarSelect.html"><a href="C5VarSelect.html#Sec562"><i class="fa fa-check"></i><b>5.6.2</b> Model Validation</a></li>
<li class="chapter" data-level="5.6.3" data-path="C5VarSelect.html"><a href="C5VarSelect.html#Sec563"><i class="fa fa-check"></i><b>5.6.3</b> Cross-Validation</a></li>
</ul></li>
<li class="chapter" data-level="5.7" data-path="C5VarSelect.html"><a href="C5VarSelect.html#Sec57"><i class="fa fa-check"></i><b>5.7</b> Heteroscedasticity</a>
<ul>
<li class="chapter" data-level="5.7.1" data-path="C5VarSelect.html"><a href="C5VarSelect.html#Sec571"><i class="fa fa-check"></i><b>5.7.1</b> Detecting Heteroscedasticity</a></li>
<li class="chapter" data-level="5.7.2" data-path="C5VarSelect.html"><a href="C5VarSelect.html#Sec572"><i class="fa fa-check"></i><b>5.7.2</b> Heteroscedasticity-Consistent Standard Errors</a></li>
<li class="chapter" data-level="5.7.3" data-path="C5VarSelect.html"><a href="C5VarSelect.html#Sec573"><i class="fa fa-check"></i><b>5.7.3</b> Weighted Least Squares</a></li>
<li class="chapter" data-level="5.7.4" data-path="C5VarSelect.html"><a href="C5VarSelect.html#Sec574"><i class="fa fa-check"></i><b>5.7.4</b> Transformations</a></li>
</ul></li>
<li class="chapter" data-level="5.8" data-path="C5VarSelect.html"><a href="C5VarSelect.html#Sec58"><i class="fa fa-check"></i><b>5.8</b> Further Reading and References</a></li>
<li class="chapter" data-level="5.9" data-path="C5VarSelect.html"><a href="C5VarSelect.html#Sec59"><i class="fa fa-check"></i><b>5.9</b> Exercises</a></li>
<li class="chapter" data-level="5.10" data-path="C5VarSelect.html"><a href="C5VarSelect.html#Sec510"><i class="fa fa-check"></i><b>5.10</b> Technical Supplements for Chapter 5</a>
<ul>
<li class="chapter" data-level="5.10.1" data-path="C5VarSelect.html"><a href="C5VarSelect.html#Sec5101"><i class="fa fa-check"></i><b>5.10.1</b> Projection Matrix</a></li>
<li class="chapter" data-level="5.10.2" data-path="C5VarSelect.html"><a href="C5VarSelect.html#Sec5102"><i class="fa fa-check"></i><b>5.10.2</b> Leave One Out Statistics</a></li>
<li class="chapter" data-level="5.10.3" data-path="C5VarSelect.html"><a href="C5VarSelect.html#Sec5103"><i class="fa fa-check"></i><b>5.10.3</b> Omitting Variables</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="6" data-path="interpreting-regression-results.html"><a href="interpreting-regression-results.html"><i class="fa fa-check"></i><b>6</b> Interpreting Regression Results</a>
<ul>
<li class="chapter" data-level="6.1" data-path="interpreting-regression-results.html"><a href="interpreting-regression-results.html#Sec61"><i class="fa fa-check"></i><b>6.1</b> What the Modeling Process Tells Us</a>
<ul>
<li class="chapter" data-level="6.1.1" data-path="interpreting-regression-results.html"><a href="interpreting-regression-results.html#Sec611"><i class="fa fa-check"></i><b>6.1.1</b> Interpreting Individual Effects</a></li>
<li class="chapter" data-level="6.1.2" data-path="interpreting-regression-results.html"><a href="interpreting-regression-results.html#Sec612"><i class="fa fa-check"></i><b>6.1.2</b> Other Interpretations</a></li>
</ul></li>
<li class="chapter" data-level="6.2" data-path="interpreting-regression-results.html"><a href="interpreting-regression-results.html#Sec62"><i class="fa fa-check"></i><b>6.2</b> The Importance of Variable Selection</a>
<ul>
<li class="chapter" data-level="6.2.1" data-path="interpreting-regression-results.html"><a href="interpreting-regression-results.html#Sec621"><i class="fa fa-check"></i><b>6.2.1</b> Overfitting the Model</a></li>
<li class="chapter" data-level="6.2.2" data-path="interpreting-regression-results.html"><a href="interpreting-regression-results.html#Sec622"><i class="fa fa-check"></i><b>6.2.2</b> Underfitting the Model</a></li>
</ul></li>
<li class="chapter" data-level="6.3" data-path="interpreting-regression-results.html"><a href="interpreting-regression-results.html#Sec63"><i class="fa fa-check"></i><b>6.3</b> The Importance of Data Collection</a>
<ul>
<li class="chapter" data-level="6.3.1" data-path="interpreting-regression-results.html"><a href="interpreting-regression-results.html#Sec631"><i class="fa fa-check"></i><b>6.3.1</b> Sampling Frame Error and Adverse Selection</a></li>
<li class="chapter" data-level="6.3.2" data-path="interpreting-regression-results.html"><a href="interpreting-regression-results.html#Sec632"><i class="fa fa-check"></i><b>6.3.2</b> Limited Sampling Regions</a></li>
<li class="chapter" data-level="6.3.3" data-path="interpreting-regression-results.html"><a href="interpreting-regression-results.html#Sec633"><i class="fa fa-check"></i><b>6.3.3</b> Limited Dependent Variables, Censoring and Truncation</a></li>
<li class="chapter" data-level="6.3.4" data-path="interpreting-regression-results.html"><a href="interpreting-regression-results.html#Sec634"><i class="fa fa-check"></i><b>6.3.4</b> Omitted and Endogenous Variables</a></li>
<li class="chapter" data-level="6.3.5" data-path="interpreting-regression-results.html"><a href="interpreting-regression-results.html#Sec635"><i class="fa fa-check"></i><b>6.3.5</b> Missing Data</a></li>
</ul></li>
<li class="chapter" data-level="6.4" data-path="interpreting-regression-results.html"><a href="interpreting-regression-results.html#Sec64"><i class="fa fa-check"></i><b>6.4</b> Missing Data Models</a>
<ul>
<li class="chapter" data-level="6.4.1" data-path="interpreting-regression-results.html"><a href="interpreting-regression-results.html#Sec641"><i class="fa fa-check"></i><b>6.4.1</b> Missing at Random</a></li>
<li class="chapter" data-level="6.4.2" data-path="interpreting-regression-results.html"><a href="interpreting-regression-results.html#Sec642"><i class="fa fa-check"></i><b>6.4.2</b> Non-Ignorable Missing Data</a></li>
</ul></li>
<li class="chapter" data-level="6.5" data-path="interpreting-regression-results.html"><a href="interpreting-regression-results.html#Sec65"><i class="fa fa-check"></i><b>6.5</b> Application: Risk Managers’ Cost Effectiveness</a></li>
<li class="chapter" data-level="6.6" data-path="interpreting-regression-results.html"><a href="interpreting-regression-results.html#Sec66"><i class="fa fa-check"></i><b>6.6</b> Further Reading and References</a></li>
<li class="chapter" data-level="6.7" data-path="interpreting-regression-results.html"><a href="interpreting-regression-results.html#Sec67"><i class="fa fa-check"></i><b>6.7</b> Exercises</a></li>
<li class="chapter" data-level="6.8" data-path="interpreting-regression-results.html"><a href="interpreting-regression-results.html#Sec68"><i class="fa fa-check"></i><b>6.8</b> Technical Supplements for Chapter 6</a>
<ul>
<li class="chapter" data-level="6.8.1" data-path="interpreting-regression-results.html"><a href="interpreting-regression-results.html#Sec681"><i class="fa fa-check"></i><b>6.8.1</b> Effects of Model Misspecification</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="7" data-path="C7Trends.html"><a href="C7Trends.html"><i class="fa fa-check"></i><b>7</b> Modeling Trends</a>
<ul>
<li class="chapter" data-level="7.1" data-path="C7Trends.html"><a href="C7Trends.html#introduction-1"><i class="fa fa-check"></i><b>7.1</b> Introduction</a>
<ul>
<li class="chapter" data-level="" data-path="C7Trends.html"><a href="C7Trends.html#time-series-and-stochastic-processes"><i class="fa fa-check"></i>Time Series and Stochastic Processes</a></li>
<li class="chapter" data-level="" data-path="C7Trends.html"><a href="C7Trends.html#time-series-versus-causal-models"><i class="fa fa-check"></i>Time Series versus Causal Models</a></li>
</ul></li>
<li class="chapter" data-level="7.2" data-path="C7Trends.html"><a href="C7Trends.html#S7:Trends"><i class="fa fa-check"></i><b>7.2</b> Fitting Trends in Time</a>
<ul>
<li class="chapter" data-level="" data-path="C7Trends.html"><a href="C7Trends.html#understanding-patterns-over-time"><i class="fa fa-check"></i>Understanding Patterns over Time</a></li>
<li class="chapter" data-level="" data-path="C7Trends.html"><a href="C7Trends.html#fitting-trends-in-time"><i class="fa fa-check"></i>Fitting Trends in Time</a></li>
<li class="chapter" data-level="" data-path="C7Trends.html"><a href="C7Trends.html#fitting-seasonal-trends"><i class="fa fa-check"></i>Fitting Seasonal Trends</a></li>
<li class="chapter" data-level="" data-path="C7Trends.html"><a href="C7Trends.html#reliability-of-time-series-forecasts"><i class="fa fa-check"></i>Reliability of Time Series Forecasts</a></li>
</ul></li>
<li class="chapter" data-level="7.3" data-path="C7Trends.html"><a href="C7Trends.html#S7:RandomWalk"><i class="fa fa-check"></i><b>7.3</b> Stationarity and Random Walk Models</a>
<ul>
<li class="chapter" data-level="" data-path="C7Trends.html"><a href="C7Trends.html#white-noise"><i class="fa fa-check"></i>White Noise</a></li>
<li class="chapter" data-level="" data-path="C7Trends.html"><a href="C7Trends.html#random-walk"><i class="fa fa-check"></i>Random Walk</a></li>
</ul></li>
<li class="chapter" data-level="7.4" data-path="C7Trends.html"><a href="C7Trends.html#inference-using-random-walk-models"><i class="fa fa-check"></i><b>7.4</b> Inference using Random Walk Models</a>
<ul>
<li class="chapter" data-level="" data-path="C7Trends.html"><a href="C7Trends.html#model-properties"><i class="fa fa-check"></i>Model Properties</a></li>
<li class="chapter" data-level="" data-path="C7Trends.html"><a href="C7Trends.html#forecasting"><i class="fa fa-check"></i>Forecasting</a></li>
<li class="chapter" data-level="" data-path="C7Trends.html"><a href="C7Trends.html#identifying-stationarity"><i class="fa fa-check"></i>Identifying Stationarity</a></li>
<li class="chapter" data-level="" data-path="C7Trends.html"><a href="C7Trends.html#identifying-random-walks"><i class="fa fa-check"></i>Identifying Random Walks</a></li>
<li class="chapter" data-level="" data-path="C7Trends.html"><a href="C7Trends.html#random-walk-versus-linear-trend-in-time-models"><i class="fa fa-check"></i>Random Walk versus Linear Trend in Time Models</a></li>
</ul></li>
<li class="chapter" data-level="7.5" data-path="C7Trends.html"><a href="C7Trends.html#filtering-to-achieve-stationarity"><i class="fa fa-check"></i><b>7.5</b> Filtering to Achieve Stationarity</a>
<ul>
<li class="chapter" data-level="" data-path="C7Trends.html"><a href="C7Trends.html#transformations"><i class="fa fa-check"></i>Transformations</a></li>
</ul></li>
<li class="chapter" data-level="7.6" data-path="C7Trends.html"><a href="C7Trends.html#forecast-evaluation"><i class="fa fa-check"></i><b>7.6</b> Forecast Evaluation</a></li>
<li class="chapter" data-level="7.7" data-path="C7Trends.html"><a href="C7Trends.html#further-reading-and-references"><i class="fa fa-check"></i><b>7.7</b> Further Reading and References</a></li>
<li class="chapter" data-level="7.8" data-path="C7Trends.html"><a href="C7Trends.html#exercises"><i class="fa fa-check"></i><b>7.8</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="C8AR.html"><a href="C8AR.html"><i class="fa fa-check"></i><b>8</b> Autocorrelations and Autoregressive Models</a>
<ul>
<li class="chapter" data-level="8.1" data-path="C8AR.html"><a href="C8AR.html#S8:Autocorrs"><i class="fa fa-check"></i><b>8.1</b> Autocorrelations</a>
<ul>
<li class="chapter" data-level="" data-path="C8AR.html"><a href="C8AR.html#application-inflation-bond-returns"><i class="fa fa-check"></i>Application: Inflation Bond Returns</a></li>
</ul></li>
<li class="chapter" data-level="8.2" data-path="C8AR.html"><a href="C8AR.html#autoregressive-models-of-order-one"><i class="fa fa-check"></i><b>8.2</b> Autoregressive Models of Order One</a></li>
<li class="chapter" data-level="8.3" data-path="C8AR.html"><a href="C8AR.html#S8:Estimation"><i class="fa fa-check"></i><b>8.3</b> Estimation and Diagnostic Checking</a></li>
<li class="chapter" data-level="8.4" data-path="C8AR.html"><a href="C8AR.html#S8:AR1Smooth"><i class="fa fa-check"></i><b>8.4</b> Smoothing and Prediction</a></li>
<li class="chapter" data-level="8.5" data-path="C8AR.html"><a href="C8AR.html#S8:BoxJenkins"><i class="fa fa-check"></i><b>8.5</b> Box-Jenkins Modeling and Forecasting</a>
<ul>
<li class="chapter" data-level="8.5.1" data-path="C8AR.html"><a href="C8AR.html#models"><i class="fa fa-check"></i><b>8.5.1</b> Models</a></li>
<li class="chapter" data-level="8.5.2" data-path="C8AR.html"><a href="C8AR.html#forecasting-1"><i class="fa fa-check"></i><b>8.5.2</b> Forecasting</a></li>
</ul></li>
<li class="chapter" data-level="8.6" data-path="C8AR.html"><a href="C8AR.html#application-hong-kong-exchange-rates"><i class="fa fa-check"></i><b>8.6</b> Application: Hong Kong Exchange Rates</a></li>
<li class="chapter" data-level="8.7" data-path="C8AR.html"><a href="C8AR.html#further-reading-and-references-1"><i class="fa fa-check"></i><b>8.7</b> Further Reading and References</a></li>
<li class="chapter" data-level="8.8" data-path="C8AR.html"><a href="C8AR.html#exercises-1"><i class="fa fa-check"></i><b>8.8</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="9" data-path="C9Forecast.html"><a href="C9Forecast.html"><i class="fa fa-check"></i><b>9</b> Forecasting and Time Series Models</a>
<ul>
<li class="chapter" data-level="9.1" data-path="C9Forecast.html"><a href="C9Forecast.html#smoothing-with-moving-averages"><i class="fa fa-check"></i><b>9.1</b> Smoothing with Moving Averages</a></li>
<li class="chapter" data-level="9.2" data-path="C9Forecast.html"><a href="C9Forecast.html#S9:ExponSmooth"><i class="fa fa-check"></i><b>9.2</b> Exponential Smoothing</a></li>
<li class="chapter" data-level="9.3" data-path="C9Forecast.html"><a href="C9Forecast.html#S9:SeasonalTSModels"><i class="fa fa-check"></i><b>9.3</b> Seasonal Time Series Models</a></li>
<li class="chapter" data-level="9.4" data-path="C9Forecast.html"><a href="C9Forecast.html#unit-root-tests"><i class="fa fa-check"></i><b>9.4</b> Unit Root Tests</a></li>
<li class="chapter" data-level="9.5" data-path="C9Forecast.html"><a href="C9Forecast.html#archgarch-models"><i class="fa fa-check"></i><b>9.5</b> ARCH/GARCH Models</a></li>
<li class="chapter" data-level="9.6" data-path="C9Forecast.html"><a href="C9Forecast.html#further-reading-and-references-2"><i class="fa fa-check"></i><b>9.6</b> Further Reading and References</a></li>
</ul></li>
<li class="chapter" data-level="10" data-path="C10Panel.html"><a href="C10Panel.html"><i class="fa fa-check"></i><b>10</b> Longitudinal and Panel Data Models</a>
<ul>
<li class="chapter" data-level="10.1" data-path="C10Panel.html"><a href="C10Panel.html#S10:Intro"><i class="fa fa-check"></i><b>10.1</b> What are Longitudinal and Panel Data?</a></li>
<li class="chapter" data-level="10.2" data-path="C10Panel.html"><a href="C10Panel.html#S10:Visual"><i class="fa fa-check"></i><b>10.2</b> Visualizing Longitudinal and Panel Data</a></li>
<li class="chapter" data-level="10.3" data-path="C10Panel.html"><a href="C10Panel.html#S10:FEModels"><i class="fa fa-check"></i><b>10.3</b> Basic Fixed Effects Models</a></li>
<li class="chapter" data-level="10.4" data-path="C10Panel.html"><a href="C10Panel.html#S10:FEModels2"><i class="fa fa-check"></i><b>10.4</b> Extended Fixed Effects Models</a></li>
<li class="chapter" data-level="10.5" data-path="C10Panel.html"><a href="C10Panel.html#S10:REModels"><i class="fa fa-check"></i><b>10.5</b> Random Effects Models</a></li>
<li class="chapter" data-level="10.6" data-path="C10Panel.html"><a href="C10Panel.html#S10:References"><i class="fa fa-check"></i><b>10.6</b> Further Reading and References</a></li>
</ul></li>
<li class="chapter" data-level="11" data-path="C11Binary.html"><a href="C11Binary.html"><i class="fa fa-check"></i><b>11</b> Categorical Dependent Variables</a>
<ul>
<li class="chapter" data-level="11.1" data-path="C11Binary.html"><a href="C11Binary.html#S:Sec111"><i class="fa fa-check"></i><b>11.1</b> Binary Dependent Variables</a></li>
<li class="chapter" data-level="11.2" data-path="C11Binary.html"><a href="C11Binary.html#S:Sec112"><i class="fa fa-check"></i><b>11.2</b> Logistic and Probit Regression Models</a>
<ul>
<li class="chapter" data-level="11.2.1" data-path="C11Binary.html"><a href="C11Binary.html#S:Sec1121"><i class="fa fa-check"></i><b>11.2.1</b> Using Nonlinear Functions of Explanatory Variables</a></li>
<li class="chapter" data-level="11.2.2" data-path="C11Binary.html"><a href="C11Binary.html#S:Sec1122"><i class="fa fa-check"></i><b>11.2.2</b> Threshold Interpretation</a></li>
<li class="chapter" data-level="11.2.3" data-path="C11Binary.html"><a href="C11Binary.html#S:Sec1123"><i class="fa fa-check"></i><b>11.2.3</b> Random Utility Interpretation</a></li>
<li class="chapter" data-level="11.2.4" data-path="C11Binary.html"><a href="C11Binary.html#S:Sec1124"><i class="fa fa-check"></i><b>11.2.4</b> Logistic Regression</a></li>
</ul></li>
<li class="chapter" data-level="11.3" data-path="C11Binary.html"><a href="C11Binary.html#S:Sec113"><i class="fa fa-check"></i><b>11.3</b> Inference for Logistic and Probit Regression Models</a>
<ul>
<li class="chapter" data-level="11.3.1" data-path="C11Binary.html"><a href="C11Binary.html#parameter-estimation"><i class="fa fa-check"></i><b>11.3.1</b> Parameter Estimation</a></li>
<li class="chapter" data-level="11.3.2" data-path="C11Binary.html"><a href="C11Binary.html#additional-inference"><i class="fa fa-check"></i><b>11.3.2</b> Additional Inference</a></li>
</ul></li>
<li class="chapter" data-level="11.4" data-path="C11Binary.html"><a href="C11Binary.html#S:Sec114"><i class="fa fa-check"></i><b>11.4</b> Application: Medical Expenditures</a></li>
<li class="chapter" data-level="11.5" data-path="C11Binary.html"><a href="C11Binary.html#S:Sec115"><i class="fa fa-check"></i><b>11.5</b> Nominal Dependent Variables</a>
<ul>
<li class="chapter" data-level="11.5.1" data-path="C11Binary.html"><a href="C11Binary.html#S:Sec1151"><i class="fa fa-check"></i><b>11.5.1</b> Generalized Logit</a></li>
<li class="chapter" data-level="11.5.2" data-path="C11Binary.html"><a href="C11Binary.html#S:Sec1152"><i class="fa fa-check"></i><b>11.5.2</b> Multinomial Logit</a></li>
<li class="chapter" data-level="11.5.3" data-path="C11Binary.html"><a href="C11Binary.html#S:Sec1153"><i class="fa fa-check"></i><b>11.5.3</b> Nested Logit</a></li>
</ul></li>
<li class="chapter" data-level="11.6" data-path="C11Binary.html"><a href="C11Binary.html#S:Sec116"><i class="fa fa-check"></i><b>11.6</b> Ordinal Dependent Variables</a>
<ul>
<li class="chapter" data-level="11.6.1" data-path="C11Binary.html"><a href="C11Binary.html#cumulative-logit"><i class="fa fa-check"></i><b>11.6.1</b> Cumulative Logit</a></li>
<li class="chapter" data-level="11.6.2" data-path="C11Binary.html"><a href="C11Binary.html#cumulative-probit"><i class="fa fa-check"></i><b>11.6.2</b> Cumulative Probit</a></li>
</ul></li>
<li class="chapter" data-level="11.7" data-path="C11Binary.html"><a href="C11Binary.html#S:Sec117"><i class="fa fa-check"></i><b>11.7</b> Further Reading and References</a></li>
<li class="chapter" data-level="11.8" data-path="C11Binary.html"><a href="C11Binary.html#S:Sec118"><i class="fa fa-check"></i><b>11.8</b> Exercises</a></li>
<li class="chapter" data-level="11.9" data-path="C11Binary.html"><a href="C11Binary.html#S:Sec119"><i class="fa fa-check"></i><b>11.9</b> Technical Supplements - Likelihood-Based Inference</a>
<ul>
<li class="chapter" data-level="11.9.1" data-path="C11Binary.html"><a href="C11Binary.html#S:Sec1191"><i class="fa fa-check"></i><b>11.9.1</b> Properties of Likelihood Functions</a></li>
<li class="chapter" data-level="11.9.2" data-path="C11Binary.html"><a href="C11Binary.html#S:Sec1192"><i class="fa fa-check"></i><b>11.9.2</b> Maximum Likelihood Estimators</a></li>
<li class="chapter" data-level="11.9.3" data-path="C11Binary.html"><a href="C11Binary.html#S:Sec1193"><i class="fa fa-check"></i><b>11.9.3</b> Hypothesis Tests</a></li>
<li class="chapter" data-level="11.9.4" data-path="C11Binary.html"><a href="C11Binary.html#S:Sec1194"><i class="fa fa-check"></i><b>11.9.4</b> Information Criteria</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="12" data-path="C12Count.html"><a href="C12Count.html"><i class="fa fa-check"></i><b>12</b> Count Dependent Variables</a>
<ul>
<li class="chapter" data-level="12.1" data-path="C12Count.html"><a href="C12Count.html#S:Sec121"><i class="fa fa-check"></i><b>12.1</b> Poisson Regression</a>
<ul>
<li class="chapter" data-level="12.1.1" data-path="C12Count.html"><a href="C12Count.html#S:Sec1211"><i class="fa fa-check"></i><b>12.1.1</b> Poisson Distribution</a></li>
<li class="chapter" data-level="12.1.2" data-path="C12Count.html"><a href="C12Count.html#S:Sec1212"><i class="fa fa-check"></i><b>12.1.2</b> Regression Model</a></li>
<li class="chapter" data-level="12.1.3" data-path="C12Count.html"><a href="C12Count.html#S:Sec1213"><i class="fa fa-check"></i><b>12.1.3</b> Estimation</a></li>
<li class="chapter" data-level="12.1.4" data-path="C12Count.html"><a href="C12Count.html#S:Sec1214"><i class="fa fa-check"></i><b>12.1.4</b> Additional Inference</a></li>
</ul></li>
<li class="chapter" data-level="12.2" data-path="C12Count.html"><a href="C12Count.html#S:Sec122"><i class="fa fa-check"></i><b>12.2</b> Application: Singapore Automobile Insurance</a></li>
<li class="chapter" data-level="12.3" data-path="C12Count.html"><a href="C12Count.html#S:Sec123"><i class="fa fa-check"></i><b>12.3</b> Overdispersion and Negative Binomial Models</a></li>
<li class="chapter" data-level="12.4" data-path="C12Count.html"><a href="C12Count.html#S:Sec124"><i class="fa fa-check"></i><b>12.4</b> Other Count Models</a>
<ul>
<li class="chapter" data-level="12.4.1" data-path="C12Count.html"><a href="C12Count.html#zero-inflated-models"><i class="fa fa-check"></i><b>12.4.1</b> Zero-Inflated Models</a></li>
<li class="chapter" data-level="12.4.2" data-path="C12Count.html"><a href="C12Count.html#hurdle-models"><i class="fa fa-check"></i><b>12.4.2</b> Hurdle Models</a></li>
<li class="chapter" data-level="12.4.3" data-path="C12Count.html"><a href="C12Count.html#heterogeneity-models"><i class="fa fa-check"></i><b>12.4.3</b> Heterogeneity Models</a></li>
<li class="chapter" data-level="12.4.4" data-path="C12Count.html"><a href="C12Count.html#latent-class-models"><i class="fa fa-check"></i><b>12.4.4</b> Latent Class Models</a></li>
</ul></li>
<li class="chapter" data-level="12.5" data-path="C12Count.html"><a href="C12Count.html#S:Sec125"><i class="fa fa-check"></i><b>12.5</b> Further Reading and References</a></li>
<li class="chapter" data-level="12.6" data-path="C12Count.html"><a href="C12Count.html#S:Sec126"><i class="fa fa-check"></i><b>12.6</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="13" data-path="C13GLM.html"><a href="C13GLM.html"><i class="fa fa-check"></i><b>13</b> Generalized Linear Models</a>
<ul>
<li class="chapter" data-level="13.1" data-path="C13GLM.html"><a href="C13GLM.html#S:Sec131"><i class="fa fa-check"></i><b>13.1</b> Introduction</a></li>
<li class="chapter" data-level="13.2" data-path="C13GLM.html"><a href="C13GLM.html#S:Sec132"><i class="fa fa-check"></i><b>13.2</b> GLM Model</a>
<ul>
<li class="chapter" data-level="13.2.1" data-path="C13GLM.html"><a href="C13GLM.html#S:Sec1321"><i class="fa fa-check"></i><b>13.2.1</b> Linear Exponential Family of Distributions</a></li>
<li class="chapter" data-level="13.2.2" data-path="C13GLM.html"><a href="C13GLM.html#S:Sec1322"><i class="fa fa-check"></i><b>13.2.2</b> Link Functions</a></li>
</ul></li>
<li class="chapter" data-level="13.3" data-path="C13GLM.html"><a href="C13GLM.html#S:Sec133"><i class="fa fa-check"></i><b>13.3</b> Estimation</a>
<ul>
<li class="chapter" data-level="13.3.1" data-path="C13GLM.html"><a href="C13GLM.html#S:Sec1331"><i class="fa fa-check"></i><b>13.3.1</b> Maximum Likelihood Estimation for Canonical Links</a></li>
<li class="chapter" data-level="13.3.2" data-path="C13GLM.html"><a href="C13GLM.html#overdispersion"><i class="fa fa-check"></i><b>13.3.2</b> Overdispersion</a></li>
<li class="chapter" data-level="13.3.3" data-path="C13GLM.html"><a href="C13GLM.html#S:Sec1333"><i class="fa fa-check"></i><b>13.3.3</b> Goodness of Fit Statistics</a></li>
</ul></li>
<li class="chapter" data-level="13.4" data-path="C13GLM.html"><a href="C13GLM.html#S:Sec134"><i class="fa fa-check"></i><b>13.4</b> Application: Medical Expenditures</a></li>
<li class="chapter" data-level="13.5" data-path="C13GLM.html"><a href="C13GLM.html#S:Sec135"><i class="fa fa-check"></i><b>13.5</b> Residuals</a></li>
<li class="chapter" data-level="13.6" data-path="C13GLM.html"><a href="C13GLM.html#S:Sec136"><i class="fa fa-check"></i><b>13.6</b> Tweedie Distribution</a></li>
<li class="chapter" data-level="13.7" data-path="C13GLM.html"><a href="C13GLM.html#S:Sec137"><i class="fa fa-check"></i><b>13.7</b> Further Reading and References</a></li>
<li class="chapter" data-level="13.8" data-path="C13GLM.html"><a href="C13GLM.html#S:Sec138"><i class="fa fa-check"></i><b>13.8</b> Exercises</a></li>
<li class="chapter" data-level="13.9" data-path="C13GLM.html"><a href="C13GLM.html#S:Sec139"><i class="fa fa-check"></i><b>13.9</b> Technical Supplements - Exponential Family</a>
<ul>
<li class="chapter" data-level="13.9.1" data-path="C13GLM.html"><a href="C13GLM.html#S:Sec1391"><i class="fa fa-check"></i><b>13.9.1</b> Linear Exponential Family of Distributions</a></li>
<li class="chapter" data-level="13.9.2" data-path="C13GLM.html"><a href="C13GLM.html#S:Sec1392"><i class="fa fa-check"></i><b>13.9.2</b> Moments</a></li>
<li class="chapter" data-level="13.9.3" data-path="C13GLM.html"><a href="C13GLM.html#S:Sec1393"><i class="fa fa-check"></i><b>13.9.3</b> Maximum Likelihood Estimation for General Links</a></li>
<li class="chapter" data-level="13.9.4" data-path="C13GLM.html"><a href="C13GLM.html#S:Sec1394"><i class="fa fa-check"></i><b>13.9.4</b> Iterated Reweighted Least Squares</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="14" data-path="C14Survival.html"><a href="C14Survival.html"><i class="fa fa-check"></i><b>14</b> Survival Models</a>
<ul>
<li class="chapter" data-level="14.1" data-path="C14Survival.html"><a href="C14Survival.html#introduction-2"><i class="fa fa-check"></i><b>14.1</b> Introduction</a></li>
<li class="chapter" data-level="14.2" data-path="C14Survival.html"><a href="C14Survival.html#S:Sec142"><i class="fa fa-check"></i><b>14.2</b> Censoring and Truncation</a>
<ul>
<li class="chapter" data-level="14.2.1" data-path="C14Survival.html"><a href="C14Survival.html#definitions-and-examples"><i class="fa fa-check"></i><b>14.2.1</b> Definitions and Examples</a></li>
<li class="chapter" data-level="14.2.2" data-path="C14Survival.html"><a href="C14Survival.html#likelihood-inference"><i class="fa fa-check"></i><b>14.2.2</b> Likelihood Inference</a></li>
<li class="chapter" data-level="14.2.3" data-path="C14Survival.html"><a href="C14Survival.html#product-limit-estimator"><i class="fa fa-check"></i><b>14.2.3</b> Product-Limit Estimator</a></li>
</ul></li>
<li class="chapter" data-level="14.3" data-path="C14Survival.html"><a href="C14Survival.html#S:Sec143"><i class="fa fa-check"></i><b>14.3</b> Accelerated Failure Time Model</a></li>
<li class="chapter" data-level="14.4" data-path="C14Survival.html"><a href="C14Survival.html#S:Sec144"><i class="fa fa-check"></i><b>14.4</b> Proportional Hazards Model</a>
<ul>
<li class="chapter" data-level="14.4.1" data-path="C14Survival.html"><a href="C14Survival.html#S:Sec1441"><i class="fa fa-check"></i><b>14.4.1</b> Proportional Hazards</a></li>
<li class="chapter" data-level="14.4.2" data-path="C14Survival.html"><a href="C14Survival.html#S:Sec1442"><i class="fa fa-check"></i><b>14.4.2</b> Inference</a></li>
</ul></li>
<li class="chapter" data-level="14.5" data-path="C14Survival.html"><a href="C14Survival.html#S:Sec145"><i class="fa fa-check"></i><b>14.5</b> Recurrent Events</a></li>
<li class="chapter" data-level="14.6" data-path="C14Survival.html"><a href="C14Survival.html#S:Sec146"><i class="fa fa-check"></i><b>14.6</b> Further Reading and References</a></li>
</ul></li>
<li class="chapter" data-level="15" data-path="C15Misc.html"><a href="C15Misc.html"><i class="fa fa-check"></i><b>15</b> Miscellaneous Regression Topics</a>
<ul>
<li class="chapter" data-level="15.1" data-path="C15Misc.html"><a href="C15Misc.html#S:Sec151"><i class="fa fa-check"></i><b>15.1</b> Mixed Linear Models</a>
<ul>
<li class="chapter" data-level="15.1.1" data-path="C15Misc.html"><a href="C15Misc.html#weighted-least-squares-2"><i class="fa fa-check"></i><b>15.1.1</b> Weighted Least Squares</a></li>
<li class="chapter" data-level="15.1.2" data-path="C15Misc.html"><a href="C15Misc.html#S:Sec1512"><i class="fa fa-check"></i><b>15.1.2</b> Variance Components Estimation</a></li>
<li class="chapter" data-level="15.1.3" data-path="C15Misc.html"><a href="C15Misc.html#best-linear-unbiased-prediction"><i class="fa fa-check"></i><b>15.1.3</b> Best Linear Unbiased Prediction</a></li>
</ul></li>
<li class="chapter" data-level="15.2" data-path="C15Misc.html"><a href="C15Misc.html#bayesian-regression"><i class="fa fa-check"></i><b>15.2</b> Bayesian Regression</a></li>
<li class="chapter" data-level="15.3" data-path="C15Misc.html"><a href="C15Misc.html#S:Sec153"><i class="fa fa-check"></i><b>15.3</b> Density Estimation and Scatterplot Smoothing}</a></li>
<li class="chapter" data-level="15.4" data-path="C15Misc.html"><a href="C15Misc.html#S:Sec154"><i class="fa fa-check"></i><b>15.4</b> Generalized Additive Models</a></li>
<li class="chapter" data-level="15.5" data-path="C15Misc.html"><a href="C15Misc.html#bootstrapping"><i class="fa fa-check"></i><b>15.5</b> Bootstrapping</a></li>
<li class="chapter" data-level="15.6" data-path="C15Misc.html"><a href="C15Misc.html#further-reading-and-references-3"><i class="fa fa-check"></i><b>15.6</b> Further Reading and References</a></li>
</ul></li>
<li class="chapter" data-level="16" data-path="C16FreqSev.html"><a href="C16FreqSev.html"><i class="fa fa-check"></i><b>16</b> Frequency-Severity Models</a>
<ul>
<li class="chapter" data-level="16.1" data-path="C16FreqSev.html"><a href="C16FreqSev.html#S:Sec161"><i class="fa fa-check"></i><b>16.1</b> Introduction</a></li>
<li class="chapter" data-level="16.2" data-path="C16FreqSev.html"><a href="C16FreqSev.html#S:Sec162"><i class="fa fa-check"></i><b>16.2</b> Tobit Model</a></li>
<li class="chapter" data-level="16.3" data-path="C16FreqSev.html"><a href="C16FreqSev.html#S:Sec163"><i class="fa fa-check"></i><b>16.3</b> Application: Medical Expenditures</a></li>
<li class="chapter" data-level="16.4" data-path="C16FreqSev.html"><a href="C16FreqSev.html#S:Sec164"><i class="fa fa-check"></i><b>16.4</b> Two-Part Model</a></li>
<li class="chapter" data-level="16.5" data-path="C16FreqSev.html"><a href="C16FreqSev.html#S:Sec165"><i class="fa fa-check"></i><b>16.5</b> Aggregate Loss Model</a></li>
<li class="chapter" data-level="16.6" data-path="C16FreqSev.html"><a href="C16FreqSev.html#S:Sec166"><i class="fa fa-check"></i><b>16.6</b> Further Reading and References</a></li>
<li class="chapter" data-level="16.7" data-path="C16FreqSev.html"><a href="C16FreqSev.html#S:Sec167"><i class="fa fa-check"></i><b>16.7</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="17" data-path="C17Fat.html"><a href="C17Fat.html"><i class="fa fa-check"></i><b>17</b> Fat-Tailed Regression Models</a>
<ul>
<li class="chapter" data-level="17.1" data-path="C17Fat.html"><a href="C17Fat.html#introduction-3"><i class="fa fa-check"></i><b>17.1</b> Introduction</a></li>
<li class="chapter" data-level="17.2" data-path="C17Fat.html"><a href="C17Fat.html#S:Sec172"><i class="fa fa-check"></i><b>17.2</b> Transformations</a></li>
<li class="chapter" data-level="17.3" data-path="C17Fat.html"><a href="C17Fat.html#S:Sec173"><i class="fa fa-check"></i><b>17.3</b> Generalized Linear Models</a>
<ul>
<li class="chapter" data-level="17.3.1" data-path="C17Fat.html"><a href="C17Fat.html#S:Sec1731"><i class="fa fa-check"></i><b>17.3.1</b> What is “Fat-Tailed?”</a></li>
<li class="chapter" data-level="17.3.2" data-path="C17Fat.html"><a href="C17Fat.html#S:Sec1732"><i class="fa fa-check"></i><b>17.3.2</b> Application: Wisconsin Nursing Homes</a></li>
</ul></li>
<li class="chapter" data-level="17.4" data-path="C17Fat.html"><a href="C17Fat.html#S:Sec174"><i class="fa fa-check"></i><b>17.4</b> Generalized Distributions</a>
<ul>
<li class="chapter" data-level="" data-path="C17Fat.html"><a href="C17Fat.html#applicationwisconsin-nursing-homes"><i class="fa fa-check"></i>Application:Wisconsin Nursing Homes</a></li>
</ul></li>
<li class="chapter" data-level="17.5" data-path="C17Fat.html"><a href="C17Fat.html#S:Sec175"><i class="fa fa-check"></i><b>17.5</b> Quantile Regression</a></li>
<li class="chapter" data-level="17.6" data-path="C17Fat.html"><a href="C17Fat.html#S:Sec176"><i class="fa fa-check"></i><b>17.6</b> Extreme Value Models</a></li>
<li class="chapter" data-level="17.7" data-path="C17Fat.html"><a href="C17Fat.html#further-reading-and-references-4"><i class="fa fa-check"></i><b>17.7</b> Further Reading and References</a></li>
<li class="chapter" data-level="17.8" data-path="C17Fat.html"><a href="C17Fat.html#exercises-2"><i class="fa fa-check"></i><b>17.8</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="18" data-path="C18Cred.html"><a href="C18Cred.html"><i class="fa fa-check"></i><b>18</b> Credibility and Bonus-Malus</a>
<ul>
<li class="chapter" data-level="18.1" data-path="C18Cred.html"><a href="C18Cred.html#risk-classification-and-experience-rating"><i class="fa fa-check"></i><b>18.1</b> Risk Classification and Experience Rating</a></li>
<li class="chapter" data-level="18.2" data-path="C18Cred.html"><a href="C18Cred.html#S:Sec182"><i class="fa fa-check"></i><b>18.2</b> Credibility</a>
<ul>
<li class="chapter" data-level="18.2.1" data-path="C18Cred.html"><a href="C18Cred.html#S:Sec1821"><i class="fa fa-check"></i><b>18.2.1</b> Limited Fluctuation Credibility</a></li>
<li class="chapter" data-level="18.2.2" data-path="C18Cred.html"><a href="C18Cred.html#S:Sec1822"><i class="fa fa-check"></i><b>18.2.2</b> Greatest Accuracy Credibility</a></li>
</ul></li>
<li class="chapter" data-level="18.3" data-path="C18Cred.html"><a href="C18Cred.html#S:Sec183"><i class="fa fa-check"></i><b>18.3</b> Credibility and Regression</a>
<ul>
<li class="chapter" data-level="18.3.1" data-path="C18Cred.html"><a href="C18Cred.html#one-way-random-effects-model"><i class="fa fa-check"></i><b>18.3.1</b> One-Way Random Effects Model</a></li>
<li class="chapter" data-level="18.3.2" data-path="C18Cred.html"><a href="C18Cred.html#longitudinal-models"><i class="fa fa-check"></i><b>18.3.2</b> Longitudinal Models</a></li>
</ul></li>
<li class="chapter" data-level="18.4" data-path="C18Cred.html"><a href="C18Cred.html#S:Sec184"><i class="fa fa-check"></i><b>18.4</b> Bonus-Malus</a></li>
</ul></li>
<li class="chapter" data-level="19" data-path="C19Triangles.html"><a href="C19Triangles.html"><i class="fa fa-check"></i><b>19</b> Claims Triangles</a>
<ul>
<li class="chapter" data-level="19.1" data-path="C19Triangles.html"><a href="C19Triangles.html#introduction-4"><i class="fa fa-check"></i><b>19.1</b> Introduction</a>
<ul>
<li class="chapter" data-level="19.1.1" data-path="C19Triangles.html"><a href="C19Triangles.html#S:Sec1911"><i class="fa fa-check"></i><b>19.1.1</b> Claims Evolution</a></li>
<li class="chapter" data-level="19.1.2" data-path="C19Triangles.html"><a href="C19Triangles.html#S:Sec1912"><i class="fa fa-check"></i><b>19.1.2</b> Claims Triangles</a></li>
<li class="chapter" data-level="19.1.3" data-path="C19Triangles.html"><a href="C19Triangles.html#S:Sec1913"><i class="fa fa-check"></i><b>19.1.3</b> Chain Ladder Method</a></li>
</ul></li>
<li class="chapter" data-level="19.2" data-path="C19Triangles.html"><a href="C19Triangles.html#S:Sec192"><i class="fa fa-check"></i><b>19.2</b> Regression Using Functions of Time as Explanatory Variables</a>
<ul>
<li class="chapter" data-level="19.2.1" data-path="C19Triangles.html"><a href="C19Triangles.html#S:Sec1921"><i class="fa fa-check"></i><b>19.2.1</b> Lognormal Model</a></li>
<li class="chapter" data-level="19.2.2" data-path="C19Triangles.html"><a href="C19Triangles.html#S:Sec1922"><i class="fa fa-check"></i><b>19.2.2</b> Hoerl Curve</a></li>
<li class="chapter" data-level="19.2.3" data-path="C19Triangles.html"><a href="C19Triangles.html#S:Sec1923"><i class="fa fa-check"></i><b>19.2.3</b> Poisson Models</a></li>
</ul></li>
<li class="chapter" data-level="19.3" data-path="C19Triangles.html"><a href="C19Triangles.html#S:Sec193"><i class="fa fa-check"></i><b>19.3</b> Using Past Developments</a>
<ul>
<li class="chapter" data-level="19.3.1" data-path="C19Triangles.html"><a href="C19Triangles.html#S:Sec1931"><i class="fa fa-check"></i><b>19.3.1</b> Mack Model</a></li>
<li class="chapter" data-level="19.3.2" data-path="C19Triangles.html"><a href="C19Triangles.html#S:Sec1932"><i class="fa fa-check"></i><b>19.3.2</b> Distributional Models</a></li>
</ul></li>
<li class="chapter" data-level="19.4" data-path="C19Triangles.html"><a href="C19Triangles.html#further-reading-and-references-5"><i class="fa fa-check"></i><b>19.4</b> Further Reading and References</a></li>
<li class="chapter" data-level="19.5" data-path="C19Triangles.html"><a href="C19Triangles.html#exercises-3"><i class="fa fa-check"></i><b>19.5</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="20" data-path="C20Report.html"><a href="C20Report.html"><i class="fa fa-check"></i><b>20</b> Report Writing: Communicating Data Analysis Results</a>
<ul>
<li class="chapter" data-level="20.1" data-path="C20Report.html"><a href="C20Report.html#S20:Overview"><i class="fa fa-check"></i><b>20.1</b> Overview</a></li>
<li class="chapter" data-level="20.2" data-path="C20Report.html"><a href="C20Report.html#S20:Methods"><i class="fa fa-check"></i><b>20.2</b> Methods for Communicating Data</a>
<ul>
<li class="chapter" data-level="" data-path="C20Report.html"><a href="C20Report.html#within-text-data"><i class="fa fa-check"></i>Within Text Data</a></li>
<li class="chapter" data-level="" data-path="C20Report.html"><a href="C20Report.html#graphs"><i class="fa fa-check"></i>Graphs</a></li>
</ul></li>
<li class="chapter" data-level="20.3" data-path="C20Report.html"><a href="C20Report.html#S20:Organize"><i class="fa fa-check"></i><b>20.3</b> How to Organize</a>
<ul>
<li class="chapter" data-level="" data-path="C20Report.html"><a href="C20Report.html#title-and-abstract"><i class="fa fa-check"></i>Title and Abstract</a></li>
<li class="chapter" data-level="" data-path="C20Report.html"><a href="C20Report.html#introduction-5"><i class="fa fa-check"></i>Introduction</a></li>
<li class="chapter" data-level="" data-path="C20Report.html"><a href="C20Report.html#model-selection-and-interpretation"><i class="fa fa-check"></i>Model Selection and Interpretation</a></li>
<li class="chapter" data-level="" data-path="C20Report.html"><a href="C20Report.html#references-and-appendix"><i class="fa fa-check"></i>References and Appendix</a></li>
</ul></li>
<li class="chapter" data-level="20.4" data-path="C20Report.html"><a href="C20Report.html#further-suggestions-for-report-writing"><i class="fa fa-check"></i><b>20.4</b> Further Suggestions for Report Writing</a></li>
<li class="chapter" data-level="20.5" data-path="C20Report.html"><a href="C20Report.html#case-study-swedish-automobile-claims"><i class="fa fa-check"></i><b>20.5</b> Case Study: Swedish Automobile Claims</a></li>
<li class="chapter" data-level="20.6" data-path="C20Report.html"><a href="C20Report.html#further-reading-and-references-6"><i class="fa fa-check"></i><b>20.6</b> Further Reading and References</a></li>
<li class="chapter" data-level="20.7" data-path="C20Report.html"><a href="C20Report.html#exercises-4"><i class="fa fa-check"></i><b>20.7</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="21" data-path="C21Design.html"><a href="C21Design.html"><i class="fa fa-check"></i><b>21</b> Designing Effective Graphs</a>
<ul>
<li class="chapter" data-level="21.1" data-path="C21Design.html"><a href="C21Design.html#S21:Intro"><i class="fa fa-check"></i><b>21.1</b> Introduction</a></li>
<li class="chapter" data-level="21.2" data-path="C21Design.html"><a href="C21Design.html#S21:GDesign"><i class="fa fa-check"></i><b>21.2</b> Graphic Design Choices Make a Difference</a></li>
<li class="chapter" data-level="21.3" data-path="C21Design.html"><a href="C21Design.html#S21:DesignGuide"><i class="fa fa-check"></i><b>21.3</b> Design Guidelines</a>
<ul>
<li class="chapter" data-level="" data-path="C21Design.html"><a href="C21Design.html#guideline-one-avoid-chartjunk"><i class="fa fa-check"></i>Guideline One: Avoid Chartjunk</a></li>
<li class="chapter" data-level="" data-path="C21Design.html"><a href="C21Design.html#guideline-two-use-small-multiples-to-promote-comparisons-and-assess-change"><i class="fa fa-check"></i>Guideline Two: Use Small Multiples to Promote Comparisons and Assess Change</a></li>
<li class="chapter" data-level="" data-path="C21Design.html"><a href="C21Design.html#guideline-three-use-complex-graphs-to-portray-complex-patterns"><i class="fa fa-check"></i>Guideline Three: Use Complex Graphs to Portray Complex Patterns</a></li>
<li class="chapter" data-level="" data-path="C21Design.html"><a href="C21Design.html#guideline-four-relate-graph-size-to-information-content"><i class="fa fa-check"></i>Guideline Four: Relate Graph Size to Information Content</a></li>
<li class="chapter" data-level="" data-path="C21Design.html"><a href="C21Design.html#guideline-five-use-graphical-forms-that-promote-comparisons"><i class="fa fa-check"></i>Guideline Five: Use Graphical Forms That Promote Comparisons</a></li>
<li class="chapter" data-level="" data-path="C21Design.html"><a href="C21Design.html#guideline-six-integrate-graphs-and-text"><i class="fa fa-check"></i>Guideline Six: Integrate Graphs and Text</a></li>
<li class="chapter" data-level="" data-path="C21Design.html"><a href="C21Design.html#guideline-seven-demonstrate-an-important-message"><i class="fa fa-check"></i>Guideline Seven: Demonstrate an Important Message</a></li>
<li class="chapter" data-level="" data-path="C21Design.html"><a href="C21Design.html#guideline-eight-know-your-audience"><i class="fa fa-check"></i>Guideline Eight: Know Your Audience</a></li>
</ul></li>
<li class="chapter" data-level="21.4" data-path="C21Design.html"><a href="C21Design.html#S21:EmpiricalFoundations"><i class="fa fa-check"></i><b>21.4</b> Empirical Foundations For Guidelines</a>
<ul>
<li class="chapter" data-level="21.4.1" data-path="C21Design.html"><a href="C21Design.html#graphs-as-units-of-study"><i class="fa fa-check"></i><b>21.4.1</b> Graphs as Units of Study</a></li>
</ul></li>
<li class="chapter" data-level="21.5" data-path="C21Design.html"><a href="C21Design.html#S21:Conclude"><i class="fa fa-check"></i><b>21.5</b> Concluding Remarks</a></li>
<li class="chapter" data-level="21.6" data-path="C21Design.html"><a href="C21Design.html#S21:References"><i class="fa fa-check"></i><b>21.6</b> Further Reading and References</a></li>
</ul></li>
<li class="chapter" data-level="22" data-path="appendices.html"><a href="appendices.html"><i class="fa fa-check"></i><b>22</b> Appendices</a>
<ul>
<li class="chapter" data-level="" data-path="appendices.html"><a href="appendices.html#appendix-a1.-basic-statistical-inference"><i class="fa fa-check"></i>Appendix A1. Basic Statistical Inference</a>
<ul>
<li class="chapter" data-level="" data-path="appendices.html"><a href="appendices.html#distributions-of-functions-of-random-variables"><i class="fa fa-check"></i>Distributions of Functions of Random Variables</a></li>
<li class="chapter" data-level="" data-path="appendices.html"><a href="appendices.html#estimation-and-prediction"><i class="fa fa-check"></i>Estimation and Prediction</a></li>
<li class="chapter" data-level="" data-path="appendices.html"><a href="appendices.html#testing-hypotheses"><i class="fa fa-check"></i>Testing Hypotheses</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="appendices.html"><a href="appendices.html#appendix-a2.-matrix-algebra"><i class="fa fa-check"></i>Appendix A2. Matrix Algebra</a>
<ul>
<li class="chapter" data-level="" data-path="appendices.html"><a href="appendices.html#basic-definitions"><i class="fa fa-check"></i>Basic Definitions</a></li>
<li class="chapter" data-level="" data-path="appendices.html"><a href="appendices.html#review-of-basic-operations"><i class="fa fa-check"></i>Review of Basic Operations</a></li>
<li class="chapter" data-level="" data-path="appendices.html"><a href="appendices.html#further-definitions"><i class="fa fa-check"></i>Further Definitions</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="appendices.html"><a href="appendices.html#appendix-a3.-probability-tables"><i class="fa fa-check"></i>Appendix A3. Probability Tables</a>
<ul>
<li class="chapter" data-level="" data-path="appendices.html"><a href="appendices.html#normal-distribution"><i class="fa fa-check"></i>Normal Distribution</a></li>
<li class="chapter" data-level="" data-path="appendices.html"><a href="appendices.html#chi-square-distribution"><i class="fa fa-check"></i>Chi-Square Distribution</a></li>
<li class="chapter" data-level="" data-path="appendices.html"><a href="appendices.html#t-distribution"><i class="fa fa-check"></i><em>t</em>-Distribution</a></li>
<li class="chapter" data-level="" data-path="appendices.html"><a href="appendices.html#f-distribution"><i class="fa fa-check"></i><em>F</em>-Distribution</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="" data-path="brief-answers-to-selected-exercises.html"><a href="brief-answers-to-selected-exercises.html"><i class="fa fa-check"></i>Brief Answers to Selected Exercises</a></li>
</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Regression Modeling with Actuarial and Financial Applications</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="C13GLM" class="section level1 hasAnchor" number="13">
<h1><span class="header-section-number">Chapter 13</span> Generalized Linear Models<a href="C13GLM.html#C13GLM" class="anchor-section" aria-label="Anchor link to header"></a></h1>
<p><em>Chapter Preview</em>. This chapter describes a unifying
framework for the Part I linear model and the binary and count
models in Chapters 11 and 12. Generalized linear models, often known
by the acronym GLM, represent an important class of nonlinear
regression models that have found extensive use in actuarial
practice. This unifying framework not only encompasses many models
we have seen but also provides a platform for new ones, including
gamma regressions for fat-tailed data and “Tweedie” distributions
for two-part data.</p>
<div id="S:Sec131" class="section level2 hasAnchor" number="13.1">
<h2><span class="header-section-number">13.1</span> Introduction<a href="C13GLM.html#S:Sec131" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>There are many ways to extend, or generalize, the linear regression
model. This chapter introduces an extension that is so widely used
that it is known as <em>the</em> “generalized linear model,” or as
the acronym GLM.</p>
<p>Generalized linear models include linear, logistic and Poisson
regressions, all as special cases. One common feature of these
models is that in each case we can express the mean response as a
function of linear combinations of explanatory variables. In the GLM
context, it is customary to use <span class="math inline">\(\mu_i = \mathrm{E}~y_i\)</span> for the
mean response and call <span class="math inline">\(\eta_i = \mathbf{x}_i^{\mathbf{\prime}} \boldsymbol \beta\)</span> the <em>systematic component</em> of the model. We
have seen that we can express the systematic component as:</p>
<ul>
<li><span class="math inline">\(\mathbf{x}_i^{\mathbf{\prime}}\boldsymbol \beta = \mu_i\)</span>, for (normal) linear regression,</li>
<li><span class="math inline">\(\mathbf{x}_i^{\mathbf{\prime}} \boldsymbol \beta = \exp(\mu_i)/(1+\exp(\mu_i)),\)</span> for logistic regression and</li>
<li><span class="math inline">\(\mathbf{x}_i^{\mathbf{\prime}} \boldsymbol \beta = \ln (\mu_i),\)</span> for Poisson regression.</li>
</ul>
<p>For GLMs, the systematic component is related to the mean through
the expression
<span class="math display" id="eq:eq131">\[\begin{equation}
\eta _i = \mathbf{x}_i^{\mathbf{\prime}} \boldsymbol \beta =
\mathrm{g}\left( \mu _i\right).
\tag{13.1}
\end{equation}\]</span>
Here, g(.) is known and called the <em>link</em> function. The inverse
of the link function, <span class="math inline">\(\mu _i = \mathrm{g}^{-1}( \mathbf{x}_i^{\mathbf{\prime}} \boldsymbol \beta)\)</span>, is the mean
function.</p>
<p>The second common feature involves the distribution of the dependent
variables. In Section <a href="C13GLM.html#S:Sec132">13.2</a>, we will introduce the
<em>linear exponential family of distributions</em>, an extension of
the exponential distribution. This family includes the normal,
Bernoulli and Poisson distributions as special cases.</p>
<p>The third common feature of GLM models is the robustness of
inference to the choice of distributions. Although linear regression
is motivated by normal distribution theory, we have seen that
responses need not be normally distributed for statistical inference
procedures to be effective. The Section 3.2 sampling assumptions
focus on:</p>
<ul>
<li>the form of the mean function (assumption F1),</li>
<li>non-stochastic or exogenous explanatory variables (F2),</li>
<li>constant variance (F3) and</li>
<li>independence among observations (F4).</li>
</ul>
<p>GLM models maintain assumptions F2 and F4 and generalize F1 through
the link function. The choice of different distributions allows us
to relax F3 by specifying the variance to be a function of the mean,
written as <span class="math inline">\(\mathrm{Var~}y_i = \phi v(\mu_i)\)</span>. <a href="C13GLM.html#Tab131">Table 13.1</a> shows how the variance depends on the
mean for different distributions. As we will see when considering
estimation (Section <a href="C13GLM.html#S:Sec133">13.3</a>), it is the choice of the
variance function that drives the most important inference
properties, not the choice of the distribution.</p>
<p><a id=Tab131></a></p>
<p><span id="Tab131">Table 13.1</span>. <strong>Variance Functions for Selected Distributions</strong></p>
<p><span class="math display">\[
\small{
\begin{array}{lc}
\hline
\text{Distribution} &amp; \text{Variance Function }v(\mu) \\
\hline
\text{Normal} &amp; 1 \\
\text{Bernoulli} &amp; \mu ( 1- \mu )  \\
\text{Poisson} &amp; \mu  \\
\text{Gamma }&amp; \mu ^2  \\
\text{Inverse Gaussian} &amp; \mu ^3  \\
\hline
\end{array}
}
\]</span></p>
<p>By considering regression in the GLM context, we will be able to
handle dependent variables that are approximately normally
distributed, binary or representing counts, all within one
framework. This will aid our understanding of regression by allowing
us to see the “big picture” and not be so concerned with the
details. Further, the generality of GLMs will allow us to introduce
new applications, such as gamma regressions that are useful for
fat-tailed distributions and the so-called “Tweedie” distributions
for two-part data. Two-part data is a topic taken up in Chapter 16,
where there is a mass at zero and a continuous component. For
insurance claims data, the zero represents no claim and the
continuous component represents the amount of a claim.</p>
<p>This chapter describes estimation procedures for calibrating GLM
models, significance tests and goodness of fit statistics for
documenting the usefulness of the model, and residuals for assessing
the robustness of the model fit. We will see that the our earlier
work done on linear, binary and count regression models provides the
foundations for the tools needed for the GLM model. Indeed, many are
slight variations of tools and concepts developed earlier in this
text and we will be able to build on these foundations.</p>
<div class="blackboxvideo">
<p><strong>Video: Section Summary</strong></p>
</div>
<center>
<iframe id="kaltura_player" src="https://cdnapisec.kaltura.com/p/1660902/embedPlaykitJs/uiconf_id/55063162?iframeembed=true&amp;entry_id=1_73v8wjtv&amp;config%5Bprovider%5D=%7B%22widgetId%22%3A%221_jeng0u1q%22%7D&amp;config%5Bplayback%5D=%7B%22startTime%22%3A0%7D" style="width: 576px;height: 324px;border: 0;" allowfullscreen webkitallowfullscreen mozAllowFullScreen allow="autoplay *; fullscreen *; encrypted-media *" title="13.1 GLMIntro">
</iframe>
</center>
</div>
<div id="S:Sec132" class="section level2 hasAnchor" number="13.2">
<h2><span class="header-section-number">13.2</span> GLM Model<a href="C13GLM.html#S:Sec132" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>To specify a GLM, the analyst chooses an underlying response
distribution, the topic of Section <a href="C13GLM.html#S:Sec1321">13.2.1</a>, and a
function that links the mean response to the covariates, the topic
of Section <a href="C13GLM.html#S:Sec1322">13.2.2</a>.</p>
<div id="S:Sec1321" class="section level3 hasAnchor" number="13.2.1">
<h3><span class="header-section-number">13.2.1</span> Linear Exponential Family of Distributions<a href="C13GLM.html#S:Sec1321" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<div class="blackbox">
<p><em>Definition</em>. The distribution of the <em>linear exponential family</em> is
<span class="math display" id="eq:eq132">\[\begin{equation}
\mathrm{f}( y; \theta ,\phi ) =\exp \left( \frac{y\theta -b(\theta )}{\phi }
+S\left( y,\phi \right) \right).
\tag{13.2}
\end{equation}\]</span>
Here, <span class="math inline">\(y\)</span> is a dependent variable and <span class="math inline">\(\theta\)</span> is the parameter of
interest. The quantity <span class="math inline">\(\phi\)</span> is a scale parameter. The term <span class="math inline">\(b(\theta )\)</span> depends only
on the parameter <span class="math inline">\(\theta\)</span>, not the dependent variable. The statistic <span class="math inline">\(S\left( y,\phi \right)\)</span> is a
function of the dependent variable and the scale parameter, not the
parameter <span class="math inline">\(\theta\)</span>.</p>
</div>
<p>The dependent variable <span class="math inline">\(y\)</span> may be discrete, continuous or a mixture.
Thus, <span class="math inline">\(\mathrm{f} \left( .\right)\)</span> may be interpreted to be a
density or mass function, depending on the application. <a href="C13GLM.html#Tab138">Table 13.8</a> provides several examples, including the normal,
binomial and Poisson distributions. To illustrate, consider a
normal distribution with a probability density function of the form
<span class="math display">\[\begin{eqnarray*}
\mathrm{f}( y; \mu ,\sigma ^{2})  &amp;=&amp;\frac{1}{\sigma \sqrt{2\pi
}}\exp \left( -
\frac{(y-\mu )^{2}}{2\sigma ^{2}}\right)  \\
&amp;=&amp;\exp \left( \frac{(y\mu -\mu ^{2}/2)}{\sigma ^{2}}-\frac{y^{2}}{2\sigma
^{2}}-\frac{1}{2}\ln \left( 2\pi \sigma ^{2}\right) \right) .
\end{eqnarray*}\]</span>
With the choices $=$, <span class="math inline">\(\phi =\sigma ^{2}\)</span>, <span class="math inline">\(b(\theta )=\theta ^{2}/2\)</span> and <span class="math inline">\(S\left( y,\phi \right) =-y^{2}/(2\phi )-\ln \left( 2\pi \phi \right) /2\)</span>, we see that the normal probability
density function can be expressed as in equation
<a href="C13GLM.html#eq:eq132">(13.2)</a>.</p>
<p>For the distribution in equation <a href="C13GLM.html#eq:eq132">(13.2)</a>, some
straightforward calculations show that</p>
<ul>
<li><span class="math inline">\(\mathrm{E~}y=b^{\prime }(\theta )\)</span> and</li>
<li><span class="math inline">\(\mathrm{Var~}y=\phi b^{\prime \prime }(\theta )\)</span>.</li>
</ul>
<p>For reference, these calculations appear in Section
<a href="C13GLM.html#S:Sec1392">13.9.2</a>. To illustrate, in the context of the normal
distribution example above, it is easy to check that
<span class="math inline">\(\mathrm{E~}y=b^{\prime }(\theta )=\theta =\mu\)</span> and <span class="math inline">\(\mathrm{Var~} y = \sigma ^{2}b^{\prime \prime }(\theta )=\sigma ^{2}\)</span>, as
anticipated.</p>
<p>In regression modeling situations, the distribution of <span class="math inline">\(y_i\)</span> varies
by observation through the subscript “<span class="math inline">\(i\)</span>”. It is customary to let the
distribution family remain constant yet allow
the parameters to vary by observation through the notation
<span class="math inline">\(\theta_i\)</span> and <span class="math inline">\(\phi_i\)</span>. For our applications, the variation of the
scale parameter is due to known weight factors. Specifically, when
the scale parameter varies by observation, it is according to <span class="math inline">\(\phi _i=\phi /w_i\)</span>, that is, a constant divided by a known weight <span class="math inline">\(w_i\)</span>.
With the relation <span class="math inline">\(\mathrm{Var~}y_i=\phi_i b^{\prime \prime }(\theta_i)=\phi b^{\prime \prime }(\theta_i)/w_i\)</span>, we have that a
larger weight implies a smaller variance, other things being equal.</p>
</div>
<div id="S:Sec1322" class="section level3 hasAnchor" number="13.2.2">
<h3><span class="header-section-number">13.2.2</span> Link Functions<a href="C13GLM.html#S:Sec1322" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>In regression situations, we wish to understand the impact of
<span class="math inline">\(\eta_i = \mathbf{x}_i^{\mathbf{\prime}} \boldsymbol \beta\)</span>, the
systematic component. As we saw in the prior subsection, we can
express the mean of <span class="math inline">\(y_i\)</span> as <span class="math inline">\(\mathrm{E~}y_i=\mu _i=b^{\prime }(\theta_i)\)</span>. Equation <a href="C13GLM.html#eq:eq131">(13.1)</a> serves to “link” the
systematic component to <span class="math inline">\(\mu_i\)</span> and thus to the parameter
<span class="math inline">\(\theta_i\)</span>. It is possible to use the identity function for g(.) so
that <span class="math inline">\(\mu _i=b^{\prime }(\theta_i)\)</span>. Indeed, this is the usual case
in linear regression. However, linear combinations of explanatory
variables, <span class="math inline">\(\mathbf{x}_i^{\mathbf{\prime }}\boldsymbol \beta\)</span>, may
vary between negative and positive infinity whereas means are often
restricted to smaller range. For example, Poisson means vary between
zero and infinity. The link function serves to map the domain of the
mean function onto the whole real line.</p>
<hr />
<p><strong>Special Case: Links for the Bernoulli distribution</strong>.
Bernoulli means are probabilities and thus vary between zero and
one. For this case, it is useful to choose a link function that maps
the unit interval (0,1) onto the whole real line. The following are
three important examples of link functions for the Bernoulli
distribution:</p>
<ul>
<li>Logit: <span class="math inline">\(g(\mu )=\mathrm{logit}(\mu )=\ln (\mu /(1-\mu ))\)</span> .</li>
<li>Probit: <span class="math inline">\(g(\mu )=\Phi ^{-1}(\mu )\)</span>, where <span class="math inline">\(\Phi ^{-1}\)</span> is the inverse
of the standard normal distribution function.</li>
<li>Complementary log-log: $g()=( -(1-)) $.</li>
</ul>
<hr />
<p>This illustration demonstrates that there may be several link
functions that are suitable for a particular distribution. To help
with the selection, an intuitively appealing case occurs when the
systematic component equals the
parameter of interest ($=$). To see this, first recall that $
=g()$ and <span class="math inline">\(\mu =b^{\prime }(\theta )\)</span>, dropping the “<span class="math inline">\(i\)</span>”
subscripts for the moment. Then, it is easy to see that if
<span class="math inline">\(g^{-1}=b^{\prime }\)</span>, then $=g(b^{}())=$.
The choice of <span class="math inline">\(g\)</span> that is the inverse of <span class="math inline">\(b^{\prime }(\theta )\)</span> is
called the <em>canonical link</em>.</p>
<p>Table <a href="C13GLM.html#Tab132">Table 13.2</a> shows the mean function and corresponding
canonical link for several important distributions.</p>
<p><a id=Tab132></a></p>
<p><span id="Tab132">Table 13.2</span>. <strong>Mean Functions and Canonical Links for Selected Distributions</strong></p>
<p><span class="math display">\[
\small{
\begin{array}{lcc}
\hline
\text{Distribution} &amp; \text{Mean function } b^{\prime }(\theta )  &amp;
\text{Canonical link }g(\mu )  \\ \hline
\text{Normal} &amp; \theta &amp;  \mu  \\
\text{Bernoulli} &amp;  e^{\theta}/(1+e^{\theta} )
&amp; \mathrm{logit}(\mu ) \\
\text{Poisson} &amp;  e^{\theta } &amp; \ln  \mu  \\
\text{Gamma} &amp; -1/\theta &amp; -1/\mu  \\
\text{Inverse Gaussian} &amp; (-2 \theta )^{-1/2}  &amp; -1 /(2 \mu^2)  \\
\hline
\end{array}
}
\]</span></p>
<p>Links relate the mean to the systematic component and to
the regression parameters. Because the regression parameters are
unknown, it is common to specify the links only up to scale. For
example, it is common to specify the inverse gaussian canonical link
as <span class="math inline">\(1 /\mu^2\)</span> (instead of $-1 /(2 ^2) $). If necessary, one can
always recover the scale when estimating the unknown regression
coefficients.</p>
<hr />
<p><strong>Example: Ratemaking Classification</strong>. The process of grouping
risks with similar characteristics is known as <em>risk
classification</em>. <em>Ratemaking</em> is the art of setting premiums,
or rates, based on loss experience and exposures of risk classes.
For example, Mildenhall (1999) considered 8,942 collision losses
from private passenger United Kingdom (UK) automobile insurance
policies. The data were derived from Nelder and McCullagh (1989,
Section 8.4.1) but originated from Baxter et al. (1980). A typical
personal auto rating plan is based on driver and vehicle
characteristics. Driver characteristics may include the driver’s
age, gender, marital status, history (accidents and violations) and
good student discount. Vehicle characteristics may include vehicle
model type and year, purpose (business/school or pleasure), garage
territory and so forth. We can represent the systematic component as
<span class="math display">\[
\eta_{ij} = \beta_0 + \alpha_i + \tau_j,
\]</span>
where <span class="math inline">\(\alpha_i\)</span> represents the effect of the <span class="math inline">\(i\)</span>th category of
driver classification and <span class="math inline">\(\tau_j\)</span> the effect of the <span class="math inline">\(j\)</span>th vehicle
type. <a href="C13GLM.html#Tab133">Table 13.3</a> displays the Mildenhall data
for eight driver types (age groups) and four vehicle classes
(vehicle use). The average severity is in pounds sterling adjusted
for inflation.</p>
<p>In GLM terminology, an <em>additive rating plan</em> is based on the
identity link function whereas a <em>multiplicative plan</em> is based
on a logarithmic link function. Specifically, if we use <span class="math inline">\(\eta_{ij} = \ln ( \mu _{ij})\)</span>, then we can write the mean as
<span class="math display" id="eq:eq133">\[\begin{equation}
\mu _{ij} = \exp(\beta_0 + \alpha_i + \tau_j) = B \times A_i \times
T_j,
\tag{13.3}
\end{equation}\]</span>
where <span class="math inline">\(B=\exp(\beta_0)\)</span> is a scaling constant, <span class="math inline">\(A_i=\exp(\alpha_i)\)</span>
represents driver effects and <span class="math inline">\(T_j=\exp(\tau_j)\)</span> represents vehicle
effects.</p>
<p><a id=Tab133></a></p>
<p><span id="Tab133">Table 13.3</span>. <strong>Private Passenger Automobile UK Collision Data</strong></p>
<p><span class="math display">\[
\small{
\begin{array}{lcrr|llcrr}
\hline
       \text{Age} &amp;   \text{Vehicle}  &amp;   \text{ Average} &amp;      \text{Claim} &amp;~~~ &amp;       \text{Age} &amp;   \text{Vehicle}  &amp;   \text{ Average} &amp;      \text{Claim} \\
     \text{Group} &amp;        \text{Use} &amp;   \text{Severity} &amp;     \text{Count} &amp; &amp;     \text{Group} &amp;        \text{Use} &amp;   \text{Severity} &amp;      \text{Count} \\
     \hline
     17-20 &amp;   \text{Pleasure} &amp;     250.48 &amp;         21 &amp;  &amp;     35-39 &amp;   \text{Pleasure} &amp;     153.62 &amp;        151 \\
     17-20 &amp; \text{DriveShort} &amp;     274.78 &amp;         40 &amp; &amp;      35-39 &amp; \text{DriveShort} &amp;     201.67 &amp;        479 \\
     17-20 &amp;  \text{DriveLong} &amp;     244.52 &amp;         23 &amp; &amp;      35-39 &amp;  \text{DriveLong} &amp;     238.21 &amp;        381 \\
     17-20 &amp;   \text{Business} &amp;     797.80 &amp;          5 &amp; &amp;      35-39 &amp;   \text{Business} &amp;     256.21 &amp;        166 \\
\hline
     21-24 &amp;   \text{Pleasure} &amp;     213.71 &amp;         63 &amp; &amp;      40-49 &amp;   \text{Pleasure} &amp;     208.59 &amp;        245 \\
     21-24 &amp; \text{DriveShort} &amp;     298.60 &amp;        171 &amp; &amp;      40-49 &amp; \text{DriveShort} &amp;     202.80 &amp;        970 \\
     21-24 &amp;  \text{DriveLong} &amp;     298.13 &amp;         92 &amp; &amp;      40-49 &amp;  \text{DriveLong} &amp;     236.06 &amp;        719 \\
     21-24 &amp;   \text{Business} &amp;     362.23 &amp;         44 &amp; &amp;     40-49 &amp;   \text{Business} &amp;     352.49 &amp;        304 \\
\hline
     25-29 &amp;   \text{Pleasure} &amp;     250.57 &amp;        140 &amp; &amp;      50-59 &amp;   \text{Pleasure} &amp;     207.57 &amp;        266 \\
     25-29 &amp; \text{DriveShort} &amp;     248.56 &amp;        343 &amp; &amp;      50-59 &amp; \text{DriveShort} &amp;     202.67 &amp;        859 \\
     25-29 &amp;  \text{DriveLong} &amp;     297.90 &amp;        318 &amp; &amp;      50-59 &amp;  \text{DriveLong} &amp;     253.63 &amp;        504 \\
     25-29 &amp;   \text{Business} &amp;     342.31 &amp;        129 &amp;  &amp;     50-59 &amp;   \text{Business} &amp;     340.56 &amp;        162 \\
\hline
     30-34 &amp;   \text{Pleasure} &amp;     229.09 &amp;        123 &amp; &amp;        60+ &amp;   \text{Pleasure} &amp;     192.00 &amp;        260 \\
     30-34 &amp; \text{DriveShort} &amp;     228.48 &amp;        448 &amp; &amp;        60+ &amp; \text{DriveShort} &amp;     196.33 &amp;        578 \\
     30-34 &amp;  \text{DriveLong} &amp;     293.87 &amp;        361 &amp; &amp;        60+ &amp;  \text{DriveLong} &amp;     259.79 &amp;        312 \\
     30-34 &amp;   \text{Business} &amp;     367.46 &amp;        169 &amp; &amp;        60+ &amp;   \text{Business} &amp;     342.58 &amp;         96 \\
\hline
\end{array}
}
\]</span>
<em>Source: Mildenhall (1999). “DriveShort” means drive to work but less than 10 miles.”DriveLong” means drive to work but more than 10 miles.</em></p>
<h5 style="text-align: center;">
<a id="displayCode.Tab133.Hide" href="javascript:togglecode('toggleCode.Tab133.Hide','displayCode.Tab133.Hide');"><i><strong>R Code to Produce Table 13.3</strong></i></a>
</h5>
<div id="toggleCode.Tab133.Hide" style="display: none">
<div class="sourceCode" id="cb109"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb109-1"><a href="C13GLM.html#cb109-1" tabindex="-1"></a>AutoDat <span class="ot">&lt;-</span> <span class="fu">read.csv</span>(<span class="st">&quot;../../CSVData/AutoCollision1.csv&quot;</span>, <span class="at">quote=</span><span class="st">&quot;&quot;</span>, <span class="at">header=</span><span class="cn">TRUE</span>)</span>
<span id="cb109-2"><a href="C13GLM.html#cb109-2" tabindex="-1"></a><span class="co">#AutoDat &lt;- read.table(&quot;CSVData/AutoCollision1.txt&quot;,  header=TRUE)</span></span>
<span id="cb109-3"><a href="C13GLM.html#cb109-3" tabindex="-1"></a>AutoDat1 <span class="ot">&lt;-</span> AutoDat</span>
<span id="cb109-4"><a href="C13GLM.html#cb109-4" tabindex="-1"></a>AutoDat1[,<span class="dv">1</span>] <span class="ot">&lt;-</span> <span class="fu">gsub</span>(<span class="st">&quot;\226&quot;</span>, <span class="st">&quot;-&quot;</span>, AutoDat1[,<span class="dv">1</span>] , <span class="at">fixed =</span> <span class="cn">TRUE</span>)</span>
<span id="cb109-5"><a href="C13GLM.html#cb109-5" tabindex="-1"></a>tableout <span class="ot">&lt;-</span> <span class="fu">cbind</span>(AutoDat1[<span class="dv">1</span><span class="sc">:</span><span class="dv">16</span>,],AutoDat1[<span class="dv">17</span><span class="sc">:</span><span class="dv">32</span>,]) </span>
<span id="cb109-6"><a href="C13GLM.html#cb109-6" tabindex="-1"></a></span>
<span id="cb109-7"><a href="C13GLM.html#cb109-7" tabindex="-1"></a><span class="fu">TableGen1</span>(<span class="at">TableData=</span>tableout, </span>
<span id="cb109-8"><a href="C13GLM.html#cb109-8" tabindex="-1"></a>         <span class="at">TextTitle=</span><span class="st">&#39;Private Passenger Automobile UK Collision Data&#39;</span>, </span>
<span id="cb109-9"><a href="C13GLM.html#cb109-9" tabindex="-1"></a>         <span class="at">Align=</span><span class="st">&#39;c&#39;</span>, <span class="at">ColumnSpec=</span><span class="dv">1</span><span class="sc">:</span><span class="dv">7</span>, <span class="at">BorderRight =</span> <span class="dv">4</span>,</span>
<span id="cb109-10"><a href="C13GLM.html#cb109-10" tabindex="-1"></a>         <span class="at">ColWidth =</span> ColWidth8 )  </span></code></pre></div>
</div>
<div class="blackboxvideo">
<p><strong>Video: Section Summary</strong></p>
</div>
<center>
<iframe id="kaltura_player" src="https://cdnapisec.kaltura.com/p/1660902/embedPlaykitJs/uiconf_id/55063162?iframeembed=true&amp;entry_id=1_nq9zwjgp&amp;config%5Bprovider%5D=%7B%22widgetId%22%3A%221_dzvhey7k%22%7D&amp;config%5Bplayback%5D=%7B%22startTime%22%3A0%7D" style="width: 576px;height: 324px;border: 0;" allowfullscreen webkitallowfullscreen mozAllowFullScreen allow="autoplay *; fullscreen *; encrypted-media *" title="13.2 GLMModel">
</iframe>
</center>
</div>
</div>
<div id="S:Sec133" class="section level2 hasAnchor" number="13.3">
<h2><span class="header-section-number">13.3</span> Estimation<a href="C13GLM.html#S:Sec133" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>This section presents maximum likelihood, the customary form of
estimation. To provide intuition, we focus on the simpler case of
canonical links. Results for more general links appear in Section
<a href="C13GLM.html#S:Sec1393">13.9.3</a>.</p>
<div id="S:Sec1331" class="section level3 hasAnchor" number="13.3.1">
<h3><span class="header-section-number">13.3.1</span> Maximum Likelihood Estimation for Canonical Links<a href="C13GLM.html#S:Sec1331" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>From equation <a href="C13GLM.html#eq:eq132">(13.2)</a> and the independence among
observations, the log-likelihood is
<span class="math display" id="eq:eq134">\[\begin{equation}
\ln \mathrm{f}( \mathbf{y}) =\sum_{i=1}^n
\left\{
\frac{y_i\theta_i-b(\theta_i)}{\phi _i}+S( y_i,\phi _i ) \right\} .
\tag{13.4}
\end{equation}\]</span>
Recall that for canonical links, we have equality between the
distribution’s parameter and the systematic component, so that
<span class="math inline">\(\theta_i=\eta _i=\mathbf{x}_i^{\mathbf{\prime }}\boldsymbol \beta\)</span>.
Thus, with <span class="math inline">\(\phi _i=\phi /w_i\)</span>, the log-likelihood is
<span class="math display" id="eq:eq135">\[\begin{equation}
L (\boldsymbol \beta, \phi ) = \ln \mathrm{f}( \mathbf{y})
=\sum_{i=1}^n \left\{ \frac{y_i\mathbf{x}
_i^{\mathbf{\prime }}\boldsymbol \beta-b(\mathbf{x}_i^{\mathbf{\prime }}
\boldsymbol \beta)}{\phi / w_i}+S( y_i,\phi / w_i) \right\} .
\tag{13.5}
\end{equation}\]</span>
Taking the partial derivative with respect to <span class="math inline">\(\boldsymbol \beta\)</span>
yields the score function
<span class="math display" id="eq:eq136">\[\begin{equation}
\frac{\partial }{\partial \boldsymbol \beta} L( \boldsymbol \beta,
\phi ) = \frac{1}{\phi} \sum_{i=1}^n \left( y_i-b^{\prime
}(\mathbf{x} _i^{\mathbf{\prime }}\boldsymbol \beta) \right) w_i
\mathbf{x}_i .
\tag{13.6}
\end{equation}\]</span>
Because <span class="math inline">\(\mu _i=b^{\prime }(\theta_i)=b^{\prime }(\mathbf{x}_i^{ \mathbf{\prime }}\boldsymbol \beta)\)</span>, we can solve for the maximum
likelihood estimators of <span class="math inline">\(\boldsymbol \beta\)</span>, $_{MLE} $,
through the “normal equations”
<span class="math display" id="eq:eq137">\[\begin{equation}
\mathbf{0}=\sum_{i=1}^n w_i \left( y_i-\mu _i\right) \mathbf{x}_i.
\tag{13.7}
\end{equation}\]</span>
There are <span class="math inline">\(k+1\)</span> equations and <span class="math inline">\(k+1\)</span>
unknowns in the equation <a href="C13GLM.html#eq:eq137">(13.7)</a>. Typically, the
solution is unique and we use the notation <span class="math inline">\(\mathbf{b}_{MLE}\)</span> to
denote the solution. One reason for the widespread use of GLM
methods is that the maximum likelihood estimators can be computed
quickly through a technique known as <em>iterated reweighted least
squares</em>, described in Section <a href="C13GLM.html#S:Sec1394">13.9.4</a>.</p>
<p>Note that, like ordinary linear regression normal equations, we do
not need to consider estimation of the variance scale parameter
<span class="math inline">\(\phi\)</span> at this stage. That is, we can first compute
<span class="math inline">\(\mathbf{b}_{MLE}\)</span> and, when necessary, estimate <span class="math inline">\(\phi\)</span>. (<span class="math inline">\(\phi\)</span> is
known for certain distributions such as the binomial and Poisson and
so does not require estimation.)</p>
<p>As described in Section 11.9, maximum likelihood estimators are consistent and have large sample
normal distributions under broad conditions. Maximum likelihood
inference provides a mechanism for calculating this distribution.
From equations <a href="C13GLM.html#eq:eq136">(13.6)</a> and the likelihood technical
supplement (Section 11.9, equation 11.14), the corresponding
information matrix is
<span class="math display" id="eq:eq138">\[\begin{equation}
\mathbf{I} \left( \mathbf{b}_{MLE} \right) =
\frac{1}{\phi}\sum_{i=1}^n w_i ~b^{\prime \prime }(\mathbf{x}_i
^{\mathbf{\prime }} \mathbf{b}_{MLE} ) ~ \mathbf{x}_i
\mathbf{x}_i^{\mathbf{\prime }} .
\tag{13.8}
\end{equation}\]</span>
The inverse of the information matrix is the large sample
variance-covariance matrix of <span class="math inline">\(\mathbf{b}_{MLE}\)</span>. Specifically, the
square root of the <span class="math inline">\((j+1)\)</span>st diagonal element of the inverse of this
matrix yields the standard error for <span class="math inline">\(b_{j,MLE}\)</span>, which we denote as
<span class="math inline">\(se(b_{j,MLE})\)</span>. Extensions to general links are
similar.</p>
<p>Inference for <span class="math inline">\(\mathbf{b}_{MLE}\)</span> is robust to the choice of
distributions in the following sense. The solution of the maximum
likelihood estimators in equation <a href="C13GLM.html#eq:eq137">(13.7)</a> only
depends on the mean function; it can be shown that consistency of
the estimators depends only on proper choice of this function.
Further, the large sample behavior of <span class="math inline">\(\mathbf{b}_{MLE}\)</span> essentially
only requires that the mean and variance functions be correctly
specified, not the choice of the distribution. (A few additional
regularity conditions are required but these are mild technical
requirements.) For example, suppose an analyst chooses a Poisson
distribution with a logarithmic link. If the log link is
appropriate, then only the equality between the mean and the
variance is needed, see <a href="C13GLM.html#Tab131">Table 13.1</a>. Unlike
the usual domain of the Poisson distribution, the dependent
variables could be non-integers or even be negative. Large sample
inference for <span class="math inline">\(\mathbf{b}_{MLE}\)</span> only requires that we choose the
mean and variance functions correctly.</p>
<hr />
<p><strong>Example: Ratemaking Classification - Continued</strong>. Using the
data in <a href="C13GLM.html#Tab133">Table 13.3</a>, a log-link function with
gamma distribution was fit using claim counts as weights (<span class="math inline">\(w_i\)</span>).
<a href="C13GLM.html#Tab134">Table 13.4</a> shows estimates of the
expected severity using equation <a href="C13GLM.html#eq:eq133">(13.3)</a>.
The averages suggest that young drivers (ages 17-20 and 21-24) have
the highest claims. For vehicle use, those driving for pleasure had
the lowest and those driving for business had the highest claims.</p>
<p><a id=Tab134></a></p>
<p><span id="Tab134">Table 13.4</span>. <strong>Estimated Expected Severity for a Multiplicative Rating Plan</strong></p>
<p><span class="math display">\[
\small{
\begin{array}{l|rrrr|r}
\hline
\text{Age Group }  &amp; \text{DriveShort }&amp;  \text{DriveLong} &amp;   \text{Pleasure} &amp;   \text{Business} &amp;    \text{Average} \\
\hline
     17-20 &amp;     322.17 &amp;     265.56 &amp;     254.90 &amp;     419.07 &amp;     315.42 \\
     21-24 &amp;     320.66 &amp;     264.31 &amp;     253.70 &amp;     417.10 &amp;     313.94 \\
     25-29 &amp;     297.26 &amp;     245.02 &amp;     235.19 &amp;     386.66 &amp;     291.03 \\
     30-34 &amp;     284.85 &amp;     234.80 &amp;     225.37 &amp;     370.53 &amp;     278.89 \\
     35-39 &amp;     229.37 &amp;     189.06 &amp;     181.47 &amp;     298.35 &amp;     224.56 \\
     40-49 &amp;     248.15 &amp;     204.54 &amp;     196.33 &amp;     322.78 &amp;     242.95 \\
     50-59 &amp;     251.95 &amp;     207.67 &amp;     199.34 &amp;     327.72 &amp;     246.67 \\
       60+ &amp;     246.47 &amp;     203.16 &amp;     195.00 &amp;     320.60 &amp;     241.31 \\
\hline
   Average &amp;     275.11 &amp;     226.77 &amp;     217.66 &amp;     357.85 &amp;     269.35 \\
\hline
\end{array}
}
\]</span></p>
<h5 style="text-align: center;">
<a id="displayCode.Tab134.Hide" href="javascript:togglecode('toggleCode.Tab134.Hide','displayCode.Tab134.Hide');"><i><strong>R Code to Produce Table 13.4</strong></i></a>
</h5>
<div id="toggleCode.Tab134.Hide" style="display: none">
<div class="sourceCode" id="cb110"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb110-1"><a href="C13GLM.html#cb110-1" tabindex="-1"></a><span class="co"># AutoDat &lt;- read.csv(&quot;CSVData/AutoCollision.csv&quot;, quote=&quot;&quot;, header=TRUE)</span></span>
<span id="cb110-2"><a href="C13GLM.html#cb110-2" tabindex="-1"></a>AutoDat <span class="ot">&lt;-</span> <span class="fu">read.table</span>(<span class="st">&quot;CSVData/AutoCollision1.txt&quot;</span>,  <span class="at">header=</span><span class="cn">TRUE</span>)</span>
<span id="cb110-3"><a href="C13GLM.html#cb110-3" tabindex="-1"></a></span>
<span id="cb110-4"><a href="C13GLM.html#cb110-4" tabindex="-1"></a><span class="co">#  MODEL WITH TWO FACTORS</span></span>
<span id="cb110-5"><a href="C13GLM.html#cb110-5" tabindex="-1"></a>model1 <span class="ot">&lt;-</span> <span class="fu">glm</span>(Severity<span class="sc">~</span><span class="fu">factor</span>(Age)<span class="sc">+</span><span class="fu">factor</span>(Vehicle_Use), </span>
<span id="cb110-6"><a href="C13GLM.html#cb110-6" tabindex="-1"></a>    <span class="at">control =</span> <span class="fu">glm.control</span>(<span class="at">maxit =</span> <span class="dv">50</span>), <span class="at">weights=</span>Claim_Count,</span>
<span id="cb110-7"><a href="C13GLM.html#cb110-7" tabindex="-1"></a>    <span class="at">family=</span><span class="fu">Gamma</span>(<span class="at">link=</span><span class="st">&quot;log&quot;</span>), <span class="at">data =</span> AutoDat)</span>
<span id="cb110-8"><a href="C13GLM.html#cb110-8" tabindex="-1"></a><span class="co">#summary(model1)</span></span>
<span id="cb110-9"><a href="C13GLM.html#cb110-9" tabindex="-1"></a><span class="co">#model1$coefficients</span></span>
<span id="cb110-10"><a href="C13GLM.html#cb110-10" tabindex="-1"></a></span>
<span id="cb110-11"><a href="C13GLM.html#cb110-11" tabindex="-1"></a>Agecoeff <span class="ot">&lt;-</span>  model1<span class="sc">$</span>coefficients[<span class="dv">1</span><span class="sc">:</span><span class="dv">8</span>]</span>
<span id="cb110-12"><a href="C13GLM.html#cb110-12" tabindex="-1"></a>Agecoeff[<span class="dv">1</span>]<span class="ot">&lt;-</span> <span class="dv">0</span></span>
<span id="cb110-13"><a href="C13GLM.html#cb110-13" tabindex="-1"></a>EAgecoeff <span class="ot">&lt;-</span>  <span class="fu">exp</span>(Agecoeff)</span>
<span id="cb110-14"><a href="C13GLM.html#cb110-14" tabindex="-1"></a><span class="co">#EAgecoeff</span></span>
<span id="cb110-15"><a href="C13GLM.html#cb110-15" tabindex="-1"></a>Vehcoeff <span class="ot">&lt;-</span>  model1<span class="sc">$</span>coefficients[<span class="dv">9</span><span class="sc">:</span><span class="dv">11</span>];</span>
<span id="cb110-16"><a href="C13GLM.html#cb110-16" tabindex="-1"></a>Vehcoeff <span class="ot">&lt;-</span>  <span class="fu">c</span>(Vehcoeff,<span class="dv">0</span>)</span>
<span id="cb110-17"><a href="C13GLM.html#cb110-17" tabindex="-1"></a>EVehcoeff <span class="ot">&lt;-</span>  <span class="fu">exp</span>(Vehcoeff)</span>
<span id="cb110-18"><a href="C13GLM.html#cb110-18" tabindex="-1"></a><span class="co">#EVehcoeff</span></span>
<span id="cb110-19"><a href="C13GLM.html#cb110-19" tabindex="-1"></a></span>
<span id="cb110-20"><a href="C13GLM.html#cb110-20" tabindex="-1"></a>Premiums <span class="ot">&lt;-</span>  <span class="fu">exp</span>(model1<span class="sc">$</span>coefficients[<span class="dv">1</span>])<span class="sc">*</span>EAgecoeff <span class="sc">%*%</span><span class="fu">t</span>(EVehcoeff)</span>
<span id="cb110-21"><a href="C13GLM.html#cb110-21" tabindex="-1"></a>Premiums1 <span class="ot">&lt;-</span> <span class="fu">round</span>(Premiums, <span class="at">digits =</span> <span class="dv">2</span>)</span>
<span id="cb110-22"><a href="C13GLM.html#cb110-22" tabindex="-1"></a></span>
<span id="cb110-23"><a href="C13GLM.html#cb110-23" tabindex="-1"></a>AgeGroup <span class="ot">&lt;-</span> <span class="fu">dimnames</span>( <span class="fu">table</span>(AutoDat<span class="sc">$</span>Age) )</span>
<span id="cb110-24"><a href="C13GLM.html#cb110-24" tabindex="-1"></a>AgeGroup1 <span class="ot">&lt;-</span> AgeGroup </span>
<span id="cb110-25"><a href="C13GLM.html#cb110-25" tabindex="-1"></a><span class="co"># AgeGroup1 &lt;- gsub(&quot;\226&quot;, &quot;-&quot;, AgeGroup1[[1]] , fixed = TRUE)</span></span>
<span id="cb110-26"><a href="C13GLM.html#cb110-26" tabindex="-1"></a></span>
<span id="cb110-27"><a href="C13GLM.html#cb110-27" tabindex="-1"></a>tableout <span class="ot">&lt;-</span> <span class="fu">cbind</span>(AgeGroup1, Premiums1)</span>
<span id="cb110-28"><a href="C13GLM.html#cb110-28" tabindex="-1"></a><span class="fu">colnames</span>(tableout) <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="st">&quot;Age Group&quot;</span>, <span class="st">&quot;DriveShort&quot;</span>, <span class="st">&quot;DriveLong&quot;</span>, <span class="st">&quot;Pleasure&quot;</span>, <span class="st">&quot;Business&quot;</span>)</span>
<span id="cb110-29"><a href="C13GLM.html#cb110-29" tabindex="-1"></a><span class="fu">TableGen1</span>(<span class="at">TableData=</span>tableout, </span>
<span id="cb110-30"><a href="C13GLM.html#cb110-30" tabindex="-1"></a>         <span class="at">TextTitle=</span><span class="st">&#39;Estimated Expected Severity for a Multiplicativefv Rating Plan&#39;</span>, </span>
<span id="cb110-31"><a href="C13GLM.html#cb110-31" tabindex="-1"></a>         <span class="at">Align=</span><span class="st">&#39;c&#39;</span>, <span class="at">ColumnSpec=</span><span class="dv">1</span><span class="sc">:</span><span class="dv">3</span>, <span class="at">Digits =</span> <span class="dv">2</span>, <span class="at">BorderRight =</span> <span class="dv">1</span>,</span>
<span id="cb110-32"><a href="C13GLM.html#cb110-32" tabindex="-1"></a>         <span class="at">ColWidth =</span> ColWidth4 )  </span></code></pre></div>
<table class=" lightable-classic table table-striped table-condensed" style="font-size: 12px; font-family: Cambria; width: auto !important; margin-left: auto; margin-right: auto; margin-left: auto; margin-right: auto;">
<caption style="font-size: initial !important;">
<span id="tab:Tab134">Table 13.1: </span><strong>Estimated Expected Severity for a Multiplicativefv Rating Plan</strong>
</caption>
<thead>
<tr>
<th style="text-align:center;">
Age Group
</th>
<th style="text-align:center;">
DriveShort
</th>
<th style="text-align:center;">
DriveLong
</th>
<th style="text-align:center;">
Pleasure
</th>
<th style="text-align:center;">
Business
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center;width: 2.5cm; border-right:1px solid;">
c(“17?20”, “21?24”, “25?29”, “30?34”, “35?39”, “40?49”, “50?59”, “60+”)
</td>
<td style="text-align:center;width: 1.8cm; ">
322.17
</td>
<td style="text-align:center;width: 1.8cm; ">
265.56
</td>
<td style="text-align:center;width: 1.8cm; ">
254.9
</td>
<td style="text-align:center;">
419.07
</td>
</tr>
<tr>
<td style="text-align:center;width: 2.5cm; border-right:1px solid;">
c(“17?20”, “21?24”, “25?29”, “30?34”, “35?39”, “40?49”, “50?59”, “60+”)
</td>
<td style="text-align:center;width: 1.8cm; ">
320.66
</td>
<td style="text-align:center;width: 1.8cm; ">
264.31
</td>
<td style="text-align:center;width: 1.8cm; ">
253.7
</td>
<td style="text-align:center;">
417.1
</td>
</tr>
<tr>
<td style="text-align:center;width: 2.5cm; border-right:1px solid;">
c(“17?20”, “21?24”, “25?29”, “30?34”, “35?39”, “40?49”, “50?59”, “60+”)
</td>
<td style="text-align:center;width: 1.8cm; ">
297.26
</td>
<td style="text-align:center;width: 1.8cm; ">
245.02
</td>
<td style="text-align:center;width: 1.8cm; ">
235.19
</td>
<td style="text-align:center;">
386.66
</td>
</tr>
<tr>
<td style="text-align:center;width: 2.5cm; border-right:1px solid;">
c(“17?20”, “21?24”, “25?29”, “30?34”, “35?39”, “40?49”, “50?59”, “60+”)
</td>
<td style="text-align:center;width: 1.8cm; ">
284.85
</td>
<td style="text-align:center;width: 1.8cm; ">
234.8
</td>
<td style="text-align:center;width: 1.8cm; ">
225.37
</td>
<td style="text-align:center;">
370.53
</td>
</tr>
<tr>
<td style="text-align:center;width: 2.5cm; border-right:1px solid;">
c(“17?20”, “21?24”, “25?29”, “30?34”, “35?39”, “40?49”, “50?59”, “60+”)
</td>
<td style="text-align:center;width: 1.8cm; ">
229.37
</td>
<td style="text-align:center;width: 1.8cm; ">
189.06
</td>
<td style="text-align:center;width: 1.8cm; ">
181.47
</td>
<td style="text-align:center;">
298.35
</td>
</tr>
<tr>
<td style="text-align:center;width: 2.5cm; border-right:1px solid;">
c(“17?20”, “21?24”, “25?29”, “30?34”, “35?39”, “40?49”, “50?59”, “60+”)
</td>
<td style="text-align:center;width: 1.8cm; ">
248.15
</td>
<td style="text-align:center;width: 1.8cm; ">
204.54
</td>
<td style="text-align:center;width: 1.8cm; ">
196.33
</td>
<td style="text-align:center;">
322.78
</td>
</tr>
<tr>
<td style="text-align:center;width: 2.5cm; border-right:1px solid;">
c(“17?20”, “21?24”, “25?29”, “30?34”, “35?39”, “40?49”, “50?59”, “60+”)
</td>
<td style="text-align:center;width: 1.8cm; ">
251.95
</td>
<td style="text-align:center;width: 1.8cm; ">
207.67
</td>
<td style="text-align:center;width: 1.8cm; ">
199.34
</td>
<td style="text-align:center;">
327.72
</td>
</tr>
<tr>
<td style="text-align:center;width: 2.5cm; border-right:1px solid;">
c(“17?20”, “21?24”, “25?29”, “30?34”, “35?39”, “40?49”, “50?59”, “60+”)
</td>
<td style="text-align:center;width: 1.8cm; ">
246.47
</td>
<td style="text-align:center;width: 1.8cm; ">
203.16
</td>
<td style="text-align:center;width: 1.8cm; ">
195
</td>
<td style="text-align:center;">
320.6
</td>
</tr>
</tbody>
</table>
</div>
</div>
<div id="overdispersion" class="section level3 hasAnchor" number="13.3.2">
<h3><span class="header-section-number">13.3.2</span> Overdispersion<a href="C13GLM.html#overdispersion" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>For some members of the linear exponential family, such as the
Bernoulli and the Poisson distributions, the variance is determined
by the mean. In contrast, the normal distribution has a separate
scale parameter. When fitting models to data with binary or count
dependent variables, it is common to observe that the variance
exceeds that anticipated by the fit of the mean parameters. This
phenomenon is known as <em>overdispersion</em>. Several alternative
probabilistic models are available to explain this phenomenon,
depending on the application at hand. See Section 12.3 for an
example and McCullagh and Nelder (1989) for a more detailed
inventory.</p>
<p>Although arriving at a satisfactory probabilistic model is the most
desirable route, in many situations analysts are content to
postulate an approximate model through the relation
<span class="math display">\[
\mathrm{Var~}y_i=\sigma ^{2}\phi ~b^{\prime \prime }(\theta_i)/w_i .
\]</span>
The parameter <span class="math inline">\(\phi\)</span> is specified through the choice of the
distribution whereas the scale parameter <span class="math inline">\(\sigma ^{2}\)</span> allows for
extra variability. For example, <a href="C13GLM.html#Tab138">Table 13.8</a> shows that
by specifying either the Bernoulli or Poisson distribution, we have
<span class="math inline">\(\phi =1\)</span>. Although the scale parameter <span class="math inline">\(\sigma ^{2}\)</span> allows for
extra variability, it may also accommodate situations in which the
variability is smaller than specified by the distributional form
(although this situation is less common). Finally, note that for
some distributions such as the normal distribution, the extra term
is already incorporated in the <span class="math inline">\(\phi\)</span> parameter and thus serves no
useful purpose.</p>
<p>When the additional scale parameter <span class="math inline">\(\sigma ^{2}\)</span> is included, it is
customary to estimate it by Pearson’s chi-square statistic divided by the
error degrees of freedom. That is,
<span class="math display">\[
\widehat{\sigma }^{2}=\frac{1}{N-k} \sum_{i=1}^n w_i\frac{\left(
y_i-b^{\prime }(\mathbf{x}_i^{\mathbf{\prime
}}\mathbf{b}_{MLE})\right)
^{2}}{\phi b^{\prime \prime }(\mathbf{x}_i^{\mathbf{\prime }}\mathbf{b}
_{MLE})} .
\]</span>
As with the Poisson distribution in Section 12.3, another way of
handling unusual variance patterns is through robust or empirical
standard errors. Section <a href="C13GLM.html#S:Sec1393">13.9.3</a> provides
additional details.</p>
</div>
<div id="S:Sec1333" class="section level3 hasAnchor" number="13.3.3">
<h3><span class="header-section-number">13.3.3</span> Goodness of Fit Statistics<a href="C13GLM.html#S:Sec1333" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>In linear regression models, the most widely cited goodness of fit
statistic is the <span class="math inline">\(R^2\)</span> measure that is based on the decomposition
<span class="math display">\[
\sum_i \left(y_i - \overline{y} \right)^2 = \sum_i \left(y_i -
\widehat{y}_i \right)^2 + \sum_i \left(\widehat{y}_i -
\overline{y}\right)^2 + 2 \times \sum_i \left(y_i - \widehat{y}_i
\right)\left(\widehat{y}_i - \overline{y}\right).
\]</span>
In the language of Section 2.3, this decomposition is:</p>
<p><span class="math display">\[
\textit{Total SS = Error SS + Regression SS + 2}
\times \textit{Sum of Cross-Products}
\]</span></p>
<p>The difficulty with nonlinear models is that the
<em>Sum of Cross-Products</em> term rarely equals zero. Thus, one
gets different statistics when defining <span class="math inline">\(R^2\)</span> as (<em>Regression
SS/Total SS</em>) as compared to (1-<em>Error SS/Total SS</em>). Section
11.3.2 described some alternative <span class="math inline">\(R^2\)</span> measures that are sometimes
cited in GLM settings.</p>
<p>A widely cited goodness of fit measure is the Pearson chi-square
statistic that was introduced in Section 12.1.4. In the GLM context,
we suppose that <span class="math inline">\(\mathrm{E~}y_i = \mu_i\)</span>, <span class="math inline">\(\mathrm{Var~}y_i = \phi v(\mu_i)\)</span> is the variance function (as in the <a href="C13GLM.html#Tab131">Table 13.1</a> examples) and that <span class="math inline">\(\widehat{\mu}_i\)</span> is
an estimator of <span class="math inline">\(\mu_i\)</span>. Then, the Pearson chi-square statistic is
defined as <span class="math inline">\(\sum_i \left( y_i - \widehat{\mu}_i \right)^2/\ ( \phi v(\widehat{\mu}_i))\)</span>. As we have seen for Poisson models of count
data, this formulation reduces to the form <span class="math inline">\(\sum_i \left( y_i - \widehat{\mu}_i \right)^2/\widehat{\mu}_i.\)</span></p>
<p>General information criteria, including <span class="math inline">\(AIC\)</span> and <span class="math inline">\(BIC\)</span>, that were
defined in Section 11.9 are also regularly cited in GLM studies.</p>
<p>A goodness of fit measure that is specific to GLM modeling is the
<em>deviance statistic</em>. To define this statistic, we work with
the notion a <em>saturated model</em> where there are as many
parameters as observations, <span class="math inline">\(\theta_i, i=1, \ldots, n\)</span>. A saturated
model provides the best possible fit. With a parameter for each
observation, we maximize the likelihood on an
observation-by-observation basis. Thus, taking derivatives of
logarithmic likelihood from equation <a href="C13GLM.html#eq:eq132">(13.2)</a> yields
<span class="math display">\[
\frac{\partial}{\partial \theta_i} \ln \mathrm{f}( y_i; \theta_i
,\phi ) = \frac{y_i-b^{\prime}(\theta_i)}{\phi}.
\]</span>
Setting this equal to zero yields the parameter estimate, say
<span class="math inline">\(\theta_{i,SAT}\)</span>, as the solution of
<span class="math inline">\(y_i=b^{\prime}(\theta_{i,Sat})\)</span>. Letting <span class="math inline">\(\boldsymbol \theta _{SAT}\)</span> be the vector of parameters, the likelihood <span class="math inline">\(L(\boldsymbol \theta _{SAT})\)</span> is the largest possible value of the log-likelihood.
Then, for a generic estimator <span class="math inline">\(\widehat{\boldsymbol \theta}\)</span>, the
<em>scaled</em> deviance statistic is defined as
<span class="math display">\[
\mathbf{\mathrm{D}}^{\ast}(\widehat{\boldsymbol \theta}) = 2 \times
\left( L(\boldsymbol \theta _{SAT}) - L(\widehat{\boldsymbol
\theta}) \right).
\]</span>
In linear exponential families,
one multiplies by the scaling factor <span class="math inline">\(\phi\)</span> to define the
<em>deviance statistic</em>, $() = ^{}() $. This multiplication actually removes the variance
scaling factor from the definition of the statistic.</p>
<p>It is straightforward to check that the deviance statistic reduces
to the following forms for three special cases:</p>
<ul>
<li>Normal: <span class="math inline">\(\mathbf{\mathrm{D}}(\widehat{\boldsymbol \mu})= \sum_i \left( y_i - \widehat \mu _i \right) ^2\)</span>,</li>
<li>Bernoulli: <span class="math inline">\(\mathbf{\mathrm{D}}(\widehat{\boldsymbol \pi})= \sum_i \left\{ y_i \ln \frac {y_i}{\widehat \pi_i} + (1-y_i) \ln \frac {1-y_i}{1-\widehat \pi_i} \right\}\)</span>, and</li>
<li>Poisson: <span class="math inline">\(\mathbf{\mathrm{D}}(\widehat{\boldsymbol \mu})= \sum_i \left\{ y_i \ln \frac {y_i}{\widehat \mu_i} + (y_i - \widehat \mu _i) \right\}\)</span>.</li>
</ul>
<p>Here, we use the convention that <span class="math inline">\(y \ln y = 0\)</span> when <span class="math inline">\(y = 0\)</span>.</p>
<div class="blackboxvideo">
<p><strong>Video: Section Summary</strong></p>
</div>
<center>
<iframe id="kaltura_player" src="https://cdnapisec.kaltura.com/p/1660902/embedPlaykitJs/uiconf_id/55063162?iframeembed=true&amp;entry_id=1_rka8hiqt&amp;config%5Bprovider%5D=%7B%22widgetId%22%3A%221_s8pdoq60%22%7D&amp;config%5Bplayback%5D=%7B%22startTime%22%3A0%7D" style="width: 576px;height: 324px;border: 0;" allowfullscreen webkitallowfullscreen mozAllowFullScreen allow="autoplay *; fullscreen *; encrypted-media *" title="13.3 GLMEstimation">
</iframe>
</center>
</div>
</div>
<div id="S:Sec134" class="section level2 hasAnchor" number="13.4">
<h2><span class="header-section-number">13.4</span> Application: Medical Expenditures<a href="C13GLM.html#S:Sec134" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>We now return to the Medical Expenditures Panel Survey (MEPS) data
introduced in Section 11.4. In that section, we sought to develop a
model to understand the event of an inpatient admission to a
hospital. In this section, we now wish to model the amount of the
expenditure. In actuarial terminology, Section 11.4 considered the
“frequency” whereas this section involves the “severity.”</p>
<p>Out of the 2,000 randomly sampled observations from year 2003
considered in Section 11.4, only <span class="math inline">\(n=157\)</span> were admitted to the
hospital during the year. <a href="C13GLM.html#Tab135">Table 13.5</a> summarizes
the data using the same explanatory variables as in Table 11.4. For
example, <a href="C13GLM.html#Tab135">Table 13.5</a> shows that the sample is 72%
female, almost 76% white and over 91% insured. The table also
shows relatively few expenditures by Asians, Native Americans and
the uninsured in our sample.</p>
<p><a href="C13GLM.html#Tab135">Table 13.5</a> also gives median expenditures by
categorical variable. This tables suggests that gender, a poor
self-rating of physical health and income that is poor or negative
may be important determinants of the amount of medical expenditures.</p>
<p><a id=Tab135></a></p>
<p><span id="Tab135">Table 13.5</span>. <strong>Median Expenditures by Explanatory Variable Based on a Sample of <span class="math inline">\(n=157\)</span> with Positive Expenditures</strong></p>
<p><span class="math display">\[
\small{
\begin{array}{lllrr}
\hline
\text{Category} &amp; \text{Variable} &amp; \text{Description }&amp; \text{Percent} &amp; \text{Median} \\
&amp;  &amp;  &amp; \text{of data} &amp; \text{Expend} \\ \hline
&amp; COUNTIP&amp; \text{Number of expenditures (median: 1.0)} \\
\text{Demography} &amp; AGE &amp; \text{Age in years between }\\
&amp; &amp; \ \ \ \text{ 18 to 65 (median: 41.0) }\\
&amp; GENDER &amp;\text{1 if female} &amp; 72.0 &amp; 5,546 \\
&amp;  &amp; \text{0 if male} &amp; 28.0 &amp; 7,313 \\
\text{Ethnicity} &amp; ASIAN &amp; \text{1 if Asian} &amp; 2.6 &amp; 4,003 \\
&amp; BLACK &amp; \text{1 if Black} &amp; 19.8 &amp; 6,100\\
&amp; NATIVE &amp; \text{1 if Native} &amp; 1.9 &amp; 2,310\\
&amp; WHITE &amp; \textit{Reference level} &amp; 75.6 &amp; 5,695\\
\text{Region} &amp; NORTHEAST &amp; \text{1 if Northeast} &amp; 18.5 &amp; 5,833 \\
&amp; MIDWEST &amp; \text{1 if Midwest} &amp; 21.7  &amp;  7,999 \\
&amp; SOUTH &amp; \text{1 if South} &amp; 40.8  &amp;  5,595 \\
&amp; WEST &amp; \textit{Reference level} &amp; 19.1  &amp;  4,297\\
\hline \text{Education} &amp; COLLEGE
&amp; \text{1 if college or higher degree} &amp; 23.6 &amp;  5,611\\
&amp; \text{HIGHSCHOOL} &amp; \text{1 if high school degree} &amp; 43.3 &amp; 5,907  \\
&amp;&amp; \text{Reference level is lower} &amp; 33.1  &amp;  5,338 \\
&amp;&amp; \ \ \ \text{   than high school degree}    &amp; \\ \hline
\text{Self-rated} &amp; POOR &amp; \text{1 if poor} &amp; 17.2 &amp; 10,447\\
\ \ \text{physical}&amp; FAIR &amp; \text{1 if fair} &amp; 10.2 &amp; 5,228 \\
\ \ \text{health} &amp; GOOD &amp; \text{1 if good }&amp; 31.2 &amp; 5,032\\
&amp; VGOOD &amp; \text{1 if very good} &amp; 24.8 &amp;  5,546 \\
&amp;&amp;   \text{Reference level is excellent health} &amp;16.6 &amp; 5,277 \\
\text{Self-rated} &amp; MPOOR &amp; \text{1 if poor or fair} &amp; 15.9  &amp; 6,583  \\
\ \ \text{mental health} &amp;  &amp; \text{0 if good to excellent mental health} &amp; 84.1 &amp; 5,599 \\
\text{Any activity} &amp; ANYLIMIT &amp; \text{1 if any functional/activity limitation}&amp;
41.4 &amp; 7,826  \\
\ \ \text{limitation} &amp;  &amp; \text{0 if otherwise }&amp; 58.6 &amp; 4,746
\\ \hline \text{Income} &amp;&amp;  \text{Reference level is high income} &amp; 21.7 &amp;  7,271 \\
\text{compared to} &amp; MINCOME &amp; \text{1 if middle income} &amp; 26.8 &amp;  5,851 \\
\text{poverty line} &amp; LINCOME &amp; \text{1 if low income} &amp; 16.6 &amp; 6,909  \\
&amp; NPOOR &amp; \text{1 if near poor} &amp; 7.0 &amp; 5,546
\\
&amp; POORNEG &amp; \text{if poor/negative income} &amp; 28.0 &amp; 4,097
\\ \hline \text{Insurance} &amp; INSURE &amp; \text{1 if covered by public/private health}
&amp;91.1 &amp;  5,943 \\
\ \ \text{coverage} &amp;  &amp; \ \ \text{insurance in any month of 2003} &amp;  &amp;
\\
&amp;  &amp; \text{0 if have no health insurance in 2003} &amp; 8.9 &amp; 2,668
\\ \hline
Total &amp;  &amp;  &amp; 100.0 &amp; 5,695 \\ \hline
\end{array}
}
\]</span></p>
<h5 style="text-align: center;">
<a id="displayCode.Table13.1Silly" href="javascript:togglecode('toggleCode.Table13.1Silly','displayCode.Table13.1Silly');"><i><strong></strong></i></a>
</h5>
<div id="toggleCode.Table13.1Silly" style="display: none">
<div class="sourceCode" id="cb111"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb111-1"><a href="C13GLM.html#cb111-1" tabindex="-1"></a>knitr<span class="sc">::</span><span class="fu">kable</span>(<span class="dv">2</span>, <span class="at">caption =</span> <span class="st">&quot;Silly. Create a table just to update the counter...&quot;</span>)</span></code></pre></div>
<table>
<caption><span id="tab:unnamed-chunk-173">Table 13.2: </span>Silly. Create a table just to update the counter…</caption>
<thead>
<tr class="header">
<th align="right">x</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="right">2</td>
</tr>
</tbody>
</table>
<div class="sourceCode" id="cb112"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb112-1"><a href="C13GLM.html#cb112-1" tabindex="-1"></a>knitr<span class="sc">::</span><span class="fu">kable</span>(<span class="dv">2</span>, <span class="at">caption =</span> <span class="st">&quot;Silly.&quot;</span>)</span></code></pre></div>
<table>
<caption><span id="tab:unnamed-chunk-174">Table 13.3: </span>Silly.</caption>
<thead>
<tr class="header">
<th align="right">x</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="right">2</td>
</tr>
</tbody>
</table>
<div class="sourceCode" id="cb113"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb113-1"><a href="C13GLM.html#cb113-1" tabindex="-1"></a>knitr<span class="sc">::</span><span class="fu">kable</span>(<span class="dv">2</span>, <span class="at">caption =</span> <span class="st">&quot;Silly. &quot;</span>)</span></code></pre></div>
<table>
<caption><span id="tab:unnamed-chunk-175">Table 13.4: </span>Silly.</caption>
<thead>
<tr class="header">
<th align="right">x</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="right">2</td>
</tr>
</tbody>
</table>
</div>
<h5 style="text-align: center;">
<a id="displayCode.Tab135.Hide" href="javascript:togglecode('toggleCode.Tab135.Hide','displayCode.Tab135.Hide');"><i><strong>R Code to Produce Table 13.5</strong></i></a>
</h5>
<div id="toggleCode.Tab135.Hide" style="display: none">
<p>As noted in the preface, most of the code for the book, written about 2008, was in SAS. The illustrative code provided here, in <code>R</code>, exhibits some slight discrepancies from the original.</p>
<div class="sourceCode" id="cb114"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb114-1"><a href="C13GLM.html#cb114-1" tabindex="-1"></a>Hexpend <span class="ot">&lt;-</span> <span class="fu">read.csv</span>(<span class="st">&quot;CSVData/HealthExpend.csv&quot;</span>, <span class="at">header=</span><span class="cn">TRUE</span>)</span>
<span id="cb114-2"><a href="C13GLM.html#cb114-2" tabindex="-1"></a><span class="co">#  Table 13.5</span></span>
<span id="cb114-3"><a href="C13GLM.html#cb114-3" tabindex="-1"></a><span class="co">#Hexpend$POSEXP &lt;- 1*(Hexpend$EXPENDIP&gt;0)</span></span>
<span id="cb114-4"><a href="C13GLM.html#cb114-4" tabindex="-1"></a>HexpendPos  <span class="ot">&lt;-</span> <span class="fu">subset</span>(Hexpend, EXPENDIP <span class="sc">&gt;</span> <span class="dv">0</span>)</span>
<span id="cb114-5"><a href="C13GLM.html#cb114-5" tabindex="-1"></a></span>
<span id="cb114-6"><a href="C13GLM.html#cb114-6" tabindex="-1"></a><span class="co">#  CREATE A SHORT FUNCTION TO SAVE WORK</span></span>
<span id="cb114-7"><a href="C13GLM.html#cb114-7" tabindex="-1"></a>fun2 <span class="ot">&lt;-</span> <span class="cf">function</span>(group_var, summary_vars){</span>
<span id="cb114-8"><a href="C13GLM.html#cb114-8" tabindex="-1"></a>    <span class="co"># Convert group_var and summary_vars to character if they are not</span></span>
<span id="cb114-9"><a href="C13GLM.html#cb114-9" tabindex="-1"></a>  group_var <span class="ot">&lt;-</span> <span class="fu">as.character</span>(<span class="fu">substitute</span>(group_var))</span>
<span id="cb114-10"><a href="C13GLM.html#cb114-10" tabindex="-1"></a>  summary_vars <span class="ot">&lt;-</span> <span class="fu">as.character</span>(<span class="fu">substitute</span>(summary_vars))</span>
<span id="cb114-11"><a href="C13GLM.html#cb114-11" tabindex="-1"></a>temp <span class="ot">&lt;-</span> doBy<span class="sc">::</span><span class="fu">summaryBy</span>(</span>
<span id="cb114-12"><a href="C13GLM.html#cb114-12" tabindex="-1"></a>  <span class="at">formula =</span> <span class="fu">as.formula</span>(<span class="fu">paste</span>(summary_vars, <span class="st">&quot;~&quot;</span>, group_var)),</span>
<span id="cb114-13"><a href="C13GLM.html#cb114-13" tabindex="-1"></a>        <span class="at">data =</span> HexpendPos, </span>
<span id="cb114-14"><a href="C13GLM.html#cb114-14" tabindex="-1"></a>           <span class="at">FUN =</span> <span class="cf">function</span>(x) { <span class="fu">c</span>(<span class="at">m =</span> <span class="fu">median</span>(x), <span class="at">num =</span> <span class="fu">length</span>(x)) } )</span>
<span id="cb114-15"><a href="C13GLM.html#cb114-15" tabindex="-1"></a>temp1 <span class="ot">&lt;-</span> temp[,<span class="fu">c</span>(<span class="dv">1</span>,<span class="dv">3</span>,<span class="dv">2</span>)]</span>
<span id="cb114-16"><a href="C13GLM.html#cb114-16" tabindex="-1"></a>temp1[,<span class="dv">2</span>] <span class="ot">&lt;-</span> <span class="fu">round</span>(<span class="dv">100</span><span class="sc">*</span>temp1[,<span class="dv">2</span>]<span class="sc">/</span><span class="fu">length</span>(HexpendPos<span class="sc">$</span>EXPENDIP), <span class="at">digits=</span><span class="dv">1</span>)</span>
<span id="cb114-17"><a href="C13GLM.html#cb114-17" tabindex="-1"></a><span class="fu">colnames</span>(temp1) <span class="ot">&lt;-</span> <span class="cn">NULL</span></span>
<span id="cb114-18"><a href="C13GLM.html#cb114-18" tabindex="-1"></a>temp1[,<span class="dv">1</span>] <span class="ot">&lt;-</span> <span class="fu">as.character</span>(temp1[,<span class="dv">1</span>])</span>
<span id="cb114-19"><a href="C13GLM.html#cb114-19" tabindex="-1"></a><span class="fu">return</span>(<span class="fu">as.matrix</span>(temp1) )</span>
<span id="cb114-20"><a href="C13GLM.html#cb114-20" tabindex="-1"></a>}</span>
<span id="cb114-21"><a href="C13GLM.html#cb114-21" tabindex="-1"></a></span>
<span id="cb114-22"><a href="C13GLM.html#cb114-22" tabindex="-1"></a>var1 <span class="ot">&lt;-</span> <span class="fu">fun2</span>(GENDER,EXPENDIP)</span>
<span id="cb114-23"><a href="C13GLM.html#cb114-23" tabindex="-1"></a>var2 <span class="ot">&lt;-</span> <span class="fu">fun2</span>(RACE,EXPENDIP)</span>
<span id="cb114-24"><a href="C13GLM.html#cb114-24" tabindex="-1"></a>var3 <span class="ot">&lt;-</span> <span class="fu">fun2</span>(REGION,EXPENDIP)</span>
<span id="cb114-25"><a href="C13GLM.html#cb114-25" tabindex="-1"></a>var4 <span class="ot">&lt;-</span> <span class="fu">fun2</span>(EDUC,EXPENDIP)</span>
<span id="cb114-26"><a href="C13GLM.html#cb114-26" tabindex="-1"></a>var5 <span class="ot">&lt;-</span> <span class="fu">fun2</span>(PHSTAT,EXPENDIP)</span>
<span id="cb114-27"><a href="C13GLM.html#cb114-27" tabindex="-1"></a><span class="co">#var6 &lt;- fun2(MPOOR,EXPENDIP)</span></span>
<span id="cb114-28"><a href="C13GLM.html#cb114-28" tabindex="-1"></a>var7 <span class="ot">&lt;-</span> <span class="fu">fun2</span>(ANYLIMIT,EXPENDIP)</span>
<span id="cb114-29"><a href="C13GLM.html#cb114-29" tabindex="-1"></a>var8 <span class="ot">&lt;-</span> <span class="fu">fun2</span>(INCOME,EXPENDIP)</span>
<span id="cb114-30"><a href="C13GLM.html#cb114-30" tabindex="-1"></a>var9 <span class="ot">&lt;-</span> <span class="fu">fun2</span>(insure,EXPENDIP)</span>
<span id="cb114-31"><a href="C13GLM.html#cb114-31" tabindex="-1"></a></span>
<span id="cb114-32"><a href="C13GLM.html#cb114-32" tabindex="-1"></a>tableout <span class="ot">&lt;-</span> <span class="fu">rbind</span>(var1, var2, var3, var4,</span>
<span id="cb114-33"><a href="C13GLM.html#cb114-33" tabindex="-1"></a>                  var5, var7, var8, var9)</span>
<span id="cb114-34"><a href="C13GLM.html#cb114-34" tabindex="-1"></a></span>
<span id="cb114-35"><a href="C13GLM.html#cb114-35" tabindex="-1"></a><span class="fu">TableGen1</span>(<span class="at">TableData=</span>tableout, </span>
<span id="cb114-36"><a href="C13GLM.html#cb114-36" tabindex="-1"></a>         <span class="at">TextTitle=</span><span class="st">&#39;Median Expenditures by Explanatory Variable  Based on a Sample of $n=157$ with Positive Expenditures&#39;</span>, </span>
<span id="cb114-37"><a href="C13GLM.html#cb114-37" tabindex="-1"></a>         <span class="at">Align=</span><span class="st">&#39;crr&#39;</span>, <span class="at">ColumnSpec=</span><span class="dv">1</span><span class="sc">:</span><span class="dv">3</span>, <span class="at">ColWidth =</span> ColWidth4 )</span></code></pre></div>
<table class=" lightable-classic table table-striped table-condensed" style="font-size: 12px; font-family: Cambria; width: auto !important; margin-left: auto; margin-right: auto; margin-left: auto; margin-right: auto;">
<caption style="font-size: initial !important;">
<span id="tab:Tab1135">Table 13.5: </span><strong>Median Expenditures by Explanatory Variable Based on a Sample of <span class="math inline">\(n=157\)</span> with Positive Expenditures</strong>
</caption>
<tbody>
<tr>
<td style="text-align:left;width: 2.5cm; border-right:1px solid;">
1
</td>
<td style="text-align:center;width: 1.8cm; ">
0
</td>
<td style="text-align:right;width: 1.8cm; ">
28
</td>
<td style="text-align:right;width: 1.8cm; ">
7312.695
</td>
</tr>
<tr>
<td style="text-align:left;width: 2.5cm; border-right:1px solid;">
2
</td>
<td style="text-align:center;width: 1.8cm; ">
1
</td>
<td style="text-align:right;width: 1.8cm; ">
72
</td>
<td style="text-align:right;width: 1.8cm; ">
5546.470
</td>
</tr>
<tr>
<td style="text-align:left;width: 2.5cm; border-right:1px solid;">
1
</td>
<td style="text-align:center;width: 1.8cm; ">
ASIAN
</td>
<td style="text-align:right;width: 1.8cm; ">
2.5
</td>
<td style="text-align:right;width: 1.8cm; ">
4002.735
</td>
</tr>
<tr>
<td style="text-align:left;width: 2.5cm; border-right:1px solid;">
2
</td>
<td style="text-align:center;width: 1.8cm; ">
BLACK
</td>
<td style="text-align:right;width: 1.8cm; ">
19.7
</td>
<td style="text-align:right;width: 1.8cm; ">
6100.200
</td>
</tr>
<tr>
<td style="text-align:left;width: 2.5cm; border-right:1px solid;">
3
</td>
<td style="text-align:center;width: 1.8cm; ">
NATIV
</td>
<td style="text-align:right;width: 1.8cm; ">
1.9
</td>
<td style="text-align:right;width: 1.8cm; ">
2310.320
</td>
</tr>
<tr>
<td style="text-align:left;width: 2.5cm; border-right:1px solid;">
4
</td>
<td style="text-align:center;width: 1.8cm; ">
OTHER
</td>
<td style="text-align:right;width: 1.8cm; ">
1.9
</td>
<td style="text-align:right;width: 1.8cm; ">
4050.650
</td>
</tr>
<tr>
<td style="text-align:left;width: 2.5cm; border-right:1px solid;">
5
</td>
<td style="text-align:center;width: 1.8cm; ">
WHITE
</td>
<td style="text-align:right;width: 1.8cm; ">
73.9
</td>
<td style="text-align:right;width: 1.8cm; ">
5725.325
</td>
</tr>
<tr>
<td style="text-align:left;width: 2.5cm; border-right:1px solid;">
1
</td>
<td style="text-align:center;width: 1.8cm; ">
MIDWEST
</td>
<td style="text-align:right;width: 1.8cm; ">
21.7
</td>
<td style="text-align:right;width: 1.8cm; ">
7998.660
</td>
</tr>
<tr>
<td style="text-align:left;width: 2.5cm; border-right:1px solid;">
2
</td>
<td style="text-align:center;width: 1.8cm; ">
NORTHEAST
</td>
<td style="text-align:right;width: 1.8cm; ">
18.5
</td>
<td style="text-align:right;width: 1.8cm; ">
5832.860
</td>
</tr>
<tr>
<td style="text-align:left;width: 2.5cm; border-right:1px solid;">
3
</td>
<td style="text-align:center;width: 1.8cm; ">
SOUTH
</td>
<td style="text-align:right;width: 1.8cm; ">
40.8
</td>
<td style="text-align:right;width: 1.8cm; ">
5595.295
</td>
</tr>
<tr>
<td style="text-align:left;width: 2.5cm; border-right:1px solid;">
4
</td>
<td style="text-align:center;width: 1.8cm; ">
WEST
</td>
<td style="text-align:right;width: 1.8cm; ">
19.1
</td>
<td style="text-align:right;width: 1.8cm; ">
4296.540
</td>
</tr>
<tr>
<td style="text-align:left;width: 2.5cm; border-right:1px solid;">
1
</td>
<td style="text-align:center;width: 1.8cm; ">
COLLEGE
</td>
<td style="text-align:right;width: 1.8cm; ">
23.6
</td>
<td style="text-align:right;width: 1.8cm; ">
5610.76
</td>
</tr>
<tr>
<td style="text-align:left;width: 2.5cm; border-right:1px solid;">
2
</td>
<td style="text-align:center;width: 1.8cm; ">
HIGHSCH
</td>
<td style="text-align:right;width: 1.8cm; ">
43.3
</td>
<td style="text-align:right;width: 1.8cm; ">
5907.33
</td>
</tr>
<tr>
<td style="text-align:left;width: 2.5cm; border-right:1px solid;">
3
</td>
<td style="text-align:center;width: 1.8cm; ">
LHIGHSC
</td>
<td style="text-align:right;width: 1.8cm; ">
33.1
</td>
<td style="text-align:right;width: 1.8cm; ">
5338.04
</td>
</tr>
<tr>
<td style="text-align:left;width: 2.5cm; border-right:1px solid;">
1
</td>
<td style="text-align:center;width: 1.8cm; ">
EXCE
</td>
<td style="text-align:right;width: 1.8cm; ">
16.6
</td>
<td style="text-align:right;width: 1.8cm; ">
5277.160
</td>
</tr>
<tr>
<td style="text-align:left;width: 2.5cm; border-right:1px solid;">
2
</td>
<td style="text-align:center;width: 1.8cm; ">
FAIR
</td>
<td style="text-align:right;width: 1.8cm; ">
10.2
</td>
<td style="text-align:right;width: 1.8cm; ">
5228.465
</td>
</tr>
<tr>
<td style="text-align:left;width: 2.5cm; border-right:1px solid;">
3
</td>
<td style="text-align:center;width: 1.8cm; ">
GOOD
</td>
<td style="text-align:right;width: 1.8cm; ">
31.2
</td>
<td style="text-align:right;width: 1.8cm; ">
5031.960
</td>
</tr>
<tr>
<td style="text-align:left;width: 2.5cm; border-right:1px solid;">
4
</td>
<td style="text-align:center;width: 1.8cm; ">
POOR
</td>
<td style="text-align:right;width: 1.8cm; ">
17.2
</td>
<td style="text-align:right;width: 1.8cm; ">
10447.130
</td>
</tr>
<tr>
<td style="text-align:left;width: 2.5cm; border-right:1px solid;">
5
</td>
<td style="text-align:center;width: 1.8cm; ">
VGOO
</td>
<td style="text-align:right;width: 1.8cm; ">
24.8
</td>
<td style="text-align:right;width: 1.8cm; ">
5546.470
</td>
</tr>
<tr>
<td style="text-align:left;width: 2.5cm; border-right:1px solid;">
1
</td>
<td style="text-align:center;width: 1.8cm; ">
0
</td>
<td style="text-align:right;width: 1.8cm; ">
58.6
</td>
<td style="text-align:right;width: 1.8cm; ">
4745.89
</td>
</tr>
<tr>
<td style="text-align:left;width: 2.5cm; border-right:1px solid;">
2
</td>
<td style="text-align:center;width: 1.8cm; ">
1
</td>
<td style="text-align:right;width: 1.8cm; ">
41.4
</td>
<td style="text-align:right;width: 1.8cm; ">
7825.50
</td>
</tr>
<tr>
<td style="text-align:left;width: 2.5cm; border-right:1px solid;">
1
</td>
<td style="text-align:center;width: 1.8cm; ">
HINCOME
</td>
<td style="text-align:right;width: 1.8cm; ">
21.7
</td>
<td style="text-align:right;width: 1.8cm; ">
7270.780
</td>
</tr>
<tr>
<td style="text-align:left;width: 2.5cm; border-right:1px solid;">
2
</td>
<td style="text-align:center;width: 1.8cm; ">
LINCOME
</td>
<td style="text-align:right;width: 1.8cm; ">
16.6
</td>
<td style="text-align:right;width: 1.8cm; ">
6908.720
</td>
</tr>
<tr>
<td style="text-align:left;width: 2.5cm; border-right:1px solid;">
3
</td>
<td style="text-align:center;width: 1.8cm; ">
MINCOME
</td>
<td style="text-align:right;width: 1.8cm; ">
26.8
</td>
<td style="text-align:right;width: 1.8cm; ">
5851.160
</td>
</tr>
<tr>
<td style="text-align:left;width: 2.5cm; border-right:1px solid;">
4
</td>
<td style="text-align:center;width: 1.8cm; ">
NPOOR
</td>
<td style="text-align:right;width: 1.8cm; ">
7.0
</td>
<td style="text-align:right;width: 1.8cm; ">
5546.470
</td>
</tr>
<tr>
<td style="text-align:left;width: 2.5cm; border-right:1px solid;">
5
</td>
<td style="text-align:center;width: 1.8cm; ">
POOR
</td>
<td style="text-align:right;width: 1.8cm; ">
28.0
</td>
<td style="text-align:right;width: 1.8cm; ">
4096.545
</td>
</tr>
<tr>
<td style="text-align:left;width: 2.5cm; border-right:1px solid;">
1
</td>
<td style="text-align:center;width: 1.8cm; ">
0
</td>
<td style="text-align:right;width: 1.8cm; ">
8.9
</td>
<td style="text-align:right;width: 1.8cm; ">
2668.37
</td>
</tr>
<tr>
<td style="text-align:left;width: 2.5cm; border-right:1px solid;">
2
</td>
<td style="text-align:center;width: 1.8cm; ">
1
</td>
<td style="text-align:right;width: 1.8cm; ">
91.1
</td>
<td style="text-align:right;width: 1.8cm; ">
5943.25
</td>
</tr>
</tbody>
</table>
</div>
<p><a href="C13GLM.html#Tab135">Table 13.5</a> uses medians as opposed to means
because the distribution of expenditures is skewed to the right.
This is evident in Figure <a href="C13GLM.html#fig:Fig131">13.1</a> that provides
a smooth histogram (known as a “kernel density estimate”, see
Section 15.2) for inpatient expenditures. For skewed distributions,
the median often provides a more helpful idea of the center of the
distribution than the mean. The distribution is even more skewed
than suggested by this figure because the largest expenditure (which
is $607,800) is omitted from the graphical display.</p>

<div class="figure" style="text-align: center"><span style="display:block;" id="fig:Fig131"></span>
<img src="RegressionMarkdown_files/figure-html/Fig131-1.png" alt="Smooth Empirical Histogram of Positive Inpatient Expenditures. The largest expenditure is omitted." width="60%" />
<p class="caption">
Figure 13.1: <strong>Smooth Empirical Histogram of Positive Inpatient Expenditures.</strong> The largest expenditure is omitted.
</p>
</div>
<h5 style="text-align: center;">
<a id="displayCode.Fig131.Hide" href="javascript:togglecode('toggleCode.Fig131.Hide','displayCode.Fig131.Hide');"><i><strong>R Code to Produce Figure 13.1</strong></i></a>
</h5>
<div id="toggleCode.Fig131.Hide" style="display: none">
<div class="sourceCode" id="cb115"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb115-1"><a href="C13GLM.html#cb115-1" tabindex="-1"></a><span class="co"># TEMPORARILY REMOVE OBS # 58</span></span>
<span id="cb115-2"><a href="C13GLM.html#cb115-2" tabindex="-1"></a>Hexpend <span class="ot">&lt;-</span> <span class="fu">read.csv</span>(<span class="st">&quot;CSVData/HealthExpend.csv&quot;</span>, <span class="at">header=</span><span class="cn">TRUE</span>)</span>
<span id="cb115-3"><a href="C13GLM.html#cb115-3" tabindex="-1"></a>Hexpend58 <span class="ot">&lt;-</span> <span class="fu">subset</span>(Hexpend, <span class="sc">!</span>(EXPENDIP<span class="sc">&gt;</span><span class="dv">600000</span>))</span>
<span id="cb115-4"><a href="C13GLM.html#cb115-4" tabindex="-1"></a><span class="fu">plot</span>(<span class="fu">density</span>(Hexpend58<span class="sc">$</span>EXPENDIP), <span class="at">main=</span><span class="st">&quot;&quot;</span>, <span class="at">xlab=</span><span class="st">&quot;Expenditures&quot;</span>)</span>
<span id="cb115-5"><a href="C13GLM.html#cb115-5" tabindex="-1"></a></span>
<span id="cb115-6"><a href="C13GLM.html#cb115-6" tabindex="-1"></a><span class="co">#hist(Hexpend58$EXPENDIP, main=&quot;&quot;, xlab=&quot;Expenditures&quot;)</span></span></code></pre></div>
</div>
<p>A gamma regression model using a logarithmic link was fit to
inpatient expenditures using all explanatory variables. The results of this model fit appear in <a href="C13GLM.html#Tab136">Table 13.6</a>. Here, we see that many of the potentially important determinants of
medical expenditures are not statistically significant. This is
common in expenditure analysis, where variables help predict the
frequency although are not as useful in explaining severity.</p>
<p>Because of collinearity, we have seen in linear models that having
too many variables in a fitted model can lead to statistical
insignificance of important variables and even cause signs to be
reversed. For a simpler model, we removed the Asian, Native American
and the uninsured variables because they account for a small subset
of our sample. We also used only the POOR variable for self-reported
health status and only POORNEG for income, essentially reducing
these categorical variables to binary variables. <a href="C13GLM.html#Tab136">Table 13.6</a>, under the heading “Reduced Model,”
reports the result of this model fit. This model has almost the same
goodness of fit statistic, <span class="math inline">\(AIC\)</span>, suggesting that it is a reasonable
alternative. Under the reduced model fit, the variables COUNTIP
(inpatient count), AGE, COLLEGE and POORNEG, are statistically
significant variables. For these significant variables, the signs
are intuitively appealing. For example, the positive coefficient
associated with COUNTIP means that as the number of inpatient visits
increases, the total expenditures increases, as anticipated.</p>
<p>For another alternative model specification, <a href="C13GLM.html#Tab136">Table 13.6</a> also shows a fit of an inverse gaussian model with a logarithmic link. From the <span class="math inline">\(AIC\)</span> statistic, we see that
this model does not fit nearly as well as the gamma regression
model. All variables are statistically insignificant, making it
difficult to interpret this model.</p>
<p><a id=Tab136></a></p>
<p><span id="Tab136">Table 13.6</span>. <strong>Comparison of Gamma and Inverse Gaussian Regression Models</strong></p>
<p><span class="math display">\[
\small{
\begin{array}{l|rr|rr|rr}
\hline &amp; \text{Gamma} &amp; &amp;\text{Gamma}&amp;&amp;\text{Inverse}&amp;\text{Gaussian} \\
\hline &amp; \text{Full} &amp;\text{Model}&amp;
\text{Reduced} &amp; \text{Model}&amp;\text{Reduced}&amp;\text{Model} \\ \hline
&amp; \textit{Parameter} &amp;  &amp; Parameter &amp;  &amp; Parameter &amp;  \\
\text{Effect} &amp; Estimate &amp; t\text{-value} &amp; Estimate &amp; t\text{-value} &amp;
Estimate &amp; t\text{-value} \\ \hline
Intercept &amp;      6.891 &amp;     13.080 &amp;      7.859 &amp;     17.951 &amp;      6.544 &amp;      3.024 \\
   COUNTIP &amp;      0.681 &amp;      6.155 &amp;      0.672 &amp;      5.965 &amp;      1.263 &amp;      0.989 \\
       AGE &amp;      0.021 &amp;      3.024 &amp;      0.015 &amp;      2.439 &amp;      0.018 &amp;      0.727 \\
    GENDER &amp;     -0.228 &amp;     -1.263 &amp;     -0.118 &amp;     -0.648 &amp;      0.363 &amp;      0.482 \\
     ASIAN &amp;     -0.506 &amp;     -1.029 &amp;            &amp;            &amp;            &amp;            \\
     BLACK &amp;     -0.331 &amp;     -1.656 &amp;     -0.258 &amp;     -1.287 &amp;     -0.321 &amp;     -0.577 \\
    NATIVE &amp;     -1.220 &amp;     -2.217 &amp;            &amp;            &amp;            &amp;            \\
NORTHEAST &amp;     -0.372 &amp;     -1.548 &amp;     -0.214 &amp;     -0.890 &amp;      0.109 &amp;      0.165 \\
   MIDWEST &amp;      0.255 &amp;      1.062 &amp;      0.448 &amp;      1.888 &amp;      0.399 &amp;      0.654 \\
     SOUTH &amp;      0.010 &amp;      0.047 &amp;      0.108 &amp;      0.516 &amp;      0.164 &amp;      0.319
     \\\hline
   COLLEGE &amp;     -0.413 &amp;     -1.723 &amp;     -0.469 &amp;     -2.108 &amp;     -0.367 &amp;     -0.606 \\
HIGHSCHOOL &amp;     -0.155 &amp;     -0.827 &amp;     -0.210 &amp;     -1.138 &amp;     -0.039 &amp;     -0.078 \\\hline
      POOR &amp;     -0.003 &amp;     -0.010 &amp;      0.167 &amp;      0.706 &amp;      0.167 &amp;      0.258 \\
      FAIR &amp;     -0.194 &amp;     -0.641 &amp;            &amp;            &amp;            &amp;            \\
      GOOD &amp;      0.041 &amp;      0.183 &amp;            &amp;            &amp;            &amp;            \\
     VGOOD &amp;      0.000 &amp;      0.000 &amp;            &amp;            &amp;            &amp;            \\
   MNHPOOR &amp;     -0.396 &amp;     -1.634 &amp;     -0.314 &amp;     -1.337 &amp;     -0.378 &amp;     -0.642 \\
  ANYLIMIT &amp;      0.010 &amp;      0.053 &amp;      0.052 &amp;      0.266 &amp;      0.218 &amp;      0.287 \\\hline
   MINCOME &amp;      0.114 &amp;      0.522 &amp;            &amp;            &amp;            &amp;            \\
   LINCOME &amp;      0.536 &amp;      2.148 &amp;            &amp;            &amp;            &amp;            \\
     NPOOR &amp;      0.453 &amp;      1.243 &amp;            &amp;            &amp;            &amp;            \\
   POORNEG &amp;     -0.078 &amp;     -0.308 &amp;     -0.406 &amp;     -2.129 &amp;     -0.356 &amp;     -0.595 \\
    INSURE &amp;      0.794 &amp;      3.068 &amp;            &amp;            &amp;            &amp;            \\\hline
     Scale &amp;      1.409 &amp;      9.779 &amp;      1.280 &amp;      9.854 &amp;      0.026 &amp;     17.720 \\ \hline
Log-Likelihood &amp; -1,558.67  &amp;&amp;  -1,567.93   &amp;&amp; -1,669.02  \\
AIC &amp;   3,163.34 &amp;&amp;  3,163.86 &amp;&amp;  3,366.04 \\
\hline
\end{array}
}
\]</span></p>
<h5 style="text-align: center;">
<a id="displayCode.Tab136.Hide" href="javascript:togglecode('toggleCode.Tab136.Hide','displayCode.Tab136.Hide');"><i><strong>R Code to Produce Table 13.6</strong></i></a>
</h5>
<div id="toggleCode.Tab136.Hide" style="display: none">
<p>As noted in the preface, most of the code for the book, written about 2008, was in SAS. The illustrative code provided here, in <code>R</code>, exhibits some slight discrepancies from the original.</p>
<div class="sourceCode" id="cb116"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb116-1"><a href="C13GLM.html#cb116-1" tabindex="-1"></a>Hexpend <span class="ot">&lt;-</span> <span class="fu">read.csv</span>(<span class="st">&quot;CSVData/HealthExpend.csv&quot;</span>, <span class="at">header=</span><span class="cn">TRUE</span>)</span>
<span id="cb116-2"><a href="C13GLM.html#cb116-2" tabindex="-1"></a><span class="co">#  Table 13.6</span></span>
<span id="cb116-3"><a href="C13GLM.html#cb116-3" tabindex="-1"></a><span class="co">#POSEXP = 1*(Hexpend$EXPENDIP&gt;0)</span></span>
<span id="cb116-4"><a href="C13GLM.html#cb116-4" tabindex="-1"></a>HexpendPos  <span class="ot">&lt;-</span> <span class="fu">subset</span>(Hexpend, EXPENDIP <span class="sc">&gt;</span> <span class="dv">0</span>)</span>
<span id="cb116-5"><a href="C13GLM.html#cb116-5" tabindex="-1"></a></span>
<span id="cb116-6"><a href="C13GLM.html#cb116-6" tabindex="-1"></a><span class="co">#  MODEL WITH ALL VARIABLES</span></span>
<span id="cb116-7"><a href="C13GLM.html#cb116-7" tabindex="-1"></a><span class="co">#  HAD TO INCREASE THE DEFAULT NUMBER OF ITERATIONS FOR CONVERGENCE</span></span>
<span id="cb116-8"><a href="C13GLM.html#cb116-8" tabindex="-1"></a>model1 <span class="ot">=</span> <span class="fu">glm</span>(EXPENDIP<span class="sc">~</span>COUNTIP<span class="sc">+</span>AGE<span class="sc">+</span>GENDER</span>
<span id="cb116-9"><a href="C13GLM.html#cb116-9" tabindex="-1"></a>    <span class="sc">+</span><span class="fu">factor</span>(RACE)<span class="sc">+</span><span class="fu">factor</span>(REGION)<span class="sc">+</span><span class="fu">factor</span>(EDUC)<span class="sc">+</span><span class="fu">factor</span>(PHSTAT)</span>
<span id="cb116-10"><a href="C13GLM.html#cb116-10" tabindex="-1"></a>    <span class="sc">+</span>MNHPOOR<span class="sc">+</span>ANYLIMIT<span class="sc">+</span><span class="fu">factor</span>(INCOME)<span class="sc">+</span>insure, </span>
<span id="cb116-11"><a href="C13GLM.html#cb116-11" tabindex="-1"></a>    <span class="at">control =</span> <span class="fu">glm.control</span>(<span class="at">maxit =</span> <span class="dv">50</span>), </span>
<span id="cb116-12"><a href="C13GLM.html#cb116-12" tabindex="-1"></a>    <span class="at">data=</span>HexpendPos,<span class="at">family=</span><span class="fu">Gamma</span>(<span class="at">link=</span><span class="st">&quot;log&quot;</span>))</span>
<span id="cb116-13"><a href="C13GLM.html#cb116-13" tabindex="-1"></a>output1 <span class="ot">&lt;-</span> <span class="fu">summary</span>(model1 )</span>
<span id="cb116-14"><a href="C13GLM.html#cb116-14" tabindex="-1"></a>tidy_model <span class="ot">&lt;-</span> broom<span class="sc">::</span><span class="fu">tidy</span>(model1)</span>
<span id="cb116-15"><a href="C13GLM.html#cb116-15" tabindex="-1"></a><span class="fu">kable</span>(tidy_model, <span class="at">format =</span> <span class="st">&quot;html&quot;</span>, <span class="at">digits =</span> <span class="dv">3</span>, </span>
<span id="cb116-16"><a href="C13GLM.html#cb116-16" tabindex="-1"></a>      <span class="at">table.attr =</span> <span class="st">&quot;class=&#39;table table-striped&#39;&quot;</span>, </span>
<span id="cb116-17"><a href="C13GLM.html#cb116-17" tabindex="-1"></a>      <span class="at">caption =</span> <span class="st">&quot;Summary of the Gamma Regression Model&quot;</span>)</span></code></pre></div>
<table class="table table-striped">
<caption>
<span id="tab:Tab1136">Table 13.6: </span>Summary of the Gamma Regression Model
</caption>
<thead>
<tr>
<th style="text-align:left;">
term
</th>
<th style="text-align:right;">
estimate
</th>
<th style="text-align:right;">
std.error
</th>
<th style="text-align:right;">
statistic
</th>
<th style="text-align:right;">
p.value
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">
(Intercept)
</td>
<td style="text-align:right;">
6.211
</td>
<td style="text-align:right;">
0.664
</td>
<td style="text-align:right;">
9.352
</td>
<td style="text-align:right;">
0.000
</td>
</tr>
<tr>
<td style="text-align:left;">
COUNTIP
</td>
<td style="text-align:right;">
0.682
</td>
<td style="text-align:right;">
0.094
</td>
<td style="text-align:right;">
7.287
</td>
<td style="text-align:right;">
0.000
</td>
</tr>
<tr>
<td style="text-align:left;">
AGE
</td>
<td style="text-align:right;">
0.021
</td>
<td style="text-align:right;">
0.007
</td>
<td style="text-align:right;">
2.989
</td>
<td style="text-align:right;">
0.003
</td>
</tr>
<tr>
<td style="text-align:left;">
GENDER
</td>
<td style="text-align:right;">
-0.238
</td>
<td style="text-align:right;">
0.172
</td>
<td style="text-align:right;">
-1.382
</td>
<td style="text-align:right;">
0.169
</td>
</tr>
<tr>
<td style="text-align:left;">
factor(RACE)BLACK
</td>
<td style="text-align:right;">
0.182
</td>
<td style="text-align:right;">
0.512
</td>
<td style="text-align:right;">
0.356
</td>
<td style="text-align:right;">
0.722
</td>
</tr>
<tr>
<td style="text-align:left;">
factor(RACE)NATIV
</td>
<td style="text-align:right;">
-0.697
</td>
<td style="text-align:right;">
0.732
</td>
<td style="text-align:right;">
-0.953
</td>
<td style="text-align:right;">
0.343
</td>
</tr>
<tr>
<td style="text-align:left;">
factor(RACE)OTHER
</td>
<td style="text-align:right;">
0.726
</td>
<td style="text-align:right;">
0.707
</td>
<td style="text-align:right;">
1.027
</td>
<td style="text-align:right;">
0.306
</td>
</tr>
<tr>
<td style="text-align:left;">
factor(RACE)WHITE
</td>
<td style="text-align:right;">
0.513
</td>
<td style="text-align:right;">
0.481
</td>
<td style="text-align:right;">
1.066
</td>
<td style="text-align:right;">
0.289
</td>
</tr>
<tr>
<td style="text-align:left;">
factor(REGION)NORTHEAST
</td>
<td style="text-align:right;">
-0.628
</td>
<td style="text-align:right;">
0.238
</td>
<td style="text-align:right;">
-2.642
</td>
<td style="text-align:right;">
0.009
</td>
</tr>
<tr>
<td style="text-align:left;">
factor(REGION)SOUTH
</td>
<td style="text-align:right;">
-0.256
</td>
<td style="text-align:right;">
0.199
</td>
<td style="text-align:right;">
-1.288
</td>
<td style="text-align:right;">
0.200
</td>
</tr>
<tr>
<td style="text-align:left;">
factor(REGION)WEST
</td>
<td style="text-align:right;">
-0.261
</td>
<td style="text-align:right;">
0.233
</td>
<td style="text-align:right;">
-1.118
</td>
<td style="text-align:right;">
0.266
</td>
</tr>
<tr>
<td style="text-align:left;">
factor(EDUC)HIGHSCH
</td>
<td style="text-align:right;">
0.261
</td>
<td style="text-align:right;">
0.193
</td>
<td style="text-align:right;">
1.356
</td>
<td style="text-align:right;">
0.177
</td>
</tr>
<tr>
<td style="text-align:left;">
factor(EDUC)LHIGHSC
</td>
<td style="text-align:right;">
0.411
</td>
<td style="text-align:right;">
0.225
</td>
<td style="text-align:right;">
1.828
</td>
<td style="text-align:right;">
0.070
</td>
</tr>
<tr>
<td style="text-align:left;">
factor(PHSTAT)FAIR
</td>
<td style="text-align:right;">
-0.165
</td>
<td style="text-align:right;">
0.314
</td>
<td style="text-align:right;">
-0.524
</td>
<td style="text-align:right;">
0.601
</td>
</tr>
<tr>
<td style="text-align:left;">
factor(PHSTAT)GOOD
</td>
<td style="text-align:right;">
0.063
</td>
<td style="text-align:right;">
0.227
</td>
<td style="text-align:right;">
0.276
</td>
<td style="text-align:right;">
0.783
</td>
</tr>
<tr>
<td style="text-align:left;">
factor(PHSTAT)POOR
</td>
<td style="text-align:right;">
0.026
</td>
<td style="text-align:right;">
0.298
</td>
<td style="text-align:right;">
0.088
</td>
<td style="text-align:right;">
0.930
</td>
</tr>
<tr>
<td style="text-align:left;">
factor(PHSTAT)VGOO
</td>
<td style="text-align:right;">
0.018
</td>
<td style="text-align:right;">
0.237
</td>
<td style="text-align:right;">
0.076
</td>
<td style="text-align:right;">
0.939
</td>
</tr>
<tr>
<td style="text-align:left;">
MNHPOOR
</td>
<td style="text-align:right;">
-0.397
</td>
<td style="text-align:right;">
0.238
</td>
<td style="text-align:right;">
-1.664
</td>
<td style="text-align:right;">
0.098
</td>
</tr>
<tr>
<td style="text-align:left;">
ANYLIMIT
</td>
<td style="text-align:right;">
-0.006
</td>
<td style="text-align:right;">
0.189
</td>
<td style="text-align:right;">
-0.031
</td>
<td style="text-align:right;">
0.976
</td>
</tr>
<tr>
<td style="text-align:left;">
factor(INCOME)LINCOME
</td>
<td style="text-align:right;">
0.551
</td>
<td style="text-align:right;">
0.257
</td>
<td style="text-align:right;">
2.147
</td>
<td style="text-align:right;">
0.034
</td>
</tr>
<tr>
<td style="text-align:left;">
factor(INCOME)MINCOME
</td>
<td style="text-align:right;">
0.123
</td>
<td style="text-align:right;">
0.211
</td>
<td style="text-align:right;">
0.583
</td>
<td style="text-align:right;">
0.561
</td>
</tr>
<tr>
<td style="text-align:left;">
factor(INCOME)NPOOR
</td>
<td style="text-align:right;">
0.463
</td>
<td style="text-align:right;">
0.354
</td>
<td style="text-align:right;">
1.308
</td>
<td style="text-align:right;">
0.193
</td>
</tr>
<tr>
<td style="text-align:left;">
factor(INCOME)POOR
</td>
<td style="text-align:right;">
-0.068
</td>
<td style="text-align:right;">
0.251
</td>
<td style="text-align:right;">
-0.273
</td>
<td style="text-align:right;">
0.785
</td>
</tr>
<tr>
<td style="text-align:left;">
insure
</td>
<td style="text-align:right;">
0.789
</td>
<td style="text-align:right;">
0.257
</td>
<td style="text-align:right;">
3.068
</td>
<td style="text-align:right;">
0.003
</td>
</tr>
</tbody>
</table>
<div class="sourceCode" id="cb117"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb117-1"><a href="C13GLM.html#cb117-1" tabindex="-1"></a><span class="co">#  REDUCED MODEL</span></span>
<span id="cb117-2"><a href="C13GLM.html#cb117-2" tabindex="-1"></a>HexpendPos<span class="sc">$</span>BLACK <span class="ot">=</span> (HexpendPos<span class="sc">$</span>RACE <span class="sc">==</span> <span class="st">&quot;BLACK&quot;</span>)</span>
<span id="cb117-3"><a href="C13GLM.html#cb117-3" tabindex="-1"></a>HexpendPos<span class="sc">$</span>POOR <span class="ot">=</span> (HexpendPos<span class="sc">$</span>PHSTAT <span class="sc">==</span> <span class="st">&quot;POOR&quot;</span>)</span>
<span id="cb117-4"><a href="C13GLM.html#cb117-4" tabindex="-1"></a>HexpendPos<span class="sc">$</span>POORNEG <span class="ot">=</span> (HexpendPos<span class="sc">$</span>INCOME <span class="sc">==</span> <span class="st">&quot;POOR&quot;</span>)</span>
<span id="cb117-5"><a href="C13GLM.html#cb117-5" tabindex="-1"></a>model2 <span class="ot">&lt;-</span> <span class="fu">glm</span>(EXPENDIP <span class="sc">~</span> COUNTIP <span class="sc">+</span> AGE <span class="sc">+</span> GENDER <span class="sc">+</span></span>
<span id="cb117-6"><a href="C13GLM.html#cb117-6" tabindex="-1"></a>    <span class="fu">factor</span>(BLACK) <span class="sc">+</span> <span class="fu">factor</span>(REGION) <span class="sc">+</span> <span class="fu">factor</span>(EDUC) <span class="sc">+</span> <span class="fu">factor</span>(POOR) <span class="sc">+</span></span>
<span id="cb117-7"><a href="C13GLM.html#cb117-7" tabindex="-1"></a>    MNHPOOR <span class="sc">+</span> ANYLIMIT <span class="sc">+</span> <span class="fu">factor</span>(POORNEG), </span>
<span id="cb117-8"><a href="C13GLM.html#cb117-8" tabindex="-1"></a>    <span class="at">data=</span>HexpendPos, <span class="at">family=</span><span class="fu">Gamma</span>(<span class="at">link=</span><span class="st">&quot;log&quot;</span>) )</span>
<span id="cb117-9"><a href="C13GLM.html#cb117-9" tabindex="-1"></a><span class="co">#summary(model2) </span></span>
<span id="cb117-10"><a href="C13GLM.html#cb117-10" tabindex="-1"></a><span class="fu">anova</span>(model1, model2)</span></code></pre></div>
<p>Analysis of Deviance Table</p>
<p>Model 1: EXPENDIP ~ COUNTIP + AGE + GENDER + factor(RACE) + factor(REGION) +
factor(EDUC) + factor(PHSTAT) + MNHPOOR + ANYLIMIT + factor(INCOME) +
insure
Model 2: EXPENDIP ~ COUNTIP + AGE + GENDER + factor(BLACK) + factor(REGION) +
factor(EDUC) + factor(POOR) + MNHPOOR + ANYLIMIT + factor(POORNEG)
Resid. Df Resid. Dev Df Deviance
1 133 123.954<br />
2 143 137.876 -10 -13.9218</p>
<div class="sourceCode" id="cb118"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb118-1"><a href="C13GLM.html#cb118-1" tabindex="-1"></a>Hexpend58 <span class="ot">&lt;-</span> <span class="fu">subset</span>(HexpendPos, <span class="sc">!</span>(EXPENDIP<span class="sc">&gt;</span><span class="dv">600000</span>))</span>
<span id="cb118-2"><a href="C13GLM.html#cb118-2" tabindex="-1"></a><span class="co">#  REDUCED MODEL - INVERSE GAUSSIAN </span></span>
<span id="cb118-3"><a href="C13GLM.html#cb118-3" tabindex="-1"></a><span class="co">#  DOES NOT WANT TO CONVERGE !!</span></span>
<span id="cb118-4"><a href="C13GLM.html#cb118-4" tabindex="-1"></a><span class="co"># model3 &lt;- glm(EXPENDIP ~ COUNTIP + AGE + GENDER +</span></span>
<span id="cb118-5"><a href="C13GLM.html#cb118-5" tabindex="-1"></a><span class="co">#     factor(BLACK) + factor(REGION) + factor(EDUC) + factor(POOR) +</span></span>
<span id="cb118-6"><a href="C13GLM.html#cb118-6" tabindex="-1"></a><span class="co">#     MNHPOOR + ANYLIMIT + factor(POORNEG), </span></span>
<span id="cb118-7"><a href="C13GLM.html#cb118-7" tabindex="-1"></a><span class="co">#     data=Hexpend58, family=inverse.gaussian(link = &quot;log&quot;) )</span></span>
<span id="cb118-8"><a href="C13GLM.html#cb118-8" tabindex="-1"></a><span class="co"># summary(model3)</span></span>
<span id="cb118-9"><a href="C13GLM.html#cb118-9" tabindex="-1"></a><span class="co">#   ALSO PROBLEMS WITH family=inverse.gaussian(link = &quot;1/mu^2&quot;)</span></span></code></pre></div>
</div>
</div>
<div id="S:Sec135" class="section level2 hasAnchor" number="13.5">
<h2><span class="header-section-number">13.5</span> Residuals<a href="C13GLM.html#S:Sec135" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>One way of selecting an appropriate model is to fit a tentative
specification and analyze ways of improving it. This diagnostic
method relies on residuals. In the linear model, we defined
residuals as the response minus the corresponding fitted values. In
a GLM context, we refer to these as “raw residuals,” denoted as
<span class="math inline">\(y_i - \widehat{\mu}_i\)</span>. As we have seen, residuals are useful for:</p>
<ul>
<li>discovering new covariates or the effects of nonlinear patterns in existing covariates,</li>
<li>identifying poorly fitting observations,</li>
<li>quantifying the effects of individual observations on model parameters and</li>
<li>revealing other model patterns, such as heteroscedasticity or time trends.</li>
</ul>
<p>As this section emphasizes, residuals are also the building blocks
for many goodness of fit statistics.</p>
<p>As we saw in Section 11.1 on binary dependent variables, analysis of
raw residuals can be meaningless in some nonlinear contexts. Cox and
Snell (1968, 1971) introduced a general notion of residuals that is
more useful in nonlinear models than the simple raw residuals. For
our applications, we assume that <span class="math inline">\(y_i\)</span> has a distribution function
F(<span class="math inline">\(\cdot\)</span>) that is indexed by explanatory variables <span class="math inline">\(\mathbf{x}_i\)</span>
and a vector of parameters <span class="math inline">\(\boldsymbol \theta\)</span> denoted as
F(<span class="math inline">\(\mathbf{x}_i,\boldsymbol \theta\)</span>). Here, the distribution
function is common to all observations but the distribution varies
through the explanatory variables. The vector of parameters
<span class="math inline">\(\boldsymbol \theta\)</span> includes the regression parameters <span class="math inline">\(\boldsymbol \beta\)</span> as well as scale parameters. With knowledge of F(<span class="math inline">\(\cdot\)</span>), we
now assume that a new function R(<span class="math inline">\(\cdot\)</span>) can be computed such that
<span class="math inline">\(\varepsilon_i = \mathrm{R}(y_i; \mathbf{x}_i,\boldsymbol \theta)\)</span>,
where <span class="math inline">\(\varepsilon_i\)</span> are identically and independently distributed.
Here, the function R(<span class="math inline">\(\cdot\)</span>) depends on explanatory variables
<span class="math inline">\(\mathbf{x}_i\)</span> and parameters <span class="math inline">\(\boldsymbol \theta\)</span>. The Cox-Snell
residuals are then <span class="math inline">\(e_i = \mathrm{R}(y_i; \mathbf{x}_i,\widehat{\boldsymbol \theta})\)</span>. If the model is
well-specified and the parameter estimates <span class="math inline">\(\widehat{\boldsymbol \theta}\)</span> are close to the model parameters <span class="math inline">\(\boldsymbol \theta\)</span>,
then the residuals <span class="math inline">\(e_i\)</span> should be close to i.i.d.</p>
<p>To illustrate, in the linear model we use the residual function
<span class="math inline">\(\mathrm{R}(y_i; \mathbf{x}_i,\boldsymbol \theta) = y_i - \mathbf{x}_i^{\prime} \boldsymbol \beta =y_i - \mu_i = \varepsilon_i,\)</span> resulting in (ordinary) raw residuals. Another
choice is to rescale by the standard deviation
<span class="math display">\[
\mathrm{R}(y_i; \mathbf{x}_i,\boldsymbol \theta) = \frac{y_i -
\mu_i}{\sqrt{\mathrm{Var~} y_i}} ,
\]</span>
that yields <em>Pearson residuals</em>.</p>
<p>Another type of residual is based on a first transforming the
response with a known function h(<span class="math inline">\(\cdot\)</span>),
<span class="math display">\[
\mathrm{R}(y_i; \mathbf{x}_i,\boldsymbol \theta) =
\frac{\mathrm{h}(y_i) - \mathrm{E~}
\mathrm{h}(y_i)}{\sqrt{\mathrm{Var~}\mathrm{h}(y_i)}} .
\]</span>
Choosing the function so that h(<span class="math inline">\(y_i\)</span>) is approximately normally
distributed yields <em>Anscombe residuals</em>. Another popular choice
is to choose the transform so that the variance is stabilized. <a href="C13GLM.html#Tab137">Table 13.7</a> gives transforms for the binomial,
Poisson and gamma distributions.</p>
<p><a id=Tab137></a></p>
<p><span id="Tab137">Table 13.7</span>. <strong>Approximate Normality and Variance-Stabilizing Transforms</strong></p>
<p><span class="math display">\[
\small{
\begin{array}{lcc}
\hline
\text{Distribution} &amp; \text{Approximate Normality} &amp; \text{Variance-Stabilizing} \\
&amp; \text{Transform} &amp; \text{Transform} \\
\hline \text{Binomial}(m,p) &amp;
\frac{\mathrm{h}_B(y/m)-[\mathrm{h}_B(p)+(p(1-p))^{-1/3}(2p-1)/(6m)]}{(p(1-p)^{1/6}/\sqrt{m}}
&amp;
\frac{\sin^{-1}(\sqrt{y/m})-\sin^{-1}(\sqrt{p})}{a/(2\sqrt{m})} \\
\text{Poisson}(\lambda) &amp; 1.5 \lambda^{-1/6} \left[
y^{2/3}-(\lambda^{2/3}-\lambda^{-1/3}/9) \right]  &amp;
2(\sqrt{y}-\sqrt{\lambda})\\
\text{Gamma}(\alpha, \gamma) &amp;  3 \alpha^{1/6} \left[
(y/\gamma)^{1/3}-(\alpha^{1/3}-\alpha^{-2/3}/9) \right]
&amp; \text{Not considered}\\
\hline \\
\end{array}
}
\]</span>
<em>Note</em>: <span class="math inline">\(\mathrm{h}_B(u) = \int_0^u s^{-1/3} (1-s)^{-1/3}ds\)</span> is the incomplete beta function evaluated at <span class="math inline">\((2/3, 2/3)\)</span>, up to a scalar constant. <em>Source: Pierce and Schafer (1986)</em>.</p>
<p>Another widely used choice in GLM studies are <em>deviance residuals</em>, defined as
<span class="math display">\[
\mathrm{sign} \left(y_i -
\widehat{\mu}_i \right)
\sqrt{2  \left( \ln \mathrm{f}(y_i;\theta_{i,SAT}) - \ln
\mathrm{f}(y_i;\widehat{\theta}_{i})
\right)}.
\]</span>
Section <a href="C13GLM.html#S:Sec1333">13.3.3</a> introduced the parameter estimates of the
saturated model, <span class="math inline">\(\theta_{i,SAT}\)</span>. As discussed by Pierce and
Schafer (1986), deviance residuals are very close to Anscombe
residuals in many cases - we can check deviance residuals for
approximate normality. Further, deviance residuals can be defined
readily for any GLM model and are easy to compute.</p>
</div>
<div id="S:Sec136" class="section level2 hasAnchor" number="13.6">
<h2><span class="header-section-number">13.6</span> Tweedie Distribution<a href="C13GLM.html#S:Sec136" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>We have seen that the natural exponential family includes continuous
distributions, such as the normal and gamma, as well as discrete
distributions, such as the binomial and Poisson. It also includes
distributions that are mixtures of discrete and continuous
components. In insurance claims modeling, the most widely used
mixture is the Tweedie (1984) distribution. It has a positive mass
at zero representing no claims and a continuous component for
positive values representing the amount of a claim.</p>
<p>The Tweedie distribution is defined as a Poisson sum of gamma random
variables, known as an <em>aggregate loss</em> in actuarial science.
Specifically, suppose that <span class="math inline">\(N\)</span> has a Poisson distribution with mean
<span class="math inline">\(\lambda\)</span>, representing the number of claims. Let {<span class="math inline">\(y_j\)</span>} be an
i.i.d. sequence, independent of <span class="math inline">\(N\)</span>, with each <span class="math inline">\(y_j\)</span> having a gamma
distribution with parameters <span class="math inline">\(\alpha\)</span> and <span class="math inline">\(\gamma\)</span>, representing the
amount of a claim. Then, <span class="math inline">\(S_N = y_1 + \ldots + y_N\)</span> is Poisson sum
of gammas. Section 16.5 will discuss aggregate loss models in
further detail. This section focuses on the important special case
of the Tweedie distribution.</p>
<p>To understand the mixture aspect of the Tweedie distribution, first
note that it is straightforward to compute the probability of zero
claims as
<span class="math display">\[
\Pr ( S_N=0) = \Pr (N=0) = e^{-\lambda}.
\]</span>
The distribution function can be computed using conditional
expectations,
<span class="math display">\[
\Pr ( S_N \le y) = e^{-\lambda}+\sum_{n=1}^{\infty} \Pr(N=n)
\Pr(S_n \le y), ~~~~~y \geq 0.
\]</span>
Because the sum of i.i.d. gammas is a gamma, <span class="math inline">\(S_n\)</span> (not <span class="math inline">\(S_N\)</span>) has a
gamma distribution with parameters <span class="math inline">\(n\alpha\)</span> and <span class="math inline">\(\gamma\)</span>. Thus, for
<span class="math inline">\(y&gt;0\)</span>, the density of the Tweedie distribution is
<span class="math display" id="eq:eq139">\[\begin{equation}
\mathrm{f}_{S}(y) = \sum_{n=1}^{\infty} e^{-\lambda} \frac{\lambda
^n}{n!} \frac{\gamma^{n \alpha}}{\Gamma(n \alpha)} y^{n \alpha -1}
e^{-y \gamma}.
\tag{13.9}
\end{equation}\]</span></p>
<p>At first glance, this density does not appear to be a member of the linear exponential family given in equation <a href="C13GLM.html#eq:eq132">(13.2)</a>. To see the relationship, we first calculate the moments using iterated expectations as
<span class="math display" id="eq:eq1310">\[\begin{equation}
\mathrm{E~}S_N = \lambda
\frac{\alpha}{\gamma}~~~~~~\mathrm{and}~~~~~ \mathrm{Var~}S_N =
\frac{\lambda \alpha}{\gamma^2} (1+\alpha).
\tag{13.10}
\end{equation}\]</span>
Now, define three parameters <span class="math inline">\(\mu, \phi, p\)</span> through the relations
<span class="math display">\[
\lambda = \frac{\mu^{2-p}}{\phi (2-p)},~~~~~~\alpha =
\frac{2-p}{p-1}~~~~~~\mathrm{and}~~~~~ \frac{1}{\gamma} =
\phi(p-1)\mu^{p-1}.
\]</span>
Inserting these new parameters in equation <a href="C13GLM.html#eq:eq139">(13.9)</a> yields
<span class="math display" id="eq:eq1311">\[\begin{equation}
\mathrm{f}_{S}(y) = \exp \left[ \frac{-1}{\phi}
\left( \frac{\mu^{2-p}}{2-p} + \frac{y}{(p-1)\mu^{p-1}} \right)
+ S(y,\phi) \right].
\tag{13.11}
\end{equation}\]</span>
We leave the calculation of <span class="math inline">\(S(y,\phi)\)</span> as an exercise.</p>
<p>Thus, the Tweedie distribution is a member of the linear exponential
family. Easy calculations show that
<span class="math display" id="eq:eq1312">\[\begin{equation}
\mathrm{E~}S_N = \mu~~~~~~\mathrm{and}~~~~~ \mathrm{Var~}S_N = \phi
\mu^p,
\tag{13.12}
\end{equation}\]</span>
where <span class="math inline">\(1&lt;p&lt;2.\)</span> Examining our variance function <a href="C13GLM.html#Tab131">Table 13.1</a>, the Tweedie distribution can also be
viewed as a choice that is intermediate between the Poisson and the
gamma distributions.</p>
<div class="blackboxvideo">
<p><strong>Video: Section Summary</strong></p>
</div>
<center>
<iframe id="kaltura_player" src="https://cdnapisec.kaltura.com/p/1660902/embedPlaykitJs/uiconf_id/55063162?iframeembed=true&amp;entry_id=1_tqyhb3o1&amp;config%5Bprovider%5D=%7B%22widgetId%22%3A%221_1m5au8rv%22%7D&amp;config%5Bplayback%5D=%7B%22startTime%22%3A0%7D" style="width: 576px;height: 324px;border: 0;" allowfullscreen webkitallowfullscreen mozAllowFullScreen allow="autoplay *; fullscreen *; encrypted-media *" title="13.4 TweedieModels">
</iframe>
</center>
</div>
<div id="S:Sec137" class="section level2 hasAnchor" number="13.7">
<h2><span class="header-section-number">13.7</span> Further Reading and References<a href="C13GLM.html#S:Sec137" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>A more extensive treatment of GLM may be found in the classic work
by McCullagh and Nelder (1989) or the gentler introduction by Dobson
(2002). de Jong and Heller (2008) provide a recent book-long
introduction to GLMs with a special insurance emphasis.</p>
<p>GLMs have enjoyed substantial attention from property and casualty
(general) insurance practicing actuaries recently, see Anderson et
al. (2004) and Clark and Thayer (2004) for introductions.</p>
<p>Mildenhall (1999) provides a systematic analysis of the connection
between GLM models and algorithms for assessing different rating
plans. Fu and Wu (2008) provide an updated version, introducing a
broader class of iterative algorithms that tie nicely to GLM models.</p>
<p>For further information on the Tweedie distribution, see
J{}rgensen and de Souza (1994) and Smyth and J{}rgensen (2002).</p>
<p><strong>Chapter References</strong></p>
<ul>
<li>Anderson, Duncan, Sholom Feldblum, Claudine Modlin, Doris
Schirmacher, Ernesto Schirmacher and Neeza Thandi (2004). A
practitioner’s guide to generalized linear models. <em>Casualty Actuarial Society 2004 Discussion Papers</em> 1-116, Casualty Actuarial Society.</li>
<li>Baxter, L. A., S. M. Coutts and G. A. F. Ross (1980). Applications of linear models in motor insurance. <em>Proceedings of the 21st International Congress of Actuaries.</em> Zurich. pp. 11-29.</li>
<li>Clark, David R. and Charles A. Thayer (2004). A primer on the exponential family of distributions. <em>Casualty Actuarial Society 2004 Discussion Papers</em> 117-148, Casualty Actuarial Society.</li>
<li>Cox, David R. and E. J. Snell (1968). A general definition of
residuals. <em>Journal of the Royal Statistical Society</em>, Series
B, 30, 248-275.</li>
<li>Cox, David R. and E. J. Snell (1971). On test statistics computed
from residuals. <em>Biometrika</em> 71, 589-594.</li>
<li>Dobson, Annette J. (2002). <em>An Introduction to Generalized Linear Models, Second Edition.</em> Chapman &amp; Hall, London.</li>
<li>Fu, Luyang and Cheng-sheng Peter Wu (2008). General iteration algorithm for classification ratemaking. <em>Variance</em> 1(2), 193-213, Casualty Actuarial Society.</li>
<li>de Jong, Piet and Gillian Z. Heller (2008). <em>Generalized Linear Models for Insurance Data</em>. Cambridge University Press, Cambridge, UK.</li>
<li>J{}rgensen, Bent and Marta C. Paes de Souza (1994). Fitting Tweedie’s compound Poisson model to insurance claims data. <em>Scandinavian Actuarial Journal</em> 1994;1, 69-93.</li>
<li>McCullagh, P. and J.A. Nelder (1989). <em>Generalized Linear Models, Second Edition.</em> Chapman &amp; Hall, London.</li>
<li>Mildenhall, Stephen J. (1999). A systematic relationship between minimum bias and generalized linear models. <em>Casualty Actuarial Society Proceedings</em> 86, Casualty Actuarial Society.</li>
<li>Pierce, Donald A. and Daniel W. Schafer (1986). Residuals in generalized linear models. <em>Journal of the American Statistical Association</em> 81, 977-986.</li>
<li>Smyth, Gordon K. and Bent J{}rgensen (2002). Fitting Tweedie’s compound Poisson model to insurance claims data: Dispersion modelling. <em>Astin Bulletin</em> 32(1), 143-157.</li>
<li>Tweedie, M. C. K. (1984). An index which distinguishes between some important exponential families. In <em>Statistics: Applications and New Directions. </em>Proceedings of the Indian Statistical Golden Jubilee International Conference* (Editors J. K. Ghosh and J. Roy), pp. 579-604. Indian Statistical Institute, Calcutta.</li>
</ul>
</div>
<div id="S:Sec138" class="section level2 hasAnchor" number="13.8">
<h2><span class="header-section-number">13.8</span> Exercises<a href="C13GLM.html#S:Sec138" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>13.1 Verify the entries in <a href="C13GLM.html#Tab138">Table 13.8</a> for the gamma
distribution. Specifically:</p>
<ol style="list-style-type: lower-alpha">
<li><p>Show that the gamma is a member of the linear exponential family
of distributions.</p></li>
<li><p>Describe the components of the linear exponential family ($
, , b(), S(y,)$) in terms of the parameters of
the gamma distribution.</p></li>
<li><p>Show that the mean and variance of the gamma and linear
exponential family distributions agree.</p></li>
</ol>
<p>13.2 <strong>Ratemaking Classification</strong>. This exercise considers the
data described in the Section <a href="C13GLM.html#S:Sec1322">13.2.2</a> ratemaking
classification example using data in <a href="C13GLM.html#Tab133">Table 13.3</a>.</p>
<ol style="list-style-type: lower-alpha">
<li><p>Fit a gamma regression model using a log-link function with claim
counts as weights (<span class="math inline">\(w_i\)</span>). Use the categorical explanatory variables
age group and vehicle use to estimate expected average severity.</p></li>
<li><p>Based on your estimated parameters in part (a), verify the
estimated expected severities in <a href="C13GLM.html#Tab134">Table 13.4</a>.</p></li>
</ol>
<p>13.3 Verify that the Tweedie distribution is a member of the linear exponential family of distributions by checking equation <a href="C13GLM.html#eq:eq139">(13.9)</a>.
In particular, provide an expression for <span class="math inline">\(S(y,\phi)\)</span> (note that
<span class="math inline">\(S(y,\phi)\)</span> also depends on <span class="math inline">\(p\)</span> but not on <span class="math inline">\(\mu\)</span>). You may wish to
see Clark and Thayer (2004) to check your work. Further, verify the
moments in equation <a href="C13GLM.html#eq:eq1310">(13.10)</a>.</p>
</div>
<div id="S:Sec139" class="section level2 hasAnchor" number="13.9">
<h2><span class="header-section-number">13.9</span> Technical Supplements - Exponential Family<a href="C13GLM.html#S:Sec139" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<div id="S:Sec1391" class="section level3 hasAnchor" number="13.9.1">
<h3><span class="header-section-number">13.9.1</span> Linear Exponential Family of Distributions<a href="C13GLM.html#S:Sec1391" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>The distribution of the random variable <span class="math inline">\(y\)</span> may be discrete,
continuous or a mixture. Thus, f(.) in equation
<a href="C13GLM.html#eq:eq132">(13.2)</a> may be interpreted to be a density or mass
function, depending on the application. <a href="C13GLM.html#Tab138">Table 13.8</a>
provides several examples, including the normal, binomial and
Poisson distributions.</p>
<p><a id=Tab138></a></p>
<p><span id="Tab138">Table 13.8</span>. <strong>Selected Distributions of the One-Parameter Exponential Family</strong></p>
<p><span class="math display">\[
\scriptsize{
\begin{array}{l|ccccc}
\hline
             &amp;             &amp; \text{Density or} &amp; &amp; &amp; \\
\text{Distribution} &amp; \text{Parameters} &amp; \text{Mass Function} &amp; \text{Components} &amp; \mathrm{E}~y &amp; \mathrm{Var}~y \\
\hline \text{General} &amp; \theta,~ \phi &amp;
\exp \left( \frac{y\theta -b(\theta )}{\phi }
+S\left( y,\phi \right) \right)
&amp; \theta,~ \phi, b(\theta), S(y, \phi) &amp; b^{\prime}(\theta) &amp; b^{\prime \prime}(\theta) \phi \\
\text{Normal} &amp; \mu, \sigma^2 &amp;
\frac{1}{\sigma \sqrt{2\pi }}\exp \left( -
\frac{(y-\mu )^{2}}{2\sigma ^{2}}\right) &amp; \mu, \sigma^2,
\frac{\theta^2}{2}, - \left(\frac{y^2}{2\phi} + \frac{\ln(2 \pi
\phi)}{2} \right) &amp; \theta=\mu &amp; \phi= \sigma^2  \\
\text{Binomal} &amp; \pi &amp; {n \choose y} \pi ^y (1-\pi)^{n-y} &amp; \ln
\left(\frac{\pi}{1-\pi} \right), 1, n \ln(1+e^{\theta} ),  &amp; n
\frac {e^{\theta}}{1+e^{\theta}}  &amp; n \frac
{e^{\theta}}{(1+e^{\theta})^2}  \\
&amp;  &amp;  &amp;  \ln {n \choose y}  &amp;  = n \pi &amp;  = n \pi (1-\pi) \\
\text{Poisson} &amp; \lambda &amp;  \frac{\lambda^y}{y!} \exp(-\lambda)  &amp;
\ln \lambda, 1, e^{\theta}, - \ln (y!)  &amp; e^{\theta} = \lambda  &amp;
e^{\theta} = \lambda  \\
\text{Negative} &amp; r,p &amp;  \frac{\Gamma(y+r)}{y!
\Gamma(r)} p^r ( 1-p)^y &amp; \ln(1-p), 1, -r \ln(1-e^{\theta}), &amp;
\frac{r(1-p)}{p}
&amp; \frac{r(1-p)}{p^2}  \\
\ \ \ \text{Binomial}^{\ast} &amp; &amp; &amp; ~~~\ln \left[ \frac{\Gamma(y+r)}{y!
\Gamma(r)} \right] &amp;  = \mu  &amp;
= \mu+\mu^2/r
\\
\text{Gamma} &amp; \alpha, \gamma  &amp; \frac{\gamma ^ \alpha}{\Gamma (\alpha)}
y^{\alpha -1 }\exp(-y \gamma)  &amp; - \frac{\gamma}{\alpha},
\frac{1}{\alpha}, - \ln ( - \theta), -\phi^{-1} \ln \phi &amp;  -
\frac{1}{\theta} = \frac{\alpha}{\gamma}  &amp; \frac{\phi}{\theta ^2}
=
\frac{\alpha}{\gamma ^2}  \\
&amp; &amp; &amp;  - \ln \left( \Gamma(\phi ^{-1}) \right) +
(\phi^{-1} - 1) \ln y &amp; &amp; \\
\text{Inverse} &amp; \mu, \lambda &amp; \sqrt{\frac{\lambda}{2 \pi y^3}
} \exp \left(- \frac{\lambda (y-\mu)^2}{2 \mu^2 y} \right)  &amp;
-1/( 2\mu^2), 1/\lambda, -\sqrt{-2 \theta},  &amp;  \left(-2 \theta
\right)^{-1/2}  &amp; \phi (-2 \theta)^{-3/2}  \\
\ \ \  \text{Gaussian} &amp;  &amp; &amp;  \theta/(\phi y) - 0.5 \ln (\phi 2 \pi y^3 ) &amp; = \mu &amp; = \frac{\mu^3}{\lambda} \\
\text{Tweedie} &amp; &amp; \textit{See Section 13.6}\\
\hline  \\
\end{array}
}
\]</span>
<span class="math inline">\(^{\ast}\)</span> This assumes that the parameter <span class="math inline">\(r\)</span> is fixed but need not be an integer.</p>
</div>
<div id="S:Sec1392" class="section level3 hasAnchor" number="13.9.2">
<h3><span class="header-section-number">13.9.2</span> Moments<a href="C13GLM.html#S:Sec1392" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>To assess the moments of exponential families, it is convenient to
work with the moment generating function. For simplicity, we assume
that the random variable <span class="math inline">\(y\)</span> is continuous. Define the moment
generating function</p>
<p><span class="math display">\[\begin{eqnarray*}
M(s) &amp;=&amp; \mathrm{E}~ e^{sy} = \int \exp \left( sy+ \frac{y \theta -
b(\theta)}{\phi} + S(y, \phi) \right) dy \\
&amp;=&amp; \exp \left(\frac{b(\theta + s \phi) - b(\theta)}{\phi} \right)
\int \exp \left( \frac{y(\theta + s\phi) - b(\theta+s\phi)}{\phi} +
S(y, \phi) \right) dy \\
&amp;=&amp; \exp \left(\frac{b(\theta + s \phi) - b(\theta)}{\phi} \right),
\end{eqnarray*}\]</span>
because <span class="math inline">\(\int \exp \left( \frac{1}{\phi} \left[ y(\theta + s\phi) - b(\theta+s\phi) \right] + S(y, \phi) \right) dy=1\)</span>. With this
expression, we can generate the moments. Thus, for the mean, we have
<span class="math display">\[\begin{eqnarray*}
\mathrm{E}~ y &amp;=&amp; M^{\prime}(0) =  \left . \frac{\partial}{\partial
s} \exp \left(\frac{b(\theta + s \phi) - b(\theta)}{\phi} \right)
\right | _{s=0} \\
&amp;=&amp; \left[ b^{\prime}(\theta + s \phi ) \exp \left( \frac{b(\theta +
s \phi) - b(\theta)}{\phi} \right) \right] _{s=0} =
b^{\prime}(\theta).
\end{eqnarray*}\]</span></p>
<p>Similarly, for the second moment, we have
<span class="math display">\[\begin{eqnarray*}
M^{\prime \prime}(s) &amp;=&amp;  \frac{\partial}{\partial s} \left[
b^{\prime}(\theta + s \phi) \exp \left(\frac{b(\theta + s \phi) -
b(\theta)}{\phi} \right) \right]  \\
&amp;=&amp; \phi b^{\prime \prime}(\theta + s \phi) \exp
\left(\frac{b(\theta + s \phi) - b(\theta)}{\phi} \right) +
(b^{\prime}(\theta + s \phi))^2 \left(\frac{b(\theta + s \phi) -
b(\theta)}{\phi} \right).
\end{eqnarray*}\]</span>
This yields <span class="math inline">\(\mathrm{E}y^2 = M^{\prime \prime}(0)\)</span> <span class="math inline">\(= \phi b^{\prime \prime}(\theta) + (b^{\prime}(\theta))^2\)</span> and <span class="math inline">\(\mathrm{Var}~y =\phi b^{\prime \prime}(\theta)\)</span>.</p>
</div>
<div id="S:Sec1393" class="section level3 hasAnchor" number="13.9.3">
<h3><span class="header-section-number">13.9.3</span> Maximum Likelihood Estimation for General Links<a href="C13GLM.html#S:Sec1393" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>For general links, we no longer assume the relationship <span class="math inline">\(\theta_i=\mathbf{ x}_i^{\mathbf{\prime }}\boldsymbol \beta\)</span> but assume that
<span class="math inline">\(\boldsymbol \beta\)</span> is related to <span class="math inline">\(\theta_i\)</span> through the relations
<span class="math inline">\(\mu _i=b^{\prime }(\theta_i)\)</span> and $_i^{}= g( _i) $. We continue to assume
that the scale parameter varies by observation so that <span class="math inline">\(\phi_i = \phi/w_i\)</span>, where <span class="math inline">\(w_i\)</span> is a known weight function. Using equation
<a href="C13GLM.html#eq:eq134">(13.4)</a>, we have that the <span class="math inline">\(j\)</span>th element of the score
function is
<span class="math display">\[
\frac{\partial }{\partial \beta _{j}}\ln \mathrm{f}\left(
\mathbf{y}\right)
=\sum_{i=1}^n  \frac{\partial \theta_i}{\partial \beta _{j}}
\frac{y_i-\mu _i}{\phi _i} ,
\]</span>
because <span class="math inline">\(b^{\prime }(\theta_i)=\mu _i\)</span>. Now, use the chain rule and
the
relation <span class="math inline">\(\mathrm{Var~}y_i=\phi _ib^{\prime \prime }(\theta_i)\)</span> to get
<span class="math display">\[
\frac{\partial \mu _i}{\partial \beta _{j}}=\frac{\partial b^{\prime
}(\theta_i)}{\partial \beta _{j}}=b^{\prime \prime }(\theta_i)\frac{
\partial \theta_i}{\partial \beta _{j}}=\frac{\mathrm{Var~}y_i}{\phi
_i}\frac{\partial \theta_i}{\partial \beta _{j}}.
\]</span>
Thus, we have
<span class="math display">\[
\frac{\partial \theta_i}{\partial \beta _{j}}\frac{1}{\phi _i}=\frac{
\partial \mu _i}{\partial \beta _{j}}\frac{1}{\mathrm{Var~}y_i}.
\]</span>
This yields
<span class="math display">\[
\frac{\partial }{\partial \beta _{j}}\ln \mathrm{f}\left(
\mathbf{y}\right) =\sum_{i=1}^n  \frac{\partial \mu _i}{\partial
\beta _{j}}\left( \mathrm{Var~}y_i\right) ^{-1}\left( y_i-\mu
_i\right)  ,
\]</span>
that we summarize as
<span class="math display" id="eq:eq1313">\[\begin{equation}
\frac{\partial  L(\boldsymbol \beta) }{\partial \boldsymbol \beta }
=  \frac{\partial }{\partial \boldsymbol \beta }\ln \mathrm{f}\left(
\mathbf{y}\right) =\sum_{i=1}^n  \frac{\partial \mu _i}{\partial
\boldsymbol \beta}\left( \mathrm{Var~}y_i\right) ^{-1}\left( y_i-\mu
_i\right) ,
\tag{13.13}
\end{equation}\]</span>
which is known as the <em>generalized estimating equations</em> form.</p>
<p>Solving for roots of the score equation <span class="math inline">\(L(\boldsymbol \beta) = \mathbf{0}\)</span> yield maximum likelihood estimates, <span class="math inline">\(\mathbf{b}_{MLE}\)</span>.
In general, this requires iterative numerical methods. An exception
is the following special case.</p>
<hr />
<p><strong>Special Case. No Covariates</strong>. Suppose that <span class="math inline">\(k=1\)</span> and that
<span class="math inline">\(x_i =1\)</span>. Thus, <span class="math inline">\(\beta = \eta = g(\mu),\)</span> and <span class="math inline">\(\mu\)</span> does not depend
on <span class="math inline">\(i\)</span>. Then, from the relation <span class="math inline">\(\mathrm{Var~}y_i = \phi b^{\prime \prime}(\theta)/w_i\)</span> and equation <a href="C13GLM.html#eq:eq1313">(13.13)</a>, the
score function is
<span class="math display">\[
\frac{\partial  L( \beta) }{\partial \beta } = \frac{\partial
\mu}{\partial \beta} ~ \frac{1}{\phi b^{\prime \prime}(\theta)}
\sum_{i=1}^n w_i \left( y_i-\mu \right) .
\]</span>
Setting this equal zero yields <span class="math inline">\(\overline{y}_w = \sum_i w_i y_i / \sum_i w_i = \widehat{\mu}_{MLE} = g^{-1}(b_{MLE})\)</span>, or
<span class="math inline">\(b_{MLE}=g(\overline{y}_w),\)</span> where <span class="math inline">\(\overline{y}_w\)</span> is a weighted
average of <span class="math inline">\(y\)</span>’s.</p>
<hr />
<p>For the information matrix, use the independence among subjects and
equation <a href="C13GLM.html#eq:eq1313">(13.13)</a> to get
<span class="math display" id="eq:eq1314">\[\begin{eqnarray}
\mathbf{I}(\boldsymbol \beta)
&amp;=&amp; \mathrm{E~} \left( \frac{\partial
L(\boldsymbol \beta) }{\partial \boldsymbol \beta } \frac{\partial
L(\boldsymbol \beta) }{\partial \boldsymbol \beta ^{\prime}} \right) \nonumber \\
&amp;=&amp; \sum_{i=1}^n \frac{\partial \mu _i}{\partial \boldsymbol
\beta}~\mathrm{E} \left( \left( \mathrm{Var~}y_i\right) ^{-1}\left(
y_i-\mu _i\right)^2 \left( \mathrm{Var~}y_i\right) ^{-1}\right)
\frac{\partial \mu _i}{\partial
\boldsymbol \beta ^{\prime}} \nonumber \\
&amp;=&amp; \sum_{i=1}^n \frac{\partial \mu _i}{\partial \boldsymbol \beta}
\left( \mathrm{Var~}y_i\right) ^{-1} \frac{\partial \mu _i}{\partial
\boldsymbol \beta ^{\prime}} .
\tag{13.14}
\end{eqnarray}\]</span></p>
<p>Taking the square root of the diagonal elements of the inverse of <span class="math inline">\(\mathbf{I}(\boldsymbol \beta)\)</span>,
after inserting parameter estimates in the mean and variance functions, yields
<em>model-based standard errors</em>. For data where the correct specification of the variance component is in doubt, one replaces Var <span class="math inline">\(y_i\)</span> by an unbiased estimate <span class="math inline">\((y_i - \mu_i)^2\)</span>. The resulting estimator
<span class="math display">\[
se(b_j) = \sqrt{ jth~diagonal~element~of~
[\sum_{i=1}^n \frac{\partial \mu _i}{\partial \boldsymbol \beta}
(y_i - \mu_i)^{-2} \frac{\partial \mu _i}{\partial
\boldsymbol \beta ^{\prime}}
]|_{\boldsymbol \beta = \mathbf{b}_{MLE}}^{-1}}
\]</span></p>
<p>is known as the <em>empirical, or robust, standard error</em>.</p>
</div>
<div id="S:Sec1394" class="section level3 hasAnchor" number="13.9.4">
<h3><span class="header-section-number">13.9.4</span> Iterated Reweighted Least Squares<a href="C13GLM.html#S:Sec1394" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>To see how general iterative methods work, we use the canonical link
so that <span class="math inline">\(\eta_i = \theta_i\)</span>. Then, the score function is given in
equation <a href="C13GLM.html#eq:eq136">(13.6)</a> and the Hessian is in equation
<a href="C13GLM.html#eq:eq138">(13.8)</a>. Using the Newton-Raphson equation (11.15) in
Section 11.9 yields
<span class="math display" id="eq:eq1315">\[\begin{equation}
\boldsymbol \beta_{NEW} = \boldsymbol \beta_{OLD} -  \left(
\sum_{i=1}^n w_i b^{\prime \prime}(\mathbf{x}_i^{\prime} \boldsymbol
\beta _{OLD}) \mathbf{x}_i \mathbf{x}_i^{\prime} \right)^{-1} \left(
\sum_{i=1}^n w_i (y_i - b^{\prime}(\mathbf{x}_i^{\prime} \boldsymbol
\beta_{OLD})) \mathbf{x}_i \right) .
\tag{13.15}
\end{equation}\]</span>
Note that because the matrix of second derivatives is
non-stochastic, the Newton-Raphson is equivalent to the Fisher
scoring algorithm. As described in Section <a href="C13GLM.html#S:Sec1331">13.3.1</a>,
the estimation of <span class="math inline">\(\boldsymbol \beta\)</span> does not require knowledge of
<span class="math inline">\(\phi\)</span>.</p>
<p>Continue using the canonical link and define an “adjusted dependent variable”
<span class="math display">\[
y_i^{\ast}(\boldsymbol \beta) = \mathbf{x}_i^{\prime} \boldsymbol
\beta + \frac{y_i - b^{\prime}(\mathbf{x}_i^{\prime} \boldsymbol
\beta)}{b^{\prime \prime}(\mathbf{x}_i^{\prime} \boldsymbol \beta)}.
\]</span>
This has variance
<span class="math display">\[
\mathrm{Var~}y_i^{\ast}(\boldsymbol \beta) =
\frac{\mathrm{Var~}y_i}{(b^{\prime \prime}(\mathbf{x}_i^{\prime}
\boldsymbol \beta))^2} = \frac{\phi_i b^{\prime
\prime}(\mathbf{x}_i^{\prime} \boldsymbol \beta)}{(b^{\prime
\prime}(\mathbf{x}_i^{\prime} \boldsymbol \beta))^2} = \frac{\phi/
w_i }{b^{\prime \prime}(\mathbf{x}_i^{\prime} \boldsymbol \beta)}.
\]</span>
Use the new weight as the reciprocal of the variance,
<span class="math inline">\(w_i(\boldsymbol \beta)=w_i b^{\prime \prime}(\mathbf{x}_i^{\prime} \boldsymbol \beta) / \phi.\)</span> Then, with the expression
<span class="math display">\[
w_i \left(y_i - b^{\prime}(\mathbf{x}_i^{\prime} \boldsymbol
\beta)\right) = w_i b^{\prime \prime}(\mathbf{x}_i^{\prime}
\boldsymbol \beta) (y_i^{\ast}(\boldsymbol \beta) -
\mathbf{x}_i^{\prime} \boldsymbol \beta) = \phi w_i(\boldsymbol
\beta) (y_i^{\ast}(\boldsymbol \beta) - \mathbf{x}_i^{\prime}
\boldsymbol \beta),
\]</span>
from the Newton-Raphson iteration in equation
<a href="C13GLM.html#eq:eq1315">(13.15)</a>, we have</p>
<p><span class="math inline">\(\boldsymbol \beta_{NEW}\)</span>
<span class="math display">\[\begin{eqnarray*}
~ &amp;=&amp; \boldsymbol \beta_{OLD} -  \left( \sum_{i=1}^n w_i b^{\prime
\prime}(\mathbf{x}_i^{\prime} \boldsymbol \beta _{OLD}) \mathbf{x}_i
\mathbf{x}_i^{\prime} \right)^{-1} \left( \sum_{i=1}^n w_i (y_i -
b^{\prime}(\mathbf{x}_i^{\prime} \boldsymbol
\beta_{OLD})) \mathbf{x}_i \right) \\
&amp;=&amp; \boldsymbol \beta_{OLD} -  \left( \sum_{i=1}^n \phi
w_i(\boldsymbol \beta _{OLD}) \mathbf{x}_i \mathbf{x}_i^{\prime}
\right)^{-1} \left( \sum_{i=1}^n \phi w_i(\boldsymbol \beta _{OLD})
(y_i^{\ast}(\boldsymbol \beta_{OLD}) - \mathbf{x}_i^{\prime}
\boldsymbol \beta_{OLD})\mathbf{x}_i \right) \\
&amp;=&amp; \boldsymbol \beta_{OLD} -  \left( \sum_{i=1}^n w_i(\boldsymbol
\beta _{OLD}) \mathbf{x}_i \mathbf{x}_i^{\prime} \right)^{-1} \left(
\sum_{i=1}^n  w_i(\boldsymbol \beta _{OLD})\mathbf{x}_i
y_i^{\ast}(\boldsymbol \beta_{OLD}) - \sum_{i=1}^n w_i(\boldsymbol
\beta _{OLD})\mathbf{x}_i
\mathbf{x}_i^{\prime} \boldsymbol \beta_{OLD}) \right) \\
&amp;=&amp; \left( \sum_{i=1}^n  w_i(\boldsymbol \beta _{OLD}) \mathbf{x}_i
\mathbf{x}_i^{\prime} \right)^{-1} \left( \sum_{i=1}^n
w_i(\boldsymbol \beta _{OLD})\mathbf{x}_i y_i^{\ast}(\boldsymbol
\beta_{OLD})  \right).
\end{eqnarray*}\]</span>
Thus, this provides a method for iteration using weighted least
squares. Iterative reweighted least squares is also available for
general links using Fisher scoring, see McCullagh and Nelder (1989)
for further details.</p>

<!-- # Chap 1 -->
<!-- # Chap 2 -->
<!-- # Chap 3 -->
<!-- # Chap 4 -->
<!-- # Chap 5 -->
<!-- # Chap 6 -->
<!-- # Chap 7 -->
<!-- # Chap 8 -->
<!-- # Chap 9 -->
<!-- # Chap 10 -->
<!-- # Chap 11 -->
<!-- # Chap 12 -->
<!-- # Chap 13 -->
</div>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="C12Count.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="C14Survival.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": null,
"search": {
"engine": "fuse",
"options": null
},
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/latest.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
