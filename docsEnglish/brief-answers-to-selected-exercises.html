<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Brief Answers to Selected Exercises | Regression Modeling with Actuarial and Financial Applications</title>
  <meta name="description" content="HTML version of ‘Regression Modeling with Actuarial and Financial Applications’" />
  <meta name="generator" content="bookdown 0.39 and GitBook 2.6.7" />

  <meta property="og:title" content="Brief Answers to Selected Exercises | Regression Modeling with Actuarial and Financial Applications" />
  <meta property="og:type" content="book" />
  
  <meta property="og:description" content="HTML version of ‘Regression Modeling with Actuarial and Financial Applications’" />
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Brief Answers to Selected Exercises | Regression Modeling with Actuarial and Financial Applications" />
  
  <meta name="twitter:description" content="HTML version of ‘Regression Modeling with Actuarial and Financial Applications’" />
  

<meta name="author" content="Edward (Jed) Frees, University of Wisconsin - Madison, Australian National University" />



  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="appendices.html"/>

<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/anchor-sections-1.1.0/anchor-sections.css" rel="stylesheet" />
<link href="libs/anchor-sections-1.1.0/anchor-sections-hash.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.1.0/anchor-sections.js"></script>
<script src="libs/kePrint-0.0.1/kePrint.js"></script>
<link href="libs/lightable-0.0.1/lightable.css" rel="stylesheet" />
<link href="libs/bsTable-3.3.7/bootstrapTable.min.css" rel="stylesheet" />
<script src="libs/bsTable-3.3.7/bootstrapTable.js"></script>

<!-- Mathjax Version 2-->
<script type='text/x-mathjax-config'>
		MathJax.Hub.Config({
			extensions: ['tex2jax.js'],
			jax: ['input/TeX', 'output/HTML-CSS'],
			tex2jax: {
				inlineMath: [ ['$','$'], ['\\(','\\)'] ],
				displayMath: [ ['$$','$$'], ['\\[','\\]'] ],
				processEscapes: true
			},
			'HTML-CSS': { availableFonts: ['TeX'] }
		});
</script>

<script type="text/javascript"  src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/MathJax.js?config=TeX-AMS_HTML"> </script>

<script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
<script type="text/javascript" src="https://unpkg.com/survey-jquery/survey.jquery.min.js"></script>
<link href="https://unpkg.com/survey-jquery/modern.min.css" type="text/css" rel="stylesheet">
<script src="https://unpkg.com/showdown/dist/showdown.min.js"></script>


<!-- Various toggle functions used throughout --> 
<script language="javascript">
function toggle(id1,id2) {
	var ele = document.getElementById(id1); var text = document.getElementById(id2);
	if (ele.style.display == "block") {ele.style.display = "none"; text.innerHTML = "Show Solution";}
		else {ele.style.display = "block"; text.innerHTML = "Hide Solution";}}
function togglecode(id1,id2) {
   var ele = document.getElementById(id1); var text = document.getElementById(id2);
   if (ele.style.display == "block") {ele.style.display = "none"; text.innerHTML = "Show R Code";}
      else {ele.style.display = "block"; text.innerHTML = "Hide R Code";}}
function toggleEX(id1,id2) {
   var ele = document.getElementById(id1); var text = document.getElementById(id2);
   if (ele.style.display == "block") {ele.style.display = "none"; text.innerHTML = "Show Example";}
      else {ele.style.display = "block"; text.innerHTML = "Hide Example";}}
function toggleTheory(id1,id2) {
   var ele = document.getElementById(id1); var text = document.getElementById(id2);
   if (ele.style.display == "block") {ele.style.display = "none"; text.innerHTML = "Show Theory";}
      else {ele.style.display = "block"; text.innerHTML = "Hide Theory";}}
function toggleSolution(id1,id2) {
   var ele = document.getElementById(id1); var text = document.getElementById(id2);
   if (ele.style.display == "block") {ele.style.display = "none"; text.innerHTML = "Show Solution";}
      else {ele.style.display = "block"; text.innerHTML = "Hide Solution";}}      
function toggleQuiz(id1,id2) {
   var ele = document.getElementById(id1); var text = document.getElementById(id2);
   if (ele.style.display == "block") {ele.style.display = "none"; text.innerHTML = "Show Quiz Solution";}
      else {ele.style.display = "block"; text.innerHTML = "Hide Quiz Solution";}}      
</script>

<!-- A few functions for revealing definitions -->
<script language="javascript">
<!--   $( function() {
    $("#tabs").tabs();
  } ); -->

$(document).ready(function(){
    $('[data-toggle="tooltip"]').tooltip();
});

$(document).ready(function(){
    $('[data-toggle="popover"]').popover(); 
});
</script>

<script language="javascript">
function openTab(evt, tabName) {
    var i, tabcontent, tablinks;
    tabcontent = document.getElementsByClassName("tabcontent");
    for (i = 0; i < tabcontent.length; i++) {
        tabcontent[i].style.display = "none";
    }
    tablinks = document.getElementsByClassName("tablinks");
    for (i = 0; i < tablinks.length; i++) {
        tablinks[i].className = tablinks[i].className.replace(" active", "");
    }
    document.getElementById(tabName).style.display = "block";
    evt.currentTarget.className += " active";
}

// Get the element with id="defaultOpen" and click on it
document.getElementById("defaultOpen").click();
</script>



<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { color: #008000; } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { color: #008000; font-weight: bold; } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<style type="text/css">
  
  div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Regression Modeling With Actuarial and Financial Applications</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="preface.html"><a href="preface.html"><i class="fa fa-check"></i>Preface</a>
<ul>
<li class="chapter" data-level="" data-path="preface.html"><a href="preface.html#dedication"><i class="fa fa-check"></i>Dedication</a></li>
<li class="chapter" data-level="" data-path="preface.html"><a href="preface.html#forward"><i class="fa fa-check"></i>Forward</a>
<ul>
<li class="chapter" data-level="" data-path="preface.html"><a href="preface.html#who-is-this-book-for"><i class="fa fa-check"></i>Who Is This Book For?</a></li>
<li class="chapter" data-level="" data-path="preface.html"><a href="preface.html#what-is-this-book-about"><i class="fa fa-check"></i>What Is This Book About?</a></li>
<li class="chapter" data-level="" data-path="preface.html"><a href="preface.html#how-does-this-book-deliver-its-message"><i class="fa fa-check"></i>How Does This Book Deliver Its Message?</a></li>
<li class="chapter" data-level="" data-path="preface.html"><a href="preface.html#acknowledgements"><i class="fa fa-check"></i>Acknowledgements</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="1" data-path="regression-and-the-normal-distribution.html"><a href="regression-and-the-normal-distribution.html"><i class="fa fa-check"></i><b>1</b> Regression and the Normal Distribution</a>
<ul>
<li class="chapter" data-level="1.1" data-path="regression-and-the-normal-distribution.html"><a href="regression-and-the-normal-distribution.html#Sec11"><i class="fa fa-check"></i><b>1.1</b> What is Regression Analysis?</a></li>
<li class="chapter" data-level="1.2" data-path="regression-and-the-normal-distribution.html"><a href="regression-and-the-normal-distribution.html#Sec12"><i class="fa fa-check"></i><b>1.2</b> Fitting Data to a Normal Distribution</a></li>
<li class="chapter" data-level="1.3" data-path="regression-and-the-normal-distribution.html"><a href="regression-and-the-normal-distribution.html#Sec13"><i class="fa fa-check"></i><b>1.3</b> Power Transforms</a></li>
<li class="chapter" data-level="1.4" data-path="regression-and-the-normal-distribution.html"><a href="regression-and-the-normal-distribution.html#Sec14"><i class="fa fa-check"></i><b>1.4</b> Sampling and the Role of Normality</a></li>
<li class="chapter" data-level="1.5" data-path="regression-and-the-normal-distribution.html"><a href="regression-and-the-normal-distribution.html#Sec15"><i class="fa fa-check"></i><b>1.5</b> Regression and Sampling Designs</a></li>
<li class="chapter" data-level="1.6" data-path="regression-and-the-normal-distribution.html"><a href="regression-and-the-normal-distribution.html#Sec16"><i class="fa fa-check"></i><b>1.6</b> Actuarial Applications of Regression</a></li>
<li class="chapter" data-level="1.7" data-path="regression-and-the-normal-distribution.html"><a href="regression-and-the-normal-distribution.html#Sec17"><i class="fa fa-check"></i><b>1.7</b> Further Reading and References</a></li>
<li class="chapter" data-level="1.8" data-path="regression-and-the-normal-distribution.html"><a href="regression-and-the-normal-distribution.html#Sec18"><i class="fa fa-check"></i><b>1.8</b> Exercises</a></li>
<li class="chapter" data-level="1.9" data-path="regression-and-the-normal-distribution.html"><a href="regression-and-the-normal-distribution.html#Sec19"><i class="fa fa-check"></i><b>1.9</b> Technical Supplement - Central Limit Theorem</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="C2BasicLR.html"><a href="C2BasicLR.html"><i class="fa fa-check"></i><b>2</b> Basic Linear Regression</a>
<ul>
<li class="chapter" data-level="2.1" data-path="C2BasicLR.html"><a href="C2BasicLR.html#Sec21"><i class="fa fa-check"></i><b>2.1</b> Correlations and Least Squares</a></li>
<li class="chapter" data-level="2.2" data-path="C2BasicLR.html"><a href="C2BasicLR.html#Sec22"><i class="fa fa-check"></i><b>2.2</b> Basic Linear Regression Model</a></li>
<li class="chapter" data-level="2.3" data-path="C2BasicLR.html"><a href="C2BasicLR.html#Sec23"><i class="fa fa-check"></i><b>2.3</b> Is the Model Useful? Some Basic Summary Measures</a>
<ul>
<li class="chapter" data-level="2.3.1" data-path="C2BasicLR.html"><a href="C2BasicLR.html#Sec231"><i class="fa fa-check"></i><b>2.3.1</b> Partitioning the Variability</a></li>
<li class="chapter" data-level="2.3.2" data-path="C2BasicLR.html"><a href="C2BasicLR.html#Sec232"><i class="fa fa-check"></i><b>2.3.2</b> The Size of a Typical Deviation: <em>s</em></a></li>
</ul></li>
<li class="chapter" data-level="2.4" data-path="C2BasicLR.html"><a href="C2BasicLR.html#Sec24"><i class="fa fa-check"></i><b>2.4</b> Properties of Regression Coefficient Estimators</a></li>
<li class="chapter" data-level="2.5" data-path="C2BasicLR.html"><a href="C2BasicLR.html#Sec25"><i class="fa fa-check"></i><b>2.5</b> Statistical Inference</a>
<ul>
<li class="chapter" data-level="2.5.1" data-path="C2BasicLR.html"><a href="C2BasicLR.html#Sec251"><i class="fa fa-check"></i><b>2.5.1</b> Is the Explanatory Variable Important?: The <em>t</em>-Test</a></li>
<li class="chapter" data-level="2.5.2" data-path="C2BasicLR.html"><a href="C2BasicLR.html#Sec252"><i class="fa fa-check"></i><b>2.5.2</b> Confidence Intervals</a></li>
<li class="chapter" data-level="2.5.3" data-path="C2BasicLR.html"><a href="C2BasicLR.html#Sec253"><i class="fa fa-check"></i><b>2.5.3</b> Prediction Intervals</a></li>
</ul></li>
<li class="chapter" data-level="2.6" data-path="C2BasicLR.html"><a href="C2BasicLR.html#Sec26"><i class="fa fa-check"></i><b>2.6</b> Building a Better Model: Residual Analysis</a></li>
<li class="chapter" data-level="2.7" data-path="C2BasicLR.html"><a href="C2BasicLR.html#Sec27"><i class="fa fa-check"></i><b>2.7</b> Application: Capital Asset Pricing Model</a></li>
<li class="chapter" data-level="2.8" data-path="C2BasicLR.html"><a href="C2BasicLR.html#Sec28"><i class="fa fa-check"></i><b>2.8</b> Illustrative Regression Computer Output</a></li>
<li class="chapter" data-level="2.9" data-path="C2BasicLR.html"><a href="C2BasicLR.html#Sec29"><i class="fa fa-check"></i><b>2.9</b> Further Reading and References</a></li>
<li class="chapter" data-level="2.10" data-path="C2BasicLR.html"><a href="C2BasicLR.html#Sec210"><i class="fa fa-check"></i><b>2.10</b> Exercises</a></li>
<li class="chapter" data-level="2.11" data-path="C2BasicLR.html"><a href="C2BasicLR.html#Sec211"><i class="fa fa-check"></i><b>2.11</b> Technical Supplement - Elements of Matrix Algebra</a>
<ul>
<li class="chapter" data-level="2.11.1" data-path="C2BasicLR.html"><a href="C2BasicLR.html#Sec2111"><i class="fa fa-check"></i><b>2.11.1</b> Basic Definitions</a></li>
<li class="chapter" data-level="2.11.2" data-path="C2BasicLR.html"><a href="C2BasicLR.html#Sec2112"><i class="fa fa-check"></i><b>2.11.2</b> Some Special Matrices</a></li>
<li class="chapter" data-level="2.11.3" data-path="C2BasicLR.html"><a href="C2BasicLR.html#Sec2113"><i class="fa fa-check"></i><b>2.11.3</b> Basic Operations</a></li>
<li class="chapter" data-level="2.11.4" data-path="C2BasicLR.html"><a href="C2BasicLR.html#Sec2114"><i class="fa fa-check"></i><b>2.11.4</b> Random Matrices</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="3" data-path="C3BasicMLR.html"><a href="C3BasicMLR.html"><i class="fa fa-check"></i><b>3</b> Multiple Linear Regression - I</a>
<ul>
<li class="chapter" data-level="3.1" data-path="C3BasicMLR.html"><a href="C3BasicMLR.html#Sec31"><i class="fa fa-check"></i><b>3.1</b> Method of Least Squares</a>
<ul>
<li class="chapter" data-level="3.1.1" data-path="C3BasicMLR.html"><a href="C3BasicMLR.html#Sec311"><i class="fa fa-check"></i><b>3.1.1</b> Least Squares Method</a></li>
<li class="chapter" data-level="3.1.2" data-path="C3BasicMLR.html"><a href="C3BasicMLR.html#Sec312"><i class="fa fa-check"></i><b>3.1.2</b> General Case with <em>k</em> Explanatory Variables</a></li>
</ul></li>
<li class="chapter" data-level="3.2" data-path="C3BasicMLR.html"><a href="C3BasicMLR.html#Sec32"><i class="fa fa-check"></i><b>3.2</b> Linear Regression Model and Properties of Estimators</a>
<ul>
<li class="chapter" data-level="3.2.1" data-path="C3BasicMLR.html"><a href="C3BasicMLR.html#Sec321"><i class="fa fa-check"></i><b>3.2.1</b> Regression Function</a></li>
<li class="chapter" data-level="3.2.2" data-path="C3BasicMLR.html"><a href="C3BasicMLR.html#Sec322"><i class="fa fa-check"></i><b>3.2.2</b> Regression Coefficient Interpretation</a></li>
<li class="chapter" data-level="3.2.3" data-path="C3BasicMLR.html"><a href="C3BasicMLR.html#Sec323"><i class="fa fa-check"></i><b>3.2.3</b> Model Assumptions</a></li>
<li class="chapter" data-level="3.2.4" data-path="C3BasicMLR.html"><a href="C3BasicMLR.html#Sec324"><i class="fa fa-check"></i><b>3.2.4</b> Properties of Regression Coefficient Estimators</a></li>
</ul></li>
<li class="chapter" data-level="3.3" data-path="C3BasicMLR.html"><a href="C3BasicMLR.html#Sec33"><i class="fa fa-check"></i><b>3.3</b> Estimation and Goodness of Fit</a></li>
<li class="chapter" data-level="3.4" data-path="C3BasicMLR.html"><a href="C3BasicMLR.html#Sec34"><i class="fa fa-check"></i><b>3.4</b> Statistical Inference for a Single Coefficient</a>
<ul>
<li class="chapter" data-level="3.4.1" data-path="C3BasicMLR.html"><a href="C3BasicMLR.html#Sec341"><i class="fa fa-check"></i><b>3.4.1</b> The <em>t</em>-Test</a></li>
<li class="chapter" data-level="3.4.2" data-path="C3BasicMLR.html"><a href="C3BasicMLR.html#Sec342"><i class="fa fa-check"></i><b>3.4.2</b> Confidence Intervals</a></li>
<li class="chapter" data-level="3.4.3" data-path="C3BasicMLR.html"><a href="C3BasicMLR.html#Sec343"><i class="fa fa-check"></i><b>3.4.3</b> Added Variable Plots</a></li>
<li class="chapter" data-level="3.4.4" data-path="C3BasicMLR.html"><a href="C3BasicMLR.html#Sec344"><i class="fa fa-check"></i><b>3.4.4</b> Partial Correlation Coefficients</a></li>
</ul></li>
<li class="chapter" data-level="3.5" data-path="C3BasicMLR.html"><a href="C3BasicMLR.html#Sec35"><i class="fa fa-check"></i><b>3.5</b> Some Special Explanatory Variables</a>
<ul>
<li class="chapter" data-level="3.5.1" data-path="C3BasicMLR.html"><a href="C3BasicMLR.html#Sec351"><i class="fa fa-check"></i><b>3.5.1</b> Binary Variables</a></li>
<li class="chapter" data-level="3.5.2" data-path="C3BasicMLR.html"><a href="C3BasicMLR.html#Sec352"><i class="fa fa-check"></i><b>3.5.2</b> Transforming Explanatory Variables</a></li>
<li class="chapter" data-level="3.5.3" data-path="C3BasicMLR.html"><a href="C3BasicMLR.html#Sec353"><i class="fa fa-check"></i><b>3.5.3</b> Interaction Terms</a></li>
</ul></li>
<li class="chapter" data-level="3.6" data-path="C3BasicMLR.html"><a href="C3BasicMLR.html#Sec36"><i class="fa fa-check"></i><b>3.6</b> Further Reading and References</a></li>
<li class="chapter" data-level="3.7" data-path="C3BasicMLR.html"><a href="C3BasicMLR.html#Sec37"><i class="fa fa-check"></i><b>3.7</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="C4MLRANOVA.html"><a href="C4MLRANOVA.html"><i class="fa fa-check"></i><b>4</b> Multiple Linear Regression - II</a>
<ul>
<li class="chapter" data-level="4.1" data-path="C4MLRANOVA.html"><a href="C4MLRANOVA.html#Sec41"><i class="fa fa-check"></i><b>4.1</b> The Role of Binary Variables</a></li>
<li class="chapter" data-level="4.2" data-path="C4MLRANOVA.html"><a href="C4MLRANOVA.html#Sec42"><i class="fa fa-check"></i><b>4.2</b> Statistical Inference for Several Coefficients</a>
<ul>
<li class="chapter" data-level="4.2.1" data-path="C4MLRANOVA.html"><a href="C4MLRANOVA.html#Sec421"><i class="fa fa-check"></i><b>4.2.1</b> Sets of Regression Coefficients</a></li>
<li class="chapter" data-level="4.2.2" data-path="C4MLRANOVA.html"><a href="C4MLRANOVA.html#Sec422"><i class="fa fa-check"></i><b>4.2.2</b> The General Linear Hypothesis</a></li>
<li class="chapter" data-level="4.2.3" data-path="C4MLRANOVA.html"><a href="C4MLRANOVA.html#Sec423"><i class="fa fa-check"></i><b>4.2.3</b> Estimating and Predicting Several Coefficients</a></li>
</ul></li>
<li class="chapter" data-level="4.3" data-path="C4MLRANOVA.html"><a href="C4MLRANOVA.html#Sec43"><i class="fa fa-check"></i><b>4.3</b> One Factor ANOVA Model</a></li>
<li class="chapter" data-level="4.4" data-path="C4MLRANOVA.html"><a href="C4MLRANOVA.html#Sec44"><i class="fa fa-check"></i><b>4.4</b> Combining Categorical and Continuous Explanatory Variables</a></li>
<li class="chapter" data-level="4.5" data-path="C4MLRANOVA.html"><a href="C4MLRANOVA.html#Sec45"><i class="fa fa-check"></i><b>4.5</b> Further Reading and References</a></li>
<li class="chapter" data-level="4.6" data-path="C4MLRANOVA.html"><a href="C4MLRANOVA.html#Sec46"><i class="fa fa-check"></i><b>4.6</b> Exercises</a></li>
<li class="chapter" data-level="4.7" data-path="C4MLRANOVA.html"><a href="C4MLRANOVA.html#Sec47"><i class="fa fa-check"></i><b>4.7</b> Technical Supplement - Matrix Expressions</a>
<ul>
<li class="chapter" data-level="4.7.1" data-path="C4MLRANOVA.html"><a href="C4MLRANOVA.html#Sec471"><i class="fa fa-check"></i><b>4.7.1</b> Expressing Models with Categorical Variables in Matrix Form</a></li>
<li class="chapter" data-level="4.7.2" data-path="C4MLRANOVA.html"><a href="C4MLRANOVA.html#Sec472"><i class="fa fa-check"></i><b>4.7.2</b> Calculating Least Squares Recursively</a></li>
<li class="chapter" data-level="4.7.3" data-path="C4MLRANOVA.html"><a href="C4MLRANOVA.html#Sec473"><i class="fa fa-check"></i><b>4.7.3</b> General Linear Model</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="5" data-path="C5VarSelect.html"><a href="C5VarSelect.html"><i class="fa fa-check"></i><b>5</b> Variable Selection</a>
<ul>
<li class="chapter" data-level="5.1" data-path="C5VarSelect.html"><a href="C5VarSelect.html#Sec51"><i class="fa fa-check"></i><b>5.1</b> An Iterative Approach to Data Analysis and Modeling</a></li>
<li class="chapter" data-level="5.2" data-path="C5VarSelect.html"><a href="C5VarSelect.html#Sec52"><i class="fa fa-check"></i><b>5.2</b> Automatic Variable Selection Procedures</a></li>
<li class="chapter" data-level="5.3" data-path="C5VarSelect.html"><a href="C5VarSelect.html#Sec53"><i class="fa fa-check"></i><b>5.3</b> Residual Analysis</a>
<ul>
<li class="chapter" data-level="5.3.1" data-path="C5VarSelect.html"><a href="C5VarSelect.html#Sec531"><i class="fa fa-check"></i><b>5.3.1</b> Residuals</a></li>
<li class="chapter" data-level="5.3.2" data-path="C5VarSelect.html"><a href="C5VarSelect.html#Sec532"><i class="fa fa-check"></i><b>5.3.2</b> Using Residuals to Identify Outliers</a></li>
<li class="chapter" data-level="5.3.3" data-path="C5VarSelect.html"><a href="C5VarSelect.html#Sec533"><i class="fa fa-check"></i><b>5.3.3</b> Using Residuals to Select Explanatory Variables</a></li>
</ul></li>
<li class="chapter" data-level="5.4" data-path="C5VarSelect.html"><a href="C5VarSelect.html#Sec54"><i class="fa fa-check"></i><b>5.4</b> Influential Points</a>
<ul>
<li class="chapter" data-level="5.4.1" data-path="C5VarSelect.html"><a href="C5VarSelect.html#Sec541"><i class="fa fa-check"></i><b>5.4.1</b> Leverage</a></li>
<li class="chapter" data-level="5.4.2" data-path="C5VarSelect.html"><a href="C5VarSelect.html#Sec542"><i class="fa fa-check"></i><b>5.4.2</b> Cook’s Distance</a></li>
</ul></li>
<li class="chapter" data-level="5.5" data-path="C5VarSelect.html"><a href="C5VarSelect.html#Sec55"><i class="fa fa-check"></i><b>5.5</b> Collinearity</a>
<ul>
<li class="chapter" data-level="5.5.1" data-path="C5VarSelect.html"><a href="C5VarSelect.html#Sec551"><i class="fa fa-check"></i><b>5.5.1</b> What is Collinearity?</a></li>
<li class="chapter" data-level="5.5.2" data-path="C5VarSelect.html"><a href="C5VarSelect.html#Sec552"><i class="fa fa-check"></i><b>5.5.2</b> Variance Inflation Factors</a></li>
<li class="chapter" data-level="5.5.3" data-path="C5VarSelect.html"><a href="C5VarSelect.html#Sec553"><i class="fa fa-check"></i><b>5.5.3</b> Collinearity and Leverage</a></li>
<li class="chapter" data-level="5.5.4" data-path="C5VarSelect.html"><a href="C5VarSelect.html#Sec554"><i class="fa fa-check"></i><b>5.5.4</b> Suppressor Variables</a></li>
<li class="chapter" data-level="5.5.5" data-path="C5VarSelect.html"><a href="C5VarSelect.html#Sec555"><i class="fa fa-check"></i><b>5.5.5</b> Orthogonal Variables</a></li>
</ul></li>
<li class="chapter" data-level="5.6" data-path="C5VarSelect.html"><a href="C5VarSelect.html#Sec56"><i class="fa fa-check"></i><b>5.6</b> Selection Criteria</a>
<ul>
<li class="chapter" data-level="5.6.1" data-path="C5VarSelect.html"><a href="C5VarSelect.html#Sec561"><i class="fa fa-check"></i><b>5.6.1</b> Goodness of Fit</a></li>
<li class="chapter" data-level="5.6.2" data-path="C5VarSelect.html"><a href="C5VarSelect.html#Sec562"><i class="fa fa-check"></i><b>5.6.2</b> Model Validation</a></li>
<li class="chapter" data-level="5.6.3" data-path="C5VarSelect.html"><a href="C5VarSelect.html#Sec563"><i class="fa fa-check"></i><b>5.6.3</b> Cross-Validation</a></li>
</ul></li>
<li class="chapter" data-level="5.7" data-path="C5VarSelect.html"><a href="C5VarSelect.html#Sec57"><i class="fa fa-check"></i><b>5.7</b> Heteroscedasticity</a>
<ul>
<li class="chapter" data-level="5.7.1" data-path="C5VarSelect.html"><a href="C5VarSelect.html#Sec571"><i class="fa fa-check"></i><b>5.7.1</b> Detecting Heteroscedasticity</a></li>
<li class="chapter" data-level="5.7.2" data-path="C5VarSelect.html"><a href="C5VarSelect.html#Sec572"><i class="fa fa-check"></i><b>5.7.2</b> Heteroscedasticity-Consistent Standard Errors</a></li>
<li class="chapter" data-level="5.7.3" data-path="C5VarSelect.html"><a href="C5VarSelect.html#Sec573"><i class="fa fa-check"></i><b>5.7.3</b> Weighted Least Squares</a></li>
<li class="chapter" data-level="5.7.4" data-path="C5VarSelect.html"><a href="C5VarSelect.html#Sec574"><i class="fa fa-check"></i><b>5.7.4</b> Transformations</a></li>
</ul></li>
<li class="chapter" data-level="5.8" data-path="C5VarSelect.html"><a href="C5VarSelect.html#Sec58"><i class="fa fa-check"></i><b>5.8</b> Further Reading and References</a></li>
<li class="chapter" data-level="5.9" data-path="C5VarSelect.html"><a href="C5VarSelect.html#Sec59"><i class="fa fa-check"></i><b>5.9</b> Exercises</a></li>
<li class="chapter" data-level="5.10" data-path="C5VarSelect.html"><a href="C5VarSelect.html#Sec510"><i class="fa fa-check"></i><b>5.10</b> Technical Supplements for Chapter 5</a>
<ul>
<li class="chapter" data-level="5.10.1" data-path="C5VarSelect.html"><a href="C5VarSelect.html#Sec5101"><i class="fa fa-check"></i><b>5.10.1</b> Projection Matrix</a></li>
<li class="chapter" data-level="5.10.2" data-path="C5VarSelect.html"><a href="C5VarSelect.html#Sec5102"><i class="fa fa-check"></i><b>5.10.2</b> Leave One Out Statistics</a></li>
<li class="chapter" data-level="5.10.3" data-path="C5VarSelect.html"><a href="C5VarSelect.html#Sec5103"><i class="fa fa-check"></i><b>5.10.3</b> Omitting Variables</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="6" data-path="interpreting-regression-results.html"><a href="interpreting-regression-results.html"><i class="fa fa-check"></i><b>6</b> Interpreting Regression Results</a>
<ul>
<li class="chapter" data-level="6.1" data-path="interpreting-regression-results.html"><a href="interpreting-regression-results.html#Sec61"><i class="fa fa-check"></i><b>6.1</b> What the Modeling Process Tells Us</a>
<ul>
<li class="chapter" data-level="6.1.1" data-path="interpreting-regression-results.html"><a href="interpreting-regression-results.html#Sec611"><i class="fa fa-check"></i><b>6.1.1</b> Interpreting Individual Effects</a></li>
<li class="chapter" data-level="6.1.2" data-path="interpreting-regression-results.html"><a href="interpreting-regression-results.html#Sec612"><i class="fa fa-check"></i><b>6.1.2</b> Other Interpretations</a></li>
</ul></li>
<li class="chapter" data-level="6.2" data-path="interpreting-regression-results.html"><a href="interpreting-regression-results.html#Sec62"><i class="fa fa-check"></i><b>6.2</b> The Importance of Variable Selection</a>
<ul>
<li class="chapter" data-level="6.2.1" data-path="interpreting-regression-results.html"><a href="interpreting-regression-results.html#Sec621"><i class="fa fa-check"></i><b>6.2.1</b> Overfitting the Model</a></li>
<li class="chapter" data-level="6.2.2" data-path="interpreting-regression-results.html"><a href="interpreting-regression-results.html#Sec622"><i class="fa fa-check"></i><b>6.2.2</b> Underfitting the Model</a></li>
</ul></li>
<li class="chapter" data-level="6.3" data-path="interpreting-regression-results.html"><a href="interpreting-regression-results.html#Sec63"><i class="fa fa-check"></i><b>6.3</b> The Importance of Data Collection</a>
<ul>
<li class="chapter" data-level="6.3.1" data-path="interpreting-regression-results.html"><a href="interpreting-regression-results.html#Sec631"><i class="fa fa-check"></i><b>6.3.1</b> Sampling Frame Error and Adverse Selection</a></li>
<li class="chapter" data-level="6.3.2" data-path="interpreting-regression-results.html"><a href="interpreting-regression-results.html#Sec632"><i class="fa fa-check"></i><b>6.3.2</b> Limited Sampling Regions</a></li>
<li class="chapter" data-level="6.3.3" data-path="interpreting-regression-results.html"><a href="interpreting-regression-results.html#Sec633"><i class="fa fa-check"></i><b>6.3.3</b> Limited Dependent Variables, Censoring and Truncation</a></li>
<li class="chapter" data-level="6.3.4" data-path="interpreting-regression-results.html"><a href="interpreting-regression-results.html#Sec634"><i class="fa fa-check"></i><b>6.3.4</b> Omitted and Endogenous Variables</a></li>
<li class="chapter" data-level="6.3.5" data-path="interpreting-regression-results.html"><a href="interpreting-regression-results.html#Sec635"><i class="fa fa-check"></i><b>6.3.5</b> Missing Data</a></li>
</ul></li>
<li class="chapter" data-level="6.4" data-path="interpreting-regression-results.html"><a href="interpreting-regression-results.html#Sec64"><i class="fa fa-check"></i><b>6.4</b> Missing Data Models</a>
<ul>
<li class="chapter" data-level="6.4.1" data-path="interpreting-regression-results.html"><a href="interpreting-regression-results.html#Sec641"><i class="fa fa-check"></i><b>6.4.1</b> Missing at Random</a></li>
<li class="chapter" data-level="6.4.2" data-path="interpreting-regression-results.html"><a href="interpreting-regression-results.html#Sec642"><i class="fa fa-check"></i><b>6.4.2</b> Non-Ignorable Missing Data</a></li>
</ul></li>
<li class="chapter" data-level="6.5" data-path="interpreting-regression-results.html"><a href="interpreting-regression-results.html#Sec65"><i class="fa fa-check"></i><b>6.5</b> Application: Risk Managers’ Cost Effectiveness</a></li>
<li class="chapter" data-level="6.6" data-path="interpreting-regression-results.html"><a href="interpreting-regression-results.html#Sec66"><i class="fa fa-check"></i><b>6.6</b> Further Reading and References</a></li>
<li class="chapter" data-level="6.7" data-path="interpreting-regression-results.html"><a href="interpreting-regression-results.html#Sec67"><i class="fa fa-check"></i><b>6.7</b> Exercises</a></li>
<li class="chapter" data-level="6.8" data-path="interpreting-regression-results.html"><a href="interpreting-regression-results.html#Sec68"><i class="fa fa-check"></i><b>6.8</b> Technical Supplements for Chapter 6</a>
<ul>
<li class="chapter" data-level="6.8.1" data-path="interpreting-regression-results.html"><a href="interpreting-regression-results.html#Sec681"><i class="fa fa-check"></i><b>6.8.1</b> Effects of Model Misspecification</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="7" data-path="C7Trends.html"><a href="C7Trends.html"><i class="fa fa-check"></i><b>7</b> Modeling Trends</a>
<ul>
<li class="chapter" data-level="7.1" data-path="C7Trends.html"><a href="C7Trends.html#introduction-1"><i class="fa fa-check"></i><b>7.1</b> Introduction</a>
<ul>
<li class="chapter" data-level="" data-path="C7Trends.html"><a href="C7Trends.html#time-series-and-stochastic-processes"><i class="fa fa-check"></i>Time Series and Stochastic Processes</a></li>
<li class="chapter" data-level="" data-path="C7Trends.html"><a href="C7Trends.html#time-series-versus-causal-models"><i class="fa fa-check"></i>Time Series versus Causal Models</a></li>
</ul></li>
<li class="chapter" data-level="7.2" data-path="C7Trends.html"><a href="C7Trends.html#S7:Trends"><i class="fa fa-check"></i><b>7.2</b> Fitting Trends in Time</a>
<ul>
<li class="chapter" data-level="" data-path="C7Trends.html"><a href="C7Trends.html#understanding-patterns-over-time"><i class="fa fa-check"></i>Understanding Patterns over Time</a></li>
<li class="chapter" data-level="" data-path="C7Trends.html"><a href="C7Trends.html#fitting-trends-in-time"><i class="fa fa-check"></i>Fitting Trends in Time</a></li>
<li class="chapter" data-level="" data-path="C7Trends.html"><a href="C7Trends.html#fitting-seasonal-trends"><i class="fa fa-check"></i>Fitting Seasonal Trends</a></li>
<li class="chapter" data-level="" data-path="C7Trends.html"><a href="C7Trends.html#reliability-of-time-series-forecasts"><i class="fa fa-check"></i>Reliability of Time Series Forecasts</a></li>
</ul></li>
<li class="chapter" data-level="7.3" data-path="C7Trends.html"><a href="C7Trends.html#S7:RandomWalk"><i class="fa fa-check"></i><b>7.3</b> Stationarity and Random Walk Models</a>
<ul>
<li class="chapter" data-level="" data-path="C7Trends.html"><a href="C7Trends.html#white-noise"><i class="fa fa-check"></i>White Noise</a></li>
<li class="chapter" data-level="" data-path="C7Trends.html"><a href="C7Trends.html#random-walk"><i class="fa fa-check"></i>Random Walk</a></li>
</ul></li>
<li class="chapter" data-level="7.4" data-path="C7Trends.html"><a href="C7Trends.html#inference-using-random-walk-models"><i class="fa fa-check"></i><b>7.4</b> Inference using Random Walk Models</a>
<ul>
<li class="chapter" data-level="" data-path="C7Trends.html"><a href="C7Trends.html#model-properties"><i class="fa fa-check"></i>Model Properties</a></li>
<li class="chapter" data-level="" data-path="C7Trends.html"><a href="C7Trends.html#forecasting"><i class="fa fa-check"></i>Forecasting</a></li>
<li class="chapter" data-level="" data-path="C7Trends.html"><a href="C7Trends.html#identifying-stationarity"><i class="fa fa-check"></i>Identifying Stationarity</a></li>
<li class="chapter" data-level="" data-path="C7Trends.html"><a href="C7Trends.html#identifying-random-walks"><i class="fa fa-check"></i>Identifying Random Walks</a></li>
<li class="chapter" data-level="" data-path="C7Trends.html"><a href="C7Trends.html#random-walk-versus-linear-trend-in-time-models"><i class="fa fa-check"></i>Random Walk versus Linear Trend in Time Models</a></li>
</ul></li>
<li class="chapter" data-level="7.5" data-path="C7Trends.html"><a href="C7Trends.html#filtering-to-achieve-stationarity"><i class="fa fa-check"></i><b>7.5</b> Filtering to Achieve Stationarity</a>
<ul>
<li class="chapter" data-level="" data-path="C7Trends.html"><a href="C7Trends.html#transformations"><i class="fa fa-check"></i>Transformations</a></li>
</ul></li>
<li class="chapter" data-level="7.6" data-path="C7Trends.html"><a href="C7Trends.html#forecast-evaluation"><i class="fa fa-check"></i><b>7.6</b> Forecast Evaluation</a></li>
<li class="chapter" data-level="7.7" data-path="C7Trends.html"><a href="C7Trends.html#further-reading-and-references"><i class="fa fa-check"></i><b>7.7</b> Further Reading and References</a></li>
<li class="chapter" data-level="7.8" data-path="C7Trends.html"><a href="C7Trends.html#exercises"><i class="fa fa-check"></i><b>7.8</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="C8AR.html"><a href="C8AR.html"><i class="fa fa-check"></i><b>8</b> Autocorrelations and Autoregressive Models</a>
<ul>
<li class="chapter" data-level="8.1" data-path="C8AR.html"><a href="C8AR.html#S8:Autocorrs"><i class="fa fa-check"></i><b>8.1</b> Autocorrelations</a>
<ul>
<li class="chapter" data-level="" data-path="C8AR.html"><a href="C8AR.html#application-inflation-bond-returns"><i class="fa fa-check"></i>Application: Inflation Bond Returns</a></li>
</ul></li>
<li class="chapter" data-level="8.2" data-path="C8AR.html"><a href="C8AR.html#autoregressive-models-of-order-one"><i class="fa fa-check"></i><b>8.2</b> Autoregressive Models of Order One</a></li>
<li class="chapter" data-level="8.3" data-path="C8AR.html"><a href="C8AR.html#S8:Estimation"><i class="fa fa-check"></i><b>8.3</b> Estimation and Diagnostic Checking</a></li>
<li class="chapter" data-level="8.4" data-path="C8AR.html"><a href="C8AR.html#S8:AR1Smooth"><i class="fa fa-check"></i><b>8.4</b> Smoothing and Prediction</a></li>
<li class="chapter" data-level="8.5" data-path="C8AR.html"><a href="C8AR.html#S8:BoxJenkins"><i class="fa fa-check"></i><b>8.5</b> Box-Jenkins Modeling and Forecasting</a>
<ul>
<li class="chapter" data-level="8.5.1" data-path="C8AR.html"><a href="C8AR.html#models"><i class="fa fa-check"></i><b>8.5.1</b> Models</a></li>
<li class="chapter" data-level="8.5.2" data-path="C8AR.html"><a href="C8AR.html#forecasting-1"><i class="fa fa-check"></i><b>8.5.2</b> Forecasting</a></li>
</ul></li>
<li class="chapter" data-level="8.6" data-path="C8AR.html"><a href="C8AR.html#application-hong-kong-exchange-rates"><i class="fa fa-check"></i><b>8.6</b> Application: Hong Kong Exchange Rates</a></li>
<li class="chapter" data-level="8.7" data-path="C8AR.html"><a href="C8AR.html#further-reading-and-references-1"><i class="fa fa-check"></i><b>8.7</b> Further Reading and References</a></li>
<li class="chapter" data-level="8.8" data-path="C8AR.html"><a href="C8AR.html#exercises-1"><i class="fa fa-check"></i><b>8.8</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="9" data-path="C9Forecast.html"><a href="C9Forecast.html"><i class="fa fa-check"></i><b>9</b> Forecasting and Time Series Models</a>
<ul>
<li class="chapter" data-level="9.1" data-path="C9Forecast.html"><a href="C9Forecast.html#smoothing-with-moving-averages"><i class="fa fa-check"></i><b>9.1</b> Smoothing with Moving Averages</a></li>
<li class="chapter" data-level="9.2" data-path="C9Forecast.html"><a href="C9Forecast.html#S9:ExponSmooth"><i class="fa fa-check"></i><b>9.2</b> Exponential Smoothing</a></li>
<li class="chapter" data-level="9.3" data-path="C9Forecast.html"><a href="C9Forecast.html#S9:SeasonalTSModels"><i class="fa fa-check"></i><b>9.3</b> Seasonal Time Series Models</a></li>
<li class="chapter" data-level="9.4" data-path="C9Forecast.html"><a href="C9Forecast.html#unit-root-tests"><i class="fa fa-check"></i><b>9.4</b> Unit Root Tests</a></li>
<li class="chapter" data-level="9.5" data-path="C9Forecast.html"><a href="C9Forecast.html#archgarch-models"><i class="fa fa-check"></i><b>9.5</b> ARCH/GARCH Models</a></li>
<li class="chapter" data-level="9.6" data-path="C9Forecast.html"><a href="C9Forecast.html#further-reading-and-references-2"><i class="fa fa-check"></i><b>9.6</b> Further Reading and References</a></li>
</ul></li>
<li class="chapter" data-level="10" data-path="C10Panel.html"><a href="C10Panel.html"><i class="fa fa-check"></i><b>10</b> Longitudinal and Panel Data Models</a>
<ul>
<li class="chapter" data-level="10.1" data-path="C10Panel.html"><a href="C10Panel.html#S10:Intro"><i class="fa fa-check"></i><b>10.1</b> What are Longitudinal and Panel Data?</a></li>
<li class="chapter" data-level="10.2" data-path="C10Panel.html"><a href="C10Panel.html#S10:Visual"><i class="fa fa-check"></i><b>10.2</b> Visualizing Longitudinal and Panel Data</a></li>
<li class="chapter" data-level="10.3" data-path="C10Panel.html"><a href="C10Panel.html#S10:FEModels"><i class="fa fa-check"></i><b>10.3</b> Basic Fixed Effects Models</a></li>
<li class="chapter" data-level="10.4" data-path="C10Panel.html"><a href="C10Panel.html#S10:FEModels2"><i class="fa fa-check"></i><b>10.4</b> Extended Fixed Effects Models</a></li>
<li class="chapter" data-level="10.5" data-path="C10Panel.html"><a href="C10Panel.html#S10:REModels"><i class="fa fa-check"></i><b>10.5</b> Random Effects Models</a></li>
<li class="chapter" data-level="10.6" data-path="C10Panel.html"><a href="C10Panel.html#S10:References"><i class="fa fa-check"></i><b>10.6</b> Further Reading and References</a></li>
</ul></li>
<li class="chapter" data-level="11" data-path="C11Binary.html"><a href="C11Binary.html"><i class="fa fa-check"></i><b>11</b> Categorical Dependent Variables</a>
<ul>
<li class="chapter" data-level="11.1" data-path="C11Binary.html"><a href="C11Binary.html#S:Sec111"><i class="fa fa-check"></i><b>11.1</b> Binary Dependent Variables</a></li>
<li class="chapter" data-level="11.2" data-path="C11Binary.html"><a href="C11Binary.html#S:Sec112"><i class="fa fa-check"></i><b>11.2</b> Logistic and Probit Regression Models</a>
<ul>
<li class="chapter" data-level="11.2.1" data-path="C11Binary.html"><a href="C11Binary.html#S:Sec1121"><i class="fa fa-check"></i><b>11.2.1</b> Using Nonlinear Functions of Explanatory Variables</a></li>
<li class="chapter" data-level="11.2.2" data-path="C11Binary.html"><a href="C11Binary.html#S:Sec1122"><i class="fa fa-check"></i><b>11.2.2</b> Threshold Interpretation</a></li>
<li class="chapter" data-level="11.2.3" data-path="C11Binary.html"><a href="C11Binary.html#S:Sec1123"><i class="fa fa-check"></i><b>11.2.3</b> Random Utility Interpretation</a></li>
<li class="chapter" data-level="11.2.4" data-path="C11Binary.html"><a href="C11Binary.html#S:Sec1124"><i class="fa fa-check"></i><b>11.2.4</b> Logistic Regression</a></li>
</ul></li>
<li class="chapter" data-level="11.3" data-path="C11Binary.html"><a href="C11Binary.html#S:Sec113"><i class="fa fa-check"></i><b>11.3</b> Inference for Logistic and Probit Regression Models</a>
<ul>
<li class="chapter" data-level="11.3.1" data-path="C11Binary.html"><a href="C11Binary.html#parameter-estimation"><i class="fa fa-check"></i><b>11.3.1</b> Parameter Estimation</a></li>
<li class="chapter" data-level="11.3.2" data-path="C11Binary.html"><a href="C11Binary.html#additional-inference"><i class="fa fa-check"></i><b>11.3.2</b> Additional Inference</a></li>
</ul></li>
<li class="chapter" data-level="11.4" data-path="C11Binary.html"><a href="C11Binary.html#S:Sec114"><i class="fa fa-check"></i><b>11.4</b> Application: Medical Expenditures</a></li>
<li class="chapter" data-level="11.5" data-path="C11Binary.html"><a href="C11Binary.html#S:Sec115"><i class="fa fa-check"></i><b>11.5</b> Nominal Dependent Variables</a>
<ul>
<li class="chapter" data-level="11.5.1" data-path="C11Binary.html"><a href="C11Binary.html#S:Sec1151"><i class="fa fa-check"></i><b>11.5.1</b> Generalized Logit</a></li>
<li class="chapter" data-level="11.5.2" data-path="C11Binary.html"><a href="C11Binary.html#S:Sec1152"><i class="fa fa-check"></i><b>11.5.2</b> Multinomial Logit</a></li>
<li class="chapter" data-level="11.5.3" data-path="C11Binary.html"><a href="C11Binary.html#S:Sec1153"><i class="fa fa-check"></i><b>11.5.3</b> Nested Logit</a></li>
</ul></li>
<li class="chapter" data-level="11.6" data-path="C11Binary.html"><a href="C11Binary.html#S:Sec116"><i class="fa fa-check"></i><b>11.6</b> Ordinal Dependent Variables</a>
<ul>
<li class="chapter" data-level="11.6.1" data-path="C11Binary.html"><a href="C11Binary.html#cumulative-logit"><i class="fa fa-check"></i><b>11.6.1</b> Cumulative Logit</a></li>
<li class="chapter" data-level="11.6.2" data-path="C11Binary.html"><a href="C11Binary.html#cumulative-probit"><i class="fa fa-check"></i><b>11.6.2</b> Cumulative Probit</a></li>
</ul></li>
<li class="chapter" data-level="11.7" data-path="C11Binary.html"><a href="C11Binary.html#S:Sec117"><i class="fa fa-check"></i><b>11.7</b> Further Reading and References</a></li>
<li class="chapter" data-level="11.8" data-path="C11Binary.html"><a href="C11Binary.html#S:Sec118"><i class="fa fa-check"></i><b>11.8</b> Exercises</a></li>
<li class="chapter" data-level="11.9" data-path="C11Binary.html"><a href="C11Binary.html#S:Sec119"><i class="fa fa-check"></i><b>11.9</b> Technical Supplements - Likelihood-Based Inference</a>
<ul>
<li class="chapter" data-level="11.9.1" data-path="C11Binary.html"><a href="C11Binary.html#S:Sec1191"><i class="fa fa-check"></i><b>11.9.1</b> Properties of Likelihood Functions</a></li>
<li class="chapter" data-level="11.9.2" data-path="C11Binary.html"><a href="C11Binary.html#S:Sec1192"><i class="fa fa-check"></i><b>11.9.2</b> Maximum Likelihood Estimators</a></li>
<li class="chapter" data-level="11.9.3" data-path="C11Binary.html"><a href="C11Binary.html#S:Sec1193"><i class="fa fa-check"></i><b>11.9.3</b> Hypothesis Tests</a></li>
<li class="chapter" data-level="11.9.4" data-path="C11Binary.html"><a href="C11Binary.html#S:Sec1194"><i class="fa fa-check"></i><b>11.9.4</b> Information Criteria</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="12" data-path="C12Count.html"><a href="C12Count.html"><i class="fa fa-check"></i><b>12</b> Count Dependent Variables</a>
<ul>
<li class="chapter" data-level="12.1" data-path="C12Count.html"><a href="C12Count.html#S:Sec121"><i class="fa fa-check"></i><b>12.1</b> Poisson Regression</a>
<ul>
<li class="chapter" data-level="12.1.1" data-path="C12Count.html"><a href="C12Count.html#S:Sec1211"><i class="fa fa-check"></i><b>12.1.1</b> Poisson Distribution</a></li>
<li class="chapter" data-level="12.1.2" data-path="C12Count.html"><a href="C12Count.html#S:Sec1212"><i class="fa fa-check"></i><b>12.1.2</b> Regression Model</a></li>
<li class="chapter" data-level="12.1.3" data-path="C12Count.html"><a href="C12Count.html#S:Sec1213"><i class="fa fa-check"></i><b>12.1.3</b> Estimation</a></li>
<li class="chapter" data-level="12.1.4" data-path="C12Count.html"><a href="C12Count.html#S:Sec1214"><i class="fa fa-check"></i><b>12.1.4</b> Additional Inference</a></li>
</ul></li>
<li class="chapter" data-level="12.2" data-path="C12Count.html"><a href="C12Count.html#S:Sec122"><i class="fa fa-check"></i><b>12.2</b> Application: Singapore Automobile Insurance</a></li>
<li class="chapter" data-level="12.3" data-path="C12Count.html"><a href="C12Count.html#S:Sec123"><i class="fa fa-check"></i><b>12.3</b> Overdispersion and Negative Binomial Models</a></li>
<li class="chapter" data-level="12.4" data-path="C12Count.html"><a href="C12Count.html#S:Sec124"><i class="fa fa-check"></i><b>12.4</b> Other Count Models</a>
<ul>
<li class="chapter" data-level="12.4.1" data-path="C12Count.html"><a href="C12Count.html#zero-inflated-models"><i class="fa fa-check"></i><b>12.4.1</b> Zero-Inflated Models</a></li>
<li class="chapter" data-level="12.4.2" data-path="C12Count.html"><a href="C12Count.html#hurdle-models"><i class="fa fa-check"></i><b>12.4.2</b> Hurdle Models</a></li>
<li class="chapter" data-level="12.4.3" data-path="C12Count.html"><a href="C12Count.html#heterogeneity-models"><i class="fa fa-check"></i><b>12.4.3</b> Heterogeneity Models</a></li>
<li class="chapter" data-level="12.4.4" data-path="C12Count.html"><a href="C12Count.html#latent-class-models"><i class="fa fa-check"></i><b>12.4.4</b> Latent Class Models</a></li>
</ul></li>
<li class="chapter" data-level="12.5" data-path="C12Count.html"><a href="C12Count.html#S:Sec125"><i class="fa fa-check"></i><b>12.5</b> Further Reading and References</a></li>
<li class="chapter" data-level="12.6" data-path="C12Count.html"><a href="C12Count.html#S:Sec126"><i class="fa fa-check"></i><b>12.6</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="13" data-path="C13GLM.html"><a href="C13GLM.html"><i class="fa fa-check"></i><b>13</b> Generalized Linear Models</a>
<ul>
<li class="chapter" data-level="13.1" data-path="C13GLM.html"><a href="C13GLM.html#S:Sec131"><i class="fa fa-check"></i><b>13.1</b> Introduction</a></li>
<li class="chapter" data-level="13.2" data-path="C13GLM.html"><a href="C13GLM.html#S:Sec132"><i class="fa fa-check"></i><b>13.2</b> GLM Model</a>
<ul>
<li class="chapter" data-level="13.2.1" data-path="C13GLM.html"><a href="C13GLM.html#S:Sec1321"><i class="fa fa-check"></i><b>13.2.1</b> Linear Exponential Family of Distributions</a></li>
<li class="chapter" data-level="13.2.2" data-path="C13GLM.html"><a href="C13GLM.html#S:Sec1322"><i class="fa fa-check"></i><b>13.2.2</b> Link Functions</a></li>
</ul></li>
<li class="chapter" data-level="13.3" data-path="C13GLM.html"><a href="C13GLM.html#S:Sec133"><i class="fa fa-check"></i><b>13.3</b> Estimation</a>
<ul>
<li class="chapter" data-level="13.3.1" data-path="C13GLM.html"><a href="C13GLM.html#S:Sec1331"><i class="fa fa-check"></i><b>13.3.1</b> Maximum Likelihood Estimation for Canonical Links</a></li>
<li class="chapter" data-level="13.3.2" data-path="C13GLM.html"><a href="C13GLM.html#overdispersion"><i class="fa fa-check"></i><b>13.3.2</b> Overdispersion</a></li>
<li class="chapter" data-level="13.3.3" data-path="C13GLM.html"><a href="C13GLM.html#S:Sec1333"><i class="fa fa-check"></i><b>13.3.3</b> Goodness of Fit Statistics</a></li>
</ul></li>
<li class="chapter" data-level="13.4" data-path="C13GLM.html"><a href="C13GLM.html#S:Sec134"><i class="fa fa-check"></i><b>13.4</b> Application: Medical Expenditures</a></li>
<li class="chapter" data-level="13.5" data-path="C13GLM.html"><a href="C13GLM.html#S:Sec135"><i class="fa fa-check"></i><b>13.5</b> Residuals</a></li>
<li class="chapter" data-level="13.6" data-path="C13GLM.html"><a href="C13GLM.html#S:Sec136"><i class="fa fa-check"></i><b>13.6</b> Tweedie Distribution</a></li>
<li class="chapter" data-level="13.7" data-path="C13GLM.html"><a href="C13GLM.html#S:Sec137"><i class="fa fa-check"></i><b>13.7</b> Further Reading and References</a></li>
<li class="chapter" data-level="13.8" data-path="C13GLM.html"><a href="C13GLM.html#S:Sec138"><i class="fa fa-check"></i><b>13.8</b> Exercises</a></li>
<li class="chapter" data-level="13.9" data-path="C13GLM.html"><a href="C13GLM.html#S:Sec139"><i class="fa fa-check"></i><b>13.9</b> Technical Supplements - Exponential Family</a>
<ul>
<li class="chapter" data-level="13.9.1" data-path="C13GLM.html"><a href="C13GLM.html#S:Sec1391"><i class="fa fa-check"></i><b>13.9.1</b> Linear Exponential Family of Distributions</a></li>
<li class="chapter" data-level="13.9.2" data-path="C13GLM.html"><a href="C13GLM.html#S:Sec1392"><i class="fa fa-check"></i><b>13.9.2</b> Moments</a></li>
<li class="chapter" data-level="13.9.3" data-path="C13GLM.html"><a href="C13GLM.html#S:Sec1393"><i class="fa fa-check"></i><b>13.9.3</b> Maximum Likelihood Estimation for General Links</a></li>
<li class="chapter" data-level="13.9.4" data-path="C13GLM.html"><a href="C13GLM.html#S:Sec1394"><i class="fa fa-check"></i><b>13.9.4</b> Iterated Reweighted Least Squares</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="14" data-path="C14Survival.html"><a href="C14Survival.html"><i class="fa fa-check"></i><b>14</b> Survival Models</a>
<ul>
<li class="chapter" data-level="14.1" data-path="C14Survival.html"><a href="C14Survival.html#introduction-2"><i class="fa fa-check"></i><b>14.1</b> Introduction</a></li>
<li class="chapter" data-level="14.2" data-path="C14Survival.html"><a href="C14Survival.html#S:Sec142"><i class="fa fa-check"></i><b>14.2</b> Censoring and Truncation</a>
<ul>
<li class="chapter" data-level="14.2.1" data-path="C14Survival.html"><a href="C14Survival.html#definitions-and-examples"><i class="fa fa-check"></i><b>14.2.1</b> Definitions and Examples</a></li>
<li class="chapter" data-level="14.2.2" data-path="C14Survival.html"><a href="C14Survival.html#likelihood-inference"><i class="fa fa-check"></i><b>14.2.2</b> Likelihood Inference</a></li>
<li class="chapter" data-level="14.2.3" data-path="C14Survival.html"><a href="C14Survival.html#product-limit-estimator"><i class="fa fa-check"></i><b>14.2.3</b> Product-Limit Estimator</a></li>
</ul></li>
<li class="chapter" data-level="14.3" data-path="C14Survival.html"><a href="C14Survival.html#S:Sec143"><i class="fa fa-check"></i><b>14.3</b> Accelerated Failure Time Model</a></li>
<li class="chapter" data-level="14.4" data-path="C14Survival.html"><a href="C14Survival.html#S:Sec144"><i class="fa fa-check"></i><b>14.4</b> Proportional Hazards Model</a>
<ul>
<li class="chapter" data-level="14.4.1" data-path="C14Survival.html"><a href="C14Survival.html#S:Sec1441"><i class="fa fa-check"></i><b>14.4.1</b> Proportional Hazards</a></li>
<li class="chapter" data-level="14.4.2" data-path="C14Survival.html"><a href="C14Survival.html#S:Sec1442"><i class="fa fa-check"></i><b>14.4.2</b> Inference</a></li>
</ul></li>
<li class="chapter" data-level="14.5" data-path="C14Survival.html"><a href="C14Survival.html#S:Sec145"><i class="fa fa-check"></i><b>14.5</b> Recurrent Events</a></li>
<li class="chapter" data-level="14.6" data-path="C14Survival.html"><a href="C14Survival.html#S:Sec146"><i class="fa fa-check"></i><b>14.6</b> Further Reading and References</a></li>
</ul></li>
<li class="chapter" data-level="15" data-path="C15Misc.html"><a href="C15Misc.html"><i class="fa fa-check"></i><b>15</b> Miscellaneous Regression Topics</a>
<ul>
<li class="chapter" data-level="15.1" data-path="C15Misc.html"><a href="C15Misc.html#S:Sec151"><i class="fa fa-check"></i><b>15.1</b> Mixed Linear Models</a>
<ul>
<li class="chapter" data-level="15.1.1" data-path="C15Misc.html"><a href="C15Misc.html#weighted-least-squares-2"><i class="fa fa-check"></i><b>15.1.1</b> Weighted Least Squares</a></li>
<li class="chapter" data-level="15.1.2" data-path="C15Misc.html"><a href="C15Misc.html#S:Sec1512"><i class="fa fa-check"></i><b>15.1.2</b> Variance Components Estimation</a></li>
<li class="chapter" data-level="15.1.3" data-path="C15Misc.html"><a href="C15Misc.html#best-linear-unbiased-prediction"><i class="fa fa-check"></i><b>15.1.3</b> Best Linear Unbiased Prediction</a></li>
</ul></li>
<li class="chapter" data-level="15.2" data-path="C15Misc.html"><a href="C15Misc.html#bayesian-regression"><i class="fa fa-check"></i><b>15.2</b> Bayesian Regression</a></li>
<li class="chapter" data-level="15.3" data-path="C15Misc.html"><a href="C15Misc.html#S:Sec153"><i class="fa fa-check"></i><b>15.3</b> Density Estimation and Scatterplot Smoothing}</a></li>
<li class="chapter" data-level="15.4" data-path="C15Misc.html"><a href="C15Misc.html#S:Sec154"><i class="fa fa-check"></i><b>15.4</b> Generalized Additive Models</a></li>
<li class="chapter" data-level="15.5" data-path="C15Misc.html"><a href="C15Misc.html#bootstrapping"><i class="fa fa-check"></i><b>15.5</b> Bootstrapping</a></li>
<li class="chapter" data-level="15.6" data-path="C15Misc.html"><a href="C15Misc.html#further-reading-and-references-3"><i class="fa fa-check"></i><b>15.6</b> Further Reading and References</a></li>
</ul></li>
<li class="chapter" data-level="16" data-path="C16FreqSev.html"><a href="C16FreqSev.html"><i class="fa fa-check"></i><b>16</b> Frequency-Severity Models</a>
<ul>
<li class="chapter" data-level="16.1" data-path="C16FreqSev.html"><a href="C16FreqSev.html#S:Sec161"><i class="fa fa-check"></i><b>16.1</b> Introduction</a></li>
<li class="chapter" data-level="16.2" data-path="C16FreqSev.html"><a href="C16FreqSev.html#S:Sec162"><i class="fa fa-check"></i><b>16.2</b> Tobit Model</a></li>
<li class="chapter" data-level="16.3" data-path="C16FreqSev.html"><a href="C16FreqSev.html#S:Sec163"><i class="fa fa-check"></i><b>16.3</b> Application: Medical Expenditures</a></li>
<li class="chapter" data-level="16.4" data-path="C16FreqSev.html"><a href="C16FreqSev.html#S:Sec164"><i class="fa fa-check"></i><b>16.4</b> Two-Part Model</a></li>
<li class="chapter" data-level="16.5" data-path="C16FreqSev.html"><a href="C16FreqSev.html#S:Sec165"><i class="fa fa-check"></i><b>16.5</b> Aggregate Loss Model</a></li>
<li class="chapter" data-level="16.6" data-path="C16FreqSev.html"><a href="C16FreqSev.html#S:Sec166"><i class="fa fa-check"></i><b>16.6</b> Further Reading and References</a></li>
<li class="chapter" data-level="16.7" data-path="C16FreqSev.html"><a href="C16FreqSev.html#S:Sec167"><i class="fa fa-check"></i><b>16.7</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="17" data-path="C17Fat.html"><a href="C17Fat.html"><i class="fa fa-check"></i><b>17</b> Fat-Tailed Regression Models</a>
<ul>
<li class="chapter" data-level="17.1" data-path="C17Fat.html"><a href="C17Fat.html#introduction-3"><i class="fa fa-check"></i><b>17.1</b> Introduction</a></li>
<li class="chapter" data-level="17.2" data-path="C17Fat.html"><a href="C17Fat.html#S:Sec172"><i class="fa fa-check"></i><b>17.2</b> Transformations</a></li>
<li class="chapter" data-level="17.3" data-path="C17Fat.html"><a href="C17Fat.html#S:Sec173"><i class="fa fa-check"></i><b>17.3</b> Generalized Linear Models</a>
<ul>
<li class="chapter" data-level="17.3.1" data-path="C17Fat.html"><a href="C17Fat.html#S:Sec1731"><i class="fa fa-check"></i><b>17.3.1</b> What is “Fat-Tailed?”</a></li>
<li class="chapter" data-level="17.3.2" data-path="C17Fat.html"><a href="C17Fat.html#S:Sec1732"><i class="fa fa-check"></i><b>17.3.2</b> Application: Wisconsin Nursing Homes</a></li>
</ul></li>
<li class="chapter" data-level="17.4" data-path="C17Fat.html"><a href="C17Fat.html#S:Sec174"><i class="fa fa-check"></i><b>17.4</b> Generalized Distributions</a>
<ul>
<li class="chapter" data-level="" data-path="C17Fat.html"><a href="C17Fat.html#applicationwisconsin-nursing-homes"><i class="fa fa-check"></i>Application:Wisconsin Nursing Homes</a></li>
</ul></li>
<li class="chapter" data-level="17.5" data-path="C17Fat.html"><a href="C17Fat.html#S:Sec175"><i class="fa fa-check"></i><b>17.5</b> Quantile Regression</a></li>
<li class="chapter" data-level="17.6" data-path="C17Fat.html"><a href="C17Fat.html#S:Sec176"><i class="fa fa-check"></i><b>17.6</b> Extreme Value Models</a></li>
<li class="chapter" data-level="17.7" data-path="C17Fat.html"><a href="C17Fat.html#further-reading-and-references-4"><i class="fa fa-check"></i><b>17.7</b> Further Reading and References</a></li>
<li class="chapter" data-level="17.8" data-path="C17Fat.html"><a href="C17Fat.html#exercises-2"><i class="fa fa-check"></i><b>17.8</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="18" data-path="C18Cred.html"><a href="C18Cred.html"><i class="fa fa-check"></i><b>18</b> Credibility and Bonus-Malus</a>
<ul>
<li class="chapter" data-level="18.1" data-path="C18Cred.html"><a href="C18Cred.html#risk-classification-and-experience-rating"><i class="fa fa-check"></i><b>18.1</b> Risk Classification and Experience Rating</a></li>
<li class="chapter" data-level="18.2" data-path="C18Cred.html"><a href="C18Cred.html#S:Sec182"><i class="fa fa-check"></i><b>18.2</b> Credibility</a>
<ul>
<li class="chapter" data-level="18.2.1" data-path="C18Cred.html"><a href="C18Cred.html#S:Sec1821"><i class="fa fa-check"></i><b>18.2.1</b> Limited Fluctuation Credibility</a></li>
<li class="chapter" data-level="18.2.2" data-path="C18Cred.html"><a href="C18Cred.html#S:Sec1822"><i class="fa fa-check"></i><b>18.2.2</b> Greatest Accuracy Credibility</a></li>
</ul></li>
<li class="chapter" data-level="18.3" data-path="C18Cred.html"><a href="C18Cred.html#S:Sec183"><i class="fa fa-check"></i><b>18.3</b> Credibility and Regression</a>
<ul>
<li class="chapter" data-level="18.3.1" data-path="C18Cred.html"><a href="C18Cred.html#one-way-random-effects-model"><i class="fa fa-check"></i><b>18.3.1</b> One-Way Random Effects Model</a></li>
<li class="chapter" data-level="18.3.2" data-path="C18Cred.html"><a href="C18Cred.html#longitudinal-models"><i class="fa fa-check"></i><b>18.3.2</b> Longitudinal Models</a></li>
</ul></li>
<li class="chapter" data-level="18.4" data-path="C18Cred.html"><a href="C18Cred.html#S:Sec184"><i class="fa fa-check"></i><b>18.4</b> Bonus-Malus</a></li>
</ul></li>
<li class="chapter" data-level="19" data-path="C19Triangles.html"><a href="C19Triangles.html"><i class="fa fa-check"></i><b>19</b> Claims Triangles</a>
<ul>
<li class="chapter" data-level="19.1" data-path="C19Triangles.html"><a href="C19Triangles.html#introduction-4"><i class="fa fa-check"></i><b>19.1</b> Introduction</a>
<ul>
<li class="chapter" data-level="19.1.1" data-path="C19Triangles.html"><a href="C19Triangles.html#S:Sec1911"><i class="fa fa-check"></i><b>19.1.1</b> Claims Evolution</a></li>
<li class="chapter" data-level="19.1.2" data-path="C19Triangles.html"><a href="C19Triangles.html#S:Sec1912"><i class="fa fa-check"></i><b>19.1.2</b> Claims Triangles</a></li>
<li class="chapter" data-level="19.1.3" data-path="C19Triangles.html"><a href="C19Triangles.html#S:Sec1913"><i class="fa fa-check"></i><b>19.1.3</b> Chain Ladder Method</a></li>
</ul></li>
<li class="chapter" data-level="19.2" data-path="C19Triangles.html"><a href="C19Triangles.html#S:Sec192"><i class="fa fa-check"></i><b>19.2</b> Regression Using Functions of Time as Explanatory Variables</a>
<ul>
<li class="chapter" data-level="19.2.1" data-path="C19Triangles.html"><a href="C19Triangles.html#S:Sec1921"><i class="fa fa-check"></i><b>19.2.1</b> Lognormal Model</a></li>
<li class="chapter" data-level="19.2.2" data-path="C19Triangles.html"><a href="C19Triangles.html#S:Sec1922"><i class="fa fa-check"></i><b>19.2.2</b> Hoerl Curve</a></li>
<li class="chapter" data-level="19.2.3" data-path="C19Triangles.html"><a href="C19Triangles.html#S:Sec1923"><i class="fa fa-check"></i><b>19.2.3</b> Poisson Models</a></li>
</ul></li>
<li class="chapter" data-level="19.3" data-path="C19Triangles.html"><a href="C19Triangles.html#S:Sec193"><i class="fa fa-check"></i><b>19.3</b> Using Past Developments</a>
<ul>
<li class="chapter" data-level="19.3.1" data-path="C19Triangles.html"><a href="C19Triangles.html#S:Sec1931"><i class="fa fa-check"></i><b>19.3.1</b> Mack Model</a></li>
<li class="chapter" data-level="19.3.2" data-path="C19Triangles.html"><a href="C19Triangles.html#S:Sec1932"><i class="fa fa-check"></i><b>19.3.2</b> Distributional Models</a></li>
</ul></li>
<li class="chapter" data-level="19.4" data-path="C19Triangles.html"><a href="C19Triangles.html#further-reading-and-references-5"><i class="fa fa-check"></i><b>19.4</b> Further Reading and References</a></li>
<li class="chapter" data-level="19.5" data-path="C19Triangles.html"><a href="C19Triangles.html#exercises-3"><i class="fa fa-check"></i><b>19.5</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="20" data-path="C20Report.html"><a href="C20Report.html"><i class="fa fa-check"></i><b>20</b> Report Writing: Communicating Data Analysis Results</a>
<ul>
<li class="chapter" data-level="20.1" data-path="C20Report.html"><a href="C20Report.html#S20:Overview"><i class="fa fa-check"></i><b>20.1</b> Overview</a></li>
<li class="chapter" data-level="20.2" data-path="C20Report.html"><a href="C20Report.html#S20:Methods"><i class="fa fa-check"></i><b>20.2</b> Methods for Communicating Data</a>
<ul>
<li class="chapter" data-level="" data-path="C20Report.html"><a href="C20Report.html#within-text-data"><i class="fa fa-check"></i>Within Text Data</a></li>
<li class="chapter" data-level="" data-path="C20Report.html"><a href="C20Report.html#graphs"><i class="fa fa-check"></i>Graphs</a></li>
</ul></li>
<li class="chapter" data-level="20.3" data-path="C20Report.html"><a href="C20Report.html#S20:Organize"><i class="fa fa-check"></i><b>20.3</b> How to Organize</a>
<ul>
<li class="chapter" data-level="" data-path="C20Report.html"><a href="C20Report.html#title-and-abstract"><i class="fa fa-check"></i>Title and Abstract</a></li>
<li class="chapter" data-level="" data-path="C20Report.html"><a href="C20Report.html#introduction-5"><i class="fa fa-check"></i>Introduction</a></li>
<li class="chapter" data-level="" data-path="C20Report.html"><a href="C20Report.html#model-selection-and-interpretation"><i class="fa fa-check"></i>Model Selection and Interpretation</a></li>
<li class="chapter" data-level="" data-path="C20Report.html"><a href="C20Report.html#references-and-appendix"><i class="fa fa-check"></i>References and Appendix</a></li>
</ul></li>
<li class="chapter" data-level="20.4" data-path="C20Report.html"><a href="C20Report.html#further-suggestions-for-report-writing"><i class="fa fa-check"></i><b>20.4</b> Further Suggestions for Report Writing</a></li>
<li class="chapter" data-level="20.5" data-path="C20Report.html"><a href="C20Report.html#case-study-swedish-automobile-claims"><i class="fa fa-check"></i><b>20.5</b> Case Study: Swedish Automobile Claims</a></li>
<li class="chapter" data-level="20.6" data-path="C20Report.html"><a href="C20Report.html#further-reading-and-references-6"><i class="fa fa-check"></i><b>20.6</b> Further Reading and References</a></li>
<li class="chapter" data-level="20.7" data-path="C20Report.html"><a href="C20Report.html#exercises-4"><i class="fa fa-check"></i><b>20.7</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="21" data-path="C21Design.html"><a href="C21Design.html"><i class="fa fa-check"></i><b>21</b> Designing Effective Graphs</a>
<ul>
<li class="chapter" data-level="21.1" data-path="C21Design.html"><a href="C21Design.html#S21:Intro"><i class="fa fa-check"></i><b>21.1</b> Introduction</a></li>
<li class="chapter" data-level="21.2" data-path="C21Design.html"><a href="C21Design.html#S21:GDesign"><i class="fa fa-check"></i><b>21.2</b> Graphic Design Choices Make a Difference</a></li>
<li class="chapter" data-level="21.3" data-path="C21Design.html"><a href="C21Design.html#S21:DesignGuide"><i class="fa fa-check"></i><b>21.3</b> Design Guidelines</a>
<ul>
<li class="chapter" data-level="" data-path="C21Design.html"><a href="C21Design.html#guideline-one-avoid-chartjunk"><i class="fa fa-check"></i>Guideline One: Avoid Chartjunk</a></li>
<li class="chapter" data-level="" data-path="C21Design.html"><a href="C21Design.html#guideline-two-use-small-multiples-to-promote-comparisons-and-assess-change"><i class="fa fa-check"></i>Guideline Two: Use Small Multiples to Promote Comparisons and Assess Change</a></li>
<li class="chapter" data-level="" data-path="C21Design.html"><a href="C21Design.html#guideline-three-use-complex-graphs-to-portray-complex-patterns"><i class="fa fa-check"></i>Guideline Three: Use Complex Graphs to Portray Complex Patterns</a></li>
<li class="chapter" data-level="" data-path="C21Design.html"><a href="C21Design.html#guideline-four-relate-graph-size-to-information-content"><i class="fa fa-check"></i>Guideline Four: Relate Graph Size to Information Content</a></li>
<li class="chapter" data-level="" data-path="C21Design.html"><a href="C21Design.html#guideline-five-use-graphical-forms-that-promote-comparisons"><i class="fa fa-check"></i>Guideline Five: Use Graphical Forms That Promote Comparisons</a></li>
<li class="chapter" data-level="" data-path="C21Design.html"><a href="C21Design.html#guideline-six-integrate-graphs-and-text"><i class="fa fa-check"></i>Guideline Six: Integrate Graphs and Text</a></li>
<li class="chapter" data-level="" data-path="C21Design.html"><a href="C21Design.html#guideline-seven-demonstrate-an-important-message"><i class="fa fa-check"></i>Guideline Seven: Demonstrate an Important Message</a></li>
<li class="chapter" data-level="" data-path="C21Design.html"><a href="C21Design.html#guideline-eight-know-your-audience"><i class="fa fa-check"></i>Guideline Eight: Know Your Audience</a></li>
</ul></li>
<li class="chapter" data-level="21.4" data-path="C21Design.html"><a href="C21Design.html#S21:EmpiricalFoundations"><i class="fa fa-check"></i><b>21.4</b> Empirical Foundations For Guidelines</a>
<ul>
<li class="chapter" data-level="21.4.1" data-path="C21Design.html"><a href="C21Design.html#graphs-as-units-of-study"><i class="fa fa-check"></i><b>21.4.1</b> Graphs as Units of Study</a></li>
</ul></li>
<li class="chapter" data-level="21.5" data-path="C21Design.html"><a href="C21Design.html#S21:Conclude"><i class="fa fa-check"></i><b>21.5</b> Concluding Remarks</a></li>
<li class="chapter" data-level="21.6" data-path="C21Design.html"><a href="C21Design.html#S21:References"><i class="fa fa-check"></i><b>21.6</b> Further Reading and References</a></li>
</ul></li>
<li class="chapter" data-level="22" data-path="appendices.html"><a href="appendices.html"><i class="fa fa-check"></i><b>22</b> Appendices</a>
<ul>
<li class="chapter" data-level="" data-path="appendices.html"><a href="appendices.html#appendix-a1.-basic-statistical-inference"><i class="fa fa-check"></i>Appendix A1. Basic Statistical Inference</a>
<ul>
<li class="chapter" data-level="" data-path="appendices.html"><a href="appendices.html#distributions-of-functions-of-random-variables"><i class="fa fa-check"></i>Distributions of Functions of Random Variables</a></li>
<li class="chapter" data-level="" data-path="appendices.html"><a href="appendices.html#estimation-and-prediction"><i class="fa fa-check"></i>Estimation and Prediction</a></li>
<li class="chapter" data-level="" data-path="appendices.html"><a href="appendices.html#testing-hypotheses"><i class="fa fa-check"></i>Testing Hypotheses</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="appendices.html"><a href="appendices.html#appendix-a2.-matrix-algebra"><i class="fa fa-check"></i>Appendix A2. Matrix Algebra</a>
<ul>
<li class="chapter" data-level="" data-path="appendices.html"><a href="appendices.html#basic-definitions"><i class="fa fa-check"></i>Basic Definitions</a></li>
<li class="chapter" data-level="" data-path="appendices.html"><a href="appendices.html#review-of-basic-operations"><i class="fa fa-check"></i>Review of Basic Operations</a></li>
<li class="chapter" data-level="" data-path="appendices.html"><a href="appendices.html#further-definitions"><i class="fa fa-check"></i>Further Definitions</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="appendices.html"><a href="appendices.html#appendix-a3.-probability-tables"><i class="fa fa-check"></i>Appendix A3. Probability Tables</a>
<ul>
<li class="chapter" data-level="" data-path="appendices.html"><a href="appendices.html#normal-distribution"><i class="fa fa-check"></i>Normal Distribution</a></li>
<li class="chapter" data-level="" data-path="appendices.html"><a href="appendices.html#chi-square-distribution"><i class="fa fa-check"></i>Chi-Square Distribution</a></li>
<li class="chapter" data-level="" data-path="appendices.html"><a href="appendices.html#t-distribution"><i class="fa fa-check"></i><em>t</em>-Distribution</a></li>
<li class="chapter" data-level="" data-path="appendices.html"><a href="appendices.html#f-distribution"><i class="fa fa-check"></i><em>F</em>-Distribution</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="" data-path="brief-answers-to-selected-exercises.html"><a href="brief-answers-to-selected-exercises.html"><i class="fa fa-check"></i>Brief Answers to Selected Exercises</a></li>
<li class="divider"></li>
<li><a href="https://github.com/OpenActTextDev/RegressionSpanish/" target="blank">Spanish Regression on GitHub</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Regression Modeling with Actuarial and Financial Applications</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="brief-answers-to-selected-exercises" class="section level1 unnumbered hasAnchor">
<h1>Brief Answers to Selected Exercises<a href="brief-answers-to-selected-exercises.html#brief-answers-to-selected-exercises" class="anchor-section" aria-label="Anchor link to header"></a></h1>
<div id="chapter-1" class="section level4 unnumbered hasAnchor">
<h4>Chapter 1<a href="brief-answers-to-selected-exercises.html#chapter-1" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p><strong>1.1</strong>
a(i). Mean = 12,840, Median = 5,695 <br>
a(ii). Standard deviation = 48,836.7 = 3.8 times the mean. The data appear to be skewed.<br>
b. The plots are not presented here. When viewing them, the distribution appears to be skewed to the right. <br>
c(i). The plots are not presented here. When viewing them, although the distribution has moved towards symmetry, it is still quite lop-sided.<br>
c(ii). The plots are not presented here. When viewing them, yes, the distribution appears to be much more symmetric. <br>
d. Mean = 1,854.0, Median = 625.7, Standard deviation =3,864.3. A similar pattern holds true for outpatient as for inpatient.<br></p>
<p><strong>1.2</strong>. Part 1. a. Descriptive Statistics for the 2000 data
<span class="math display">\[
\small{
\begin{array}{lrrrrrrr}
   \hline
         &amp;   &amp; 1st  &amp;   &amp;    &amp; 3rd  &amp;   &amp; \text{Standard} \\
         &amp; \text{Min}  &amp; \text{Quartile}  &amp; \text{Median} &amp; \text{Mean}  &amp; \text{Quartile} &amp; \text{Max}   &amp; \text{Deviation}
         \\\hline
   \text{TPY}   &amp; 11.57 &amp; 56.72 &amp; 80.54 &amp; 88.79 &amp; 108.60 &amp; 314.70 &amp; 46.10 \\
   \text{NUMBED} &amp; 18.00    &amp; 60.25 &amp; 90.00    &amp; 97.08 &amp; 118.8 &amp; 320.00   &amp; 48.99 \\
   \text{SQRFOOT} &amp; 5.64  &amp; 28.64 &amp; 39.22 &amp; 50.14 &amp; 65.49 &amp; 262.00   &amp; 34.50 \\
    \hline
\end{array}
}
\]</span>
b. The plots are not presented here. When viewing them, the histogram appears to be skewed to the right but only mildly.<br>
c. The plots are not presented here. When viewing them, both the histogram and the <span class="math inline">\(qq\)</span> plot suggest that the transformed distribution is close to a normal distribution.<br>
Part 2. a. Descriptive Statistics for the 2001 data
<span class="math display">\[
\small{
\begin{array}{lrrrrrrr}
   \hline
         &amp;   &amp; 1st  &amp;   &amp;    &amp; 3rd  &amp;   &amp; \text{Standard} \\
         &amp; \text{Min}  &amp; \text{Quartile}  &amp; \text{Median} &amp; \text{Mean}  &amp; \text{Quartile} &amp; \text{Max}   &amp; \text{Deviation}
         \\\hline
   \text{TPY}   &amp; 12.31 &amp; 56.89 &amp; 81.13 &amp; 89.71 &amp; 109.90 &amp; 440.70 &amp; 49.05 \\
   \text{NUMBED} &amp; 18.00    &amp; 60.00    &amp; 90.00    &amp; 97.33 &amp; 119.00   &amp; 457.00   &amp; 51.97 \\
   \text{SQRFOOT} &amp; 5.64  &amp; 28.68 &amp; 40.26 &amp; 50.37 &amp; 63.49 &amp; 262.00   &amp; 35.56 \\
   \hline
\end{array}
}
\]</span>
c. Both the histogram and the <span class="math inline">\(qq\)</span> plot (not presented here) suggest that the transformed distribution is close to the normal distribution.<br></p>
<p><strong>1.5</strong>
a. Mean = 5.953, Median = 2.331<br>
b. The plots are not presented here. When viewing them, the histogram appears to be skewed to the right. The <span class="math inline">\(qq\)</span> plot indicates a serious departure from normality.<br>
c(i). For ATTORNEY=1, we have Mean = 9.863 and Median = 3.417. For ATTORNEY=2, we have Mean = 1.865 and Median = 0.986. This suggests that the losses associated with attorney involvement (ATTORNEY=1) are higher than when an attorney is not involved (ATTORNEY=1).<br></p>
<p><strong>1.7</strong> a. The plots are not presented here. When viewing them, the histogram appears to be skewed to the left. The <span class="math inline">\(qq\)</span> plot indicates a serious departure from normality.<br>
b. The plots are not presented here. When viewing them, the transformation does little to symmetrize the distribution.</p>
</div>
<div id="chapter-2" class="section level4 unnumbered hasAnchor">
<h4>Chapter 2<a href="brief-answers-to-selected-exercises.html#chapter-2" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p><strong>2.1</strong>
<span class="math inline">\(r=0.5491, b_0=4.2054, b_1=0.1279\)</span> <br></p>
<p><strong>2.3</strong> a.
<span class="math display">\[\begin{eqnarray*} 0 &amp; \leq &amp;
\frac{1}{n-1}\sum_{i=1}^n\left( a\frac{x_i-\overline{x}}{s_{x}}-c
\frac{y_i-\overline{y}}{s_{y}}\right) ^{2} \\
&amp;=&amp;{\frac{1}{n-1}}\sum_{i=1}^n\left[a^2\frac{(x_i-\overline{x})^2}{s_{x}^2}
-2ac\frac{(x_i-\overline{x})(y_i-\overline{y})}{s_x s_{y}}+c^2\frac{(y_i-\overline{y})^2}{s_{y}^2} \right]\\
&amp;=&amp; a^2\frac{1}{s_x^2}\frac{1}{n-1}\sum_{i=1}^n\left(x_i-\overline{x}\right)^2-2ac\frac{1}{s_x s_y}\frac{1}{n-1}\sum_{i=1}^n\left(x_i-\overline{x}\right)\left(y_i-\overline{y}\right)\\
&amp;&amp;+~c^2\frac{1}{s_y^2}\frac{1}{n-1}\sum_{i=1}^n\left(y_i-\overline{y}\right)^2\\
&amp;=&amp;a^2\frac{1}{s_x^2}s_x^2-2acr+c^2\frac{1}{s_y^2}s_y^2\\
&amp;=&amp; a^{2}+c^{2}-2acr.
\end{eqnarray*}\]</span>
b. From part (a), we have <span class="math inline">\(a^{2}+c^{2}-2acr \geq 0\)</span>.
So,<span class="math display">\[\begin{eqnarray*}
a^{2}+c^{2}-2ac+2ac &amp;\geq&amp; 2acr\\
(a-c)^2&amp;\geq&amp; 2acr-2ac\\
(a-c)^2&amp;\geq&amp; 2ac(r-1)
\end{eqnarray*}\]</span>
c. Using the result in part b) and taking <span class="math inline">\(a = c\)</span>, we can get <span class="math inline">\(2a^{2}(r-1)\leq0\)</span>.
Also <span class="math inline">\(a^2\geq 0\)</span>, so <span class="math inline">\(r-1\leq 0\)</span>. Thus, $ r $.<br>
d. Using the result in part (b) and taking <span class="math inline">\(a = -c\)</span>, we can get <span class="math inline">\(-2a^{2}(r-1)\leq4a^2\)</span>.
Also <span class="math inline">\(-2a^2\leq 0\)</span>, so <span class="math inline">\(r-1\geq -2\)</span>. Thus, <span class="math inline">\(r \geq -1\)</span>.<br>
e. If all of the data lie on a straight line that goes through the upper left and lower right hand quadrants, then <span class="math inline">\(r=-1\)</span>.
If all of the data lie on a straight line that goes through the lower left and upper right hand quadrants, then <span class="math inline">\(r=1\)</span>.<br></p>
<p><strong>2.5</strong> a.
<span class="math display">\[\begin{eqnarray*} b_1 =
r\frac{s_{y}}{s_{x}} &amp;=&amp; \frac{1}{(n-1)s_{x}^{2}}\sum_{i=1}^n\left(
x_{i}-\overline{x}\right) \left( y_{i}-\overline{y}\right)  \\
&amp;=&amp; \frac{1}{\sum_{i=1}^n\left(
x_{i}-\overline{x}\right)^{2}}\sum_{i=1}^n\left[\frac{y_{i}-\overline{y}}{x_{i}-\overline{x}}\left(
x_{i}-\overline{x}\right)^2\right]\\
&amp;&amp; \\
&amp;&amp;\\
&amp;=&amp; \frac{\sum_{i=1}^nweight_i~slope_i}{\sum_{i=1}^nweight_{i}}.
\end{eqnarray*}\]</span>
where,
<span class="math display">\[
slope_i=\frac{y_{i}-\overline{y}}{x_{i}-\overline{x}}~~~~~\mathrm{and}~~~~~weight_i=\left(
x_{i}-\overline{x}\right)^2
\]</span>
b. <span class="math inline">\(slope_1=-1.5, weight_1=4\)</span><br></p>
<p><strong>2.7</strong> a. For the model in this exercise, the least squares estimate of <span class="math inline">\(\beta_1\)</span> is the <span class="math inline">\(b_1\)</span> that minimizes the sum of squares <span class="math inline">\(\mathrm{SS}(b_1^{\ast} )=\sum_{i=1}^n\left( y_i - b_1^{\ast }x_i\right) ^{2}.\)</span> So, taking derivative with respect to <span class="math inline">\(b_1^{\ast}\)</span>, we have
<span class="math display">\[
\frac{\partial }{\partial b_1^{\ast }}SS(b_1^{\ast
})=\sum_{i=1}^n(-2x_{i})\left( y_{i}-b_1^{\ast }x_{i}\right)
\]</span>
Setting this quantity equal to zero and canceling constant terms yields
<span class="math display">\[
\sum_{i=1}^n\left(x_{i}y_{i}-b_1^{\ast }x_{i}^2\right) =0
\]</span>
So, we get the conclusion
<span class="math display">\[
b_1 = \frac{\sum_{i=1}^n x_i y_i}{\sum_{i=1}^nx_i^{2}}.
\]</span>
b. From the problem, we have <span class="math inline">\(x_i = z_i^2\)</span>. Using the result of part
(a), we can reach the conclusion that
<span class="math display">\[
b_1 = \frac{\sum_{i=1}^n z_i^2 y_i}{\sum_{i=1}^nz_i^{4}}.
\]</span></p>
<p><strong>2.10</strong>
a(i). Correlation<span class="math inline">\(= 0.9372\)</span><br>
a(ii). Table of correlations
<span class="math display">\[
\small{
\begin{array}{llll}
   \hline
   &amp;\text{TPY} &amp;   \text{NUMBED} &amp;  \text{SQRFOOT}  \\\hline
\text{TPY}  &amp;   1.0000 &amp; 0.9791 &amp; 0.8244\\
\text{NUMBED} &amp;  0.9791 &amp; 1.0000 &amp; 0.8192\\
\text{SQRFOOT} &amp; 0.8244 &amp; 0.8192 &amp; 1.0000\\
  \hline
\end{array}
}
\]</span>
a(iii). Correlation<span class="math inline">\(= 0.9791.\)</span> Correlations are unaffected by scale changes.<br>
b. The plots are not presented here. When viewing them, there is a strong linear relationship between NUMBED and TPY. The linear relationship of SQRFOOT and TPY is not as strong as that of NUMBED and TPY.<br>
c(i). <span class="math inline">\(b_1=0.92142, t-\mathrm{ratio}=91.346, R^2=0.9586\)</span><br>
c(ii). <span class="math inline">\(R^2 =0.6797.\)</span> The model using NUMBED is preferred.<br>
c(iii). <span class="math inline">\(b_1 =1.01231, t-\mathrm{ratio}=81.235, R^2=0.9483\)</span><br>
c(iv). <span class="math inline">\(b_1 =0.68737, t-\mathrm{ratio}=27.25, R^2=0.6765\)</span><br>
Part 2: <span class="math inline">\(b_1=0.932384, t-\mathrm{ratio}=120.393, R^2=0.9762.\)</span> The pattern is similar to the cost report for year 2000.<br></p>
<p><strong>2.11</strong> <span class="math inline">\(\hat{e}_1 = -23.\)</span><br></p>
<p><strong>2.13</strong> a.
<span class="math display">\[
\hat{y}_i - \overline{y} = (b_0 + b_1 x_i) - \overline{y} = (\overline{y}-b_1 \overline{x} + b_1 x_i) - \overline{y} = b_1(x_i - \overline{x}).
\]</span>
b.
<span class="math display">\[
\sum^n_{i=1}(y_i - \overline{y})^2 =
\sum^n_{i=1}(b_1(x_i - \overline{x}))^2 = b_1^2 \sum_{i=1}^n(x_i -
\overline{x})^2 = b_1^2 s_x^2(n-1).
\]</span>
c. 
<span class="math display">\[
R^2 = \frac{Regression ~SS}{Total ~SS} =
\frac{b_1^2 s_x^2(n-1)}{\sum_{i=1}^n(y_i - \overline{y})^2} =
\frac{b_1^2 s_x^2(n-1)}{s_y^2(n-1)} = \frac{b_1^2 s_x^2}{s_y^2}.
\]</span></p>
<p><strong>2.15</strong> a. From the definition of the correlation coefficient
and Exercise 2.8(b), we have
<span class="math display">\[
r(y,x)(n-1)s_y s_x = \sum_{i=1}^n \left( y_i-\overline{y}\right)
\left( x_i-\overline{x}\right) = \sum_{i=1}^n y_i x_i - n
\overline{x} \overline{y}.
\]</span>
If either <span class="math inline">\(\overline{y}=0,\overline{x}=0\)</span> or both <span class="math inline">\(\overline{x}\)</span>
and <span class="math inline">\(\overline{y}=0,\)</span> then $r(y,x)(n-1)s_y s_x = _{i=1}^n y_i
x_i $. Therefore, <span class="math inline">\(r(y,x)=0\)</span> implies
<span class="math inline">\(\sum_{i=1}^ny_i x_i=0\)</span> and vice-versa.<br>
b.
<span class="math display">\[\begin{eqnarray*}
\sum_{i=1}^n x_i e_i &amp;=&amp; \sum_{i=1}^n x_i (y_i - (\overline{y} + b_1(x_i-\overline{x}) )) \\
&amp;=&amp; \sum_{i=1}^n x_i (y_i - \overline{y}) - b_1 \sum_{i=1}^n x_i (x_i-\overline{x}) \\
&amp;=&amp; \sum_{i=1}^n x_i b_1(x_i - \overline{x}) - b_1 \sum_{i=1}^n x_i (x_i-\overline{x}) = 0,
\end{eqnarray*}\]</span>
c.
<span class="math display">\[\begin{eqnarray*}
\sum_{i=1}^n \widehat{y}_i e_i &amp;=&amp; \sum_{i=1}^n
( \overline{y}+b_1(x_i-\overline{x}) ) e_i \\
&amp;=&amp;  \overline{y} \sum_{i=1}^n e_i + b_1\sum_{i=1}^n ( (x_i-\overline{x})) e_i = 0,
\end{eqnarray*}\]</span></p>
<p><strong>2.17</strong>
When <span class="math inline">\(n = 100\)</span>, <span class="math inline">\(k = 1\)</span>, <span class="math inline">\(Error~SS = [n-(k+1)]s^2 = 98s^2\)</span><br>
a. <span class="math inline">\(e_{10}^2/(Error~SS) = (8s)^2/(98s^2) = 65.31\%\)</span><br>
b. <span class="math inline">\(e_{10}^2/(Error~SS) = (4s)^2/(98s^2) = 16.33\%\)</span><br>
When <span class="math inline">\(n = 20\)</span>, <span class="math inline">\(k = 1\)</span>, <span class="math inline">\(Error~SS = [n-(k+1)]s^2 = 18s^2\)</span><br>
c. <span class="math inline">\(e_{10}^2/(Error~SS) = (4s)^2/(18s^2) = 88.89\%\)</span><br></p>
<p><strong>2.20</strong>
a. Correlation=0.9830<br>
Descriptive Statistics
<span class="math display">\[
\small{
\begin{array}
{lrrrrrrr}
   \hline
         &amp;   &amp; 1st  &amp;   &amp;    &amp; 3rd  &amp;   &amp; \text{Standard} \\
         &amp; \text{Min}  &amp; \text{Quartile}  &amp; \text{Median} &amp; \text{Mean}  &amp; \text{Quartile} &amp; \text{Max}   &amp; \text{Deviation}
         \\\hline
   \text{LOGTPY}   &amp; 2.51 &amp;  4.04 &amp; 4.40 &amp; 4.37 &amp; 4.70 &amp; 6.09 &amp; 0.51 \\
   \text{LOGNUMBED} &amp; 2.89    &amp; 4.09 &amp; 4.50    &amp; 4.46 &amp; 4.78 &amp; 6.13   &amp; 0.49 \\
   \hline
\end{array}
}
\]</span>
b. <span class="math inline">\(R^2 = 0.9664\)</span>, <span class="math inline">\(b_1 = 1.01923\)</span>, <span class="math inline">\(t(b_1) = 100.73\)</span>.<br>
c(i). The degrees of freedom is <span class="math inline">\(df = 355 - (1+1) = 353\)</span>. The corresponding <span class="math inline">\(t\)</span>-value is 1.96. Because the <span class="math inline">\(t\)</span>-statistic <span class="math inline">\(t(b_1) = 100.73 &gt; 1.9667\)</span>, we reject <span class="math inline">\(H_0\)</span> in favor of the alternative.<br>
c(ii). The <span class="math inline">\(t\)</span>-statistic is <span class="math inline">\(t - \mathrm{ratio} = (b_1 - 1)/se(b_1) = (1.01923 - 1)/0.01012  = 1.9002.\)</span> Because <span class="math inline">\(t-\mathrm{ratio} &lt; 1.9667\)</span>, we do not reject <span class="math inline">\(H_0\)</span> in favor of the alternative.<br>
c(iii). The corresponding <span class="math inline">\(t\)</span>-value is 1.645. The <span class="math inline">\(t\)</span>-statistic is <span class="math inline">\(t - \mathrm{ratio} = 1.9002.\)</span>
We reject <span class="math inline">\(H_0\)</span> in favor of the alternative.<br>
c(iv). The corresponding <span class="math inline">\(t\)</span>-value is -1.645. The <span class="math inline">\(t\)</span>-statistic is <span class="math inline">\(t - \mathrm{ratio} = 1.9002.\)</span> We do not reject <span class="math inline">\(H_0\)</span> in favor of the alternative.<br>
d(i). A point estimate is 2.0384<br>
d(ii). 95% C.I. for slope <span class="math inline">\(b_1\)</span> is <span class="math inline">\(1.0192 \pm 1.9667 \times 0.0101 = (0.9993, 1.0391)\)</span>. A 95% C.I. for expected change of LOGTPY is <span class="math inline">\((0.9993 \times 2, 1.0391 \times 2) = (1.9987, 2.0781)\)</span><br>
d(iii). 99% C.I. is $(2(1.0192 - 2.5898), 2(1.0192 + 2.5898)
=(1.9861, 2.0907) $<br>
e(i). <span class="math inline">\(\widehat{y} = -0.1747 + 1.0192 \times \ln 100 = 4.519037.\)</span> <br>
e(ii). The standard error of the prediction
<span class="math display">\[
se(pred) = s \sqrt{1+\frac{1}{n}+\frac{\left( x^{\ast }-\overline{x}\right) ^{2} }{(n-1)s_{x}^{2}}} =
0.09373 \sqrt{1+\frac{1}{355}+\frac{\left( \ln(100)-4.4573\right) ^{2} }{(355-1)0.4924^{2}}}=0.0938.
\]</span>
e(iii). The 95% prediction interval at <span class="math inline">\(x^*\)</span> is
<span class="math display">\[
\widehat{y}^{\ast } \pm t_{n-2,1-\alpha /2} ~se(pred) = 4.519037 \pm
1.9667(0.0938) = (4.3344, 4.7034).
\]</span>
e(iv). The point prediction is <span class="math inline">\(e^{4.519037}= 91.747\)</span>. <br>
The prediction interval is <span class="math inline">\((e^{4.334405}=76.280, e^{4.703668}=110.351 ).\)</span><br>
e(v). The prediction interval is <span class="math inline">\((e^{4.364214}=78.588, e^{4.673859}=107.110 ).\)</span><br></p>
<p><strong>2.22</strong>
a. Fitted US <span class="math inline">\(LIFEEXP = 83.7381 - 5.2735 \times 2.0 = 73.1911\)</span><br>
b. A 95% prediction interval for the life expectancy in Dominica is
<span class="math display">\[
\widehat{y}_{\ast} \pm t_{n-2,1-\alpha /2} ~se(pred)=73.1911\pm(1.973)(6.642)=(60.086, 86.296)
\]</span>
c. 
<span class="math display">\[
e_{i}=y_{i}-\widehat{y}_{i}=y_{i}-\left(
b_0+b_1x_{i}\right)= 72.5-(83.7381 - 5.2735 \times 1.7)=-2.273
\]</span>
This residual is 2.273/6.615 = 0.3436 multiples of <span class="math inline">\(s\)</span> below zero.<br>
d. Test <span class="math inline">\(H_0: \beta_1 = -6.0\)</span> versus <span class="math inline">\(H_a: \beta_1 &gt; -6.0\)</span> at the 5% level of significance using a <span class="math inline">\(t\)</span>-value = 1.645. The calculated <span class="math inline">\(t\)</span>-statistics <span class="math inline">\(= \frac{-5.2735-(-6)}{0.2887}=2.5165\)</span>, which is <span class="math inline">\(\geq1.645\)</span>. Hence, we reject <span class="math inline">\(H_0\)</span> in favor of the alternative. The corresponding <span class="math inline">\(p\)</span>-value <span class="math inline">\(= 0.00637\)</span>.</p>
</div>
<div id="chapter-3" class="section level4 unnumbered hasAnchor">
<h4>Chapter 3<a href="brief-answers-to-selected-exercises.html#chapter-3" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p><strong>3.1</strong>. a. <span class="math inline">\(R^2_a = 1 - s/{s^2_y} = 1 - {(50)^2}/{(100)^2} = 1 - 1/4 = 0.75.\)</span><br>
b. <span class="math inline">\(Total ~SS =(n - 1)s^2_y = 99(100)^2 = 990000\)</span> and <br>
<span class="math inline">\(Error ~SS = (n - (k + 1))s^2 = (100 - (3 + 1))(50)^2 = 240000.\)</span><br>
<span class="math display">\[
\small{
\begin{array}{lcrcc}
\hline
Source &amp; SS &amp; df &amp; MS &amp; F \\ \hline
\text{Regression} &amp; 750000 &amp; 3 &amp; 250000 &amp; 100 \\
\text{Error} &amp; 240000 &amp; 96 &amp; 2500 &amp; \\
\text{Total} &amp; 990000 &amp;99 &amp;&amp; \\
\hline
\end{array}
}
\]</span>
c. <span class="math inline">\(R^2 = (Regression~SS)/(Total~SS) =750000/990000 = 75.76\%\)</span>.<br></p>
<p><strong>3.3</strong> a. <span class="math inline">\({\bf y}=(0~1~5~8)^{\prime}\)</span>, <span class="math inline">\(\mathbf{X}=\left(  \begin{array}{ccc}  1 &amp; -1 &amp; 0 \\  1 &amp; 2 &amp; 0 \\  1 &amp; 4 &amp; 1 \\  1 &amp; 6 &amp; 1 \\  \end{array}  \right)\)</span>.<br>
b. <span class="math inline">\(\hat{y}_{3}=x^{\prime}_{3}\mathbf{b}=(1~4~1)\left(  \begin{array}{c}  0.15 \\  0.692 \\  2.88 \\  \end{array}  \right)=5.798\)</span>
<br>
c. <span class="math inline">\(se(b_{2})=s\sqrt{3rd~diagonal~element~of~(\mathbf{X^{\prime }X)}^{-1}} = 1.373\sqrt{4.11538}=2.785\)</span><br>
d. <span class="math inline">\(t(b_1)=b_1/se(b_1)=0.692/(1.373\times\sqrt{0.15385})=1.286\)</span><br></p>
<p><strong>3.6</strong> a. The regression coefficient is -0.1846, meaning that when public education expenditures increase by 1% of GDP, life expectancies is expected to decrease by 0.1846 years, holding other
variables fixed.<br>
b. The regression coefficient is -0.2358, meaning that when health expenditures increase by 1% of GDP, life expectancies is expected to decrease by 0.2358 years, holding other variables fixed.<br>
c. <span class="math inline">\(H_{0}:\beta_2=0, H_{1}:\beta_2\neq0\)</span>. We can not reject null hypothesis because the <span class="math inline">\(p\)</span>-value is greater than the significance level, say 0.05. Therefore, PUBLICEDUCATION is not a statistically significant variable.<br>
d(i). The purpose of added variable plot is to explore the correlation between PUBLICEDUCATION and LIFEEXP after removing the effects of other variables.<br>
d(ii). The partial correlation is
<span class="math display">\[
r=\frac{t(b_2)}{\sqrt{t(b_2)^2+n-(k+1)}}=\frac{-0.6888}{\sqrt{-0.6888^2+152-(3+1)}}=-0.0565 .
\]</span></p>
</div>
<div id="chapter-4" class="section level4 unnumbered hasAnchor">
<h4>Chapter 4<a href="brief-answers-to-selected-exercises.html#chapter-4" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p><strong>4.1</strong> a. <span class="math inline">\(R^2 = (Regression~SS)/(Total~SS)\)</span>. <br>
b. <span class="math inline">\(F\)</span>-ratio=<span class="math inline">\((Regression~MS)/(Error~MS)\)</span>.<br>
c. 
<span class="math display">\[
1-R^2 =
\frac{Total~SS}{Total~SS}-\frac{Regression~SS}{Total~SS}=
\frac{Error~SS}{Total~SS}.
\]</span>
Now, from the right hand side, we have
<span class="math display">\[\begin{align*}
\frac{R^2}{1-R^2} \frac{(n-(k+1))}{k}
&amp;=\frac{(Regression~SS)/(Total~SS)}{(Error~SS)/(Total~SS)}\frac{(n-(k+1))}{k}\\
&amp;= \frac{Regression~SS}{Error~SS}\frac{(n-(k+1))}{k}\\
&amp;=\frac{(Regression~SS)/k}{(Error~SS)/(n-(k+1))}\\
&amp;=\frac{Regression~MS}{Error~MS} = F-\mathrm{ratio}.
\end{align*}\]</span><br>
d. <span class="math inline">\(F-\mathrm{ratio}=1.7.\)</span><br>
e. <span class="math inline">\(F-\mathrm{ratio}=19.7.\)</span><br></p>
<p><strong>4.3</strong> a. The third level of organizational structure
will be captured by the intercept term of the regression.<br>
b. <span class="math inline">\(H_0\)</span>:TAXEXEMPT is not important, <span class="math inline">\(H_1\)</span>: TAXEXEMPT is important. <span class="math inline">\(p= 0.7694&gt;0.05\)</span>, we do not reject null hypothesis.<br>
c. Because <span class="math inline">\(p\)</span>-value = $ 1.74e^{-6}$ is less than significance level <span class="math inline">\(\alpha=0.05\)</span>, MCERT is an important factor in determining LOGTPY.<br>
c(i). The point estimate of LOGTPY is 3.988.<br>
c(ii). The 95% confidence interval is
$ 3.988  /() = (3.826, 4.150)$.<br>
d. <span class="math inline">\(R^2=0.1448\)</span>. All the variables are statistically significant.<br>
e. <span class="math inline">\(R^2= 0.9673\)</span>. Only LOGNUMBED is statistically significant at <span class="math inline">\(\alpha=0.05\)</span>.<br>
e(i). The partial correlation is 0.0744. The correlation between LOGTPY and
LOGSQRFOOT is 0.8151. The partial correlation removes the effect of other variables on LOGTPY.<br>
e(ii). The <span class="math inline">\(t\)</span>-ratio tests whether the individual explanatory variable is statistically significant. The <span class="math inline">\(F\)</span>-ratio tests whether the explanatory variables taken together have an significant impact
on response variable. In this case, only LOGNUMBED is significant and the <span class="math inline">\(R^2\)</span> is high, this explains why <span class="math inline">\(F\)</span>-ratio is large while most of the <span class="math inline">\(t\)</span>-ratios are small.<br></p>
<p><strong>4.7</strong> a. <span class="math inline">\(H_0\)</span>: PUBLICEDUCATION and lnHEALTH are not jointly statistically significant. That is to say that the coefficients of the two variables are equal to zero. <span class="math inline">\(H_1\)</span>: PUBLICEDUCATION and lnHEALTH are jointly statistically significant. At least one of the coefficients of the two variables is not equal to zero. To make decision, we compare the <span class="math inline">\(F\)</span> statistics with critical value, if <span class="math inline">\(F\)</span> statistics is greater than critical value, we reject null hypothesis. Otherwise, we do not.<br>
<span class="math inline">\(F-ratio = (6602.7 - 6535.7)/(2 \times 44.2) = 0.76\)</span>.
The 95% of <span class="math inline">\(F\)</span> distribution with <span class="math inline">\(df_1=2\)</span> and <span class="math inline">\(df_2=148\)</span> is approximately 3.00. Since <span class="math inline">\(F-ratio\)</span> is less than the critical value, we can not reject null hypothesis. That is, PUBLICEDUCATION and lnHEALTH are not jointly significant.<br>
b. We can see that the life expectancy varies across different regions.<br>
c. <span class="math inline">\(H_0\)</span>: <span class="math inline">\(\beta_{REGION}=0\)</span>, <span class="math inline">\(H_1\)</span>: <span class="math inline">\(\beta_{REGION}\neq0\)</span>. To make the decision, we compare the <span class="math inline">\(p\)</span>-value with significance level <span class="math inline">\(\alpha=0.05\)</span>. If <span class="math inline">\(p&lt;\alpha\)</span>, we reject null hypothesis. Otherwise,
we do not. In this case, <span class="math inline">\(p=0.000 &lt; 0.05\)</span>, so reject null hypothesis. REGION is a statistically significant determinant of LIFEEXP.<br>
d(i). If REGION=Abrab state, <span class="math inline">\(\widehat{LIFEEXP} = 83.3971-2.7559 \times 2-0.4333\times 5-0.7939\times 1=74.9249\)</span>. If REGION=Sub-Sahara Africa, <span class="math inline">\(\widehat{LIFEEXP} = 83.3971-2.7559\times 2-0.4333 \times 5-0.7939 \times 1 -14.3567 = 60.5682\)</span>.<br>
d(ii). The 95% confidence interval is <span class="math inline">\(-14.3567\pm 1.976\times 1.8663=(-18.044,-10.669).\)</span><br>
d(iii). The point estimate for the difference is 18.1886.</p>
</div>
<div id="chapter-5" class="section level4 unnumbered hasAnchor">
<h4>Chapter 5<a href="brief-answers-to-selected-exercises.html#chapter-5" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p><strong>5.1</strong> a. From equation (2.9), we have
<span class="math display">\[\begin{eqnarray*}
h_{ii} &amp; = &amp; \mathbf{x_i}^{\prime}\left(\mathbf{X}^{\prime }\mathbf{X}\right)^{-1}\mathbf{x_i}\\
&amp;=&amp;\left(\begin{array}{cc}1 &amp; x_i\end{array}\right)
\frac{1}{ \sum_{i=1}^{n}x_i^2-n\overline{x}^2}
\left(\begin{array}{cc}n^{-1}\sum_{i=1}^{n}x_i^2 &amp; -\overline{x} \\-\overline{x} &amp; 1\end{array}\right)
\left(\begin{array}{c}1 \\x_i\end{array}\right)\\
&amp;=&amp; \frac{1}{\sum_{i=1}^{n}x_i^2-n\overline{x}^2} \left(
n^{-1}(\sum_{i=1}^{n}x_i^2-n\overline{x}^2)+\overline{x}^2-2\overline{x}x_i+x_i^2
\right)\\
&amp;=&amp;\frac{1}{n}+\frac{(x_i-\overline{x})^2}{(n-1)s_x^2} .
\end{eqnarray*}\]</span></p>
<ol start="2" style="list-style-type: lower-alpha">
<li><p>The average leverage is
<span class="math display">\[
\bar{h}=\frac{1}{n} \sum_{i=1}^n h_{ii} =
\frac{1}{n}+\frac{1}{n}\sum_{i=1}^n\frac{(x_i-\bar{x})^2}{(n-1)s_{x}^2}=\frac{1}{n}+\frac{1}{n}=\frac{2}{n}
\]</span></p></li>
<li><p>Let <span class="math inline">\(c = (x_i-\bar{x})/s_x\)</span>. Then,
<span class="math display">\[
\frac{6}{n}=h_{ii}=\frac{1}{n}+\frac{(x_i-\bar{x})^2}{(n-1)s_{x}^2} =
\frac{1}{n}+\frac{(cs_x)^2}{(n-1)s_{x}^2}=\frac{1}{n}+\frac{c^2}{n-1} .
\]</span>
For large <span class="math inline">\(n\)</span>, <span class="math inline">\(x_i\)</span> is approximately <span class="math inline">\(c=\sqrt{5}=2.236\)</span> standard deviations away from the mean.</p></li>
</ol>
<p><strong>5.3</strong> a. The plots are not presented here. When viewing them, it is difficult to detect linear patterns from the plot of GDP versus LIFEEXP. The logarithmic transform of GDP spreads out values
of GDP, allowing us to see linear patterns. Similar arguments hold for HEALTH, where the pattern in lnHEALTH is more linear.<br>
c(ii). It is both. The standardized residual is -2.66, which exceeds the cut-off of 2, in absolute value. The leverage is 0.1529, which is greater than the cut off <span class="math inline">\(3 \times\overline{h} =3\times (k+1)/n = 0.08\)</span>. <br>
c(iii). The variable PUBLICEDUCATION is no longer statistically significant.</p>
</div>
<div id="chapter-6" class="section level4 unnumbered hasAnchor">
<h4>Chapter 6<a href="brief-answers-to-selected-exercises.html#chapter-6" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p><strong>6.1</strong> a. The variable involact is somewhat right-skewed but
not drastically so. The variable involact has several zeros that may
be a problem with limited dependent variables. The variable age
appears to be bimodal, with six observations that are 28 or less and
the others greater than or equal to 40.
<span class="math display">\[
\small{
\begin{array}{lrrrrrrr}
   \hline
       &amp;   &amp;  &amp; \text{Standard} \\
       &amp;  \text{Mean}  &amp;  \text{Median} &amp; \text{Deviation} &amp; \text{Minimum} &amp; \text{Maximum}\\
   \hline
\text{race}  &amp;   34.9    &amp;   24.5 &amp;  32.6  &amp;      1.0  &amp;     99.7\\
\text{fire}   &amp;   12.3    &amp;   10.4 &amp;   9.3  &amp;      2.0  &amp;     39.7\\
\text{theft}  &amp;   32.4    &amp;   29.0 &amp;  22.3  &amp;      3.0  &amp;    147.0\\
\text{age}    &amp;   60.3    &amp;   65.0 &amp;  22.6  &amp;      2.0  &amp;     90.1\\
\text{income} &amp;   10,696  &amp;  10694.0 &amp; 2,754  &amp;    5,583 &amp;   21,480\\
\text{volact}  &amp;  6.5    &amp;    5.9  &amp;  3.9     &amp;   0.5    &amp;   14.3\\
\text{involact} &amp; 0.6   &amp;     0.4  &amp;  0.6     &amp;   0.0    &amp;    2.2\\
   \hline
\end{array}
}
\]</span>
b. The scatterplot matrix (not presented here) shows a negative
relation between volact and involact, a negative relation between
race and volact and a positive relation between race and involact.
If there exists racial discrimination, we would expect zip codes
with more minorities to have less access to the voluntary (less
expensive) market, meaning that the have to go to the involuntary
market for insurance.</p>
<ol start="3" style="list-style-type: lower-alpha">
<li>Table of correlations
<span class="math display">\[
\small{
\begin{array}{lrrrrrrr}
\hline
    &amp;    \text{race}&amp;  \text{race}  &amp;\text{theft} &amp;   \text{age} &amp; \text{income} &amp;\text{volact} &amp;\text{involact}\\
\hline
\text{race}  &amp;   1.000 &amp;   &amp; &amp;  &amp;  &amp;  &amp;\\
\text{fire}   &amp;   0.593 &amp; 1.000  &amp; &amp; &amp;  &amp;  &amp;\\
\text{theft}  &amp;   0.255 &amp; 0.556  &amp;1.000 &amp;  &amp;  &amp;  &amp;\\
\text{age}    &amp;   0.251 &amp; 0.412  &amp;0.318 &amp; 1.000 &amp;  &amp;  &amp;\\
\text{income} &amp;  -0.704 &amp;-0.610 &amp;-0.173 &amp;-0.529 &amp; 1.000  &amp;  &amp;\\
\text{volact} &amp;  -0.759 &amp;-0.686 &amp;-0.312 &amp;-0.606 &amp; 0.751  &amp;1.000   &amp;\\
\text{involact} &amp; 0.714 &amp; 0.703 &amp; 0.150 &amp; 0.476 &amp; -0.665 &amp;-0.746  &amp;  1.000\\
\hline
\end{array}
}
\]</span></li>
</ol>
<p>d(i). The coefficient associated with race is negative and statistically significant.<br>
d(ii). The high leverage zip codes are number 7 and 24. The variable race remains statistically negatively significant. The variable fire is no longer significant although income becomes significant.<br>
e. The variable race remains positively statistically significant. Similarly, the role of the other variables do not change depending on the presence of the two high leverage points.<br>
f. The variable race remains positively statistically significant. Similarly, the role of the other variables do not change depending on the presence of the two high leverage points.<br>
g. Leverage depends on the explanatory variables, not on the dependent variables. Because the explanatory variables remained unchanged in the three analyses, the leverages remained unchanged.<br>
h. The demand for insurance depends on the size of the loss to be insured, the ability of the applicant to pay for it and knowledge of insurance contracts. For homeowners insurance, the size of the loss relates to house price, type of dwelling structure, available safety precautions taken, susceptibility to catastrophes such as tornado, flood and so on. Ability to pay is based on income, wealth, number of dependents and other factors. Knowledge of insurance contracts depends on, for example, education. All of these omitted factors may be related to race.<br>
i. One would expect zip codes that are adjacent to one another (``contiguous’’) to share similar economic experiences. We could subdivide the city into homogeneous groups, such as inner city and
suburbs. We could also do a weighted least squares where the weights are given by the distance from the city center.</p>
</div>
<div id="chapter-7" class="section level4 unnumbered hasAnchor">
<h4>Chapter 7<a href="brief-answers-to-selected-exercises.html#chapter-7" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p><strong>7.1</strong> a. <span class="math display">\[\begin{align*}
\textrm{E}~y_t &amp;= \textrm{E}~(y_0+c_1+\cdots+c_t)=\textrm{E}~y_0+\textrm{E}~c_1+\cdots+\textrm{E}~c_t\\
&amp;= y_0+\mu_c+\cdots+\mu_c = y_0 + t \mu_c.
\end{align*}\]</span></p>
<ol start="2" style="list-style-type: lower-alpha">
<li><span class="math display">\[\begin{align*}
\textrm{Var}~y_t &amp;= \textrm{Var}~(y_0+c_1+\cdots+c_t)=\textrm{Var}~c_1+\cdots+\textrm{Var}~c_t\\
&amp;=\sigma_c^2+\cdots+\sigma_c^2 = t\sigma_t^2.
\end{align*}\]</span></li>
</ol>
<p><strong>7.3</strong> a(ii). No. There is a clear downward trend in the series, indicating that the mean changes over time.<br>
b(i). The <span class="math inline">\(t-\)</span>ratios associated with the linear and quadratic trend portions are highly statistically significant. The <span class="math inline">\(R^2 = 0.8733\)</span> indicates that the model fits well.<br>
b(ii). The sign of a residual is highly likely to be the same as preceding a subsequent residuals. This suggests a strong degree of autocorrelation in the residuals.<br>
b(iii). <span class="math inline">\(\widehat{EURO_{702}} = 0.808 + 0.0001295(702) - 4.639 \times 10^{-7}(702)^2 = 0.6703.\)</span><br>
c(i). This is a random walk model.<br>
c(ii). <span class="math inline">\(\widehat{EURO_{702}} = 0.6795 + 3(-0.0001374) = 0.679088.\)</span><br>
c(iii). An approximate 95% prediction interval for <span class="math inline">\(EURO_{702}\)</span> is
<span class="math display">\[
0.679088\pm2(0.003621979)\sqrt{3} \approx (0.66654, 0.691635).
\]</span></p>
</div>
<div id="chapter-8" class="section level4 unnumbered hasAnchor">
<h4>Chapter 8<a href="brief-answers-to-selected-exercises.html#chapter-8" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p><strong>8.1</strong>
<span class="math display">\[
\begin{array}{ll}
r_1 &amp;=\left(\sum_{t=2}^{5}(y_{t-1}-\bar y)(y_{t}-\bar
y)\right) /\left(\sum_{t=1}^{5}(y_{t}-\bar y)^{2}\right) = -0.0036/0.0134 = -0.2687 \\
r_2 &amp;= \left(\sum_{t=3}^{5}(y_{t-2}-\bar y)(y_{t}-\bar
y)\right) /\left(\sum_{t=1}^{5}(y_{t}-\bar y)^{2}\right) = 0.0821
\end{array}
\]</span></p>
<p><strong>8.3</strong> a. <span class="math inline">\(b_1= \left(\sum_{t=2}^{T}(y_{t-1}-\bar y_{-})(y_t-\bar y_{+})\right) /\left(\sum_{t=2}^{T}(y_{t-1}-\bar y_{-})^2\right)\)</span>,
where <span class="math inline">\(\bar y_{+}=\left(\sum_{t=2}^{T}y_{t}\right)/(T-1)\)</span> and <span class="math inline">\(\bar y_{-}=\left(\sum_{t=1}^{T-1}y_{t} \right)/(T-1)\)</span>.<br>
b.
<span class="math inline">\(b_0=\bar y_{+}-b_1 \bar y_{-}\)</span>.<br>
c. <span class="math inline">\(b_0\approx \bar y \left[ 1- \left(\sum_{t=2}^{T}(y_{t-1}-\bar y_{-})(y_t-\bar y_{+})\right) /\left(\sum_{t=2}^{T}(y_{t-1}-\bar y_{-})^2\right) \right] \approx \bar y \left[1-r_1\right]\)</span>.</p>
<p><strong>8.6</strong> a. Since the mean and variance of the sequence does not vary over time, the sequence can be thought to be weakly stationary. <br>
b. The summary statistics of the sequence are as follows:
<span class="math display">\[
\small{
\begin{array}{rrrrr} \hline
\text{Mean}&amp; \text{Median}&amp; \text{Std}&amp; \text{Minimum}&amp; \text{Max}\\
0.0004&amp; 0.0008&amp; 0.0064&amp; -0.0182 &amp; 0.0213\\
\hline
\end{array}
}
\]</span>
Under the assumption of white noise, the forecast of an observation in the future is its sample mean, that is 0.0004. This forecast does not depend on the number of steps ahead.<br>
c. The autocorrelations for the lags 1 through 10 is shown:
<span class="math display">\[
\small{
\begin{array}{ccccccccccc}
\hline
         0   &amp;   1  &amp;    2  &amp;    3   &amp;   4   &amp;   5   &amp;   6   &amp;   7   &amp;   8   &amp;   9   &amp;  10\\
     1.000 &amp; -0.046 &amp; -0.096 &amp; 0.019 &amp; -0.002 &amp;  -0.004 &amp; -0.054 &amp; -0.035 &amp; -0.034 &amp; -0.051 &amp; 0.026\\
\hline
\end{array}
}
\]</span>
Because <span class="math inline">\(|r_k/se(r_k)|&lt;2\)</span> (<span class="math inline">\(se(r_k)=1/\sqrt{503} = 0.0446\)</span>) for <span class="math inline">\(i=1,\ldots,10\)</span>, none of the autocorrelations is strongly statistically significant different from zero except for lag 2. For
lag 2, the autocorrelation is <span class="math inline">\(0.096/0.0446 = 2.15\)</span> standard errors below zero.</p>
</div>
<div id="chapter-11" class="section level4 unnumbered hasAnchor">
<h4>Chapter 11<a href="brief-answers-to-selected-exercises.html#chapter-11" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p><strong>11.1</strong> a. The probability density function is
<span class="math display">\[
\mathrm{f}(y)=\frac{\partial}{\partial y}\mathrm{F}(y)
=(-1)(1+e^{-y})^{-2}e^{-y}(-1)= \frac{e^y}{(1+e^y)^2}.
\]</span>
b.
<span class="math display">\[
\mu_y = \int_{-\infty}^{\infty}\ y \mathrm{f}(y)dy =
\int_{-\infty}^{\infty}\ y \frac{e^{y}}{(1+e^{y})^{2}}dy= 0.
\]</span>
c.
<span class="math display">\[
\mathrm{E~}y^2 = \int_{-\infty}^{\infty}\ y^2 \mathrm{f}(y)dy =
\pi^2 /3 .
\]</span>
Since <span class="math inline">\(\mu_y = 0\)</span>, the standard deviation is $ _y = / =1.813798.$ <br>
d. The probability density function for <span class="math inline">\(y^{\ast \ast}\)</span> is<br>
<span class="math display">\[\begin{eqnarray*}
\mathrm{f}^{\ast}(y)&amp;=&amp; \frac{\partial}{\partial y}\Pr(y^{\ast \ast}
\leq y) = \frac{\partial}{\partial y}\Pr(y^{\ast } \leq y \sigma_y +
\mu_y) =\sigma_y \mathrm{f}(y \sigma_y) = \sigma_y
\frac{e^{y\sigma_y}}{(1+e^{y\sigma_y})^2}.
\end{eqnarray*}\]</span></p>
<p><strong>11.3</strong> Let <span class="math inline">\(\Pr(\varepsilon_{i1} \leq a) = F(a)=\exp(-e^{-a})\)</span> and <span class="math inline">\(f(a)=\frac{dF(a)}{da}=\exp(-e^{-a})e^{-a}.\)</span>
Then</p>
<p><span class="math display">\[\begin{align*}
\Pr(\varepsilon_{i2}-\varepsilon_{i1} \leq a)
&amp;=\int_{-\infty}^{\infty}F(a+y)f(y)\,dy=\int_{-\infty}^{\infty}\exp\left[-e^{-y}(e^{-a}+1)\right]e^{-y}\,dy\\
&amp;=\int_{\infty}^0\exp(-zA)z \,d(-\ln z)=-\int_{\infty}^0\exp(-zA)\,dz\\
&amp;= \frac{\exp(-zA)}{A}|_\infty^0=\frac{1}{A}=\frac{1}{1+e^{-a}},
\end{align*}\]</span>
with <span class="math inline">\(A=e^{-a}+1\)</span> and <span class="math inline">\(z=e^{-y}\)</span>. Thus,</p>
<p><span class="math display">\[
\pi_i=\Pr (\epsilon _{i2}-\epsilon _{i1}&lt;V_{i1}-V_{i2})=\Pr
(\epsilon _{i2}-\epsilon _{i1}&lt;\mathbf{x}_i^{\mathbf{\prime
}}\boldsymbol \beta) =\frac{1}{1+\exp (-\mathbf{x}_i^{\mathbf{\prime
}}\boldsymbol \beta)}.
\]</span></p>
<p><strong>11.5</strong> From equation (11.5) we know that</p>
<p><span class="math display">\[
\sum\limits_{i=1}^{n}\mathbf{x}_i\left( y_i-\mathrm{\pi }(\mathbf{x}
_i^{\mathbf{\prime}}\mathbf{b}_{MLE})\right) =
\sum\limits_{i=1}^{n}(1~~x_{i1}~~\cdots~~x_{ik})^\prime \left(
y_i-\mathrm{\pi }(\mathbf{x}
_i^{\mathbf{\prime}}\mathbf{b}_{MLE})\right)
=(0~~0~~\cdots~~0)^{\prime}.
\]</span></p>
<p>From the first row, we get <span class="math inline">\(\sum\limits_{i=1}^{n} \left( y_i-\mathrm{\pi }(\mathbf{x} _i^{\mathbf{\prime}}\mathbf{b}_{MLE})\right) =0\)</span>. Dividing by <span class="math inline">\(n\)</span>
yields <span class="math inline">\(\overline{y} = n^{-1} \sum_{i=1}^n \widehat{y}_i .\)</span></p>
<p><strong>11.7</strong> a. The derivative of the logit function is
<span class="math display">\[
\frac{\partial}{\partial y}\mathrm{\pi}(y) =
\mathrm{\pi}(y)\frac{1}{(1+e^y)}=\mathrm{\pi}(y)(1-\mathrm{\pi}(y)).
\]</span>
Thus, using the chain rule and equation (11.5), we have
<span class="math display">\[
\begin{array}{ll}
\mathbf{I}(\boldsymbol \beta) &amp;=&amp;  - \mathrm{E~}\frac{\partial
^{2}}{\partial \boldsymbol \beta\partial \boldsymbol \beta ^{\prime
}}L(\boldsymbol \beta) = -\mathrm{E~} \frac{\partial }{\partial
\boldsymbol \beta^{\prime}} \left(
\sum\limits_{i=1}^{n}\mathbf{x}_i\left( y_i-\mathrm{\pi }(\mathbf{x}
_i^{\mathbf{\prime }}\boldsymbol \beta)\right) \right) \\
&amp;=&amp; \sum\limits_{i=1}^{n}\mathbf{x}_i \frac{\partial }{\partial
\boldsymbol \beta^{\prime}} \mathrm{\pi }(\mathbf{x}
_i^{\mathbf{\prime }}\boldsymbol \beta)
=\sum\limits_{i=1}^{n}\mathbf{x}_i \mathbf{x}_i^{\prime}
\mathrm{\pi}(\mathbf{x} _i^{\mathbf{\prime}}\boldsymbol
\beta)(1-\mathrm{\pi}(\mathbf{x} _i^{\mathbf{\prime}}\boldsymbol
\beta)).
\end{array}
\]</span>
This provides the result with <span class="math inline">\(\sigma_i^2 = \mathrm{\pi}(\mathbf{x}_i^{\prime} \boldsymbol \beta)(1-\mathrm{\pi}(\mathbf{x}_i^{\prime}\boldsymbol \beta))\)</span>.<br></p>
<ol start="2" style="list-style-type: lower-alpha">
<li>Define <span class="math inline">\(\mathbf{a}_i=\mathbf{x}_i\left( y_i-\mathrm{\pi }(\mathbf{x} _i^{\mathbf{\prime}}\boldsymbol \beta)\right)\)</span> and
<span class="math inline">\(\mathbf{H}_i = \frac{\partial }{\partial \boldsymbol \beta^{\prime}}\mathbf{a}_i =-\mathbf{x}_i \mathbf{x}_i^{\mathbf{\prime}} \mathrm{\pi }^{\prime}( \mathbf{x}_i^{\mathbf{\prime}}\boldsymbol \beta).\)</span> <br>
Note that
<span class="math inline">\(\mathrm{E}(\mathbf{a}_i)=\mathbf{x}_i \mathrm{E}\left( y_i-\mathrm{\pi }(\mathbf{x} _i^{\mathbf{\prime}}\boldsymbol \beta)\right)= \mathbf{0}\)</span>. Further define <span class="math inline">\(b_i=\frac{\mathrm{\pi }^{\prime}( \mathbf{x}_i^{\mathbf{\prime}}\boldsymbol \beta)}{\mathrm{\pi }(\mathbf{x} _i^{\mathbf{\prime}}\boldsymbol \beta)(1-\mathrm{\pi }(\mathbf{x}_i^{ \mathbf{\prime}}\boldsymbol \beta))}\)</span>. With this notation, the score function is <span class="math inline">\(\frac{\partial }{\partial \boldsymbol \beta}L(\boldsymbol \beta) = \sum\limits_{i=1}^{n} \mathbf{a}_i b_i\)</span>. Thus,
<span class="math display">\[
\begin{array}{ll}
\mathbf{I}(\boldsymbol \beta) &amp; =  - \mathrm{E} \left(
\frac{\partial^2}{\partial \boldsymbol \beta ~ \partial \boldsymbol \beta ^{\prime}}L(\boldsymbol \beta) \right) = - \mathrm{E} \left( \frac{\partial}{\partial \boldsymbol \beta^{\prime}}\sum\limits_{i=1}^{n} \mathbf{a}_i b_i\right) \\
&amp;= - \mathrm{E} \left( \sum\limits_{i=1}^{n} \left( \left(\frac{\partial}{\partial \boldsymbol
\beta^{\prime}}\mathbf{a}_i \right) b_i + \mathbf{a}_i \frac{\partial}{\partial \boldsymbol \beta^{\prime}}b_i \right) \right)
= - \sum\limits_{i=1}^{n} \left[\mathrm{E}(\mathbf{H}_i)b_i + \mathrm{E}(\mathbf{a}_i)
\frac{\partial}{\partial \boldsymbol \beta^{\prime}}b_i \right] \\
&amp;=  - \sum\limits_{i=1}^{n} \mathbf{H}_i b_i  =  \sum\limits_{i=1}^{n} \mathbf{x}_i \mathbf{x}_i^{\mathbf{\prime}} \frac {\left( \mathrm{\pi }^{\prime}( \mathbf{x}_i^{\mathbf{\prime}}\boldsymbol \beta)\right)^2} {\mathrm{\pi }(\mathbf{x} _i^{\mathbf{\prime}}\boldsymbol \beta)(1-\mathrm{\pi }(\mathbf{x}_i^{ \mathbf{\prime}}\boldsymbol \beta))} .
\end{array}
\]</span></li>
</ol>
<p><strong>11.8</strong> a(i). The plots are not presented here.
<span class="math display">\[
\small{
\begin{array}{lrrrrrrr}
   \hline
       &amp;  mean  &amp;  median &amp; std &amp; minimum &amp; maximum\\
   \hline
\text{CLMAGE}    &amp; 32.531  &amp;   31.000  &amp;  17.089  &amp;    0.000  &amp;     95.000\\
\text{LOSS}      &amp;  5.954  &amp;    2.331  &amp;  33.136  &amp;    0.005  &amp;   1067.700\\
   \hline
\end{array}
}
\]</span>
a(ii). Not for CLMAGE, but both versions of LOSS appear to differ by ATTORNEY.
<span class="math display">\[
\small{
\begin{array}{crrr}
   \hline
   \text{ ATTORNEY}   &amp; \text{CLMAGE} &amp;  \text{LOSS} &amp; \text{lnLOSS} \\
   \hline
      1 &amp; 32.270  &amp; 9.863   &amp; 1.251\\
      2 &amp; 32.822  &amp; 1.865   &amp; -0.169\\
   \hline
\end{array}
}
\]</span>
a(iii). SEATBELT and CLMINSUR appear to be different, CLMSEX and MARITAL are less so.</p>
<p><span class="math display">\[
\small{
\begin{array}{cccccccc}
\hline
  \text{ATTORNEY} &amp;  \text{CLMSEX} &amp; &amp; \text{MARITAL} &amp;&amp;&amp;  &amp; \text{  CLMINSUR } &amp;  &amp;  \text{SEATBELT} \\
           &amp;          1 &amp;          2 &amp;          1 &amp;          2 &amp;          3 &amp;          4 &amp;          1 &amp;          2 &amp;          1 &amp;          2 \\
\hline
         1 &amp;        325 &amp;        352 &amp;        320 &amp;        329 &amp;          6 &amp;         20 &amp;         76 &amp;        585 &amp;        643 &amp;         16 \\
         2 &amp;        261 &amp;        390 &amp;        304 &amp;        321 &amp;          9 &amp;         15 &amp;         44 &amp;        594 &amp;        627 &amp;          6 \\
\hline
\end{array}
}
\]</span>
a(iv). Number of values missing is shown as:</p>
<p><span class="math display">\[
\small{
\begin{array}{cccccc}
\hline
\text{CLMAGE}  &amp;  \text{LOSS} &amp; \text{CLMSEX} &amp; \text{MARITAL}&amp; \text{CLMINSUR} &amp; \text{SEATBELT}\\
                   189         &amp;     12         &amp;   16          &amp;         41        &amp;        48       &amp;      NA\\
\hline
\end{array}
}
\]</span>
b(i). The variable CLMSEX is statistically significant. The odds ratio is <span class="math inline">\(\exp(-0.3218) = 0.7248\)</span>, indicating that women are 72% times as likely to use an attorney as men (or men are 1/0.72 = 1.379
times as likely to use an attorney than women).<br>
b(ii). CLMSEX and CLMINSUR are statistically significantly and SEATBELT is somewhat significant, as given by the <span class="math inline">\(p\)</span>-values. CLMAGE is not significant. MARITAL does not appear to be statistically
significant.<br>
b(iii). Men use attorneys more often - the odds ratio is <span class="math inline">\(\exp(-0.37691) = 0.686\)</span>, indicating that women are 68.6% times as likely to use an attorney as men.<br>
b(iv). The logarithmic version, lnLOSS, is more important. In the final model without LOSS, the <span class="math inline">\(p\)</span>-value associated with lnLOSS was very tiny (<span class="math inline">\(&lt; 2e-16\)</span>), indicating strong statistical significance.<br> b(v). All variables remain the same except one of the MARITAL binary
variables becomes marginally statistically significant. The main difference is that we are using an additional <span class="math inline">\(168\)</span> observations by not requiring that CLMAGE be in the model.<br>
b(vi). For the systematic component, we have
<span class="math display">\[
\begin{array}{llll}
\mathbf{x}^{\prime}\mathbf{b}_{MLE}
&amp;= 0.75424 \\
&amp;~~~ -0.51210* (\text{CLMSEX}=2)&amp; +  0.04613*(\text{MARITAL}=2) \\
&amp;~~~+ 0.37762*(\text{MARITAL}=3) &amp;+ 0.12099*(\text{MARITAL}=4) \\
&amp;~~~+ 0.13692*(\text{SEATBELT}=2) &amp;-0.52960*(\text{CLMINSUR}=2)  \\
&amp;~~~-0.01628* \text{CLMAGE} &amp;+ 0.98260*\text{lnLOSS} \\
&amp;= 1.3312.
\end{array}
\]</span>
The estimated probability of using an attorney is
<span class="math display">\[
\widehat{\pi} = \frac {\exp (1.3312)}{1+\exp (1.3312)} = 0.791.
\]</span>
c. Females are less likely to use attorneys. Those not wearing a seat belt (SEATBELT=2) are more likely to use an attorney (although not significant). Single (MARITAL=2) are more likely to use an
attorney. Claimants not uninsured (CLMINSUR=2) (are insured) are less likely to use an attorney. The higher the loss, the more likely that an attorney will be involved.</p>
<p><strong>11.11</strong> a. The intercept and variables PLACE%, MSAT, RANK are significant at 5% level.<br>
b(i). The success probability for this case is 0.482. <br>
b(ii). The success probability for this case is 0.281. <br>
b(iii). The success probability for this case is 0.366. <br>
b(iv). The success probability for this case is 0.497. <br>
b(v). The success probability for this case is 0.277. <br></p>
</div>
<div id="chapter-12" class="section level4 unnumbered hasAnchor">
<h4>Chapter 12<a href="brief-answers-to-selected-exercises.html#chapter-12" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p><strong>12.1</strong> Take derivative of equation (12.2) with respect to <span class="math inline">\(\mu\)</span> and set the first order condition equal to zero. With this, we have <span class="math inline">\(\partial L(\mu)/\partial \mu=\sum_{i=1}^{n}(-1+y_i/\mu)=0\)</span>,
that is <span class="math inline">\(\hat\mu=\bar y\)</span>.</p>
<p><strong>12.3</strong> a. From the expression of the score equation (12.5),
<span class="math display">\[
\left. \frac{\partial }{\partial \boldsymbol \beta} L(\boldsymbol
\beta )\right\vert _{\mathbf{\beta =b}}= \sum_{i=1}^{n}\left(
y_i-\widehat{\mu }_i\right) \left(
                                                   \begin{array}{c}
                                                     1 \\
                                                     x_{i,1} \\
                                                     \vdots \\
                                                      x_{i,k} \\
                                                   \end{array}
                                                 \right) =
                                                 \mathbf{0}.
\]</span>
From the first row, we have that the average of residuals <span class="math inline">\(e_i = y_i - \widehat{\mu}_i\)</span> is equal to zero.<br>
b. From the <span class="math inline">\((j+1)^{st}\)</span> row of the score equation (12.5), we have
<span class="math display">\[
\sum_{i=1}^{n} e_i x_{i,j}= 0.
\]</span>
Because residuals have a zero average, the sample covariance between
residuals and <span class="math inline">\(x_j\)</span> is zero, and hence the sample correlation is
zero.</p>
<p><strong>12.5</strong> a. The distribution of COUNTOP has a long tail and is
skewed to the right. The variance (<span class="math inline">\(12.5^2 = 156.25\)</span>) is much bigger
than the mean, 5.67.<br>
<span class="math display">\[
\small{
\begin{array}{cccccc} \hline
   &amp;1st &amp;  &amp;  &amp;3rd  &amp;  \\
  \text{Minimum} &amp; \text{Quartile} &amp; \text{Median} &amp;   \text{Mean} &amp;\text{Quartile} &amp;  \text{Maximum}\\\hline
   0.00   &amp; 0.00 &amp;   2.00 &amp;   5.67 &amp;   6.00 &amp; 167.00\\
\hline
\end{array}
}
\]</span>
b. Yes, the tables suggest that most variables have a significant impact on COUNTOP. <br>
c. The Pearson’s chi-square statistic is 55044. <br>
d(i). All of the variables appear to be very statistically significant. <br>
d(ii). The coefficient of GENDER is 0.4197. Roughly, we would expect females to have 42% more outpatient expenditures than males. <br>
d(iii). The chi-square statistic is 33,214 - lower that the one in part (b) (55,044). This indicates that the covariates help with the fitting process. The statistical significance also indicates that
the covariates are statistically significant but the overdispersion is suspect - see d(iv). <br>
d(iv). Now most of the variables remain statistically significant but the strength of statistical significance has decreased dramatically. It is not clear if the income variable is statistically significant. <br>
e(i). All of the variables appear to be statistically significant. The income variable is perhaps the least important. <br>
e(ii). The chi-square statistic is 33,660 - higher than the Poisson model (33,214) but lower that the one in part (b) (55,044). This suggests that the two models fit about the same with the Poisson
having the slight edge. The AIC for the basic Poisson is 22,725 - which is much higher than the AIC for the negative binomial (10,002). Thus, the negative binomial is preferred to the basic Poisson. However, the quasi-Poisson is probably as good as the negative binomial. <br>
e(iii). From the output, the likelihood ratio test statistic is 18.7 - based on 4 degrees of freedom, the <span class="math inline">\(p\)</span>-value is 0.000915. This indicates that income is a statistically significant factor in the
model. <br>
f. For GENDER, education, personal health status, anylimit, income and insurance, the models report the same sign and statistically significant effects. RACE does not appear to be statistically
significant in the logistic regression model. For REGION, the signs appear to be the same although the statistical significance has changed.</p>

</div>
</div>







            </section>

          </div>
        </div>
      </div>
<a href="appendices.html" class="navigation navigation-prev navigation-unique" aria-label="Previous page"><i class="fa fa-angle-left"></i></a>

    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": null,
"search": {
"engine": "fuse",
"options": null
},
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/latest.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
