<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapter 3 Some Special Explanatory Variables | Regression Modeling with Actuarial and Financial Applications</title>
  <meta name="description" content="Development of a research monograph that provides quantitative tools to assess the relevance of dependence in insurance risk management." />
  <meta name="generator" content="bookdown 0.39 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapter 3 Some Special Explanatory Variables | Regression Modeling with Actuarial and Financial Applications" />
  <meta property="og:type" content="book" />
  
  <meta property="og:description" content="Development of a research monograph that provides quantitative tools to assess the relevance of dependence in insurance risk management." />
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 3 Some Special Explanatory Variables | Regression Modeling with Actuarial and Financial Applications" />
  
  <meta name="twitter:description" content="Development of a research monograph that provides quantitative tools to assess the relevance of dependence in insurance risk management." />
  

<meta name="author" content="Edward (Jed) Frees, University of Wisconsin - Madison, Australian National University" />



  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="estimation-and-goodness-of-fit.html"/>
<link rel="next" href="bibliography.html"/>
<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/anchor-sections-1.1.0/anchor-sections.css" rel="stylesheet" />
<link href="libs/anchor-sections-1.1.0/anchor-sections-hash.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.1.0/anchor-sections.js"></script>

<!-- Mathjax Version 2-->
<script type='text/x-mathjax-config'>
		MathJax.Hub.Config({
			extensions: ['tex2jax.js'],
			jax: ['input/TeX', 'output/HTML-CSS'],
			tex2jax: {
				inlineMath: [ ['$','$'], ['\\(','\\)'] ],
				displayMath: [ ['$$','$$'], ['\\[','\\]'] ],
				processEscapes: true
			},
			'HTML-CSS': { availableFonts: ['TeX'] }
		});
</script>

<script type="text/javascript"  src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/MathJax.js?config=TeX-AMS_HTML"> </script>

<script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
<script type="text/javascript" src="https://unpkg.com/survey-jquery/survey.jquery.min.js"></script>
<link href="https://unpkg.com/survey-jquery/modern.min.css" type="text/css" rel="stylesheet">
<script src="https://unpkg.com/showdown/dist/showdown.min.js"></script>


<!-- Various toggle functions used throughout --> 
<script language="javascript">
function toggle(id1,id2) {
	var ele = document.getElementById(id1); var text = document.getElementById(id2);
	if (ele.style.display == "block") {ele.style.display = "none"; text.innerHTML = "Show Solution";}
		else {ele.style.display = "block"; text.innerHTML = "Hide Solution";}}
function togglecode(id1,id2) {
   var ele = document.getElementById(id1); var text = document.getElementById(id2);
   if (ele.style.display == "block") {ele.style.display = "none"; text.innerHTML = "Show R Code";}
      else {ele.style.display = "block"; text.innerHTML = "Hide R Code";}}
function toggleEX(id1,id2) {
   var ele = document.getElementById(id1); var text = document.getElementById(id2);
   if (ele.style.display == "block") {ele.style.display = "none"; text.innerHTML = "Show Example";}
      else {ele.style.display = "block"; text.innerHTML = "Hide Example";}}
function toggleTheory(id1,id2) {
   var ele = document.getElementById(id1); var text = document.getElementById(id2);
   if (ele.style.display == "block") {ele.style.display = "none"; text.innerHTML = "Show Theory";}
      else {ele.style.display = "block"; text.innerHTML = "Hide Theory";}}
function toggleSolution(id1,id2) {
   var ele = document.getElementById(id1); var text = document.getElementById(id2);
   if (ele.style.display == "block") {ele.style.display = "none"; text.innerHTML = "Show Solution";}
      else {ele.style.display = "block"; text.innerHTML = "Hide Solution";}}      
function toggleQuiz(id1,id2) {
   var ele = document.getElementById(id1); var text = document.getElementById(id2);
   if (ele.style.display == "block") {ele.style.display = "none"; text.innerHTML = "Show Quiz Solution";}
      else {ele.style.display = "block"; text.innerHTML = "Hide Quiz Solution";}}      
</script>

<!-- A few functions for revealing definitions -->
<script language="javascript">
<!--   $( function() {
    $("#tabs").tabs();
  } ); -->

$(document).ready(function(){
    $('[data-toggle="tooltip"]').tooltip();
});

$(document).ready(function(){
    $('[data-toggle="popover"]').popover(); 
});
</script>

<script language="javascript">
function openTab(evt, tabName) {
    var i, tabcontent, tablinks;
    tabcontent = document.getElementsByClassName("tabcontent");
    for (i = 0; i < tabcontent.length; i++) {
        tabcontent[i].style.display = "none";
    }
    tablinks = document.getElementsByClassName("tablinks");
    for (i = 0; i < tablinks.length; i++) {
        tablinks[i].className = tablinks[i].className.replace(" active", "");
    }
    document.getElementById(tabName).style.display = "block";
    evt.currentTarget.className += " active";
}

// Get the element with id="defaultOpen" and click on it
document.getElementById("defaultOpen").click();
</script>



<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { color: #008000; } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { color: #008000; font-weight: bold; } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<style type="text/css">
  
  div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Regression Modeling With Actuarial and Financial Applications</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="preface.html"><a href="preface.html"><i class="fa fa-check"></i>Preface</a>
<ul>
<li class="chapter" data-level="" data-path="preface.html"><a href="preface.html#dedication"><i class="fa fa-check"></i>Dedication</a></li>
<li class="chapter" data-level="" data-path="preface.html"><a href="preface.html#forward"><i class="fa fa-check"></i>Forward</a>
<ul>
<li class="chapter" data-level="" data-path="preface.html"><a href="preface.html#who-is-this-book-for"><i class="fa fa-check"></i>Who Is This Book For?</a></li>
<li class="chapter" data-level="" data-path="preface.html"><a href="preface.html#what-is-this-book-about"><i class="fa fa-check"></i>What Is This Book About?</a></li>
<li class="chapter" data-level="" data-path="preface.html"><a href="preface.html#how-does-this-book-deliver-its-message"><i class="fa fa-check"></i>How Does This Book Deliver Its Message?</a></li>
<li class="chapter" data-level="" data-path="preface.html"><a href="preface.html#acknowledgements"><i class="fa fa-check"></i>Acknowledgements</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="1" data-path="multiple-linear-regression---i.html"><a href="multiple-linear-regression---i.html"><i class="fa fa-check"></i><b>1</b> Multiple Linear Regression - I</a>
<ul>
<li class="chapter" data-level="1.1" data-path="multiple-linear-regression---i.html"><a href="multiple-linear-regression---i.html#S3:LSMethod"><i class="fa fa-check"></i><b>1.1</b> Method of Least Squares</a>
<ul>
<li class="chapter" data-level="1.1.1" data-path="multiple-linear-regression---i.html"><a href="multiple-linear-regression---i.html#least-squares-method"><i class="fa fa-check"></i><b>1.1.1</b> Least Squares Method</a></li>
<li class="chapter" data-level="1.1.2" data-path="multiple-linear-regression---i.html"><a href="multiple-linear-regression---i.html#example-term-life-insurance"><i class="fa fa-check"></i><b>1.1.2</b> Example: Term Life Insurance</a></li>
<li class="chapter" data-level="1.1.3" data-path="multiple-linear-regression---i.html"><a href="multiple-linear-regression---i.html#general-case-with-k-explanatory-variables"><i class="fa fa-check"></i><b>1.1.3</b> General Case with k Explanatory Variables</a></li>
<li class="chapter" data-level="1.1.4" data-path="multiple-linear-regression---i.html"><a href="multiple-linear-regression---i.html#summarizing-the-data"><i class="fa fa-check"></i><b>1.1.4</b> Summarizing the Data</a></li>
<li class="chapter" data-level="1.1.5" data-path="multiple-linear-regression---i.html"><a href="multiple-linear-regression---i.html#method-of-least-squares"><i class="fa fa-check"></i><b>1.1.5</b> Method of Least Squares</a></li>
<li class="chapter" data-level="1.1.6" data-path="multiple-linear-regression---i.html"><a href="multiple-linear-regression---i.html#matrix-notation"><i class="fa fa-check"></i><b>1.1.6</b> Matrix Notation</a></li>
</ul></li>
<li class="chapter" data-level="1.2" data-path="multiple-linear-regression---i.html"><a href="multiple-linear-regression---i.html#linear-regression-model-and-properties-of-estimators"><i class="fa fa-check"></i><b>1.2</b> Linear Regression Model and Properties of Estimators</a>
<ul>
<li class="chapter" data-level="1.2.1" data-path="multiple-linear-regression---i.html"><a href="multiple-linear-regression---i.html#regression-function"><i class="fa fa-check"></i><b>1.2.1</b> Regression Function</a></li>
<li class="chapter" data-level="1.2.2" data-path="multiple-linear-regression---i.html"><a href="multiple-linear-regression---i.html#regression-coefficient-interpretation"><i class="fa fa-check"></i><b>1.2.2</b> Regression Coefficient Interpretation</a></li>
</ul></li>
<li class="chapter" data-level="1.3" data-path="multiple-linear-regression---i.html"><a href="multiple-linear-regression---i.html#model-assumptions"><i class="fa fa-check"></i><b>1.3</b> Model Assumptions</a></li>
<li class="chapter" data-level="1.4" data-path="multiple-linear-regression---i.html"><a href="multiple-linear-regression---i.html#properties-of-regression-coefficient-estimators"><i class="fa fa-check"></i><b>1.4</b> Properties of Regression Coefficient Estimators</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="estimation-and-goodness-of-fit.html"><a href="estimation-and-goodness-of-fit.html"><i class="fa fa-check"></i><b>2</b> Estimation and Goodness of Fit</a>
<ul>
<li class="chapter" data-level="2.1" data-path="estimation-and-goodness-of-fit.html"><a href="estimation-and-goodness-of-fit.html#residual-standard-deviation"><i class="fa fa-check"></i><b>2.1</b> Residual Standard Deviation</a></li>
<li class="chapter" data-level="2.2" data-path="estimation-and-goodness-of-fit.html"><a href="estimation-and-goodness-of-fit.html#the-coefficient-of-determination-r2"><i class="fa fa-check"></i><b>2.2</b> The Coefficient of Determination: <span class="math inline">\(R^2\)</span></a></li>
<li class="chapter" data-level="2.3" data-path="estimation-and-goodness-of-fit.html"><a href="estimation-and-goodness-of-fit.html#statistical-inference-for-a-single-coefficient"><i class="fa fa-check"></i><b>2.3</b> Statistical Inference for a Single Coefficient</a>
<ul>
<li class="chapter" data-level="2.3.1" data-path="estimation-and-goodness-of-fit.html"><a href="estimation-and-goodness-of-fit.html#the-t-test"><i class="fa fa-check"></i><b>2.3.1</b> The <em>t</em>-Test</a></li>
<li class="chapter" data-level="2.3.2" data-path="estimation-and-goodness-of-fit.html"><a href="estimation-and-goodness-of-fit.html#confidence-intervals"><i class="fa fa-check"></i><b>2.3.2</b> Confidence Intervals</a></li>
<li class="chapter" data-level="2.3.3" data-path="estimation-and-goodness-of-fit.html"><a href="estimation-and-goodness-of-fit.html#added-variable-plots"><i class="fa fa-check"></i><b>2.3.3</b> Added Variable Plots</a></li>
<li class="chapter" data-level="2.3.4" data-path="estimation-and-goodness-of-fit.html"><a href="estimation-and-goodness-of-fit.html#producing-an-added-variable-plot"><i class="fa fa-check"></i><b>2.3.4</b> Producing an Added Variable Plot</a></li>
<li class="chapter" data-level="2.3.5" data-path="estimation-and-goodness-of-fit.html"><a href="estimation-and-goodness-of-fit.html#partial-correlation-coefficients"><i class="fa fa-check"></i><b>2.3.5</b> Partial Correlation Coefficients</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="3" data-path="some-special-explanatory-variables.html"><a href="some-special-explanatory-variables.html"><i class="fa fa-check"></i><b>3</b> Some Special Explanatory Variables</a>
<ul>
<li class="chapter" data-level="3.1" data-path="some-special-explanatory-variables.html"><a href="some-special-explanatory-variables.html#binary-variables"><i class="fa fa-check"></i><b>3.1</b> Binary Variables</a></li>
<li class="chapter" data-level="3.2" data-path="some-special-explanatory-variables.html"><a href="some-special-explanatory-variables.html#transforming-explanatory-variables"><i class="fa fa-check"></i><b>3.2</b> Transforming Explanatory Variables</a></li>
<li class="chapter" data-level="3.3" data-path="some-special-explanatory-variables.html"><a href="some-special-explanatory-variables.html#interaction-terms"><i class="fa fa-check"></i><b>3.3</b> Interaction Terms</a>
<ul>
<li class="chapter" data-level="3.3.1" data-path="some-special-explanatory-variables.html"><a href="some-special-explanatory-variables.html#example-term-life-insurance---continued"><i class="fa fa-check"></i><b>3.3.1</b> Example: Term Life Insurance - Continued</a></li>
<li class="chapter" data-level="3.3.2" data-path="some-special-explanatory-variables.html"><a href="some-special-explanatory-variables.html#example-life-insurance-company-expenses"><i class="fa fa-check"></i><b>3.3.2</b> Example: Life Insurance Company Expenses</a></li>
<li class="chapter" data-level="3.3.3" data-path="some-special-explanatory-variables.html"><a href="some-special-explanatory-variables.html#special-case-curvilinear-response-functions"><i class="fa fa-check"></i><b>3.3.3</b> Special Case: Curvilinear Response Functions</a></li>
<li class="chapter" data-level="3.3.4" data-path="some-special-explanatory-variables.html"><a href="some-special-explanatory-variables.html#special-case-nonlinear-functions-of-a-continuous-variable"><i class="fa fa-check"></i><b>3.3.4</b> Special Case: Nonlinear Functions of a Continuous Variable</a></li>
</ul></li>
<li class="chapter" data-level="3.4" data-path="some-special-explanatory-variables.html"><a href="some-special-explanatory-variables.html#further-reading-and-references"><i class="fa fa-check"></i><b>3.4</b> Further Reading and References</a></li>
<li class="chapter" data-level="3.5" data-path="some-special-explanatory-variables.html"><a href="some-special-explanatory-variables.html#exercises"><i class="fa fa-check"></i><b>3.5</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="bibliography.html"><a href="bibliography.html"><i class="fa fa-check"></i>Bibliography</a></li>
<li class="divider"></li>
<li><a href="https://github.com/OpenActTextDev/RegressionSpanish/" target="blank">Spanish Regression on GitHub</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Regression Modeling with Actuarial and Financial Applications</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="some-special-explanatory-variables" class="section level1 hasAnchor" number="3">
<h1><span class="header-section-number">Chapter 3</span> Some Special Explanatory Variables<a href="some-special-explanatory-variables.html#some-special-explanatory-variables" class="anchor-section" aria-label="Anchor link to header"></a></h1>
<p>The linear regression model is the basis of a rich family of models. This section provides several examples to illustrate the richness of this family. These examples demonstrate the use of (i) binary variables, (ii) transformation of explanatory variables, and (iii) interaction terms. This section also serves to underscore the meaning of the adjective <em>linear</em> in the phrase “linear regression”; the regression function is linear in the parameters but may be a highly nonlinear function of the explanatory variables.</p>
<div id="binary-variables" class="section level2 hasAnchor" number="3.1">
<h2><span class="header-section-number">3.1</span> Binary Variables<a href="some-special-explanatory-variables.html#binary-variables" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Categorical variables provide a numerical label for measurements of observations that fall in distinct groups, or <em>categories</em>. Because of the grouping, categorical variables are discrete and generally take on a finite number of values. We begin our discussion with a categorical variable that can take on one of only two values, a <em>binary</em> variable. Further discussion of categorical variables is the topic of Chapter 4.</p>
<hr />
<p><strong>Example: Term Life Insurance - Continued.</strong> We now consider the marital status of the survey respondent. In the Survey of Consumer Finances, respondents can select among several options describing their marital status including “married,” “living with a partner,” “divorced,” and so on. Marital status is not measured continuously but rather takes on values that fall into distinct groups. In this chapter, we group survey respondents according to whether or not they are single, defined to include those who are separated, divorced, widowed, never married, and are not married nor living with a partner. Chapter 4 will present a more complete analysis of marital status by including additional categories.</p>
<p>The binary variable <code>SINGLE</code> is defined to be one if the survey respondent is single and 0 otherwise. The variable <code>SINGLE</code> is also known as an <em>indicator</em> variable because it indicates whether or not the respondent is single. Another name for this important type of variable is a <em>dummy</em> variable. We could use 0 and 100, or 20 and 36, or any other distinct values. However, 0 and 1 are convenient for the interpretation of the parameter values, discussed below. To streamline the discussion, we now present a model using only <code>LNINCOME</code> and <code>SINGLE</code> as explanatory variables.</p>
<p>For our sample of <span class="math inline">\(n = 275\)</span> households, 57 are single and the other 218 are not. To see the relationships among <code>LNFACE</code>, <code>LNINCOME</code>, and <code>SINGLE</code>, Figure @ref{F3:LinesLetterPlot} introduces a <em>letter plot</em> of <code>LNFACE</code> versus <code>LNINCOME</code>, with <code>SINGLE</code> as the code variable. We can see that Figure @ref{F3:LinesLetterPlot} is a scatter plot of <code>LNFACE</code> versus <code>LNINCOME</code>, using 50 randomly selected households from our sample of 275 (for clarity of the graph). However, instead of using the same plotting symbol for each observation, we have coded the symbols so that we can easily understand the behavior of a third variable, <code>SINGLE</code>. In other applications, you may elect to use other plotting symbols such as <span class="math inline">\(\clubsuit\)</span>, <span class="math inline">\(\heartsuit\)</span>, <span class="math inline">\(\spadesuit\)</span>, and so on, or use different colors, to encode additional information. For this application, the letter codes “S” for single and “o” for other were selected because they remind the reader of the nature of the coding scheme. Regardless of the coding scheme, the important point is that a letter plot is a useful device for graphically portraying three or more variables in two dimensions. The main restriction is that the additional information must be categorized, such as with binary variables, to make the coding scheme work.</p>

<div class="figure" style="text-align: center"><span style="display:block;" id="fig:LinesLetterPlot"></span>
<img src="Chapters/Chapter3/F3LinesLetterPlot.eps" alt="Letter plot of LNFACE versus LNINCOME, with the letter code ‘S’ for single and ‘o’ for other. The fitted regression lines have been superimposed. The lower line is for single and the upper line is for other." width="60%" />
<p class="caption">
Figure 3.1: <strong>Letter plot of LNFACE versus LNINCOME, with the letter code ‘S’ for single and ‘o’ for other.</strong> The fitted regression lines have been superimposed. The lower line is for single and the upper line is for other.
</p>
</div>
<p>Figure @ref{F3:LinesLetterPlot} suggests that <code>LNFACE</code> is lower for those single than others for a given level of income. Thus, we now consider a regression model, <code>LNFACE = β_0 + β_1 LNINCOME + β_2 SINGLE + ϵ</code>. The regression function can be written as:</p>
<p><span class="math display">\[
\text{E } y =
\begin{cases}
    \beta_0 + \beta_1 \text{LNINCOME} &amp; \text{for other respondents} \\
    \beta_0 + \beta_2 + \beta_1 \text{LNINCOME} &amp; \text{for single respondents}
\end{cases}
\]</span></p>
<p>The interpretation of the model coefficients differs from the continuous variable case. For continuous variables such as <code>LNINCOME</code>, we interpret <span class="math inline">\(\beta_1\)</span> as the expected change in <span class="math inline">\(y\)</span> per unit change of logarithmic income, holding other variables fixed. For binary variables such as <code>SINGLE</code>, we interpret <span class="math inline">\(\beta_2\)</span> as the expected increase in <span class="math inline">\(y\)</span> when going from the base level of <code>SINGLE</code> (=0) to the alternative level. Thus, although we have one model for both marital statuses, we can interpret the model using two regression equations, one for each type of marital status. By writing a separate equation for each marital status, we have been able to simplify a complicated multiple regression equation. Sometimes, you will find it easier to communicate a series of simple relationships compared to a single, complex relationship.</p>
<p>Although the interpretation for binary explanatory variables differs from the continuous, the ordinary least squares estimation method remains valid. To illustrate, the fitted version of the above model is</p>
<p><span class="math display">\[
\begin{array}{cclll}
  \widehat{LNFACE} &amp; = &amp; 5.09   &amp;  + 0.634 \text{LNINCOME} &amp; - 0.800 \text{SINGLE} .\\
  \text{std error}    &amp;   &amp; (0.89) &amp; ~~(0.078) &amp; ~(0.248) \\
\end{array}
\]</span></p>
<p>To interpret <span class="math inline">\(b_2 = -0.800\)</span>, we say that we expect the logarithmic face to be smaller by 0.80 for a survey respondent who is single compared to the other category. This assumes that other things, such as income, remain unchanged. For a graphical interpretation, the two fitted regression lines are superimposed in Figure @ref{F3:LinesLetterPlot}.</p>
<hr />
</div>
<div id="transforming-explanatory-variables" class="section level2 hasAnchor" number="3.2">
<h2><span class="header-section-number">3.2</span> Transforming Explanatory Variables<a href="some-special-explanatory-variables.html#transforming-explanatory-variables" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Regression models have the ability to represent complex, <em>nonlinear</em> relationships between the expected response and the explanatory variables. For example, early regression texts, such as Plackett (1960, Chapter 6), devote an entire chapter of material to polynomial regression,</p>
<p><span class="math display">\[
\text{E } y  =  \beta_0 + \beta_1 x + \beta_2 x^2 + \ldots + \beta_p x^p.
\]</span></p>
<p>Here, the idea is that a <span class="math inline">\(p\)</span>th order polynomial in <span class="math inline">\(x\)</span> can be used to approximate general, unknown nonlinear functions of <span class="math inline">\(x\)</span>.</p>
<p>The modern-day treatment of polynomial regression does not require an entire chapter because the model in equation <span class="math inline">\(\text{E } y = \beta_0 + \beta_1 x + \beta_2 x^2 + \ldots + \beta_p x^p\)</span> can be expressed as a special case of the linear regression model. That is, with the regression function in equation <span class="math inline">\(\text{E } y = \beta_0 + \beta_1 x_1 + \beta_2 x_2 + \ldots + \beta_k x_k\)</span>, we can choose <span class="math inline">\(k = p\)</span> and <span class="math inline">\(x_1 = x\)</span>, <span class="math inline">\(x_2 = x^2\)</span>, <span class="math inline">\(\ldots\)</span>, <span class="math inline">\(x_p = x^p\)</span>. Thus, with these choices of explanatory variables, we can model a highly nonlinear function of <span class="math inline">\(x\)</span>.</p>
<p>We are not restricted to powers of <span class="math inline">\(x\)</span> in our choice of transformations. For example, the model <span class="math inline">\(\text{E } y = \beta_0 + \beta_1 \ln x\)</span>, provides another way to represent a gently sloping curve in <span class="math inline">\(x\)</span>. This model can be written as a special case of the basic linear regression model using <span class="math inline">\(x^{\ast} = \ln x\)</span> as the transformed version of <span class="math inline">\(x\)</span>.</p>
<p>Transformations of explanatory variables need not be smooth functions. To illustrate, in some applications, it is useful to categorize a continuous explanatory variable. For example, suppose that <span class="math inline">\(x\)</span> represents the number of years of education, ranging from 0 to 17. If we are relying on information self-reported by our sample of senior citizens, there may be a substantial amount of error in the measurement of <span class="math inline">\(x\)</span>. We could elect to use a less informative, but more reliable, transform of <span class="math inline">\(x\)</span> such as <span class="math inline">\(x^{\ast}\)</span>, a binary variable for finishing 13 years of school (finishing high school). Formally, we would code <span class="math inline">\(x^{\ast} = 1\)</span> if <span class="math inline">\(x \geq 13\)</span> and <span class="math inline">\(x^{\ast} = 0\)</span> if <span class="math inline">\(x &lt; 13\)</span>.</p>
<p>Thus, there are several ways that nonlinear functions of the explanatory variables can be used in the regression model. An example of a nonlinear regression model is <span class="math inline">\(y = \beta_0 + \exp (\beta_1 x) + \varepsilon.\)</span> These typically arise in science applications of regressions where there are fundamental scientific principles guiding the complex model development.</p>
</div>
<div id="interaction-terms" class="section level2 hasAnchor" number="3.3">
<h2><span class="header-section-number">3.3</span> Interaction Terms<a href="some-special-explanatory-variables.html#interaction-terms" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>We have so far discussed how explanatory variables, say <span class="math inline">\(x_1\)</span> and <span class="math inline">\(x_2\)</span>, affect the mean response in an additive fashion, that is, <span class="math inline">\(\mathrm{E}~y = \beta_0 + \beta_1 x_1 + \beta_2 x_2\)</span>. Here, we expect <span class="math inline">\(y\)</span> to increase by <span class="math inline">\(\beta_1\)</span> per unit increase in <span class="math inline">\(x_1\)</span>, with <span class="math inline">\(x_2\)</span> held fixed. What if the marginal rate of increase of <span class="math inline">\(\mathrm{E}~y\)</span> differs for high values of <span class="math inline">\(x_2\)</span> when compared to low values of <span class="math inline">\(x_2\)</span>? One way to represent this is to create an <em>interaction variable</em> <span class="math inline">\(x_3 = x_1 \times x_2\)</span> and consider the model <span class="math inline">\(\mathrm{E}~y = \beta_0 + \beta_1 x_1 + \beta_2 x_2 + \beta_3 x_3\)</span>.</p>
<p>With this model, the change in the expected <span class="math inline">\(y\)</span> per unit change in <span class="math inline">\(x_1\)</span> now depends on <span class="math inline">\(x_2\)</span>. Formally, we can assess small changes in the regression function as:</p>
<p><span class="math display">\[
\frac{\partial \mathrm{E}~y}{\partial x_1} = \frac{\partial}{\partial x_1} \left(\beta_0 + \beta_1 x_1 + \beta_2 x_2 + \beta_3 x_1 x_2 \right) = \beta_1 + \beta_3 x_2 .
\]</span></p>
<p>In this way, we may allow for more complicated functions of <span class="math inline">\(x_1\)</span> and <span class="math inline">\(x_2\)</span>. Figure <a href="some-special-explanatory-variables.html#fig:interaction">3.2</a> illustrates this complex structure. From this figure and the above calculations, we see that the partial changes of <span class="math inline">\(\mathrm{E}~y\)</span> due to movement of <span class="math inline">\(x_1\)</span> depend on the value of <span class="math inline">\(x_2\)</span>. In this way, we say that the partial changes due to each variable are not unrelated but rather “move together.”</p>

<div class="figure" style="text-align: center"><span style="display:block;" id="fig:interaction"></span>
<img src="Chapters/Chapter3/F3Interaction.eps" alt="Plot of \(\mathrm{E}~y = \beta_0 + \beta_1 x_1 + \beta_2 x_2 + \beta_3 x_1 x_2\) versus \(x_1\) and \(x_2\)." width="60%" />
<p class="caption">
Figure 3.2: <strong>Plot of <span class="math inline">\(\mathrm{E}~y = \beta_0 + \beta_1 x_1 + \beta_2 x_2 + \beta_3 x_1 x_2\)</span> versus <span class="math inline">\(x_1\)</span> and <span class="math inline">\(x_2\)</span>.</strong>
</p>
</div>
<p>More generally, an interaction term is a variable that is created as a nonlinear function of two or more explanatory variables. These special terms, even though permitting us to explore a rich family of nonlinear functions, can be cast as special cases of the linear regression model. To do this, we simply create the variable of interest and treat this new term as another explanatory variable. Of course, not every variable that we create will be useful. In some instances, the created variable will be so similar to variables already in our model that it will provide us with no new information. Fortunately, we can use <span class="math inline">\(t\)</span>-tests to check whether the new variable is useful. Further, Chapter 4 will introduce a test to decide whether a group of variables is useful.</p>
<p>The function that we use to create an interaction variable must be more than just a linear combination of other explanatory variables. For example, if we use <span class="math inline">\(x_3 = x_1 + x_2\)</span>, we will not be able to estimate all of the parameters. Chapter 5 will introduce some techniques to help avoid situations when one variable is a linear combination of the others.</p>
<p>To give you some exposure to the wide variety of potential applications of special explanatory variables, we now present a series of short examples.</p>
<hr />
<div id="example-term-life-insurance---continued" class="section level3 hasAnchor" number="3.3.1">
<h3><span class="header-section-number">3.3.1</span> Example: Term Life Insurance - Continued<a href="some-special-explanatory-variables.html#example-term-life-insurance---continued" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>How do we interpret the interaction of a binary variable with a continuous variable? To illustrate, consider a Term Life regression model, <span class="math inline">\(\mathrm{LNFACE} = \beta_0 + \beta_1 \mathrm{LNINCOME} + \beta_2 \mathrm{SINGLE} + \beta_3 \mathrm{LNINCOME*SINGLE} + \varepsilon\)</span>. In this model, we have created a third explanatory variable through the interaction of LNINCOME and SINGLE. The regression function can be written as:</p>
<p><span class="math display">\[
\mathrm{E}~y = \begin{cases}
        \beta_0 + \beta_1  \mathrm{LNINCOME}, &amp; \text{for other respondents}, \\
        \beta_0 + \beta_2 + (\beta_1 + \beta_3)  \mathrm{LNINCOME}, &amp; \text{for single respondents}.
\end{cases}
\]</span></p>
<p>Thus, through this single model with four parameters, we can create two separate regression lines, one for those single and one for others. Figure <a href="some-special-explanatory-variables.html#fig:letterinteract">3.3</a> shows the two fitted regression lines for our data.</p>

<div class="figure" style="text-align: center"><span style="display:block;" id="fig:letterinteract"></span>
<img src="Chapters/Chapter3/F3LetterInteract.eps" alt="Letter plot of LNFACE versus LNINCOME, with the letter code S for single and o for other. The fitted regression lines have been superimposed. The lower line is for single and the upper line is for other." width="60%" />
<p class="caption">
Figure 3.3: <strong>Letter plot of LNFACE versus LNINCOME, with the letter code <code>S</code> for single and <code>o</code> for other.</strong> The fitted regression lines have been superimposed. The lower line is for single and the upper line is for other.
</p>
</div>
<hr />
</div>
<div id="example-life-insurance-company-expenses" class="section level3 hasAnchor" number="3.3.2">
<h3><span class="header-section-number">3.3.2</span> Example: Life Insurance Company Expenses<a href="some-special-explanatory-variables.html#example-life-insurance-company-expenses" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>In a well-developed life insurance industry, minimizing expenses is critical for a company’s competitive position. Segal (2002) analyzed annual accounting data from over 100 firms for the period 1995-1998, inclusive, using a database from the National Association of Insurance Commissioners (NAIC) and other reported information. Segal modeled overall company expenses as a function of firm outputs and the price of inputs. The outputs consist of insurance production, measured by <span class="math inline">\(x_1\)</span> through <span class="math inline">\(x_5\)</span>, described in Table <a href="#tab:expenses"><strong>??</strong></a>. Segal also considered the square of each output, as well as an interaction term with a dummy/binary variable <span class="math inline">\(D\)</span> that indicates whether or not the firm uses a branch company to distribute its products. (In a branch company, field managers are company employees, not independent agents.)</p>

<p>For the price inputs, the price of labor (<span class="math inline">\(PL\)</span>) is defined to be the total cost of employees and agents divided by their number, in logarithmic units. The price of capital (<span class="math inline">\(PC\)</span>) is approximated by the ratio of capital expense to the number of employees and agents, also in logarithmic units. The price of materials consists of expenses other than labor and capital divided by the number of policies sold and terminated during the year. It does not appear directly as an explanatory variable. Rather, Segal took the dependent variable (<span class="math inline">\(y\)</span>) to be total company expenses divided by the price of materials, again in logarithmic units.</p>
<p>With these variable definitions, Segal estimated the following regression function:</p>
<p><span class="math display">\[
\mathrm{E~}y=\beta_0 + \sum_{j=1}^5 \left( \beta_j x_j + \beta_{j+5} D x_j + \beta_{j+10} x_j^2 + \beta_{j+15}D x_j^2  \right) + \beta_{21} PL + \beta_{22} PC.
\]</span></p>
<p>The parameter estimates appear in Table <a href="#tab:expenses"><strong>??</strong></a>. For example, the marginal change in <span class="math inline">\(\mathrm{E}~y\)</span> per unit change in <span class="math inline">\(x_1\)</span> is:</p>
<p><span class="math display">\[
\frac{\partial ~ \mathrm{E}~y}{\partial x_1}= \beta_1 + \beta_{6} D + 2 \beta_{11} x_1 + 2 \beta_{16}D x_1,
\]</span></p>
<p>which is estimated as $ -0.454 + 0.152 D + (0.064 - 0.014 D) x_1$. For these data, the median number of policies issued was <span class="math inline">\(x_1=15,944\)</span>. At this value of <span class="math inline">\(x_1\)</span>, the estimated marginal change is $ -0.454 + 0.152 D + (0.064 - 0.014 D) (15944) = 0.165 + 0.017 D,$ or 0.165 for baseline <span class="math inline">\((D=0)\)</span> and 0.182 for branch <span class="math inline">\((D=1)\)</span> companies.</p>
<p>These estimates are elasticities, as defined in Section 3.2.2. To interpret these coefficients further, let <span class="math inline">\(COST\)</span> represent total general company expenses and <span class="math inline">\(NUMPOL\)</span> represent the number of life policies issued. Then, for branch <span class="math inline">\((D=1)\)</span> companies, we have:</p>
<p><span class="math display">\[
0.182 \approx \frac{\partial y }{\partial x_1 } = \frac{\partial ~ \mathrm{ln}~COST}{\partial ~ \mathrm{ln}~NUMPOL}= \frac{ \frac{\partial ~ COST}{\partial ~NUMPOL}} {\frac{COST}{NUMPOL}},
\]</span></p>
<p>or <span class="math inline">\(\frac{\partial ~ COST}{\partial ~NUMPOL} \approx 0.182 \frac{COST}{NUMPOL}\)</span>. The median cost is $15,992,000, so the marginal cost per policy at these median values is $ 0.182 (15992000/15944) = $182.55$.</p>
<hr />
</div>
<div id="special-case-curvilinear-response-functions" class="section level3 hasAnchor" number="3.3.3">
<h3><span class="header-section-number">3.3.3</span> Special Case: Curvilinear Response Functions<a href="some-special-explanatory-variables.html#special-case-curvilinear-response-functions" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>We can expand the polynomial functions of an explanatory variable to include several explanatory variables. For example, the expected response, or <em>response function</em>, for a second-order model with two explanatory variables is:</p>
<p><span class="math display">\[
\mathrm{E} y = \beta_0 + \beta_1 x_1 + \beta_2 x_2 + \beta_{11} x_1^2 + \beta_{22} x_2^2 + \beta_{12} x_1 x_2.
\]</span></p>
<p>Figure <a href="some-special-explanatory-variables.html#fig:Curvilinear">3.4</a> illustrates this response function. Similarly, the response function for a second-order model with three explanatory variables is:</p>
<p><span class="math display">\[
\mathrm{E} y = \beta_0 + \beta_1 x_1 + \beta_2 x_2 + \beta_3 x_3 + \beta_{11} x_1^2 + \beta_{22} x_2^2 + \beta_{33} x_3^2 + \beta_{12} x_1 x_2 + \beta_{13} x_1 x_3 + \beta_{23} x_2 x_3.
\]</span></p>
<p>When there is more than one explanatory variable, third and higher-order models are rarely used in applications.</p>

<div class="figure" style="text-align: center"><span style="display:block;" id="fig:Curvilinear"></span>
<img src="Chapters/Chapter3/F3Curvilinear.eps" alt="Plot of \(\mathrm{E}~y = \\beta_0 + \beta_1~x_1 + \beta_2~x_2 + \beta_{11}~x_1^2 + \beta_{22}~x_2^2 + \beta_{12}~x_1~x_2\) versus \(x_1\) and \(x_2\)." width="60%" />
<p class="caption">
Figure 3.4: <strong>Plot of <span class="math inline">\(\mathrm{E}~y = \\beta_0 + \beta_1~x_1 + \beta_2~x_2 + \beta_{11}~x_1^2 + \beta_{22}~x_2^2 + \beta_{12}~x_1~x_2\)</span> versus <span class="math inline">\(x_1\)</span> and <span class="math inline">\(x_2\)</span>.</strong>
</p>
</div>
</div>
<div id="special-case-nonlinear-functions-of-a-continuous-variable" class="section level3 hasAnchor" number="3.3.4">
<h3><span class="header-section-number">3.3.4</span> Special Case: Nonlinear Functions of a Continuous Variable<a href="some-special-explanatory-variables.html#special-case-nonlinear-functions-of-a-continuous-variable" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>In some applications, we expect the response to have some abrupt changes in behavior at certain values of an explanatory variable, even if the variable is continuous. For example, suppose that we are trying to model an individual’s charitable contributions (<span class="math inline">\(y\)</span>) in terms of their wages (<span class="math inline">\(x\)</span>). For 2007 data, a simple model we might entertain is given in Figure <a href="some-special-explanatory-variables.html#fig:Charity">3.5</a>.</p>

<div class="figure" style="text-align: center"><span style="display:block;" id="fig:Charity"></span>
<img src="Chapters/Chapter3/F3Charity.eps" alt="The marginal change in \(\mathrm{E}~y\) is lower below $97,500. The parameter \(\beta_2\) represents the difference in the slopes." width="60%" />
<p class="caption">
Figure 3.5: <strong>The marginal change in <span class="math inline">\(\mathrm{E}~y\)</span> is lower below $97,500.</strong> The parameter <span class="math inline">\(\beta_2\)</span> represents the difference in the slopes.
</p>
</div>
<p>A rationale for this model is that, in 2007, individuals paid 7.65% of their income for Social Security taxes up to $97,500. No Social Security taxes are excised on wages in excess of $97,500. Thus, one theory is that, for wages in excess of $97,500, individuals have more disposable income per dollar and thus should be more willing to make charitable contributions.</p>
<p>To model this relationship, define the binary variable <span class="math inline">\(z\)</span> to be zero if <span class="math inline">\(x &lt; 97,500\)</span> and to be one if <span class="math inline">\(x \geq 97,500\)</span>. Define the regression function to be <span class="math inline">\(\mathrm{E}~y = \beta_0 + \beta_1 x + \beta_2 z (x - 97,500)\)</span>. This can be written as:</p>
<p><span class="math display">\[
\mathrm{E}~y = \begin{cases}
\beta_0 + \beta_1  x &amp; x &lt; 97,500 \\
\beta_0 - \beta_2(97,500) + (\beta_1+\beta_2) x &amp; x \geq 97,500
\end{cases}
\]</span></p>
<p>To estimate this model, we would run a regression of <span class="math inline">\(y\)</span> on two explanatory variables, <span class="math inline">\(x_1 = x\)</span> and <span class="math inline">\(x_2 = z \times (x - 97,500)\)</span>. If <span class="math inline">\(\beta_2 &gt; 0\)</span>, then the marginal rate of charitable contributions is higher for incomes exceeding $97,500.</p>
<p>Figure <a href="some-special-explanatory-variables.html#fig:Charity">3.5</a> illustrates this relationship, known as <em>piecewise linear regression</em> or sometimes a “broken stick” model. The sharp break in Figure <a href="some-special-explanatory-variables.html#fig:Charity">3.5</a> at <span class="math inline">\(x = 97,500\)</span> is called a “kink.” We have linear relationships above and below the kinks and have used a binary variable to put the two pieces together. We are not restricted to one kink. For example, suppose that we wish to do a historical study of Federal taxable income for 1992 single filers. Then, there were three tax brackets: the marginal tax rate below $21,450 was 15%, above $51,900 was 31%, and in between was 28%. For this example, we would use two kinks, at 21,450 and 51,900.</p>
<p>Further, piecewise linear regression is not restricted to continuous response functions. For example, suppose that we are studying the commissions paid to stockbrokers (<span class="math inline">\(y\)</span>) in terms of the number of shares purchased by a client (<span class="math inline">\(x\)</span>). We might expect to see the relationship illustrated in Figure <a href="some-special-explanatory-variables.html#fig:Break">3.6</a>. Here, the discontinuity at <span class="math inline">\(x = 100\)</span> reflects the administrative expenses of trading in odd lots, as trades of less than 100 shares are called. The lower marginal cost for trades in excess of 100 shares simply reflects the economies of scale for doing business in larger volumes. A regression model of this is <span class="math inline">\(\mathrm{E}~y = \beta_0 + \beta_1 x + \beta_2 z + \beta_3 z x\)</span> where <span class="math inline">\(z = 0\)</span> if <span class="math inline">\(x &lt; 100\)</span> and <span class="math inline">\(z = 1\)</span> if <span class="math inline">\(x \geq 100\)</span>. The regression function depicted in Figure <a href="some-special-explanatory-variables.html#fig:Break">3.6</a> is:</p>
<p><span class="math display">\[
\mathrm{E}~y = \begin{cases}
\beta_0 + \beta_1  x_1 &amp; x &lt; 100 \\
\beta_0 + \beta_2 + (\beta_1+\beta_3) x_1 &amp; x \geq 100
\end{cases}
\]</span></p>

<div class="figure" style="text-align: center"><span style="display:block;" id="fig:Break"></span>
<img src="Chapters/Chapter3/F3Break.eps" alt="Plot of expected commissions (\(\\mathrm{E}~y\)) versus number of shares traded (\(x\)). The break at \(x=100\) reflects savings in administrative expenses. The lower slope for \(x \ge 100\) reflects economies of scales in expenses." width="60%" />
<p class="caption">
Figure 3.6: <strong>Plot of expected commissions (<span class="math inline">\(\\mathrm{E}~y\)</span>) versus number of shares traded (<span class="math inline">\(x\)</span>)</strong>. The break at <span class="math inline">\(x=100\)</span> reflects savings in administrative expenses. The lower slope for <span class="math inline">\(x \ge 100\)</span> reflects economies of scales in expenses.
</p>
</div>
</div>
</div>
<div id="further-reading-and-references" class="section level2 hasAnchor" number="3.4">
<h2><span class="header-section-number">3.4</span> Further Reading and References<a href="some-special-explanatory-variables.html#further-reading-and-references" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>For proofs of the Chapter 3 results, we refer the reader to
Goldberger (1991). Nonlinear regression models are discussed in, for
example, Bates and Watts (1988).</p>
<p>Chapter 3 has introduced the fundamentals of multiple linear
regression. Chapter 4 will widen the scope by introducing
categorical variables and statistical inference methods for handling
several coefficients simultaneously. Chapter 5 will introduce
techniques to help you pick appropriate variables in a multiple
linear regression model. Chapter 6 is a synthesis chapter,
discussing model interpretation, variable selection and data
collection.</p>
<p><strong>Chapter References</strong></p>
<ul>
<li>Bates, Douglas M. and Watts, D. G. (1988). <em>Nonlinear Regression Analysis and its Applications</em>. John Wiley &amp; Sons, New York.</li>
<li>Lemaire, Jean (2002). Why do females live longer than males? <em>North American Actuarial Journal</em>, 6(4), 21-37.</li>
<li>Goldberger, Arthur (1991). <em>A Course in Econometrics</em>. Harvard University Press, Cambridge.</li>
<li>Plackett, R.L. (1960). <em>Regression Analysis</em>. Clarendon Press, Oxford, England.</li>
<li>Segal, Dan (2002). An economic analysis of life insurance company expenses. <em>North American Actuarial Journal</em>, 6(4), 81-94.</li>
</ul>
</div>
<div id="exercises" class="section level2 hasAnchor" number="3.5">
<h2><span class="header-section-number">3.5</span> Exercises<a href="some-special-explanatory-variables.html#exercises" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>3.1. Consider a fictitious data set of <span class="math inline">\(n = 100\)</span> observations with <span class="math inline">\(s_y = 80\)</span>. We run a regression with three explanatory variables to get <span class="math inline">\(s = 50\)</span>.</p>
<pre><code>a. Calculate the adjusted coefficient of determination, $R_a^2$.
b. Complete the ANOVA table.</code></pre>
<p><span class="math display">\[
    \begin{array}{|l|l|c|l|}
    \hline
    \multicolumn{4}{|c|}{\text{ANOVA Table}} \\ \hline
    \text{Source} &amp; \text{Sum of Squares} &amp; \text{df} &amp; \text{Mean Square} \\ \hline
    \text{Regression} &amp; &amp; &amp; \\
    \text{Error} &amp; &amp; &amp; \\
    \text{Total} &amp; &amp; &amp; \\ \hline
    \end{array}
\]</span>
c. Calculate the (unadjusted) coefficient of determination, <span class="math inline">\(R^2\)</span>.</p>
<p>3.2. Consider a fictitious data set of <span class="math inline">\(n = 100\)</span> observations with <span class="math inline">\(s_y = 80\)</span>. We run a regression with three explanatory variables to get <span class="math inline">\(s = 50\)</span>. We also get</p>
<p><span class="math display">\[
    \left(\mathbf{X^{\prime} X} \right)^{-1} = \begin{pmatrix}
    100 &amp; 20 &amp; 20 &amp; 20 \\
    20 &amp; 90 &amp; 30 &amp; 40 \\
    20 &amp; 30 &amp; 80 &amp; 50 \\
    20 &amp; 40 &amp; 50 &amp; 70 \\
    \end{pmatrix}.
\]</span></p>
<pre><code>a. Determine the standard error of $b_3$, $se(b_3)$.
b. Determine the estimated covariance between $b_2$ and $b_3$.
c. Determine the estimated correlation between $b_2$ and $b_3$.
d. Determine the estimated variance of $4b_2 + 3b_3$.</code></pre>
<p>3.3. Consider the following small fictitious data set. You will be fitting a regression model to <span class="math inline">\(y\)</span> using two explanatory variables, <span class="math inline">\(x_1\)</span> and <span class="math inline">\(x_2\)</span>.</p>
<p><span class="math display">\[
    \begin{array}{c|cccc}
    \hline
    i &amp; 1 &amp; 2 &amp; 3 &amp; 4 \\ \hline
    x_{i,1} &amp; -1 &amp; 2 &amp; 4 &amp; 6 \\
    x_{i,2} &amp; 0 &amp; 0 &amp; 1 &amp; 1 \\
    y_i &amp; 0 &amp; 1 &amp; 5 &amp; 8 \\ \hline
    \end{array}
\]</span></p>
<pre><code>From the fitted regression model, we have $s = 1.373$ and</code></pre>
<p><span class="math display">\[
    \mathbf{b} = \begin{pmatrix}
    0.15 \\
    0.692 \\
    2.88
    \end{pmatrix}
    ~~~\text{and}~~~
    \left(\mathbf{X^{\prime} X} \right)^{-1} = \begin{pmatrix}
    0.53846 &amp; -0.07692 &amp; -0.15385 \\
    -0.07692 &amp; 0.15385 &amp; -0.69231 \\
    -0.15385 &amp; -0.69231 &amp; 4.11538 \\
    \end{pmatrix}.
\]</span></p>
<pre><code>a. Write down the vector of dependent variables, $\mathbf{y}$, and the matrix of explanatory variables, $\mathbf{X}$.
b. Determine the numerical value for $\widehat{y}_3$, the fitted value for the third observation.
c. Determine the numerical value for $se(b_2)$.
d. Determine the numerical value for $t(b_1)$.</code></pre>
<p>3.4. <strong>Wisconsin Lottery.</strong> Section 2.1 described a sample of <span class="math inline">\(n=50\)</span> geographic areas (zip codes) containing sales data on the Wisconsin state lottery (<span class="math inline">\(y = \text{SALES}\)</span>). In that section, sales were analyzed using a basic linear regression model with <span class="math inline">\(x = \text{POP}\)</span>, the area population, as the explanatory variable. This exercise extends that analysis by introducing additional explanatory variables given in Table @ref{Ex:LotVariables}.</p>
<p><span class="math display">\[
    \text{Table \@ref{Ex:LotVariables}: Lottery, economic and demographic characteristics of fifty Wisconsin ZIP codes}
\]</span></p>
<p><span class="math display">\[
    \begin{array}{ll}
    \hline
    \multicolumn{2}{c}{\text{\bf Lottery characteristics}} \\ \hline
    \text{SALES} &amp; \text{Online lottery sales to individual consumers} \\ \hline
    \multicolumn{2}{c}{\text{\bf Economic and demographic characteristics}} \\ \hline
    \text{PERPERHH} &amp; \text{Persons per household} \\
    \text{MEDSCHYR} &amp; \text{Median years of schooling} \\
    \text{MEDHVL} &amp; \text{Median home value in \$1000s for owner-occupied homes} \\
    \text{PRCRENT} &amp; \text{Percent of housing that is renter occupied} \\
    \text{PRC55P} &amp; \text{Percent of population that is 55 or older} \\
    \text{HHMEDAGE} &amp; \text{Household median age} \\
    \text{MEDINC} &amp; \text{Estimated median household income, in \$1000s} \\
    \text{POP} &amp; \text{Population, in thousands} \\ \hline
    \end{array}
\]</span></p>
<pre><code>a. Produce a table of summary statistics for all variables. One zip code (observation 11, zip = 53211, Shorewood Wisconsin, a suburb of Milwaukee) appears to have unusually large values of MEDSCHYR and MEDHVL. For this observation, how many standard deviations is the value of MEDSCHYR above the mean? For this observation, how many standard deviations is the value of MEDHVL above the mean?
b. Produce a table of correlations. What three variables are most highly correlated with SALES?
c. Produce a scatter plot matrix of all explanatory variables and SALES. In the plot of MEDSCHYR versus SALES, describe the position of observation 11.
d. Fit a linear model of SALES on all eight explanatory variables. Summarize the fit of this model by citing the residual standard deviation, $s$, the coefficient of determination, $R^2$ and its adjusted version, $R_a^2$.
e. Based on your part (d) model fit, is MEDSCHYR a statistically significant variable? To respond to this question, use a formal test of hypothesis. State your null and alternative hypotheses, decision-making criterion and your decision-making rule.
f. Now fit a more parsimonious model, using SALES as the dependent variable and MEDSCHYR, MEDHVL and POP as explanatory variables. Summarize the fit of this model by citing the residual standard deviation, $s$, the coefficient of determination, $R^2$ and its adjusted version, $R_a^2$. How do these values compare to the model fit in part (d)?
g. Note that the sign of the regression coefficient associated with MEDSCHYR is now negative. To help interpret this coefficient, compute the corresponding partial correlation coefficient. What is the interpretation of this coefficient?
h. To get further insights into the relation between MEDSCHYR and SALES, produce an added variable plot controlling for the effects of MEDHVL and POP. Check that the correlation associated with this plot agrees with your answer in part (g).
i. Re-run the regression in part (f), after removing observation 11. Cite the basic summary statistics from this regression. For this model fit, is MEDSCHYR a statistically significant variable? To respond to this question, use a formal test of hypothesis. State your null and alternative hypotheses, decision-making criterion and your decision-making rule.
j. Re-run the regression in part (f), after removing observation 9. Cite the basic summary statistics from this regression.</code></pre>
<p>3.5. <strong>Insurance Company Expenses</strong>. This exercise considers insurance company data from the NAIC and described in Exercise 1.</p>
<p>Table @ref{tab:NAICVariables} describes several variables that can be used to explain expenses. As with Segal’s (2002) study of life insurers, firm “outputs” consist of premiums written (for property and casualty, these are subdivided into personal and commercial lines) as well as losses (subdivided into short and long tail lines). ASSETS and CASH are commonly used measures of the size of a company. GROUP, STOCK, and MUTUAL describe the organizational structure. Firm “inputs” were gathered from the Bureau of Labor Statistics (BLS, from the Occupational Employee Statistics program). WAGESTAFF is calculated as the average wage in the state where the insurance company is headquartered. AGENTWAGE is calculated as the weighted average of annual wages of the brokerage industry, weighted by the percentage of gross premium written in each state.</p>
<table>
<caption><span id="tab:unnamed-chunk-9">Table 3.1: </span>Insurer Expense Variables</caption>
<colgroup>
<col width="12%" />
<col width="87%" />
</colgroup>
<thead>
<tr class="header">
<th align="left">Variable</th>
<th align="left">Description</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">EXPENSES</td>
<td align="left">Total expenses incurred, in millions of dollars</td>
</tr>
<tr class="even">
<td align="left">LOSSLONG</td>
<td align="left">Losses incurred for long tail lines, in millions of dollars</td>
</tr>
<tr class="odd">
<td align="left">LOSSSHORT</td>
<td align="left">Losses incurred for short tail lines, in millions of dollars</td>
</tr>
<tr class="even">
<td align="left">GPWPERSONAL</td>
<td align="left">Gross premium written for personal lines, in millions of dollars</td>
</tr>
<tr class="odd">
<td align="left">GPWCOMM</td>
<td align="left">Gross premium written for commercial lines, in millions of dollars</td>
</tr>
<tr class="even">
<td align="left">ASSETS</td>
<td align="left">Net admitted assets, in millions of dollars</td>
</tr>
<tr class="odd">
<td align="left">CASH</td>
<td align="left">Cash and invested assets, in millions of dollars</td>
</tr>
<tr class="even">
<td align="left">GROUP</td>
<td align="left">Indicates if the company is affiliated</td>
</tr>
<tr class="odd">
<td align="left">STOCK</td>
<td align="left">Indicates if the company is a stock company</td>
</tr>
<tr class="even">
<td align="left">MUTUAL</td>
<td align="left">Indicates if the company is a mutual company</td>
</tr>
<tr class="odd">
<td align="left">STAFFWAGE</td>
<td align="left">Annual average wage of the insurer’s administrative staff, in thousands of dollars</td>
</tr>
<tr class="even">
<td align="left">AGENTWAGE</td>
<td align="left">Annual average wage of the insurance agent, in thousands of dollars</td>
</tr>
</tbody>
</table>
<p>A preliminary inspection of the data showed that many firms did not report any insurance losses incurred in 2005. For this exercise, we consider the 384 companies with some losses in the file <code>NAICExpense.csv</code>.</p>
<pre><code>a. Summary Statistics</code></pre>
<p>Produce summary statistics of the response variable and the (non-binary) explanatory variables. Note the pattern of skewness for each variable. Note that many variables have negative values.</p>
<pre><code>b. Transform Variables</code></pre>
<p>Transform each non-binary variable through the modified logarithm transform, $ (1+x) <span class="math inline">\(. Produce summary statistics of these modified non-binary explanatory variables. Let `LNEXPENSES` (\)</span> = (1+) $) denote the modified expense variable.</p>
<p>For subsequent analysis, use only the modified variables described in part (b).</p>
<pre><code>c. Correlation Table</code></pre>
<p>Produce a table of correlations for the non-binary variables. What three variables are most highly correlated with <code>LNEXPENSES</code>?</p>
<pre><code>d. Boxplot of LNEXPENSES by GROUP</code></pre>
<p>Provide a boxplot of <code>LNEXPENSES</code> by level of <code>GROUP</code>. Which level of group has higher expenses?</p>
<pre><code>e. Linear Model on All Variables</code></pre>
<p>Fit a linear model of <code>LNEXPENSES</code> on all eleven explanatory variables. Summarize the fit of this model by citing the residual standard deviation, <span class="math inline">\(s\)</span>, the coefficient of determination, <span class="math inline">\(R^2\)</span>, and its adjusted version, <span class="math inline">\(R^2_a\)</span>.</p>
<pre><code>f. Reduced Model</code></pre>
<p>Fit a linear model of <code>LNEXPENSES</code> on a reduced model using eight explanatory variables, dropping <code>CASH</code>, <code>STOCK</code>, and <code>MUTUAL</code>. For the explanatory variables, include <code>ASSETS</code>, <code>GROUP</code>, both versions of losses, and gross premiums, as well as the two BLS variables.</p>
<pre><code>    **f(i).** Summarize the fit of this model by citing $s$, $R^2$, and $R^2_a$.

    **f(ii).** Interpret the coefficient associated with commercial lines gross premiums on the logarithmic scale.

    **f(iii).** Suppose that `GPWCOMM` increases by \$1, how much do we expect `EXPENSES` to increase? Use your answer in part f(ii) and median values of `GPWCOMM` and `EXPENSES` for this question.

g. Quadratic Terms</code></pre>
<p>Square each of the two loss and the two gross premium variables. Fit a linear model of <code>LNEXPENSES</code> on a reduced model using twelve explanatory variables, the eight variables in part (f) and the four additional squared terms just created.</p>
<pre><code>    **g(i).** Summarize the fit of this model by citing $s$, $R^2$, and $R^2_a$.

    **g(ii).** Do the quadratic variables appear to be useful explanatory variables?

h. Excluding BLS Variables</code></pre>
<p>Now omit the two BLS variables, so you are fitting a model of <code>LNEXPENSES</code> on <code>ASSETS</code>, <code>GROUP</code>, both versions of losses, and gross premiums, as well as quadratic terms. Summarize the fit of this model by citing <span class="math inline">\(s\)</span>, <span class="math inline">\(R^2\)</span>, and <span class="math inline">\(R^2_a\)</span>. Comment on the number of observations used to fit this model compared to part (f).</p>
<pre><code>i. Interaction Terms</code></pre>
<p>Drop the quadratic terms in part (g) and add interaction terms with the dummy variable <code>GROUP</code>. Thus, there are now eleven variables: <code>ASSETS</code>, <code>GROUP</code>, both versions of losses and gross premiums, as well as interactions of <code>GROUP</code> with <code>ASSETS</code> and both versions of losses and gross premiums.</p>
<pre><code>    **i(i).** Summarize the fit of this model by citing $s$, $R^2$, and $R^2_a$.

    **i(ii).** Suppose that `GPWCOMM` increases by \$1, how much do we expect `EXPENSES` to increase for `GROUP=0` companies? Use the median values of `GPWCOMM` and `EXPENSES` of `GROUP=0` companies for this question.

    **i(iii).** Suppose that `GPWCOMM` increases by \$1, how much do we expect `EXPENSES` to increase for `GROUP=1` companies? Use the median values of `GPWCOMM` and `EXPENSES` of `GROUP=1` companies for this question.</code></pre>
<p>3.6 <strong>National Life Expectancies</strong>. We continue the analysis begun in Exercises 1 and 2. Now fit a regression model on <code>LIFEEXP</code> using three explanatory variables: <code>FERTILITY</code>, <code>PUBLICEDUCATION</code>, and <code>lnHEALTH</code> (the natural logarithmic transform of <code>PRIVATEHEALTH</code>).</p>
<pre><code>a. Interpretation of Public Education Coefficient</code></pre>
<p>Interpret the regression coefficient associated with <code>PUBLICEDUCATION</code>.</p>
<pre><code>b. Interpretation of Health Expenditures Coefficient</code></pre>
<p>Interpret the regression coefficient associated with <code>HEALTH</code> expenditures without using the logarithmic scale for expenditures.</p>
<pre><code>c. Statistical Significance of PUBLICEDUCATION</code></pre>
<p>Based on the model fit, is <code>PUBLICEDUCATION</code> a statistically significant variable? To respond to this question, use a formal test of hypothesis. State your null and alternative hypotheses, decision-making criterion, and your decision-making rule.</p>
<pre><code>d. Added Variable Plot</code></pre>
<p>The negative sign of the <code>PUBLICEDUCATION</code> coefficient is surprising, given that the sign of the correlation between <code>PUBLICEDUCATION</code> and <code>LIFEEXP</code> is positive and intuition suggests a positive relation. To check this result, an added variable plot appears in Figure~@ref{fig:UNLIFEPlot2}.</p>
<pre><code>    **d(i).** For an added variable plot, describe its purpose and a method for producing it.

    **d(ii).** Calculate the correlation corresponding to the added variable plot that appears in Figure~\@ref{fig:UNLIFEPlot2}.
    </code></pre>

<div class="figure" style="text-align: center"><span style="display:block;" id="fig:unnamed-chunk-10"></span>
<img src="Chapters/Chapter3/UNLIFE2.eps" alt="Added variable plot of PUBLICEDUCATION versus LIFEEXP, controlling for FERTILITY and lnHEALTH" width="100%" />
<p class="caption">
Figure 3.7: <strong>Added variable plot of PUBLICEDUCATION versus LIFEEXP, controlling for FERTILITY and lnHEALTH</strong>
</p>
</div>

</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="estimation-and-goodness-of-fit.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="bibliography.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": null,
"search": {
"engine": "fuse",
"options": null
},
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/latest.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
