<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapter 17 Fat-Tailed Regression Models | Regression Modeling with Actuarial and Financial Applications</title>
  <meta name="description" content="HTML version of ‘Regression Modeling with Actuarial and Financial Applications’" />
  <meta name="generator" content="bookdown 0.39 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapter 17 Fat-Tailed Regression Models | Regression Modeling with Actuarial and Financial Applications" />
  <meta property="og:type" content="book" />
  
  <meta property="og:description" content="HTML version of ‘Regression Modeling with Actuarial and Financial Applications’" />
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 17 Fat-Tailed Regression Models | Regression Modeling with Actuarial and Financial Applications" />
  
  <meta name="twitter:description" content="HTML version of ‘Regression Modeling with Actuarial and Financial Applications’" />
  

<meta name="author" content="Edward (Jed) Frees, University of Wisconsin - Madison, Australian National University" />



  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="chap-16.html"/>
<link rel="next" href="appendices.html"/>
<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/anchor-sections-1.1.0/anchor-sections.css" rel="stylesheet" />
<link href="libs/anchor-sections-1.1.0/anchor-sections-hash.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.1.0/anchor-sections.js"></script>
<script src="libs/kePrint-0.0.1/kePrint.js"></script>
<link href="libs/lightable-0.0.1/lightable.css" rel="stylesheet" />
<link href="libs/bsTable-3.3.7/bootstrapTable.min.css" rel="stylesheet" />
<script src="libs/bsTable-3.3.7/bootstrapTable.js"></script>

<!-- Mathjax Version 2-->
<script type='text/x-mathjax-config'>
		MathJax.Hub.Config({
			extensions: ['tex2jax.js'],
			jax: ['input/TeX', 'output/HTML-CSS'],
			tex2jax: {
				inlineMath: [ ['$','$'], ['\\(','\\)'] ],
				displayMath: [ ['$$','$$'], ['\\[','\\]'] ],
				processEscapes: true
			},
			'HTML-CSS': { availableFonts: ['TeX'] }
		});
</script>

<script type="text/javascript"  src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/MathJax.js?config=TeX-AMS_HTML"> </script>

<script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
<script type="text/javascript" src="https://unpkg.com/survey-jquery/survey.jquery.min.js"></script>
<link href="https://unpkg.com/survey-jquery/modern.min.css" type="text/css" rel="stylesheet">
<script src="https://unpkg.com/showdown/dist/showdown.min.js"></script>


<!-- Various toggle functions used throughout --> 
<script language="javascript">
function toggle(id1,id2) {
	var ele = document.getElementById(id1); var text = document.getElementById(id2);
	if (ele.style.display == "block") {ele.style.display = "none"; text.innerHTML = "Show Solution";}
		else {ele.style.display = "block"; text.innerHTML = "Hide Solution";}}
function togglecode(id1,id2) {
   var ele = document.getElementById(id1); var text = document.getElementById(id2);
   if (ele.style.display == "block") {ele.style.display = "none"; text.innerHTML = "Show R Code";}
      else {ele.style.display = "block"; text.innerHTML = "Hide R Code";}}
function toggleEX(id1,id2) {
   var ele = document.getElementById(id1); var text = document.getElementById(id2);
   if (ele.style.display == "block") {ele.style.display = "none"; text.innerHTML = "Show Example";}
      else {ele.style.display = "block"; text.innerHTML = "Hide Example";}}
function toggleTheory(id1,id2) {
   var ele = document.getElementById(id1); var text = document.getElementById(id2);
   if (ele.style.display == "block") {ele.style.display = "none"; text.innerHTML = "Show Theory";}
      else {ele.style.display = "block"; text.innerHTML = "Hide Theory";}}
function toggleSolution(id1,id2) {
   var ele = document.getElementById(id1); var text = document.getElementById(id2);
   if (ele.style.display == "block") {ele.style.display = "none"; text.innerHTML = "Show Solution";}
      else {ele.style.display = "block"; text.innerHTML = "Hide Solution";}}      
function toggleQuiz(id1,id2) {
   var ele = document.getElementById(id1); var text = document.getElementById(id2);
   if (ele.style.display == "block") {ele.style.display = "none"; text.innerHTML = "Show Quiz Solution";}
      else {ele.style.display = "block"; text.innerHTML = "Hide Quiz Solution";}}      
</script>

<!-- A few functions for revealing definitions -->
<script language="javascript">
<!--   $( function() {
    $("#tabs").tabs();
  } ); -->

$(document).ready(function(){
    $('[data-toggle="tooltip"]').tooltip();
});

$(document).ready(function(){
    $('[data-toggle="popover"]').popover(); 
});
</script>

<script language="javascript">
function openTab(evt, tabName) {
    var i, tabcontent, tablinks;
    tabcontent = document.getElementsByClassName("tabcontent");
    for (i = 0; i < tabcontent.length; i++) {
        tabcontent[i].style.display = "none";
    }
    tablinks = document.getElementsByClassName("tablinks");
    for (i = 0; i < tablinks.length; i++) {
        tablinks[i].className = tablinks[i].className.replace(" active", "");
    }
    document.getElementById(tabName).style.display = "block";
    evt.currentTarget.className += " active";
}

// Get the element with id="defaultOpen" and click on it
document.getElementById("defaultOpen").click();
</script>




<style type="text/css">
  
  div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Regression Modeling With Actuarial and Financial Applications</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="preface.html"><a href="preface.html"><i class="fa fa-check"></i>Preface</a>
<ul>
<li class="chapter" data-level="" data-path="preface.html"><a href="preface.html#dedication"><i class="fa fa-check"></i>Dedication</a></li>
<li class="chapter" data-level="" data-path="preface.html"><a href="preface.html#forward"><i class="fa fa-check"></i>Forward</a>
<ul>
<li class="chapter" data-level="" data-path="preface.html"><a href="preface.html#who-is-this-book-for"><i class="fa fa-check"></i>Who Is This Book For?</a></li>
<li class="chapter" data-level="" data-path="preface.html"><a href="preface.html#what-is-this-book-about"><i class="fa fa-check"></i>What Is This Book About?</a></li>
<li class="chapter" data-level="" data-path="preface.html"><a href="preface.html#how-does-this-book-deliver-its-message"><i class="fa fa-check"></i>How Does This Book Deliver Its Message?</a></li>
<li class="chapter" data-level="" data-path="preface.html"><a href="preface.html#acknowledgements"><i class="fa fa-check"></i>Acknowledgements</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="1" data-path="chap-1.html"><a href="chap-1.html"><i class="fa fa-check"></i><b>1</b> Chap 1</a></li>
<li class="chapter" data-level="2" data-path="chap-2.html"><a href="chap-2.html"><i class="fa fa-check"></i><b>2</b> Chap 2</a></li>
<li class="chapter" data-level="3" data-path="chap-3.html"><a href="chap-3.html"><i class="fa fa-check"></i><b>3</b> Chap 3</a></li>
<li class="chapter" data-level="4" data-path="chap-4.html"><a href="chap-4.html"><i class="fa fa-check"></i><b>4</b> Chap 4</a></li>
<li class="chapter" data-level="5" data-path="chap-5.html"><a href="chap-5.html"><i class="fa fa-check"></i><b>5</b> Chap 5</a></li>
<li class="chapter" data-level="6" data-path="chap-6.html"><a href="chap-6.html"><i class="fa fa-check"></i><b>6</b> Chap 6</a></li>
<li class="chapter" data-level="7" data-path="chap-7.html"><a href="chap-7.html"><i class="fa fa-check"></i><b>7</b> Chap 7</a></li>
<li class="chapter" data-level="8" data-path="chap-8.html"><a href="chap-8.html"><i class="fa fa-check"></i><b>8</b> Chap 8</a></li>
<li class="chapter" data-level="9" data-path="chap-9.html"><a href="chap-9.html"><i class="fa fa-check"></i><b>9</b> Chap 9</a></li>
<li class="chapter" data-level="10" data-path="chap-10.html"><a href="chap-10.html"><i class="fa fa-check"></i><b>10</b> Chap 10</a></li>
<li class="chapter" data-level="11" data-path="chap-11.html"><a href="chap-11.html"><i class="fa fa-check"></i><b>11</b> Chap 11</a></li>
<li class="chapter" data-level="12" data-path="chap-12.html"><a href="chap-12.html"><i class="fa fa-check"></i><b>12</b> Chap 12</a></li>
<li class="chapter" data-level="13" data-path="chap-13.html"><a href="chap-13.html"><i class="fa fa-check"></i><b>13</b> Chap 13</a></li>
<li class="chapter" data-level="14" data-path="chap-14.html"><a href="chap-14.html"><i class="fa fa-check"></i><b>14</b> Chap 14</a></li>
<li class="chapter" data-level="15" data-path="chap-15.html"><a href="chap-15.html"><i class="fa fa-check"></i><b>15</b> Chap 15</a></li>
<li class="chapter" data-level="16" data-path="chap-16.html"><a href="chap-16.html"><i class="fa fa-check"></i><b>16</b> Chap 16</a></li>
<li class="chapter" data-level="17" data-path="fat-tailed-regression-models.html"><a href="fat-tailed-regression-models.html"><i class="fa fa-check"></i><b>17</b> Fat-Tailed Regression Models</a>
<ul>
<li class="chapter" data-level="17.1" data-path="fat-tailed-regression-models.html"><a href="fat-tailed-regression-models.html#introduction"><i class="fa fa-check"></i><b>17.1</b> Introduction</a></li>
<li class="chapter" data-level="17.2" data-path="fat-tailed-regression-models.html"><a href="fat-tailed-regression-models.html#S:Sec172"><i class="fa fa-check"></i><b>17.2</b> Transformations</a></li>
<li class="chapter" data-level="17.3" data-path="fat-tailed-regression-models.html"><a href="fat-tailed-regression-models.html#S:Sec173"><i class="fa fa-check"></i><b>17.3</b> Generalized Linear Models</a>
<ul>
<li class="chapter" data-level="17.3.1" data-path="fat-tailed-regression-models.html"><a href="fat-tailed-regression-models.html#S:Sec1731"><i class="fa fa-check"></i><b>17.3.1</b> What is “Fat-Tailed?”</a></li>
<li class="chapter" data-level="17.3.2" data-path="fat-tailed-regression-models.html"><a href="fat-tailed-regression-models.html#S:Sec1732"><i class="fa fa-check"></i><b>17.3.2</b> Application: Wisconsin Nursing Homes</a></li>
</ul></li>
<li class="chapter" data-level="17.4" data-path="fat-tailed-regression-models.html"><a href="fat-tailed-regression-models.html#S:Sec174"><i class="fa fa-check"></i><b>17.4</b> Generalized Distributions</a>
<ul>
<li class="chapter" data-level="" data-path="fat-tailed-regression-models.html"><a href="fat-tailed-regression-models.html#applicationwisconsin-nursing-homes"><i class="fa fa-check"></i>Application:Wisconsin Nursing Homes</a></li>
<li class="chapter" data-level="17.4.1" data-path="fat-tailed-regression-models.html"><a href="fat-tailed-regression-models.html#S:Sec175"><i class="fa fa-check"></i><b>17.4.1</b> Quantile Regression</a></li>
</ul></li>
<li class="chapter" data-level="17.5" data-path="fat-tailed-regression-models.html"><a href="fat-tailed-regression-models.html#S:Sec176"><i class="fa fa-check"></i><b>17.5</b> Extreme Value Models</a></li>
<li class="chapter" data-level="17.6" data-path="fat-tailed-regression-models.html"><a href="fat-tailed-regression-models.html#further-reading-and-references"><i class="fa fa-check"></i><b>17.6</b> Further Reading and References</a></li>
<li class="chapter" data-level="17.7" data-path="fat-tailed-regression-models.html"><a href="fat-tailed-regression-models.html#exercises"><i class="fa fa-check"></i><b>17.7</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="18" data-path="appendices.html"><a href="appendices.html"><i class="fa fa-check"></i><b>18</b> Appendices</a>
<ul>
<li class="chapter" data-level="" data-path="appendices.html"><a href="appendices.html#appendix-a1.-basic-statistical-inference"><i class="fa fa-check"></i>Appendix A1. Basic Statistical Inference</a>
<ul>
<li class="chapter" data-level="" data-path="appendices.html"><a href="appendices.html#distributions-of-functions-of-random-variables"><i class="fa fa-check"></i>Distributions of Functions of Random Variables</a></li>
<li class="chapter" data-level="" data-path="appendices.html"><a href="appendices.html#estimation-and-prediction"><i class="fa fa-check"></i>Estimation and Prediction</a></li>
<li class="chapter" data-level="" data-path="appendices.html"><a href="appendices.html#testing-hypotheses"><i class="fa fa-check"></i>Testing Hypotheses</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="appendices.html"><a href="appendices.html#appendix-a2.-matrix-algebra"><i class="fa fa-check"></i>Appendix A2. Matrix Algebra</a>
<ul>
<li class="chapter" data-level="" data-path="appendices.html"><a href="appendices.html#basic-definitions"><i class="fa fa-check"></i>Basic Definitions</a></li>
<li class="chapter" data-level="" data-path="appendices.html"><a href="appendices.html#review-of-basic-operations"><i class="fa fa-check"></i>Review of Basic Operations</a></li>
<li class="chapter" data-level="" data-path="appendices.html"><a href="appendices.html#further-definitions"><i class="fa fa-check"></i>Further Definitions</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="appendices.html"><a href="appendices.html#appendix-a3.-probability-tables"><i class="fa fa-check"></i>Appendix A3. Probability Tables</a>
<ul>
<li class="chapter" data-level="" data-path="appendices.html"><a href="appendices.html#normal-distribution"><i class="fa fa-check"></i>Normal Distribution</a></li>
<li class="chapter" data-level="" data-path="appendices.html"><a href="appendices.html#chi-square-distribution"><i class="fa fa-check"></i>Chi-Square Distribution</a></li>
<li class="chapter" data-level="" data-path="appendices.html"><a href="appendices.html#t-distribution"><i class="fa fa-check"></i><em>t</em>-Distribution</a></li>
<li class="chapter" data-level="" data-path="appendices.html"><a href="appendices.html#f-distribution"><i class="fa fa-check"></i><em>F</em>-Distribution</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="" data-path="bibliography.html"><a href="bibliography.html"><i class="fa fa-check"></i>Bibliography</a></li>
<li class="divider"></li>
<li><a href="https://github.com/OpenActTextDev/RegressionSpanish/" target="blank">Spanish Regression on GitHub</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Regression Modeling with Actuarial and Financial Applications</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="fat-tailed-regression-models" class="section level1 hasAnchor" number="17">
<h1><span class="header-section-number">Chapter 17</span> Fat-Tailed Regression Models<a href="fat-tailed-regression-models.html#fat-tailed-regression-models" class="anchor-section" aria-label="Anchor link to header"></a></h1>
<p><em>Chapter Preview</em>. When modeling financial
quantities, we are just as interested in the extreme values as the
center of the distribution; these extreme values can represent the
most unusual claims, profits or sales. Actuaries often encounter
situations where the data exhibit “fat-tails,” meaning extreme
values in the data are more likely to occur than in normally
distributed data. Traditional regression focuses on the center of
the distribution and downplays extreme values. In contrast, the
focus of this chapter is on the entire distribution. This chapter
surveys four techniques for regression analysis of fat-tailed data:
transformation, generalized linear models, more general
distributions and quantile regression.</p>
<div id="introduction" class="section level2 hasAnchor" number="17.1">
<h2><span class="header-section-number">17.1</span> Introduction<a href="fat-tailed-regression-models.html#introduction" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Actuaries often encounter situations where the data exhibit
“fat-tails,” meaning extreme values in the data are more likely to
occur than in normally distributed data. These distributions can be
described as “fat,” “heavy,” “thick” or “long” when compared
to the normal distribution. (Section <a href="fat-tailed-regression-models.html#S:Sec1731">17.3.1</a> will be
more precise on what constitutes “fat-tailed.”) In finance, for
example, the asset pricing theories CAPM and APT assume normally
distributed asset returns. Empirical distributions of the returns of
financial assets, however, suggest fat-tailed distributions rather
than normal distributions as assumed in the pricing theories (see,
for example, Rachev, Menn and Fabozzi, 2005). In healthcare,
fat-tailed data are also common. For example, outcomes of interest
such as the number of inpatient days or inpatient expenditures are
typically right skewed and heavy-tailed due to a few yet high-cost
patients (Basu, Manning and Mullahy, 2004). Actuaries also regularly
analyze fat-tailed data in non-life insurance (Klugman, Panjer and
Willmot, 2008).</p>
<p>As with any other data set, the outcome of interest may be related
to other factors and so regression analysis is of interest. However,
employing the usual regression routines without addressing the
fat-tailed nature can lead to serious difficulties.</p>
<ul>
<li>Regression coefficients can be expressed as weighted sums of
dependent variables. Thus, coefficients may be unduly influenced by
extreme observations.</li>
<li>Because the distribution is fat-tailed, the usual rules of thumb for
approximate (large-sample) normality of parameter estimates no
longer apply. Thus, for example, the standard <span class="math inline">\(t\)</span>-ratios and
<span class="math inline">\(p\)</span>-values associated with regression estimates may no longer be
meaningful indicators of statistical significance.</li>
<li>The usual regression routines minimize a squared error loss
function. For some problems, we are more concerned with errors in
one direction (either small or high), not a symmetric function.</li>
<li>Large values in the data set may be the most important in a
financial sense, for example, an extremely high expenditure when
examining medical costs. Although atypical, this is not an
observation that we wish to neglect nor downweight simply because it
does not fit the usual normal-based regression model.</li>
</ul>
<p>This chapter describes four basic approaches for handling fat-tailed
regression data:</p>
<ul>
<li>transformations of the dependent variable,</li>
<li>generalized linear models,</li>
<li>models using more flexible positive random variable distributions, such as the generalized gamma, and</li>
<li>quantile regression models.</li>
</ul>
<p>Sections <a href="fat-tailed-regression-models.html#S:Sec172">17.2</a>-<a href="fat-tailed-regression-models.html#S:Sec175">17.4.1</a> address each in turn.</p>
<p>Another area of statistics that is devoted to the analysis of tail
behavior is known as “extreme-value statistics.” This area
concerns modeling tail behavior, largely at the expense of ignoring
the rest of the distribution. In contrast, traditional regression
focuses on the center of the distribution and downplays extreme
values. For financial quantities, we are just as interested in the
extremes as the center of the distribution; these extreme values can
represent the most unusual claims, profits or sales. The focus of
this chapter is on the entire distribution. Regression modeling
within extreme-value statistics is a topic that has only begun to
receive serious attention; Section <a href="fat-tailed-regression-models.html#S:Sec176">17.5</a>
provides a brief survey.</p>
</div>
<div id="S:Sec172" class="section level2 hasAnchor" number="17.2">
<h2><span class="header-section-number">17.2</span> Transformations<a href="fat-tailed-regression-models.html#S:Sec172" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>As we have seen throughout this text, the most commonly used
approach for handling fat-tailed data is to simply transform the
dependent variable. As a matter of routine, analysts take a
logarithmic transformation of <span class="math inline">\(y\)</span> and then use ordinary least
squares on <span class="math inline">\(\ln (y)\)</span>. Even though this technique is not always
appropriate, it has proven effective for a surprisingly large number
of data sets. This section summarizes what we have learned about
transformations and provides some additional tools that can be
helpful in certain applications.</p>
<p>Section 1.3 introduced the idea of transformations and showed how
(power) transforms could be used to symmetrize a distribution. Power
transforms, such as <span class="math inline">\(y^{\lambda}\)</span>, can “pull in” extreme values so
that any observation will not have an undue effect on parameter
estimates. Moreover, the usual rules of thumb for approximate
(large-sample) normality of parameter estimates are more likely to
apply when data are approximately symmetric (when compared to skewed
data).</p>
<p>However, there are three major drawbacks to transformation. The
first is that it can be difficult to interpret the resulting
regression coefficients. One of the main reasons that we introduced
the natural logarithmic transform in Section 3.2.2 was its ability
to provide interpretations of the regression coefficients as
proportional changes. Other transformations may not enjoy this
intuitively appealing interpretation.</p>
<p>The second drawback, introduced in Section 5.7.4, is that a
transformation also affects other aspects of the model, such as the
heteroscedasticity. For example, if the original model is a
multiplicative (heteroscedastic) model of the form <span class="math inline">\(y_i=(\mathrm{E}% y_i)~\varepsilon_i\)</span>, then a logarithmic transform means that the new
model is
<span class="math display">\[
\ln y_i=\ln \mathrm{E}(y_i)~+\ln \varepsilon_i.
\]</span>
Often, the ability to stabilize the variance is viewed as a positive
aspect of transformations. However, the point is that a
transformation affects both the symmetry and the heteroscedasticity,
when only one aspect may be viewed as troublesome.</p>
<p>The third drawback of transforming the dependent variable is that
the analyst is implicitly optimizing on the transformed scale. This
has been viewed negatively by some scholars. As noted by Manning
(1998), “ no one is interested in log model results per se.
Congress does not appropriate log dollars.”</p>
<p>Our discussions of transformation refers to functions of the
dependent variables. As we have seen in Section 3.5, it is common to
transform explanatory variables. The adjective “linear” in the
phrase “multiple linear regression” refers to linear combinations
of parameters – the explanatory variables themselves may be highly
nonlinear.</p>
<p>Another technique that we have used implicitly throughout the text
for handling fat-tailed data is known as <em>rescaling</em>. In
rescaling, one divides the dependent variable by an explanatory
variable so that the resulting ratio is more comparable among
observations. For example, in Section 6.5 we used property and
casualty premiums and uninsured losses divided by assets as the
dependent variable. Although the numerator, a proxy for annual
expenditures associated with insurable events, is the key measure of
interest, it is common to standardize by company size (as measured
by assets).</p>
<p>Many transformations are special cases of the Box-Cox family of
transforms, introduced in Section 1.3. Recall that this family is
given as
<span class="math display">\[
y^{(\lambda)}=\left\{
\begin{array}{ll}
\frac{y^{\lambda }-1}{\lambda } &amp; \mathrm{if}~\lambda \neq 0 \\
\ln y &amp; \mathrm{if}~\lambda =0
\end{array}%
\right. ,
\]</span>
where <span class="math inline">\(\lambda\)</span> is the transformation parameter (typically <span class="math inline">\(\lambda =1,1/2,0~ \mathrm{or}~-1\)</span>). When data are non-positive, it is common
to add a constant to each observation so that all observations are
positive prior to transformation. For example, the transform <span class="math inline">\(\ln (1+y)\)</span> accommodates the presence of zeros. One can also multiply by
a constant so that the approximate original units are retained. For
example, the transform <span class="math inline">\(100\ln (1+y/100)\)</span> may applied to percentage
data where negative percentages sometimes appear. For the binomial,
Poisson and gamma distributions, we also showed how to use power
transforms for approximate normality and variance stabilization in
Section 13.5.</p>
<p>Alternatively, for handling non-positive data, an easy-to-use
modification is the <em>signed-log transformation</em>, given by
<span class="math inline">\(\mathrm{sign}(y) \ln(|y|+1)\)</span>. This is a special case of the family
introduced by John and Draper (1980):
<span class="math display">\[
y^{(\lambda)}=\left\{
\begin{array}{lr}
\mathrm{sign}(y) \left\{(|y|+1)^\lambda-1\right\}/\lambda, &amp; \lambda \neq 0 \\
\mathrm{sign}(y)  \ln(|y|+1),&amp; \lambda=0
\end{array} \right. .
\]</span></p>
<p>A drawback of the John and Draper family is that its derivative is
not continuous at zero meaning that there can be abrupt
discontinuities for observations around zero. To address this, Yeo
and Johnson (2000) recommend the following extension of the Box-Cox
family,
<span class="math display">\[
y^{(\lambda )}=\left\{
\begin{array}{ll}
\frac{(1+y)^{\lambda }-1}{\lambda } &amp; y\geq 0,\lambda \neq 0 \\
\ln (1+y) &amp; y\geq 0,\lambda =0 \\
-\frac{(1+|y|)^{2-\lambda }-1}{2-\lambda } &amp; y&lt;0,\lambda \neq 2 \\
-\ln (1+|y|) &amp; y&lt;0,\lambda =2%
\end{array}
\right. .
\]</span>
For nonnegative values of <span class="math inline">\(y\)</span>, this transform is the same as the
Box-Cox family with the use of <span class="math inline">\(1+y\)</span> instead of <span class="math inline">\(y\)</span> to accommodate
zeros. For negative values, the power $$ is replaced by
$2-$ , so that a right skewed distribution remains
right-skewed after the change sign. Figure <a href="fat-tailed-regression-models.html#fig:Fig171">17.1</a>
displays this function for several values of <span class="math inline">\(\lambda\)</span>.</p>

<div class="figure" style="text-align: center"><span style="display:block;" id="fig:Fig171"></span>
<img src="RegressionMarkdown_files/figure-html/Fig171-1.png" alt="Yeo-Johnson Transformations. From bottom to top, the curves correspond to \(\lambda =0,0.5,1,1.5\) and 2." width="60%" />
<p class="caption">
Figure 17.1: <strong>Yeo-Johnson Transformations.</strong> From bottom to top, the curves correspond to <span class="math inline">\(\lambda =0,0.5,1,1.5\)</span> and 2.
</p>
</div>
<p>Both the John and Draper as well as the Yeo and Johnson families are
based on power transforms. An alternative family, due to Burbidge
and Magee (1988), is a modification of the inverse hyperbolic sine
transformation. This family is given by:
<span class="math display">\[
y^{(\lambda)}=\sinh^{-1}(\lambda y)/\lambda .
\]</span></p>
</div>
<div id="S:Sec173" class="section level2 hasAnchor" number="17.3">
<h2><span class="header-section-number">17.3</span> Generalized Linear Models<a href="fat-tailed-regression-models.html#S:Sec173" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>As introduced in Chapter 13, the generalized linear model (GLM)
method has become popular in financial and actuarial statistics. An
advantage of this methodology is the ability to fit distributions
with tails heavier than the normal distribution. In particular, GLM
methods are based on the exponential family that includes the
normal, gamma and inverse gaussian distributions. As we will see in
Section <a href="fat-tailed-regression-models.html#S:Sec1731">17.3.1</a>, it is customary to think of the
gamma distribution as having intermediate tails and the inverse
gaussian as having heavy tails compared to the thin-tailed normal
distribution.</p>
<p>The idea of a GLM is to map a linear systematic component
<span class="math inline">\(\mathbf{x}^{\prime }\boldsymbol \beta\)</span> into the mean of the
variable of interest through a known function. Thus, GLMs provide a
natural way to include covariates into the modeling. With a GLM, the
variance is not required to be constant as in the linear model, but
is a function of the mean. Once the distribution family and link
function have been specified, estimation of GLM regression
coefficients depends only on the mean and thus is robust to some
model distribution mis-specifications. This is both a strength and
weakness of the GLM approach. Although more flexible than the linear
model, this approach does not handle many of the long-tail
distributions traditionally used for modeling insurance data. Thus,
in Section <a href="fat-tailed-regression-models.html#S:Sec174">17.4</a> we will present more flexible
distributions.</p>
<div id="S:Sec1731" class="section level3 hasAnchor" number="17.3.1">
<h3><span class="header-section-number">17.3.1</span> What is “Fat-Tailed?”<a href="fat-tailed-regression-models.html#S:Sec1731" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Many analysts begin discussions of tail heaviness through skewness
and kurtosis coefficients. <em>Skewness</em> measures the lack of
symmetry, or lop-sidedness, of a distribution. It is typically
quantified by the third standardized moment,
<span class="math inline">\(\mathrm{E}(y-\mathrm{E~}y)^3/ (\mathrm{Var~}y)^{3/2}.\)</span>
<em>Kurtosis</em> measures tail heaviness, or its converse,
“peakedness.” It is typically quantified by the fourth
standardized moment minus 3, <span class="math inline">\(\mathrm{E}(y-\mathrm{E~}y)^4/ (\mathrm{Var~}y)^{2} -3.\)</span> The “minus 3” is to center discussions
around the normal distribution; that is, for a normal distribution,
one can check that<br />
<span class="math inline">\(\mathrm{E}(y-\mathrm{E~}y)^4/(\mathrm{Var~}y)^{2} =3.\)</span>
Distributions with positive kurtosis are called <em>leptokurtic</em>
whereas those with negative kurtosis are called <em>platykurtic</em>.
These definitions focus heavily on the normal that has traditionally
been viewed as the benchmark distribution.</p>
<p>For many actuarial and financial applications, the normal
distribution is not an appropriate starting point and so we seek
other definitions of “fat-tail.” In addition to moments, the size
of the tail can be measured using a density (or mass, for discrete
distributions) function, the survival function, or a conditional
moment. Typically, the measure would be used to compare one
distribution to another.</p>
<p>For example, comparing the right tails of the normal to a gamma
density function, we
have
<span class="math display">\[\begin{eqnarray*}
\frac{\mathrm{f}_{normal}\left( y\right) }{\mathrm{f}_{gamma}\left( y\right)
} &amp;=&amp;\frac{\sqrt{2\pi \sigma ^{2}}\exp \left( -\left( y-\mu \right)
^{2}/(2\sigma ^{2})\right) }{\left[ \lambda ^{\alpha }\Gamma \left( \alpha
\right) \right] ^{-1}y^{\alpha -1}\exp \left( -y/\lambda \right) } \\
&amp;=&amp;C_1\mathit{\exp }\left( -(\alpha -1)\ln y+y/\lambda -\left( y-\mu
\right) /(2\sigma ^{2})\right) \rightarrow 0,
\end{eqnarray*}\]</span>
as $y$, indicating that the gamma has a heavier, or
fatter, tail than the normal.</p>
<p>Both the normal and the gamma are members of the exponential family
of distributions. For comparison with another member of this family,
the inverse gaussian distribution,
consider
<span class="math display">\[\begin{eqnarray*}
\frac{\mathrm{f}_{gamma}\left( y\right)
}{\mathrm{f}_{invGaussian}\left( y\right) } &amp;=&amp;\frac{\left[ \lambda
^{\alpha }\Gamma \left( \alpha \right) \right] ^{-1}y^{\alpha
-1}\exp \left( -y/\lambda \right) }{\sqrt{\theta /(2\pi y^{3})}\exp
\left( -\theta \left( y-\mu \right) ^{2}/(2y\mu
^{2})\right) } \\
&amp;=&amp;C_2\mathit{\exp }\left( (\alpha +1/2)\ln y-y/\lambda +\theta
\left( y-\mu \right) ^{2}/(2y\mu ^{2}))\right) .
\end{eqnarray*}\]</span>
As $y$, this ratio tends to zero for <span class="math inline">\(\theta /(2\mu ^{2})&lt;\lambda ,\)</span> indicating that the inverse gaussian can
have a heavier tail than the gamma.</p>
<p>For a distribution that is not a member of the exponential family,
consider the Pareto distribution. Similar calculations
show
<span class="math display">\[\begin{eqnarray*}
\frac{\mathrm{f}_{gamma}\left( y\right) }{\mathrm{f}_{Pareto}\left( y\right)
} &amp;=&amp;\frac{\left[ \lambda ^{\alpha }\Gamma \left( \alpha \right) \right]
^{-1}y^{\alpha -1}\exp \left( -y/\lambda \right) }{\alpha \theta ^{-\alpha
}\left( y+\theta \right) ^{-\alpha -1}} \\
&amp;=&amp;C_3\mathit{\exp }\left( (\alpha -1)\ln y-y/\lambda +\left( \alpha
+1\right) \ln \left( y+\theta \right) \right) \rightarrow 0,
\end{eqnarray*}\]</span>
as $y$, indicating that the Pareto has a heavier tail
than the gamma.</p>
<p>The ratio of densities is an easily interpretable measure for
comparing the tail heaviness of two distributions. Because densities
and survival functions have a limiting value of zero, by
L’H^{o}pital’s rule the ratio of survival functions is equivalent
to the ratio of densities. That is,
<span class="math display">\[
\lim_{y\rightarrow \infty }\frac{\mathrm{S}_1\left( y\right)
}{\mathrm{S} _2\left( y\right) }=\lim_{y\rightarrow \infty
}\frac{\mathrm{S} _1^{\prime }\left( y\right) }{\mathrm{S}_2^{\prime
}\left( y\right) } = \lim_{y\rightarrow \infty }\frac{\mathrm{f}_1
\left( y\right) }{\mathrm{f}_2 \left( y\right) }.
\]</span>
This provides another motivation for using this measure.</p>
</div>
<div id="S:Sec1732" class="section level3 hasAnchor" number="17.3.2">
<h3><span class="header-section-number">17.3.2</span> Application: Wisconsin Nursing Homes<a href="fat-tailed-regression-models.html#S:Sec1732" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Nursing home financing has drawn the attention of policymakers and
researchers for the past several decades. With aging populations and
increasing life expectancies, expenditures on nursing homes and
demands of long term care are expected to increase in the future. In
this section, we analyze the data of 349 nursing facilities in the
State of Wisconsin in the cost report year 2001.</p>
<p>The state of Wisconsin Medicaid program funds nursing home care for
individuals qualifying on the basis of need and financial status.
Most, but not all, nursing homes in Wisconsin are certified to
provide Medicaid-funded care. Those that do not accept Medicaid are
generally paid directly by the resident or the resident’s insurer.</p>
<p>Similarly, most, but not all, nursing facilities are certified to
provide Medicare-funded care. Medicare provides post-acute care for
100 days following a related hospitalization. Medicare does not fund
care provided by intermediate care facilities to individuals with
developmental disabilities. As part of the conditions for
participation, Medicare-certified nursing homes must file an annual
cost report to the Wisconsin Department of Health and Family
Services summarizing the volume and cost of care provided to all of
its residents, Medicare-funded and otherwise.</p>
<p>Nursing homes are owned and operated by a variety of entities,
including the state, counties, municipalities, for-profit businesses
and tax-exempt organizations. Private firms often own several
nursing homes. Periodically, facilities may change ownership and,
less frequently, ownership type.</p>
<p>Typically, utilization of nursing home care is measured in patient
days. Facilities bill the fiscal intermediary at the end of each
month for total patient days incurred in the month, itemized by
resident and level of care. Projections of patient days by facility
and level of care play a key role in the annual process of updating
facility rate schedules. Rosenberg et al. (2007) provides additional
discussion.</p>
<div id="summarizing-the-data" class="section level4 unnumbered hasAnchor">
<h4>Summarizing the Data<a href="fat-tailed-regression-models.html#summarizing-the-data" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>After examining the data, we found some minor variations in the
number of days that a facility was open, primarily due to openings
and closing of facilities. Thus, to make utilization more comparable
among facilities, we examine TPY, defined to be the total number of
patient days divided by the number of days the facility was open;
this has a median value of 81.99 per facility.</p>
<p>Table <a href="fat-tailed-regression-models.html#tab:Tab171">17.1</a> describes the variables that
will be used to explain the distribution of TPY. More than half of
the facilities have self funding of insurance. Approximately
<span class="math inline">\(90.5\%\)</span> of the facilities are Medicare Certified. Regarding the
organizational structure, about half <span class="math inline">\((51.9\%)\)</span> are run on a
for-profit basis, and about one third <span class="math inline">\((37.5\%)\)</span> are organized as
tax exempt and the remainder are governmental organizations. The tax
exempt facilities have the highest median occupancy rates. Slightly
more than half of the facilities are located in an urban environment
(53.3%).</p>
<table class=" lightable-classic table table-striped table-condensed" style="font-size: 12px; font-family: Cambria; width: auto !important; margin-left: auto; margin-right: auto; margin-left: auto; margin-right: auto;">
<caption style="font-size: initial !important;">
<span id="tab:Tab171">Table 17.1: </span><strong>Nursing Home Descriptive Statistics</strong>
</caption>
<thead>
<tr>
<th style="text-align:left;">
Variable
</th>
<th style="text-align:center;">
Description
</th>
<th style="text-align:right;">
</th>
<th style="text-align:right;">
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;width: 4cm; border-right:1px solid;">
TPY
</td>
<td style="text-align:center;width: 3cm; width: 8cm; ">
Total person years (median 81.89)
</td>
<td style="text-align:right;width: 3cm; ">
</td>
<td style="text-align:right;width: 3cm; ">
</td>
</tr>
<tr>
<td style="text-align:left;width: 4cm; border-right:1px solid;">
NumBed
</td>
<td style="text-align:center;width: 3cm; width: 8cm; ">
Number of beds (median 90)
</td>
<td style="text-align:right;width: 3cm; ">
</td>
<td style="text-align:right;width: 3cm; ">
</td>
</tr>
<tr>
<td style="text-align:left;width: 4cm; border-right:1px solid;">
SqrFoot
</td>
<td style="text-align:center;width: 3cm; width: 8cm; ">
Nursing home net square footage (in thousands, median 40.25)
</td>
<td style="text-align:right;width: 3cm; ">
</td>
<td style="text-align:right;width: 3cm; ">
</td>
</tr>
<tr>
<td style="text-align:left;width: 4cm; border-right:1px solid;">
Categorical Explanatory Variables
</td>
<td style="text-align:center;width: 3cm; width: 8cm; ">
</td>
<td style="text-align:right;width: 3cm; ">
Percentage
</td>
<td style="text-align:right;width: 3cm; ">
Median TPY
</td>
</tr>
<tr>
<td style="text-align:left;width: 4cm; border-right:1px solid;">
POPID
</td>
<td style="text-align:center;width: 3cm; width: 8cm; ">
Nursing home identification number
</td>
<td style="text-align:right;width: 3cm; ">
</td>
<td style="text-align:right;width: 3cm; ">
</td>
</tr>
<tr>
<td style="text-align:left;width: 4cm; border-right:1px solid;">
SelfIns
</td>
<td style="text-align:center;width: 3cm; width: 8cm; ">
Self Funding of Insurance
</td>
<td style="text-align:right;width: 3cm; ">
</td>
<td style="text-align:right;width: 3cm; ">
</td>
</tr>
<tr>
<td style="text-align:left;width: 4cm; border-right:1px solid;">
</td>
<td style="text-align:center;width: 3cm; width: 8cm; ">
Yes
</td>
<td style="text-align:right;width: 3cm; ">
62.8
</td>
<td style="text-align:right;width: 3cm; ">
88.4
</td>
</tr>
<tr>
<td style="text-align:left;width: 4cm; border-right:1px solid;">
</td>
<td style="text-align:center;width: 3cm; width: 8cm; ">
No
</td>
<td style="text-align:right;width: 3cm; ">
37.2
</td>
<td style="text-align:right;width: 3cm; ">
67.84
</td>
</tr>
<tr>
<td style="text-align:left;width: 4cm; border-right:1px solid;">
MCert
</td>
<td style="text-align:center;width: 3cm; width: 8cm; ">
Medicare Certified
</td>
<td style="text-align:right;width: 3cm; ">
</td>
<td style="text-align:right;width: 3cm; ">
</td>
</tr>
<tr>
<td style="text-align:left;width: 4cm; border-right:1px solid;">
</td>
<td style="text-align:center;width: 3cm; width: 8cm; ">
Yes
</td>
<td style="text-align:right;width: 3cm; ">
90.5
</td>
<td style="text-align:right;width: 3cm; ">
84.06
</td>
</tr>
<tr>
<td style="text-align:left;width: 4cm; border-right:1px solid;">
</td>
<td style="text-align:center;width: 3cm; width: 8cm; ">
No
</td>
<td style="text-align:right;width: 3cm; ">
9.5
</td>
<td style="text-align:right;width: 3cm; ">
53.38
</td>
</tr>
<tr>
<td style="text-align:left;width: 4cm; border-right:1px solid;">
Organizational
</td>
<td style="text-align:center;width: 3cm; width: 8cm; ">
Pro (for profit)
</td>
<td style="text-align:right;width: 3cm; ">
51.9
</td>
<td style="text-align:right;width: 3cm; ">
77.23
</td>
</tr>
<tr>
<td style="text-align:left;width: 4cm; border-right:1px solid;">
Structure
</td>
<td style="text-align:center;width: 3cm; width: 8cm; ">
TaxExempt (tax exempt)
</td>
<td style="text-align:right;width: 3cm; ">
37.5
</td>
<td style="text-align:right;width: 3cm; ">
81.13
</td>
</tr>
<tr>
<td style="text-align:left;width: 4cm; border-right:1px solid;">
</td>
<td style="text-align:center;width: 3cm; width: 8cm; ">
Govt (governmental unit)
</td>
<td style="text-align:right;width: 3cm; ">
10.6
</td>
<td style="text-align:right;width: 3cm; ">
106.7
</td>
</tr>
<tr>
<td style="text-align:left;width: 4cm; border-right:1px solid;">
Location
</td>
<td style="text-align:center;width: 3cm; width: 8cm; ">
Urban
</td>
<td style="text-align:right;width: 3cm; ">
53.3
</td>
<td style="text-align:right;width: 3cm; ">
91.55
</td>
</tr>
<tr>
<td style="text-align:left;width: 4cm; border-right:1px solid;">
</td>
<td style="text-align:center;width: 3cm; width: 8cm; ">
Rural
</td>
<td style="text-align:right;width: 3cm; ">
46.7
</td>
<td style="text-align:right;width: 3cm; ">
74.12
</td>
</tr>
</tbody>
</table>
</div>
<div id="fitting-generalized-linear-models" class="section level4 unnumbered hasAnchor">
<h4>Fitting Generalized Linear Models<a href="fat-tailed-regression-models.html#fitting-generalized-linear-models" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>Figure <a href="fat-tailed-regression-models.html#fig:Fig172">17.2</a> shows the distribution of the dependent
variable TPY. From this figure, we see clear evidence of the
right-skewness of the distribution. One option would be to take a
transform as described in Section <a href="fat-tailed-regression-models.html#S:Sec172">17.2</a>. Rosenberg et
al. (2007) explored this option using a logarithmic transformation.</p>

<div class="figure" style="text-align: center"><span style="display:block;" id="fig:Fig172"></span>
<img src="RegressionMarkdown_files/figure-html/Fig172-1.png" alt="Histogram of TPY. This plot demonstrates the right skewness of the distribution." width="60%" />
<p class="caption">
Figure 17.2: <strong>Histogram of TPY.</strong> This plot demonstrates the right skewness of the distribution.
</p>
</div>
<p>Another option is to directly fit a skewed distribution to the data.
Figure <a href="fat-tailed-regression-models.html#fig:Fig173">17.3</a> presents the <span class="math inline">\(qq\)</span> plots of the gamma and
inverse gaussian distributions. The data fall fairly close to the
line in both panels, meaning both models are reasonable choices. The
normal <span class="math inline">\(qq\)</span> plot, not shown here, indicates that the normal
regression model is not a reasonable fit.</p>

<div class="figure" style="text-align: center"><span style="display:block;" id="fig:Fig173"></span>
<img src="RegressionMarkdown_files/figure-html/Fig173-1.png" alt="\(qq\) Plots of TPY for the Gamma and Inverse Gaussian Distributions" width="100%" />
<p class="caption">
Figure 17.3: <strong><span class="math inline">\(qq\)</span> Plots of TPY for the Gamma and Inverse Gaussian Distributions</strong>
</p>
</div>
<p>We fit the generalized linear models using the gamma and inverse
gaussian distributions. In both models, we choose the logarithmic
link function. The linear systematic component that is common to
each model is
<span class="math display" id="eq:eq171">\[\begin{eqnarray}
&amp;&amp; \eta = \beta_0 + \beta_1 \ln(\text{NumBed}) + \beta_2
\ln(\text{SqrFoot}) +
\beta_3 \text{Pro}  \\
&amp;&amp; + \beta_4 \text{TaxExempt} + \beta_5 \text{SelfIns} + \beta_6
\text{MCert} + \beta_7 \text{Urban}. \notag
\tag{17.1}
\end{eqnarray}\]</span></p>
<p>Table <span class="math inline">\(\ref{T17:GLMWiscNursHome}\)</span> summarizes the parameter estimates
of the models. By comparing the BIC statistics, or the AIC and
log-likelihood in that the number of estimated parameters and the
sample size in both models are identical, we find the gamma model
performs better than the inverse gaussian. As anticipated, the
coefficient for the size variable NumBed is positive and
significant. The only other variable that is statistically
significant is the SqrFoot variable, and this only in the gamma
model.</p>
\begin{table}[h]
<p>\begin{tabular}{l|rrrr}
&amp; &amp; \
Variables &amp; Estimate &amp; <span class="math inline">\(t\)</span>-ratio &amp; Estimate &amp; <span class="math inline">\(t\)</span>-ratio\</p>
<p><a id=Tab172></a></p>
<p><span id="Tab172">Table 17.2</span>. <strong>Fitted Nursing Home Generalized Linear Models</strong></p>
<p><span class="math display">\[
\small{
\begin{array}{llll}
\hline
Intercept    &amp; -0.159 &amp; -3.75 &amp; -0.196 &amp; -4.42 \\
ln(NumBed)   &amp; 0.996  &amp; 66.46 &amp; 1.023 &amp; 65.08 \\
ln(SqrFoot)  &amp; 0.026  &amp; 2.07  &amp; 0.003 &amp; 0.19 \\
SelfIns      &amp; 0.006  &amp; 0.75  &amp; 0.003 &amp; 0.27 \\
MCert        &amp; -0.008 &amp; -0.55  &amp; -0.008 &amp; -0.57 \\
Pro          &amp; 0.004  &amp; 0.29  &amp; 0.007 &amp; 0.36 \\
TaxExempt    &amp; 0.018  &amp; 1.28  &amp; 0.021 &amp; 1.12 \\
Urban        &amp; -0.011 &amp; -1.25 &amp; -0.006 &amp; -0.64 \\
Scale        &amp;    165.64&amp;   &amp; 0.0112  \\ \hline
\\multicolumn{2}{l}{Goodness of Fit Statistics}  \\
Log Likelihood &amp; \\multicolumn{2}{r}{-1,131.24} &amp; \\multicolumn{2}{r}{-1,218.15}  \\
AIC &amp;\\multicolumn{2}{r}{2,280.47} &amp; \\multicolumn{2}{r}{2,454.31}\\
BIC &amp; \\multicolumn{2}{r}{2,315.17}  &amp; \\multicolumn{2}{r}{2,489.00}  \\ \hline
\end{array}
}
\]</span></p>
<p>Figure <a href="fat-tailed-regression-models.html#fig:Fig174">17.4</a> presents the plots of deviance residuals
against the fitted value of TPY for the gamma and inverse gaussian
models. No patterns are found in the plots, supporting the position
that these models are reasonable fits to the data.</p>

<div class="figure" style="text-align: center"><span style="display:block;" id="fig:Fig174"></span>
<img src="RegressionMarkdown_files/figure-html/Fig174-1.png" alt="Plots of Deviance Residuals versus Fitted Values for the Gamma and Inverse Gaussian Models." width="100%" />
<p class="caption">
Figure 17.4: <strong>Plots of Deviance Residuals versus Fitted Values for the Gamma and Inverse Gaussian Models.</strong>
</p>
</div>
</div>
</div>
</div>
<div id="S:Sec174" class="section level2 hasAnchor" number="17.4">
<h2><span class="header-section-number">17.4</span> Generalized Distributions<a href="fat-tailed-regression-models.html#S:Sec174" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Another approach for handling fat-tailed regression data is to use
parametric distributions, such as those from the survival modeling.
Although survival analysis focuses on censored data, the methods can
certainly be applied to complete data. In Section 14.3 we introduced
an accelerated failure time (AFT) model. The AFT is a log
location-scale model, so that <span class="math inline">\(\ln (y)\)</span> follows a parametric
location-scale density distribution in the form
$(y)=_0( (y-)/) /$,
where $$ and <span class="math inline">\(\sigma &gt;0\)</span> are location and scale parameters, and
<span class="math inline">\(\mathrm{f}_0\)</span> is the standard form of the distribution. The
Weibull, lognormal and loglogistic distributions are commonly used
lifetime distributions that are special cases of the AFT framework.</p>
<p>For fitting fat-tailed distributions of interest in actuarial
science, we consider the following minor variation, and examine
distributions from the relation
<span class="math display" id="eq:eq172">\[\begin{equation}
\ln y = \mu + \sigma \ln y_0.
\tag{17.2}
\end{equation}\]</span>
As before, the distribution associated with <span class="math inline">\(y_0\)</span> is a standard one
and we are interested in the distribution of the random variable
<span class="math inline">\(y\)</span>. Two important special cases are the generalized gamma and the
generalized beta of the second kind. These distributions have been
used extensively in modeling insurance data, see for example,
Klugman et al. (2008), although most applications have not utilized
regression covariates.</p>
<p>The <em>generalized gamma distribution</em> is obtained when <span class="math inline">\(y_0\)</span><br />
has a gamma distribution with shape parameter <span class="math inline">\(\alpha\)</span> and scale
parameter 1. When including limiting distributions (such as allowing
coefficients to become arbitrarily large), it includes the
exponential, Weibull, gamma, and lognormal distributions as special
cases. Therefore, it can be used to discriminate between the
alternate models. The generalized gamma distribution is also known
as the transformed gamma distribution (Klugman et al., 2008).</p>
<p>When <span class="math inline">\(y_0\)</span> has a distribution that is the ratio of two gammas, then
<span class="math inline">\(y\)</span> is said to have a <em>generalized beta of the second kind
distribution</em>, commonly known by the acronym <em>GB2</em>.
Specifically, we assume that <span class="math inline">\(y_0 = Gamma_1/Gamma_2\)</span>, where
<span class="math inline">\(Gamma_i\)</span> has a gamma distribution with shape parameter <span class="math inline">\(\alpha_i\)</span>
and scale parameter 1, <span class="math inline">\(i=1,2\)</span>, and that <span class="math inline">\(Gamma_1\)</span> and <span class="math inline">\(Gamma_2\)</span> are
independent. Thus, the GB2 family has four parameters (<span class="math inline">\(\alpha_1\)</span>,
<span class="math inline">\(\alpha_2\)</span>, <span class="math inline">\(\mu\)</span> and <span class="math inline">\(\sigma\)</span>) compared to the three parameter
generalized gamma distribution. When including limiting
distributions, the GB2 encompasses the generalized gamma (by
allowing <span class="math inline">\(\alpha_2 \rightarrow \infty)\)</span> and hence the exponential,
Weibull, and so forth. It also encompasses the Burr Type 12 (by
allowing <span class="math inline">\(\alpha_1 = 1\)</span>), as well as other families of interest,
including the Pareto distributions.</p>
<p>The distribution of <span class="math inline">\(y\)</span> from equation <a href="fat-tailed-regression-models.html#eq:eq172">(17.2)</a> contains
location parameter <span class="math inline">\(\mu\)</span>, scale parameter <span class="math inline">\(\sigma\)</span> and additional
parameters that describe the distribution of <span class="math inline">\(y_0\)</span>. In principle,
one could allow for any distribution parameter to be a function of
the covariates. However, following this principle would lead to a
large number of parameters; this typically yields computational
difficulties as well as problems of interpretations. To limit the
number of parameters, it is customary to assume that the parameters
from <span class="math inline">\(y_0\)</span> do not depend on covariates. It is natural to allow the
location parameter to be a linear function of covariates so that
<span class="math inline">\(\mu =\mu \left( \mathbf{x}\right)= \mathbf{x}^{\prime } \boldsymbol \beta\)</span>. One may also allow the scale parameter <span class="math inline">\(\sigma\)</span> to depend on
<span class="math inline">\(\mathbf{x}\)</span>. For $$ positive, a common specification is $
=()$ = exp<span class="math inline">\((\mathbf{x}^{\prime }\boldsymbol \beta_{\sigma })\)</span>, where <span class="math inline">\(\boldsymbol \beta_{\sigma }\)</span> are
regression coefficients associated with the scale parameter. Other
parameters are typically held fixed.</p>
<p>The interpretability of parameters is one reason to hold the scale
and other non-location parameters fixed. By doing this, it is
straightforward to show that the regression function is of the form
<span class="math display">\[
\mathrm{E}\left( y|\mathbf{x}\right) =C\exp \left( \mu \left(
\mathbf{x} \right) \right) =C~e^{\mathbf{x}^{\prime }\boldsymbol
\beta},
\]</span>
where the constant <span class="math inline">\(C\)</span> is a function of other (non-location) model
parameters. Thus, one can interpret the regression coefficients in
terms of a proportional change (an <em>elasticity</em> in economics).
That is, <span class="math inline">\(\partial \left[ \ln \mathrm{E}(y) \right] /\partial x_k= \beta_k.\)</span></p>
<p>Another reason for holding non-location parameters fixed is the ease
of computing sensible residuals and using these residuals to assist
with model selection. Specifically, with equation
<a href="fat-tailed-regression-models.html#eq:eq172">(17.2)</a>, one can compute residuals of the form
<span class="math display">\[
r_i = \frac{\ln y_i-\widehat{\mu}_i }{\widehat{\sigma }},
\]</span>
where <span class="math inline">\(\widehat{\mu}_i\)</span> and <span class="math inline">\(\widehat{\sigma }\)</span> are maximum
likelihood estimates. For large data sets, we may assume little
estimation error so that $ r_i (y_i - _i) /,$
and the quantity on the right-hand side has a known distribution.</p>
<p>To illustrate, consider the case when <span class="math inline">\(y\)</span> follows a GB2
distribution. In this case,
<span class="math display">\[
y_0 = \frac{Gamma_1}{Gamma_2}= \frac{\alpha_1}{\alpha_2} \times
\frac{Gamma_1/(2\alpha_1)}{Gamma_2/(2\alpha_2)} =
\frac{\alpha_1}{\alpha_2} \times F ,
\]</span>
where <span class="math inline">\(F\)</span> has an <span class="math inline">\(F\)</span>-distribution with numerator and denominator
degrees of freedom <span class="math inline">\(df_1 = 2 \alpha_1\)</span> and <span class="math inline">\(df_2 = 2 \alpha_2\)</span>.
Then, $(r_i) (_1 /_2) F_i $, so that the
exponentiated residuals should have an approximate
<em>F</em>-distribution (up to a scale parameter). This fact allows
us to compute quantile-quantile (<em>qq</em>) plots to assess model
adequacy graphically.</p>
<p>To illustrate, we consider a few insurance related examples that use
fat-tailed regression models. McDonald and Butler (1990) discussed
regression models including those commonly used as well as the GB2
and generalized gamma distribution. They applied the model to the
duration of poverty spells and found that the GB2 improved model
fitting significantly over the lognormal. Beirlant et al. (1998)
proposed two Burr regression models, and applied them to portfolio
segmentation for fire insurance. The Burr is a an extension of the
Pareto distribution, although still a special case of the GB2.
Manning, Basu and Mullahy (2005) applied the generalized gamma
distribution to inpatient expenditures using the data from a study
of hospitals conducted at the University of Chicago.</p>
<p>Because the regression model is fully parametric, maximum likelihood
is generally the estimation method of choice. If <span class="math inline">\(y\)</span> follows a GB2
distribution, straight-forward calculations show that its density
can be expressed as
<span class="math display" id="eq:eq173">\[\begin{equation}
f(y; \mu, \sigma, \alpha_1, \alpha_2) = \frac{[\exp(
z)]^{\alpha_{1}}}{y |\sigma| B(\alpha_1, \alpha_2) [1 + \exp(z)
]^{\alpha_1 + \alpha_2} },
\tag{17.3}
\end{equation}\]</span>
where <span class="math inline">\(z= (\ln y - \mu)/{\sigma}\)</span> and B(<span class="math inline">\(\cdot,\cdot\)</span>) is the beta
function, defined as <span class="math inline">\(\text{B}(\alpha_1, \alpha_2) = \Gamma(\alpha_1)\Gamma(\alpha_2)/\Gamma(\alpha_1+\alpha_2)\)</span>. This
density can be used directly in likelihood routines of many
statistical packages. As described in Section 11.9, the method of
maximum likelihood automatically provides:</p>
<ul>
<li>standard errors for the parameter estimates,</li>
<li>methods of model selection via likelihood ratio testing and</li>
<li>goodness of fit statistics such as AIC and BIC.</li>
</ul>
<div id="applicationwisconsin-nursing-homes" class="section level3 unnumbered hasAnchor">
<h3>Application:Wisconsin Nursing Homes<a href="fat-tailed-regression-models.html#applicationwisconsin-nursing-homes" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>In the fitted generalized linear models summarized in Table
<span class="math inline">\(\ref{T17:GLMWiscNursHome}\)</span>, we saw that the coefficients associated
with ln(NumBed) were close to one. This suggest identifying
ln(NumBed) as an <em>offset variable</em>, that is, forcing the
coefficient associated with ln(NumBed) to be 1. For another modeling
strategy, it also suggests rescaling the dependent variable by
NumBed. This is sensible because we used a logarithmic link function
so that the expected value of TPY is proportional to NumBed.
Pursuing this approach, we now define the annual occupancy rate
(Rate) to be
<span class="math display" id="eq:eq174">\[\begin{equation}
\text{Occupancy Rate} = \frac{\text{Total Patient
Days}}{\text{Number of Beds} \times \text{Days Open}} \times 100.
\tag{17.4}
\end{equation}\]</span>
This new dependent variable is easy to interpret - it measures the
percentage of beds being used on any given day. Occupancy rates were
calculated using the average number of licensed beds within a cost
report year rather than the number of licensed beds on a specific
day. This gives rise to a few occupancy rates greater than 100.</p>
<p>One difficulty of using occupancy rates is that its distribution
cannot reasonably be approximated by a member of the exponential
family. Figure <a href="fat-tailed-regression-models.html#fig:Fig175">17.5</a> shows a smoothed histogram of the
Rate variable (using a kernel smoother); this distribution is
<em>left</em>-skewed. Superimposed on it with the dotted line is the
inverse gaussian distribution where the parameters were fit without
covariates, using method of moments. The gamma and normal
distributions are very close to the inverse gaussian, and hence are
not shown here. In contrast, the fitted (also without covariates)
GB2 distribution shown in Figure <a href="fat-tailed-regression-models.html#fig:Fig175">17.5</a> captures
important parts of the distribution; in particular, it captures the
peakedness and left-skewness.</p>

<div class="figure" style="text-align: center"><span style="display:block;" id="fig:Fig175"></span>
<img src="RegressionMarkdown_files/figure-html/Fig175-1.png" alt="Nursing Home Densities. The empirical version, based on a kernel density estimate, is compared to fitted GB2 and inverse gaussian densities." width="60%" />
<p class="caption">
Figure 17.5: <strong>Nursing Home Densities.</strong> The empirical version, based on a kernel density estimate, is compared to fitted GB2 and inverse gaussian densities.
</p>
</div>
<p>The GB2 distribution was fit using maximum likelihood with the same
covariates as in Table <span class="math inline">\(\ref{T17:GLMWiscNursHome}\)</span>. Specifically, we
used location parameter <span class="math inline">\(\mu = \exp(\eta)\)</span>, where <span class="math inline">\(\eta\)</span> is
specified in equation <a href="fat-tailed-regression-models.html#eq:eq171">(17.1)</a>. As is customary in
likelihood estimation, we reparameterized the scale and two shape
parameters, <span class="math inline">\(\sigma\)</span>, <span class="math inline">\(\alpha_1\)</span> and <span class="math inline">\(\alpha_2\)</span>, to be transformed
on the log scale so that they could range over the whole real line.
In this way, we avoided boundary problems that could arise when
trying to fit models with negative parameter values. Table
<span class="math inline">\(\ref{T17:GModelsWiscNursHome}\)</span> summarizes the fitted model.
Unfortunately, for this fitted model, none of the explanatory
variables turned out to be statistically significant. (Recall that
we rescaled by number of beds, a very important explanatory
variable.)</p>
\begin{table}[h]
<p>\[
\begin{array}{lrrrr}
\hline &amp; \multicolumn{2}{c}{Generalized Gamma}
&amp;\multicolumn{2}{c}{GB2} \
\hline Variables &amp; Estimate &amp; <em>t</em>-ratio &amp;Estimate &amp;
<em>t</em>-ratio \\ \hline
Intercept &amp; 4.522 &amp; 78.15 &amp; 4.584 &amp; 198.47 \\
ln(NumBed) &amp; -0.027 &amp; -2.06 &amp; -0.010 &amp; -1.17 \\
ln(SqrFoot) &amp; 0.031 &amp; 2.89 &amp; 0.010 &amp; 1.28 \\
SelfIns &amp; 0.003 &amp; 0.44 &amp; -0.001 &amp; -0.25 \\
MCert &amp; -0.010 &amp; -0.81 &amp; -0.010 &amp; -1.30 \\
Pro &amp; -0.021 &amp; -1.46 &amp; -0.002 &amp; -0.20 \\
TaxExempt &amp; -0.007 &amp; -0.48 &amp; 0.015 &amp; 1.66 \\
Urban &amp; -0.014 &amp; -1.78 &amp; -0.003 &amp; -0.60 \\
\hline &amp; Estimate &amp; Std Error &amp; Estimate &amp; Std Error \\
<span class="math inline">\(\\ln \\sigma\)</span> &amp; -2.406 &amp; 0.131 &amp; -5.553 &amp; 1.716 \\
<span class="math inline">\(\\ln \\alpha_1\)</span> &amp; 0.655 &amp; 0.236 &amp; -2.906 &amp; 1.752 \\
<span class="math inline">\(\\ln \\alpha_2\)</span> &amp; &amp; &amp; -1.696 &amp; 1.750 \\
\hline
Log-Likelihood &amp; \multicolumn{2}{c}{-1,148.135} &amp; \multicolumn{2}{c}{-1,098.723} \\
AIC &amp; \multicolumn{2}{c}{~2,316.270} &amp; \multicolumn{2}{c}{~2,219.446} \\
BIC &amp; \multicolumn{2}{c}{~2,319.296} &amp; \multicolumn{2}{c}{~2,223.822}\\
\hline
\end{array}
\]</p>
<p>To further assess the model fit, Figure <a href="fat-tailed-regression-models.html#fig:Fig176">17.6</a>
shows residuals from this fitted model. For these figures, residuals
are computed using <span class="math inline">\(r_i = (\ln y_i-\widehat{\mu}_i)/\widehat{\sigma }.\)</span> The left-hand panel shows the residuals versus fitted values
(<span class="math inline">\(\exp(\widehat{\mu}_i)\)</span>), no apparent patterns are evident in this
display. The right-hand panel is a <span class="math inline">\(qq\)</span> plot of residuals, where the
reference distributions is the logarithmic <span class="math inline">\(F\)</span>-distribution (plus a
constant) described above. This figure shows some discrepancies for
smaller values of nursing homes. Because of this, Table
<span class="math inline">\(\ref{T17:GModelsWiscNursHome}\)</span> also reports fits from the generalized
gamma model. This fit is more pleasing in the sense that two of the
explanatory variable are statistically significant. However, from
the goodness of fit statistics, we see that the GB2 is a better
fitting model. Note that the goodness of fit statistics for the
generalized gamma model are not directly comparable with the gamma
regression fits in Table <span class="math inline">\(\ref{T17:GLMWiscNursHome}\)</span>; this is only
because the dependent variable differs by the scale variable
NumBeds.</p>

<div class="figure" style="text-align: center"><span style="display:block;" id="fig:Fig176"></span>
<img src="RegressionMarkdown_files/figure-html/Fig176-1.png" alt="Residual Analysis of the GB2 Model. The left-hand panel is a plot of residuals versus fitted values. The right-hand panel is a \(qq\) plot of residuals." width="60%" />
<p class="caption">
Figure 17.6: <strong>Residual Analysis of the GB2 Model.</strong> The left-hand panel is a plot of residuals versus fitted values. The right-hand panel is a <span class="math inline">\(qq\)</span> plot of residuals.
</p>
</div>
</div>
<div id="S:Sec175" class="section level3 hasAnchor" number="17.4.1">
<h3><span class="header-section-number">17.4.1</span> Quantile Regression<a href="fat-tailed-regression-models.html#S:Sec175" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Quantile regression is an extension of median regression, so it is
helpful to introduce this concept first.</p>
<p>In median regression, one finds the set of regression coefficients
<span class="math inline">\(\boldsymbol \beta\)</span> that minimizes</p>
<p><span class="math display">\[
\sum_{i=1}^n | y_i - \mathbf{x}_i^{\prime} \boldsymbol \beta |.
\]</span>
That is, we simply replace the usual squared loss function with an
absolute value function. Although we will not go into the details
here, finding these optimal coefficients is a simple optimization
problem in nonlinear programming that can be readily implemented in
modern statistical software.</p>
<p>Because this procedure uses the absolute value as the loss function,
median regression is also known as <em>LAD</em> for <em>least absolution deviations</em> as compared to <em>OLS</em> (for ordinary least squares). The adjective “median” comes from the special case where there are no regressors so that <span class="math inline">\(\mathbf{x}\)</span> is a scalar 1. In this
case the minimization problem reduces to finding an intercept
<span class="math inline">\(\beta_0\)</span> that minimizes</p>
<p><span class="math display">\[
\sum_{i=1}^n | y_i - \beta_0 |.
\]</span>
The solution to this problem is the <em>median</em> of <span class="math inline">\(\{y_1, \ldots, y_n\}\)</span>.</p>
<p>Suppose that you would also like to find the <span class="math inline">\(25^{th}\)</span>, <span class="math inline">\(75^{th}\)</span>,
or some other percentile of <span class="math inline">\(\{y_1, \ldots, y_n\}\)</span>. One can also use
this optimization procedure to find any percentile, or
<em>quantile</em>. Let <span class="math inline">\(\tau\)</span> be a fraction between 0 and 1. Then, the
<span class="math inline">\(\tau\)</span>th sample quantile of <span class="math inline">\(\{y_1, \ldots, y_n\}\)</span> is the value of
<span class="math inline">\(\beta_0\)</span> that minimizes
<span class="math display">\[
\sum_{i=1}^n \rho_{\tau}( y_i - \beta_0).
\]</span>
Here, <span class="math inline">\(\rho_{\tau}(u)=u(\tau-{\rm I}(u\leq0))\)</span> is called a
<em>check function</em> and <span class="math inline">\({\rm I}(\cdot)\)</span> is the indicator
function.</p>
<p>Extending this procedure, in quantile regression one finds the set
of regression coefficients <span class="math inline">\(\boldsymbol \beta\)</span> that minimizes
<span class="math display">\[
\sum_{i=1}^n \rho_{\tau}( y_i - \mathbf{x}_i^{\prime} \boldsymbol
\beta ).
\]</span>
The estimated regression coefficients depend on the fraction <span class="math inline">\(\tau\)</span>,
so we use the notation <span class="math inline">\(\widehat{\boldsymbol \beta}(\tau)\)</span> to
emphasize this dependence. The quantity
<span class="math inline">\(\mathbf{x}_i^{\prime}\widehat{\boldsymbol \beta}(\tau)\)</span> represents
the <span class="math inline">\(\tau^{\rm th}\)</span> quantile of the distribution of <span class="math inline">\(y_i\)</span> for the
explanatory vector <span class="math inline">\(\mathbf{x}_i\)</span>. To illustrate, for <span class="math inline">\(\tau = 0.5\)</span>,
<span class="math inline">\(\mathbf{x}_i^{\prime}\widehat{\boldsymbol \beta}(0.5)\)</span> represents
the estimated <em>median</em> of the distribution of <span class="math inline">\(y_i\)</span>. In
contrast, the <span class="math inline">\(OLS\)</span> fitted value <span class="math inline">\(\mathbf{x}_i^{\prime}\mathbf{b}\)</span>
represents the estimated <em>mean</em> of the distribution of <span class="math inline">\(y_i\)</span>.</p>
<hr />
<p><strong>Example: Wisconsin Nursing Homes - Continued</strong>. To illustrate
quantile regression techniques, we fit a regression of square
footage (SqrFoot) on total person years (TPY). Figure
<a href="#fig:Fig177"><strong>??</strong></a> shows the relationship between these two
variables, with mean (OLS) and median (LAD) fitted lines
superimposed. Unlike the original TPY distribution that is skewed,
for each value of SqrFoot we can see little difference between the
mean and median values. This suggests that the conditional
distribution of TPY given SqrFoot is not skewed.</p>
<p>Figure <a href="#fig:Fig177"><strong>??</strong></a> also shows the fitted lines that result
from fitting quantile regressions at four additional values of <span class="math inline">\(\tau =0.05,0.25, 0.75\)</span> and 0.95. These fits are indicated by the grey
lines. At each value of SqrFoot, we can visually get a sense of the
<span class="math inline">\(5^{th}\)</span>, <span class="math inline">\(25^{th}\)</span>, <span class="math inline">\(50^{th}\)</span>, <span class="math inline">\(75^{th}\)</span>, and <span class="math inline">\(95^{th}\)</span> percentiles
of the distribution of TPY. Although classic ordinary least squares
also provides this, the classic recipes generally assume
homoscedasticity. From <a href="#fig:Fig177"><strong>??</strong></a>, we see that the
distribution of <span class="math inline">\(y\)</span> seems to widen as SqrFoot increases, suggesting
a heteroscedastic relationship.</p>

<div class="figure" style="text-align: center"><span style="display:block;" id="fig:Fig147"></span>
<img src="RegressionMarkdown_files/figure-html/Fig147-1.png" alt="Quantile Regression Fits of Square Footage on Total Person Years. Superimposed are fits from mean (OLS) and median (LAD) regressions, indicated in the legend. Also superimposed with grey lines are quantile regression fits – from bottom to top, the fits correspond to \(\tau =0.05,0.25, 0.75\) and 0.95." width="60%" />
<p class="caption">
Figure 17.7: <strong>Quantile Regression Fits of Square Footage on Total Person Years.</strong> Superimposed are fits from mean (OLS) and median (LAD) regressions, indicated in the legend. Also superimposed with grey lines are quantile regression fits – from bottom to top, the fits correspond to <span class="math inline">\(\tau =0.05,0.25, 0.75\)</span> and 0.95.
</p>
</div>
<hr />
<p>Quantile regressions perform well in situations when ordinary least
squares requires careful attention to be used with confidence. As
demonstrated in the Wisconsin Nursing Home example, quantile
regression handles skewed distributions and heteroscedasticity
readily. Just as ordinary quantiles are relatively robust to unusual
observations, quantile regression estimates are much less sensitive
to outlying observations than the usual regression routines.</p>
</div>
</div>
<div id="S:Sec176" class="section level2 hasAnchor" number="17.5">
<h2><span class="header-section-number">17.5</span> Extreme Value Models<a href="fat-tailed-regression-models.html#S:Sec176" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Extreme value models focus on the extremes, the “tip of the
iceberg,” such as the highest temperature over a month, the fastest
time to run a kilometer or the lowest return from the stock market.
Some extreme value models are motivated by maximal statistics.
Suppose that we consider annual chief executive officer (CEO)
compensation in a country, <span class="math inline">\(y_1, y_2, \ldots\)</span>. Then, <span class="math inline">\(M = \max(y_1, \ldots, y_n)\)</span> represents the compensation of the most highly paid
CEO during the year. If values <span class="math inline">\(y\)</span> were observed, then we could use
some mild additional assumptions (such as independence) to make
inference about the the distribution of <span class="math inline">\(M\)</span>. However, in many cases,
only <span class="math inline">\(M\)</span> is directly observed, forcing us to base inference
procedures on “extreme” observations <span class="math inline">\(M\)</span>. As a variation, we might
have observations for the top 20 CEO’s – not the entire population.
This variation uses inference based on the “20” largest order
statistics, see for example Coles (2003, Section 3.5.2).</p>
<p>Modeling <span class="math inline">\(M\)</span> is often based on the <em>generalized extreme value</em>, or <span class="math inline">\(GEV\)</span>, distribution, defined by the distribution function
<span class="math display" id="eq:eq175">\[\begin{equation}
\Pr(M \leq x) = \exp \left[-(1+ \gamma z )^{-1/\gamma} \right],
\tag{17.5}
\end{equation}\]</span>
where <span class="math inline">\(z=(x-\mu)/ \sigma\)</span>. This is a location-scale model, with
location and scale parameters <span class="math inline">\(\mu\)</span> and <span class="math inline">\(\sigma\)</span>, respectively. In
the standard case where <span class="math inline">\(\mu=0\)</span> and <span class="math inline">\(\sigma=1\)</span>, allowing $
$ means that <span class="math inline">\(\Pr(M \leq x) \rightarrow \exp \left[- e^{-x} \right],\)</span> the classical extreme value distribution.
Thus, the parameter <span class="math inline">\(\gamma\)</span> provides the generalization of this
classical distribution.</p>
<p>Beirlant, Goegebeur, Segers and Teugels (2004) discuss ways in which
one could introduce regression covariates into the <span class="math inline">\(GEV\)</span>
distribution, essentially by allowing each parameter to depend on
covariates. Estimation is done via maximum likelihood. In their
inference procedures, the focus is on the behavior of the extreme
quantiles (conditional on the covariates).</p>
<p>Another approach to modeling extreme values is to focus on data that
must be large to be included in the sample.</p>
<hr />
<p><strong>Example: Large Medical Claims</strong>. Cebri'{a}n, Denuit and
Lambert (2003) analyzed 75,789 large group medical insurance claims
from 1991. To be included in this database, claims must exceed
$25,000. Thus, these data are left-truncated at $25,000. The
interest in their study was to interpret the long-tailed
distribution in terms of covariates age and sex.</p>
<hr />
<p>The <em>peaks over threshold</em> approach to modeling extremes values
is motivated by left-truncated data where the truncation point, or
“threshold,” is large. To be included in the data set, the
observations must exceed a large threshold that we refer to as a
“peak.” Following our Section 14.2 discussion on truncation, if
<span class="math inline">\(C_L\)</span> is the left truncation point, then the distribution function
of <span class="math inline">\(y-C_L\)</span> given that <span class="math inline">\(y&gt;C_L\)</span> is <span class="math inline">\(1 - \Pr(y-C_L &gt; x |y&gt;C_L) = 1 - (1-F_y(C_L+x))/(1-F_y(C_L))\)</span>. Instead of modeling the distribution
of <span class="math inline">\(y\)</span>, <span class="math inline">\(F_y\)</span>, directly as in prior sections, one assumes that it
can be directly approximated by a <em>generalized Pareto distribution</em>. That is, we assume
<span class="math display" id="eq:eq176">\[\begin{equation}
\Pr(y-C_L \leq x |y&gt;C_L) \approx 1 - (1+ \frac{z}{\theta}
)^{-\theta} ,
\tag{17.6}
\end{equation}\]</span>
where <span class="math inline">\(z=x / \sigma\)</span>, <span class="math inline">\(\sigma\)</span> is a scale parameter, <span class="math inline">\(x \geq 0\)</span> if
<span class="math inline">\(\theta \geq 0\)</span> and $ 0 x - $ if <span class="math inline">\(\theta &lt; 0\)</span>. Here,
the right-hand side of equation <a href="fat-tailed-regression-models.html#eq:eq176">(17.6)</a> is the generalized
Pareto distribution. The usual Pareto distribution restricts
<span class="math inline">\(\theta\)</span> to be positive; this specification allows for negative
values of <span class="math inline">\(\theta\)</span>. Allowing $ $ means that <span class="math inline">\(1 - (1+ z/\theta )^{-\theta} \rightarrow 1 - e^{-x/\sigma},\)</span> the
exponential distribution.</p>
<hr />
<p>**Example: Large Medical Claims - Continued.} To incorporate
age and sex covariates, Cebri'{a}n et al. (2003) categorized the
variables, allowed parameters to vary by category and estimated each
category in isolation of the others. Alternative, more efficient,
approaches are described in Chapter 7 of Beirlant et al. (2004).</p>
<hr />
</div>
<div id="further-reading-and-references" class="section level2 hasAnchor" number="17.6">
<h2><span class="header-section-number">17.6</span> Further Reading and References<a href="fat-tailed-regression-models.html#further-reading-and-references" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>The literature on long-tailed claims modeling is actively
developing. A standard reference is Klugman et al (2008). Kleiber
and Kotz (2003) provide an excellent survey of the univariate
literature, with many historical references. Carroll and Ruppert
(1988) provide extensive discussions of transformations in
regression modeling.</p>
<p>This chapter has emphasized the GB2 distribution with its many
special cases. Venter (2007) discusses extensions of the generalized
linear model, focusing on loss reserving applications. Balasooriya
and Low (2008) provide a recent applications to insurance claims
modeling, although without any regression covariates. Another
approach is to use a skewed elliptical (such as a normal or <span class="math inline">\(t\)</span>-)
distribution. Bali and Theodossiou (2008) provide a recent
application, showing how to use such distributions in time series
modeling of stock returns.</p>
<p>Koenker (2005) is an excellent book-long introduction to quantile
regression. Yu, Lu and Stander (2003) provide an accessible shorter
introduction.</p>
<p>Coles (2003) and Beirlant et al. (2004) are two excellent book-long
introductions to extreme value statistics.</p>
<p><strong>References</strong></p>
<ul>
<li>Balasooriya, Uditha and Chan-Kee Low (2008). Modeling insurance
claims with extreme observations: Transformed kernel density and generalized lambda distribution. <em>North American Actuarial Journal</em> 11(2) 129-142.</li>
<li>Bali, Turan G. and Panayiotis Theodossiou (2008). Risk measurement
of alternative distribution functions. <em>Journal of Risk and Insurance</em> 75(2), 411-437.</li>
<li>Beirlant, Jan, Yuir Goegebeur, Robert Verlaak and Petra Vynckier
(1998). Burr regression and portfolio segmentation. <em>Insurance: Mathematics and Economics</em> 23, 231-250.</li>
<li>Beirlant, Jan, Yuir Goegebeur, Johan Segers and Jozef Teugels (2004). <em>Statistics of Extremes</em>. Wiley, New York.</li>
<li>Burbidge, J.B. and Magee, L. and Robb, A.L. (1988). Alternative transformations to handle extreme values of the dependent variable. <em>Journal of the American Statistical Association</em> 83, 123-127.</li>
<li>Carroll, Raymond and David Ruppert (1988). <em>Transformation and Weighting in Regression</em>. Chapman-Hall.</li>
<li>Cebri'{a}n, Ana C., Michel Denuit and Philippe Lambert (2003).
Generalized Pareto fit to the Society of Actuaries’ large claims database. <em>North American Actuarial Journal</em> 7 (3), 18-36.</li>
<li>Coles, Stuart (2003). <em>An Introduction to Statistical Modeling of Extreme Values</em>. Springer, New York.</li>
<li>Cummins, J. David, Georges Dionne, James B. McDonald and B. Michael Pritchett (1990). Applications of the GB2 family of distributions in modeling insurance loss processes. <em>Insurance: Mathematics and Economics</em> 9, 257-272.</li>
<li>John, J. A. and Norman R. Draper (1980). An alternative family of
transformations. <em>Applied Statistics</em> 29 (2), 190-197.</li>
<li>Kleiber, Christian and Samuel Kotz (2003). <em>Statistical Size
Distributions in Economics and Actuarial Sciences</em>. John Wiley and
Sons, New York.</li>
<li>Klugman, Stuart A, Harry H. Panjer and Gordon E. Willmot (2008). <em>Loss Models: From Data to Decisions</em>. John Wiley &amp; Sons, Hoboken, New Jersey.</li>
<li>Koenker, Roger (2005). <em>Quantile Regression</em>. Cambridge University Press, New York.</li>
<li>Manning, William G (1998). The logged dependent variable, heteroscedasticity, and the retransformation problem. <em>Journal of Health Economics</em> 17, 283-295.</li>
<li>Manning, William G, Anirban Basu and John Mullahy (2005).
Generalized modeling approaches to risk adjustment of skewed outcomes data. <em>Journal of Health Economics</em> 24, 465-488.</li>
<li>McDonald, James B. and Richard J. Butler (1990). Regression models for positive random variables. <em>Journal of Econometrics</em> 43, 227-251.</li>
<li>Rachev, Svetiozar, T., Christian Menn and Frank Fabozzi (2005). <em>Fat-Tailed and Skewed Asset Return Distributions: Implications for Risk Management, Portfolio Selection, and Option Pricing</em>. Wiley, New York.</li>
<li>Rosenberg, Marjorie A., Edward W. Frees, Jiafeng Sun, Paul Johnson and James M. Robinson (2007). Predictive modeling with longitudinal data: A case study of Wisconsin nursing homes. <em>North American Actuarial Journal</em> 11(3), 54-69.</li>
<li>Sun, Jiafeng, Edward W. Frees and Marjorie A. Rosenberg (2008). Heavy-tailed longitudinal data modeling using copulas. <em>Insurance: Mathematics and Economics</em> 42(2), 817-830.</li>
<li>Venter, Gary (2007). Generalized linear models beyond the exponential family with loss reserve applications. <em>Astin Bulletin: Journal of the International Actuarial Association</em> 37 (2), 345-364.</li>
<li>Yeo, In-Kwon and Richard A. Johnson (2000). A new family of power transformations to improve normality or symmetry. <em>Biometrika</em> 87, 954-959.</li>
<li>Yu, Keming, Zudi Lu and Julian Stander (2003). Quantile regression: applications and current research areas. <em>Journal of the Royal Statistical Society Series D (The Statistician)</em> 52 (3), 331-350.</li>
</ul>
</div>
<div id="exercises" class="section level2 hasAnchor" number="17.7">
<h2><span class="header-section-number">17.7</span> Exercises<a href="fat-tailed-regression-models.html#exercises" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>17.1. Quantiles and Simulation. Use equation <a href="fat-tailed-regression-models.html#eq:eq172">(17.2)</a> to establish the
following distributional relationships that are helpful for
calculating quantiles.</p>
<ol style="list-style-type: lower-alpha">
<li><p>Assume that <span class="math inline">\(y_0 = \alpha_1 F/\alpha_2\)</span> where <span class="math inline">\(F\)</span> has an
<span class="math inline">\(F\)</span>-distribution with numerator and denominator degrees of freedom
<span class="math inline">\(df_1 = 2 \alpha_1\)</span> and <span class="math inline">\(df_2 = 2 \alpha_2\)</span>. Show that <span class="math inline">\(y\)</span> has a GB2
distribution.</p></li>
<li><p>Assume that <span class="math inline">\(y_0 = B/(1-B),\)</span> where <span class="math inline">\(B\)</span> has a beta distribution
with parameters <span class="math inline">\(\alpha_1\)</span> and <span class="math inline">\(\alpha_2\)</span>. Show that <span class="math inline">\(y\)</span> has a GB2
distribution.</p></li>
<li><p>Describe how to use parts (a) and (b) for calculating quantiles.</p></li>
<li><p>Describe how to use parts (a) and (b) for simulation.</p></li>
</ol>
<p>17.2 Consider a GB2 probability density function given in equation
<a href="fat-tailed-regression-models.html#eq:eq173">(17.3)</a>.</p>
<ol style="list-style-type: lower-alpha">
<li><p>Reparameterize the distribution by defining the new parameter
<span class="math inline">\(\theta =e^{\mu }.\)</span> Show that the density can be expressed as:
<span class="math display">\[
\mathrm{f}_{GB2}(y;\theta, \sigma ,\alpha _1,\alpha _2)=\frac{\Gamma
\left( \alpha _1+\alpha _2\right) }{\Gamma \left( \alpha _1\right)
\Gamma \left( \alpha _2\right) }\frac{\left( y/\theta \right)
^{\alpha _2/\sigma }}{\sigma y\left[ 1+\left( y/\theta \right)
^{1/\sigma }\right] ^{\alpha _1+\alpha _2}},
\]</span></p></li>
<li><p>Using part (a), show that
<span class="math display">\[
\lim_{\alpha _2\rightarrow \infty }\mathrm{f}_{GB2}(y; \theta \alpha
_2^{\sigma },\sigma ,\alpha _1,\alpha _2)=\frac{1}{\sigma y\Gamma
\left( \alpha _1\right) }\left( y/\theta \right) ^{\alpha _1/\sigma
}\exp \left( -\left( y/\theta \right) ^{1/\sigma }\right)
=\mathrm{f}_{GG}(y;\theta, \sigma, \alpha _1),
\]</span>
a generalized gamma density.</p></li>
<li><p>Using part (a), show that
<span class="math display">\[
\mathrm{f}_{GB2}(y;\theta, \sigma, 1, \alpha_2)=\frac{\alpha
_2\left( y/\theta \right) ^{\alpha _2/\sigma }}{\sigma y\left[
1+\left( y/\theta \right) ^{1/\sigma }\right] ^{1+\alpha
_2}}=\mathrm{f}_{Burr}(y;\theta, \sigma, \alpha _2),
\]</span>
a Burr Type 12 density.</p></li>
</ol>
<p>17.3 Recall that the density of a gamma distribution with shape
parameter $$ and scale parameter $$ has a density
given by <span class="math inline">\(\mathrm{f}(y)=\left[ \theta ^{\alpha }\Gamma \left( \alpha \right) \right] ^{-1}y^{\alpha -1}\exp \left( -y/\theta \right)\)</span> and k<span class="math inline">\(^{th}\)</span> moment given by <span class="math inline">\(\mathrm{E} (y^{k})=\theta ^{k}\Gamma \left( \alpha +k\right) /\Gamma \left( \alpha \right)\)</span>, for <span class="math inline">\(k&gt;-\alpha .\)</span></p>
<ol style="list-style-type: lower-alpha">
<li><p>For the GB2 distribution, show that
<span class="math display">\[
\mathrm{E}(y)=e^{\mu }\frac{\Gamma \left( \alpha _1+\sigma \right)
\Gamma \left( \alpha _2-\sigma \right) }{\Gamma \left( \alpha
_1\right) \Gamma \left( \alpha _2\right) }.
\]</span></p></li>
<li><p>For the generalized gamma distribution, show that
<span class="math display">\[
\mathrm{E}(y)=e^{\mu }\Gamma \left( \alpha_1 +\sigma \right) /\Gamma
\left( \alpha_1 \right) .
\]</span></p></li>
<li><p>Calculate the moments of a Burr Type 12 density.</p></li>
</ol>

</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="chap-16.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="appendices.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": null,
"search": {
"engine": "fuse",
"options": null
},
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/latest.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
