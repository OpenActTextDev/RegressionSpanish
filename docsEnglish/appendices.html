<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapter 22 Appendices | Regression Modeling with Actuarial and Financial Applications</title>
  <meta name="description" content="HTML version of ‘Regression Modeling with Actuarial and Financial Applications’" />
  <meta name="generator" content="bookdown 0.39 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapter 22 Appendices | Regression Modeling with Actuarial and Financial Applications" />
  <meta property="og:type" content="book" />
  
  <meta property="og:description" content="HTML version of ‘Regression Modeling with Actuarial and Financial Applications’" />
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 22 Appendices | Regression Modeling with Actuarial and Financial Applications" />
  
  <meta name="twitter:description" content="HTML version of ‘Regression Modeling with Actuarial and Financial Applications’" />
  

<meta name="author" content="Edward (Jed) Frees, University of Wisconsin - Madison, Australian National University" />



  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="C21Design.html"/>
<link rel="next" href="brief-answers-to-selected-exercises.html"/>
<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/anchor-sections-1.1.0/anchor-sections.css" rel="stylesheet" />
<link href="libs/anchor-sections-1.1.0/anchor-sections-hash.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.1.0/anchor-sections.js"></script>
<script src="libs/kePrint-0.0.1/kePrint.js"></script>
<link href="libs/lightable-0.0.1/lightable.css" rel="stylesheet" />
<link href="libs/bsTable-3.3.7/bootstrapTable.min.css" rel="stylesheet" />
<script src="libs/bsTable-3.3.7/bootstrapTable.js"></script>

<!-- Mathjax Version 2-->
<script type='text/x-mathjax-config'>
		MathJax.Hub.Config({
			extensions: ['tex2jax.js'],
			jax: ['input/TeX', 'output/HTML-CSS'],
			tex2jax: {
				inlineMath: [ ['$','$'], ['\\(','\\)'] ],
				displayMath: [ ['$$','$$'], ['\\[','\\]'] ],
				processEscapes: true
			},
			'HTML-CSS': { availableFonts: ['TeX'] }
		});
</script>

<script type="text/javascript"  src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/MathJax.js?config=TeX-AMS_HTML"> </script>

<script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
<script type="text/javascript" src="https://unpkg.com/survey-jquery/survey.jquery.min.js"></script>
<link href="https://unpkg.com/survey-jquery/modern.min.css" type="text/css" rel="stylesheet">
<script src="https://unpkg.com/showdown/dist/showdown.min.js"></script>


<!-- Various toggle functions used throughout --> 
<script language="javascript">
function toggle(id1,id2) {
	var ele = document.getElementById(id1); var text = document.getElementById(id2);
	if (ele.style.display == "block") {ele.style.display = "none"; text.innerHTML = "Show Solution";}
		else {ele.style.display = "block"; text.innerHTML = "Hide Solution";}}
function togglecode(id1,id2) {
   var ele = document.getElementById(id1); var text = document.getElementById(id2);
   if (ele.style.display == "block") {ele.style.display = "none"; text.innerHTML = "Show R Code";}
      else {ele.style.display = "block"; text.innerHTML = "Hide R Code";}}
function toggleEX(id1,id2) {
   var ele = document.getElementById(id1); var text = document.getElementById(id2);
   if (ele.style.display == "block") {ele.style.display = "none"; text.innerHTML = "Show Example";}
      else {ele.style.display = "block"; text.innerHTML = "Hide Example";}}
function toggleTheory(id1,id2) {
   var ele = document.getElementById(id1); var text = document.getElementById(id2);
   if (ele.style.display == "block") {ele.style.display = "none"; text.innerHTML = "Show Theory";}
      else {ele.style.display = "block"; text.innerHTML = "Hide Theory";}}
function toggleSolution(id1,id2) {
   var ele = document.getElementById(id1); var text = document.getElementById(id2);
   if (ele.style.display == "block") {ele.style.display = "none"; text.innerHTML = "Show Solution";}
      else {ele.style.display = "block"; text.innerHTML = "Hide Solution";}}      
function toggleQuiz(id1,id2) {
   var ele = document.getElementById(id1); var text = document.getElementById(id2);
   if (ele.style.display == "block") {ele.style.display = "none"; text.innerHTML = "Show Quiz Solution";}
      else {ele.style.display = "block"; text.innerHTML = "Hide Quiz Solution";}}      
</script>

<!-- A few functions for revealing definitions -->
<script language="javascript">
<!--   $( function() {
    $("#tabs").tabs();
  } ); -->

$(document).ready(function(){
    $('[data-toggle="tooltip"]').tooltip();
});

$(document).ready(function(){
    $('[data-toggle="popover"]').popover(); 
});
</script>

<script language="javascript">
function openTab(evt, tabName) {
    var i, tabcontent, tablinks;
    tabcontent = document.getElementsByClassName("tabcontent");
    for (i = 0; i < tabcontent.length; i++) {
        tabcontent[i].style.display = "none";
    }
    tablinks = document.getElementsByClassName("tablinks");
    for (i = 0; i < tablinks.length; i++) {
        tablinks[i].className = tablinks[i].className.replace(" active", "");
    }
    document.getElementById(tabName).style.display = "block";
    evt.currentTarget.className += " active";
}

// Get the element with id="defaultOpen" and click on it
document.getElementById("defaultOpen").click();
</script>



<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { color: #008000; } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { color: #008000; font-weight: bold; } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<style type="text/css">
  
  div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Regression Modeling With Actuarial and Financial Applications</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="preface.html"><a href="preface.html"><i class="fa fa-check"></i>Preface</a>
<ul>
<li class="chapter" data-level="" data-path="preface.html"><a href="preface.html#dedication"><i class="fa fa-check"></i>Dedication</a></li>
<li class="chapter" data-level="" data-path="preface.html"><a href="preface.html#forward"><i class="fa fa-check"></i>Forward</a>
<ul>
<li class="chapter" data-level="" data-path="preface.html"><a href="preface.html#who-is-this-book-for"><i class="fa fa-check"></i>Who Is This Book For?</a></li>
<li class="chapter" data-level="" data-path="preface.html"><a href="preface.html#what-is-this-book-about"><i class="fa fa-check"></i>What Is This Book About?</a></li>
<li class="chapter" data-level="" data-path="preface.html"><a href="preface.html#how-does-this-book-deliver-its-message"><i class="fa fa-check"></i>How Does This Book Deliver Its Message?</a></li>
<li class="chapter" data-level="" data-path="preface.html"><a href="preface.html#acknowledgements"><i class="fa fa-check"></i>Acknowledgements</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="1" data-path="regression-and-the-normal-distribution.html"><a href="regression-and-the-normal-distribution.html"><i class="fa fa-check"></i><b>1</b> Regression and the Normal Distribution</a>
<ul>
<li class="chapter" data-level="1.1" data-path="regression-and-the-normal-distribution.html"><a href="regression-and-the-normal-distribution.html#Sec11"><i class="fa fa-check"></i><b>1.1</b> What is Regression Analysis?</a></li>
<li class="chapter" data-level="1.2" data-path="regression-and-the-normal-distribution.html"><a href="regression-and-the-normal-distribution.html#Sec12"><i class="fa fa-check"></i><b>1.2</b> Fitting Data to a Normal Distribution</a></li>
<li class="chapter" data-level="1.3" data-path="regression-and-the-normal-distribution.html"><a href="regression-and-the-normal-distribution.html#Sec13"><i class="fa fa-check"></i><b>1.3</b> Power Transforms</a></li>
<li class="chapter" data-level="1.4" data-path="regression-and-the-normal-distribution.html"><a href="regression-and-the-normal-distribution.html#Sec14"><i class="fa fa-check"></i><b>1.4</b> Sampling and the Role of Normality</a></li>
<li class="chapter" data-level="1.5" data-path="regression-and-the-normal-distribution.html"><a href="regression-and-the-normal-distribution.html#Sec15"><i class="fa fa-check"></i><b>1.5</b> Regression and Sampling Designs</a></li>
<li class="chapter" data-level="1.6" data-path="regression-and-the-normal-distribution.html"><a href="regression-and-the-normal-distribution.html#Sec16"><i class="fa fa-check"></i><b>1.6</b> Actuarial Applications of Regression</a></li>
<li class="chapter" data-level="1.7" data-path="regression-and-the-normal-distribution.html"><a href="regression-and-the-normal-distribution.html#Sec17"><i class="fa fa-check"></i><b>1.7</b> Further Reading and References</a></li>
<li class="chapter" data-level="1.8" data-path="regression-and-the-normal-distribution.html"><a href="regression-and-the-normal-distribution.html#Sec18"><i class="fa fa-check"></i><b>1.8</b> Exercises</a></li>
<li class="chapter" data-level="1.9" data-path="regression-and-the-normal-distribution.html"><a href="regression-and-the-normal-distribution.html#Sec19"><i class="fa fa-check"></i><b>1.9</b> Technical Supplement - Central Limit Theorem</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="C2BasicLR.html"><a href="C2BasicLR.html"><i class="fa fa-check"></i><b>2</b> Basic Linear Regression</a>
<ul>
<li class="chapter" data-level="2.1" data-path="C2BasicLR.html"><a href="C2BasicLR.html#Sec21"><i class="fa fa-check"></i><b>2.1</b> Correlations and Least Squares</a></li>
<li class="chapter" data-level="2.2" data-path="C2BasicLR.html"><a href="C2BasicLR.html#Sec22"><i class="fa fa-check"></i><b>2.2</b> Basic Linear Regression Model</a></li>
<li class="chapter" data-level="2.3" data-path="C2BasicLR.html"><a href="C2BasicLR.html#Sec23"><i class="fa fa-check"></i><b>2.3</b> Is the Model Useful? Some Basic Summary Measures</a>
<ul>
<li class="chapter" data-level="2.3.1" data-path="C2BasicLR.html"><a href="C2BasicLR.html#Sec231"><i class="fa fa-check"></i><b>2.3.1</b> Partitioning the Variability</a></li>
<li class="chapter" data-level="2.3.2" data-path="C2BasicLR.html"><a href="C2BasicLR.html#Sec232"><i class="fa fa-check"></i><b>2.3.2</b> The Size of a Typical Deviation: <em>s</em></a></li>
</ul></li>
<li class="chapter" data-level="2.4" data-path="C2BasicLR.html"><a href="C2BasicLR.html#Sec24"><i class="fa fa-check"></i><b>2.4</b> Properties of Regression Coefficient Estimators</a></li>
<li class="chapter" data-level="2.5" data-path="C2BasicLR.html"><a href="C2BasicLR.html#Sec25"><i class="fa fa-check"></i><b>2.5</b> Statistical Inference</a>
<ul>
<li class="chapter" data-level="2.5.1" data-path="C2BasicLR.html"><a href="C2BasicLR.html#Sec251"><i class="fa fa-check"></i><b>2.5.1</b> Is the Explanatory Variable Important?: The <em>t</em>-Test</a></li>
<li class="chapter" data-level="2.5.2" data-path="C2BasicLR.html"><a href="C2BasicLR.html#Sec252"><i class="fa fa-check"></i><b>2.5.2</b> Confidence Intervals</a></li>
<li class="chapter" data-level="2.5.3" data-path="C2BasicLR.html"><a href="C2BasicLR.html#Sec253"><i class="fa fa-check"></i><b>2.5.3</b> Prediction Intervals</a></li>
</ul></li>
<li class="chapter" data-level="2.6" data-path="C2BasicLR.html"><a href="C2BasicLR.html#Sec26"><i class="fa fa-check"></i><b>2.6</b> Building a Better Model: Residual Analysis</a></li>
<li class="chapter" data-level="2.7" data-path="C2BasicLR.html"><a href="C2BasicLR.html#Sec27"><i class="fa fa-check"></i><b>2.7</b> Application: Capital Asset Pricing Model</a></li>
<li class="chapter" data-level="2.8" data-path="C2BasicLR.html"><a href="C2BasicLR.html#Sec28"><i class="fa fa-check"></i><b>2.8</b> Illustrative Regression Computer Output</a></li>
<li class="chapter" data-level="2.9" data-path="C2BasicLR.html"><a href="C2BasicLR.html#Sec29"><i class="fa fa-check"></i><b>2.9</b> Further Reading and References</a></li>
<li class="chapter" data-level="2.10" data-path="C2BasicLR.html"><a href="C2BasicLR.html#Sec210"><i class="fa fa-check"></i><b>2.10</b> Exercises</a></li>
<li class="chapter" data-level="2.11" data-path="C2BasicLR.html"><a href="C2BasicLR.html#Sec211"><i class="fa fa-check"></i><b>2.11</b> Technical Supplement - Elements of Matrix Algebra</a>
<ul>
<li class="chapter" data-level="2.11.1" data-path="C2BasicLR.html"><a href="C2BasicLR.html#Sec2111"><i class="fa fa-check"></i><b>2.11.1</b> Basic Definitions</a></li>
<li class="chapter" data-level="2.11.2" data-path="C2BasicLR.html"><a href="C2BasicLR.html#Sec2112"><i class="fa fa-check"></i><b>2.11.2</b> Some Special Matrices</a></li>
<li class="chapter" data-level="2.11.3" data-path="C2BasicLR.html"><a href="C2BasicLR.html#Sec2113"><i class="fa fa-check"></i><b>2.11.3</b> Basic Operations</a></li>
<li class="chapter" data-level="2.11.4" data-path="C2BasicLR.html"><a href="C2BasicLR.html#Sec2114"><i class="fa fa-check"></i><b>2.11.4</b> Random Matrices</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="3" data-path="C3BasicMLR.html"><a href="C3BasicMLR.html"><i class="fa fa-check"></i><b>3</b> Multiple Linear Regression - I</a>
<ul>
<li class="chapter" data-level="3.1" data-path="C3BasicMLR.html"><a href="C3BasicMLR.html#Sec31"><i class="fa fa-check"></i><b>3.1</b> Method of Least Squares</a>
<ul>
<li class="chapter" data-level="3.1.1" data-path="C3BasicMLR.html"><a href="C3BasicMLR.html#Sec311"><i class="fa fa-check"></i><b>3.1.1</b> Least Squares Method</a></li>
<li class="chapter" data-level="3.1.2" data-path="C3BasicMLR.html"><a href="C3BasicMLR.html#Sec312"><i class="fa fa-check"></i><b>3.1.2</b> General Case with <em>k</em> Explanatory Variables</a></li>
</ul></li>
<li class="chapter" data-level="3.2" data-path="C3BasicMLR.html"><a href="C3BasicMLR.html#Sec32"><i class="fa fa-check"></i><b>3.2</b> Linear Regression Model and Properties of Estimators</a>
<ul>
<li class="chapter" data-level="3.2.1" data-path="C3BasicMLR.html"><a href="C3BasicMLR.html#Sec321"><i class="fa fa-check"></i><b>3.2.1</b> Regression Function</a></li>
<li class="chapter" data-level="3.2.2" data-path="C3BasicMLR.html"><a href="C3BasicMLR.html#Sec322"><i class="fa fa-check"></i><b>3.2.2</b> Regression Coefficient Interpretation</a></li>
<li class="chapter" data-level="3.2.3" data-path="C3BasicMLR.html"><a href="C3BasicMLR.html#Sec323"><i class="fa fa-check"></i><b>3.2.3</b> Model Assumptions</a></li>
<li class="chapter" data-level="3.2.4" data-path="C3BasicMLR.html"><a href="C3BasicMLR.html#Sec324"><i class="fa fa-check"></i><b>3.2.4</b> Properties of Regression Coefficient Estimators</a></li>
</ul></li>
<li class="chapter" data-level="3.3" data-path="C3BasicMLR.html"><a href="C3BasicMLR.html#Sec33"><i class="fa fa-check"></i><b>3.3</b> Estimation and Goodness of Fit</a></li>
<li class="chapter" data-level="3.4" data-path="C3BasicMLR.html"><a href="C3BasicMLR.html#Sec34"><i class="fa fa-check"></i><b>3.4</b> Statistical Inference for a Single Coefficient</a>
<ul>
<li class="chapter" data-level="3.4.1" data-path="C3BasicMLR.html"><a href="C3BasicMLR.html#Sec341"><i class="fa fa-check"></i><b>3.4.1</b> The <em>t</em>-Test</a></li>
<li class="chapter" data-level="3.4.2" data-path="C3BasicMLR.html"><a href="C3BasicMLR.html#Sec342"><i class="fa fa-check"></i><b>3.4.2</b> Confidence Intervals</a></li>
<li class="chapter" data-level="3.4.3" data-path="C3BasicMLR.html"><a href="C3BasicMLR.html#Sec343"><i class="fa fa-check"></i><b>3.4.3</b> Added Variable Plots</a></li>
<li class="chapter" data-level="3.4.4" data-path="C3BasicMLR.html"><a href="C3BasicMLR.html#Sec344"><i class="fa fa-check"></i><b>3.4.4</b> Partial Correlation Coefficients</a></li>
</ul></li>
<li class="chapter" data-level="3.5" data-path="C3BasicMLR.html"><a href="C3BasicMLR.html#Sec35"><i class="fa fa-check"></i><b>3.5</b> Some Special Explanatory Variables</a>
<ul>
<li class="chapter" data-level="3.5.1" data-path="C3BasicMLR.html"><a href="C3BasicMLR.html#Sec351"><i class="fa fa-check"></i><b>3.5.1</b> Binary Variables</a></li>
<li class="chapter" data-level="3.5.2" data-path="C3BasicMLR.html"><a href="C3BasicMLR.html#Sec352"><i class="fa fa-check"></i><b>3.5.2</b> Transforming Explanatory Variables</a></li>
<li class="chapter" data-level="3.5.3" data-path="C3BasicMLR.html"><a href="C3BasicMLR.html#Sec353"><i class="fa fa-check"></i><b>3.5.3</b> Interaction Terms</a></li>
</ul></li>
<li class="chapter" data-level="3.6" data-path="C3BasicMLR.html"><a href="C3BasicMLR.html#Sec36"><i class="fa fa-check"></i><b>3.6</b> Further Reading and References</a></li>
<li class="chapter" data-level="3.7" data-path="C3BasicMLR.html"><a href="C3BasicMLR.html#Sec37"><i class="fa fa-check"></i><b>3.7</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="C4MLRANOVA.html"><a href="C4MLRANOVA.html"><i class="fa fa-check"></i><b>4</b> Multiple Linear Regression - II</a>
<ul>
<li class="chapter" data-level="4.1" data-path="C4MLRANOVA.html"><a href="C4MLRANOVA.html#Sec41"><i class="fa fa-check"></i><b>4.1</b> The Role of Binary Variables</a></li>
<li class="chapter" data-level="4.2" data-path="C4MLRANOVA.html"><a href="C4MLRANOVA.html#Sec42"><i class="fa fa-check"></i><b>4.2</b> Statistical Inference for Several Coefficients</a>
<ul>
<li class="chapter" data-level="4.2.1" data-path="C4MLRANOVA.html"><a href="C4MLRANOVA.html#Sec421"><i class="fa fa-check"></i><b>4.2.1</b> Sets of Regression Coefficients</a></li>
<li class="chapter" data-level="4.2.2" data-path="C4MLRANOVA.html"><a href="C4MLRANOVA.html#Sec422"><i class="fa fa-check"></i><b>4.2.2</b> The General Linear Hypothesis</a></li>
<li class="chapter" data-level="4.2.3" data-path="C4MLRANOVA.html"><a href="C4MLRANOVA.html#Sec423"><i class="fa fa-check"></i><b>4.2.3</b> Estimating and Predicting Several Coefficients</a></li>
</ul></li>
<li class="chapter" data-level="4.3" data-path="C4MLRANOVA.html"><a href="C4MLRANOVA.html#Sec43"><i class="fa fa-check"></i><b>4.3</b> One Factor ANOVA Model</a></li>
<li class="chapter" data-level="4.4" data-path="C4MLRANOVA.html"><a href="C4MLRANOVA.html#Sec44"><i class="fa fa-check"></i><b>4.4</b> Combining Categorical and Continuous Explanatory Variables</a></li>
<li class="chapter" data-level="4.5" data-path="C4MLRANOVA.html"><a href="C4MLRANOVA.html#Sec45"><i class="fa fa-check"></i><b>4.5</b> Further Reading and References</a></li>
<li class="chapter" data-level="4.6" data-path="C4MLRANOVA.html"><a href="C4MLRANOVA.html#Sec46"><i class="fa fa-check"></i><b>4.6</b> Exercises</a></li>
<li class="chapter" data-level="4.7" data-path="C4MLRANOVA.html"><a href="C4MLRANOVA.html#Sec47"><i class="fa fa-check"></i><b>4.7</b> Technical Supplement - Matrix Expressions</a>
<ul>
<li class="chapter" data-level="4.7.1" data-path="C4MLRANOVA.html"><a href="C4MLRANOVA.html#Sec471"><i class="fa fa-check"></i><b>4.7.1</b> Expressing Models with Categorical Variables in Matrix Form</a></li>
<li class="chapter" data-level="4.7.2" data-path="C4MLRANOVA.html"><a href="C4MLRANOVA.html#Sec472"><i class="fa fa-check"></i><b>4.7.2</b> Calculating Least Squares Recursively</a></li>
<li class="chapter" data-level="4.7.3" data-path="C4MLRANOVA.html"><a href="C4MLRANOVA.html#Sec473"><i class="fa fa-check"></i><b>4.7.3</b> General Linear Model</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="5" data-path="C5VarSelect.html"><a href="C5VarSelect.html"><i class="fa fa-check"></i><b>5</b> Variable Selection</a>
<ul>
<li class="chapter" data-level="5.1" data-path="C5VarSelect.html"><a href="C5VarSelect.html#Sec51"><i class="fa fa-check"></i><b>5.1</b> An Iterative Approach to Data Analysis and Modeling</a></li>
<li class="chapter" data-level="5.2" data-path="C5VarSelect.html"><a href="C5VarSelect.html#Sec52"><i class="fa fa-check"></i><b>5.2</b> Automatic Variable Selection Procedures</a></li>
<li class="chapter" data-level="5.3" data-path="C5VarSelect.html"><a href="C5VarSelect.html#Sec53"><i class="fa fa-check"></i><b>5.3</b> Residual Analysis</a>
<ul>
<li class="chapter" data-level="5.3.1" data-path="C5VarSelect.html"><a href="C5VarSelect.html#Sec531"><i class="fa fa-check"></i><b>5.3.1</b> Residuals</a></li>
<li class="chapter" data-level="5.3.2" data-path="C5VarSelect.html"><a href="C5VarSelect.html#Sec532"><i class="fa fa-check"></i><b>5.3.2</b> Using Residuals to Identify Outliers</a></li>
<li class="chapter" data-level="5.3.3" data-path="C5VarSelect.html"><a href="C5VarSelect.html#Sec533"><i class="fa fa-check"></i><b>5.3.3</b> Using Residuals to Select Explanatory Variables</a></li>
</ul></li>
<li class="chapter" data-level="5.4" data-path="C5VarSelect.html"><a href="C5VarSelect.html#Sec54"><i class="fa fa-check"></i><b>5.4</b> Influential Points</a>
<ul>
<li class="chapter" data-level="5.4.1" data-path="C5VarSelect.html"><a href="C5VarSelect.html#Sec541"><i class="fa fa-check"></i><b>5.4.1</b> Leverage</a></li>
<li class="chapter" data-level="5.4.2" data-path="C5VarSelect.html"><a href="C5VarSelect.html#Sec542"><i class="fa fa-check"></i><b>5.4.2</b> Cook’s Distance</a></li>
</ul></li>
<li class="chapter" data-level="5.5" data-path="C5VarSelect.html"><a href="C5VarSelect.html#Sec55"><i class="fa fa-check"></i><b>5.5</b> Collinearity</a>
<ul>
<li class="chapter" data-level="5.5.1" data-path="C5VarSelect.html"><a href="C5VarSelect.html#Sec551"><i class="fa fa-check"></i><b>5.5.1</b> What is Collinearity?</a></li>
<li class="chapter" data-level="5.5.2" data-path="C5VarSelect.html"><a href="C5VarSelect.html#Sec552"><i class="fa fa-check"></i><b>5.5.2</b> Variance Inflation Factors</a></li>
<li class="chapter" data-level="5.5.3" data-path="C5VarSelect.html"><a href="C5VarSelect.html#Sec553"><i class="fa fa-check"></i><b>5.5.3</b> Collinearity and Leverage</a></li>
<li class="chapter" data-level="5.5.4" data-path="C5VarSelect.html"><a href="C5VarSelect.html#Sec554"><i class="fa fa-check"></i><b>5.5.4</b> Suppressor Variables</a></li>
<li class="chapter" data-level="5.5.5" data-path="C5VarSelect.html"><a href="C5VarSelect.html#Sec555"><i class="fa fa-check"></i><b>5.5.5</b> Orthogonal Variables</a></li>
</ul></li>
<li class="chapter" data-level="5.6" data-path="C5VarSelect.html"><a href="C5VarSelect.html#Sec56"><i class="fa fa-check"></i><b>5.6</b> Selection Criteria</a>
<ul>
<li class="chapter" data-level="5.6.1" data-path="C5VarSelect.html"><a href="C5VarSelect.html#Sec561"><i class="fa fa-check"></i><b>5.6.1</b> Goodness of Fit</a></li>
<li class="chapter" data-level="5.6.2" data-path="C5VarSelect.html"><a href="C5VarSelect.html#Sec562"><i class="fa fa-check"></i><b>5.6.2</b> Model Validation</a></li>
<li class="chapter" data-level="5.6.3" data-path="C5VarSelect.html"><a href="C5VarSelect.html#Sec563"><i class="fa fa-check"></i><b>5.6.3</b> Cross-Validation</a></li>
</ul></li>
<li class="chapter" data-level="5.7" data-path="C5VarSelect.html"><a href="C5VarSelect.html#Sec57"><i class="fa fa-check"></i><b>5.7</b> Heteroscedasticity</a>
<ul>
<li class="chapter" data-level="5.7.1" data-path="C5VarSelect.html"><a href="C5VarSelect.html#Sec571"><i class="fa fa-check"></i><b>5.7.1</b> Detecting Heteroscedasticity</a></li>
<li class="chapter" data-level="5.7.2" data-path="C5VarSelect.html"><a href="C5VarSelect.html#Sec572"><i class="fa fa-check"></i><b>5.7.2</b> Heteroscedasticity-Consistent Standard Errors</a></li>
<li class="chapter" data-level="5.7.3" data-path="C5VarSelect.html"><a href="C5VarSelect.html#Sec573"><i class="fa fa-check"></i><b>5.7.3</b> Weighted Least Squares</a></li>
<li class="chapter" data-level="5.7.4" data-path="C5VarSelect.html"><a href="C5VarSelect.html#Sec574"><i class="fa fa-check"></i><b>5.7.4</b> Transformations</a></li>
</ul></li>
<li class="chapter" data-level="5.8" data-path="C5VarSelect.html"><a href="C5VarSelect.html#Sec58"><i class="fa fa-check"></i><b>5.8</b> Further Reading and References</a></li>
<li class="chapter" data-level="5.9" data-path="C5VarSelect.html"><a href="C5VarSelect.html#Sec59"><i class="fa fa-check"></i><b>5.9</b> Exercises</a></li>
<li class="chapter" data-level="5.10" data-path="C5VarSelect.html"><a href="C5VarSelect.html#Sec510"><i class="fa fa-check"></i><b>5.10</b> Technical Supplements for Chapter 5</a>
<ul>
<li class="chapter" data-level="5.10.1" data-path="C5VarSelect.html"><a href="C5VarSelect.html#Sec5101"><i class="fa fa-check"></i><b>5.10.1</b> Projection Matrix</a></li>
<li class="chapter" data-level="5.10.2" data-path="C5VarSelect.html"><a href="C5VarSelect.html#Sec5102"><i class="fa fa-check"></i><b>5.10.2</b> Leave One Out Statistics</a></li>
<li class="chapter" data-level="5.10.3" data-path="C5VarSelect.html"><a href="C5VarSelect.html#Sec5103"><i class="fa fa-check"></i><b>5.10.3</b> Omitting Variables</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="6" data-path="interpreting-regression-results.html"><a href="interpreting-regression-results.html"><i class="fa fa-check"></i><b>6</b> Interpreting Regression Results</a>
<ul>
<li class="chapter" data-level="6.1" data-path="interpreting-regression-results.html"><a href="interpreting-regression-results.html#Sec61"><i class="fa fa-check"></i><b>6.1</b> What the Modeling Process Tells Us</a>
<ul>
<li class="chapter" data-level="6.1.1" data-path="interpreting-regression-results.html"><a href="interpreting-regression-results.html#Sec611"><i class="fa fa-check"></i><b>6.1.1</b> Interpreting Individual Effects</a></li>
<li class="chapter" data-level="6.1.2" data-path="interpreting-regression-results.html"><a href="interpreting-regression-results.html#Sec612"><i class="fa fa-check"></i><b>6.1.2</b> Other Interpretations</a></li>
</ul></li>
<li class="chapter" data-level="6.2" data-path="interpreting-regression-results.html"><a href="interpreting-regression-results.html#Sec62"><i class="fa fa-check"></i><b>6.2</b> The Importance of Variable Selection</a>
<ul>
<li class="chapter" data-level="6.2.1" data-path="interpreting-regression-results.html"><a href="interpreting-regression-results.html#Sec621"><i class="fa fa-check"></i><b>6.2.1</b> Overfitting the Model</a></li>
<li class="chapter" data-level="6.2.2" data-path="interpreting-regression-results.html"><a href="interpreting-regression-results.html#Sec622"><i class="fa fa-check"></i><b>6.2.2</b> Underfitting the Model</a></li>
</ul></li>
<li class="chapter" data-level="6.3" data-path="interpreting-regression-results.html"><a href="interpreting-regression-results.html#Sec63"><i class="fa fa-check"></i><b>6.3</b> The Importance of Data Collection</a>
<ul>
<li class="chapter" data-level="6.3.1" data-path="interpreting-regression-results.html"><a href="interpreting-regression-results.html#Sec631"><i class="fa fa-check"></i><b>6.3.1</b> Sampling Frame Error and Adverse Selection</a></li>
<li class="chapter" data-level="6.3.2" data-path="interpreting-regression-results.html"><a href="interpreting-regression-results.html#Sec632"><i class="fa fa-check"></i><b>6.3.2</b> Limited Sampling Regions</a></li>
<li class="chapter" data-level="6.3.3" data-path="interpreting-regression-results.html"><a href="interpreting-regression-results.html#Sec633"><i class="fa fa-check"></i><b>6.3.3</b> Limited Dependent Variables, Censoring and Truncation</a></li>
<li class="chapter" data-level="6.3.4" data-path="interpreting-regression-results.html"><a href="interpreting-regression-results.html#Sec634"><i class="fa fa-check"></i><b>6.3.4</b> Omitted and Endogenous Variables</a></li>
<li class="chapter" data-level="6.3.5" data-path="interpreting-regression-results.html"><a href="interpreting-regression-results.html#Sec635"><i class="fa fa-check"></i><b>6.3.5</b> Missing Data</a></li>
</ul></li>
<li class="chapter" data-level="6.4" data-path="interpreting-regression-results.html"><a href="interpreting-regression-results.html#Sec64"><i class="fa fa-check"></i><b>6.4</b> Missing Data Models</a>
<ul>
<li class="chapter" data-level="6.4.1" data-path="interpreting-regression-results.html"><a href="interpreting-regression-results.html#Sec641"><i class="fa fa-check"></i><b>6.4.1</b> Missing at Random</a></li>
<li class="chapter" data-level="6.4.2" data-path="interpreting-regression-results.html"><a href="interpreting-regression-results.html#Sec642"><i class="fa fa-check"></i><b>6.4.2</b> Non-Ignorable Missing Data</a></li>
</ul></li>
<li class="chapter" data-level="6.5" data-path="interpreting-regression-results.html"><a href="interpreting-regression-results.html#Sec65"><i class="fa fa-check"></i><b>6.5</b> Application: Risk Managers’ Cost Effectiveness</a></li>
<li class="chapter" data-level="6.6" data-path="interpreting-regression-results.html"><a href="interpreting-regression-results.html#Sec66"><i class="fa fa-check"></i><b>6.6</b> Further Reading and References</a></li>
<li class="chapter" data-level="6.7" data-path="interpreting-regression-results.html"><a href="interpreting-regression-results.html#Sec67"><i class="fa fa-check"></i><b>6.7</b> Exercises</a></li>
<li class="chapter" data-level="6.8" data-path="interpreting-regression-results.html"><a href="interpreting-regression-results.html#Sec68"><i class="fa fa-check"></i><b>6.8</b> Technical Supplements for Chapter 6</a>
<ul>
<li class="chapter" data-level="6.8.1" data-path="interpreting-regression-results.html"><a href="interpreting-regression-results.html#Sec681"><i class="fa fa-check"></i><b>6.8.1</b> Effects of Model Misspecification</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="7" data-path="C7Trends.html"><a href="C7Trends.html"><i class="fa fa-check"></i><b>7</b> Modeling Trends</a>
<ul>
<li class="chapter" data-level="7.1" data-path="C7Trends.html"><a href="C7Trends.html#introduction-1"><i class="fa fa-check"></i><b>7.1</b> Introduction</a>
<ul>
<li class="chapter" data-level="" data-path="C7Trends.html"><a href="C7Trends.html#time-series-and-stochastic-processes"><i class="fa fa-check"></i>Time Series and Stochastic Processes</a></li>
<li class="chapter" data-level="" data-path="C7Trends.html"><a href="C7Trends.html#time-series-versus-causal-models"><i class="fa fa-check"></i>Time Series versus Causal Models</a></li>
</ul></li>
<li class="chapter" data-level="7.2" data-path="C7Trends.html"><a href="C7Trends.html#S7:Trends"><i class="fa fa-check"></i><b>7.2</b> Fitting Trends in Time</a>
<ul>
<li class="chapter" data-level="" data-path="C7Trends.html"><a href="C7Trends.html#understanding-patterns-over-time"><i class="fa fa-check"></i>Understanding Patterns over Time</a></li>
<li class="chapter" data-level="" data-path="C7Trends.html"><a href="C7Trends.html#fitting-trends-in-time"><i class="fa fa-check"></i>Fitting Trends in Time</a></li>
<li class="chapter" data-level="" data-path="C7Trends.html"><a href="C7Trends.html#fitting-seasonal-trends"><i class="fa fa-check"></i>Fitting Seasonal Trends</a></li>
<li class="chapter" data-level="" data-path="C7Trends.html"><a href="C7Trends.html#reliability-of-time-series-forecasts"><i class="fa fa-check"></i>Reliability of Time Series Forecasts</a></li>
</ul></li>
<li class="chapter" data-level="7.3" data-path="C7Trends.html"><a href="C7Trends.html#S7:RandomWalk"><i class="fa fa-check"></i><b>7.3</b> Stationarity and Random Walk Models</a>
<ul>
<li class="chapter" data-level="" data-path="C7Trends.html"><a href="C7Trends.html#white-noise"><i class="fa fa-check"></i>White Noise</a></li>
<li class="chapter" data-level="" data-path="C7Trends.html"><a href="C7Trends.html#random-walk"><i class="fa fa-check"></i>Random Walk</a></li>
</ul></li>
<li class="chapter" data-level="7.4" data-path="C7Trends.html"><a href="C7Trends.html#inference-using-random-walk-models"><i class="fa fa-check"></i><b>7.4</b> Inference using Random Walk Models</a>
<ul>
<li class="chapter" data-level="" data-path="C7Trends.html"><a href="C7Trends.html#model-properties"><i class="fa fa-check"></i>Model Properties</a></li>
<li class="chapter" data-level="" data-path="C7Trends.html"><a href="C7Trends.html#forecasting"><i class="fa fa-check"></i>Forecasting</a></li>
<li class="chapter" data-level="" data-path="C7Trends.html"><a href="C7Trends.html#identifying-stationarity"><i class="fa fa-check"></i>Identifying Stationarity</a></li>
<li class="chapter" data-level="" data-path="C7Trends.html"><a href="C7Trends.html#identifying-random-walks"><i class="fa fa-check"></i>Identifying Random Walks</a></li>
<li class="chapter" data-level="" data-path="C7Trends.html"><a href="C7Trends.html#random-walk-versus-linear-trend-in-time-models"><i class="fa fa-check"></i>Random Walk versus Linear Trend in Time Models</a></li>
</ul></li>
<li class="chapter" data-level="7.5" data-path="C7Trends.html"><a href="C7Trends.html#filtering-to-achieve-stationarity"><i class="fa fa-check"></i><b>7.5</b> Filtering to Achieve Stationarity</a>
<ul>
<li class="chapter" data-level="" data-path="C7Trends.html"><a href="C7Trends.html#transformations"><i class="fa fa-check"></i>Transformations</a></li>
</ul></li>
<li class="chapter" data-level="7.6" data-path="C7Trends.html"><a href="C7Trends.html#forecast-evaluation"><i class="fa fa-check"></i><b>7.6</b> Forecast Evaluation</a></li>
<li class="chapter" data-level="7.7" data-path="C7Trends.html"><a href="C7Trends.html#further-reading-and-references"><i class="fa fa-check"></i><b>7.7</b> Further Reading and References</a></li>
<li class="chapter" data-level="7.8" data-path="C7Trends.html"><a href="C7Trends.html#exercises"><i class="fa fa-check"></i><b>7.8</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="C8AR.html"><a href="C8AR.html"><i class="fa fa-check"></i><b>8</b> Autocorrelations and Autoregressive Models</a>
<ul>
<li class="chapter" data-level="8.1" data-path="C8AR.html"><a href="C8AR.html#S8:Autocorrs"><i class="fa fa-check"></i><b>8.1</b> Autocorrelations</a>
<ul>
<li class="chapter" data-level="" data-path="C8AR.html"><a href="C8AR.html#application-inflation-bond-returns"><i class="fa fa-check"></i>Application: Inflation Bond Returns</a></li>
</ul></li>
<li class="chapter" data-level="8.2" data-path="C8AR.html"><a href="C8AR.html#autoregressive-models-of-order-one"><i class="fa fa-check"></i><b>8.2</b> Autoregressive Models of Order One</a></li>
<li class="chapter" data-level="8.3" data-path="C8AR.html"><a href="C8AR.html#S8:Estimation"><i class="fa fa-check"></i><b>8.3</b> Estimation and Diagnostic Checking</a></li>
<li class="chapter" data-level="8.4" data-path="C8AR.html"><a href="C8AR.html#S8:AR1Smooth"><i class="fa fa-check"></i><b>8.4</b> Smoothing and Prediction</a></li>
<li class="chapter" data-level="8.5" data-path="C8AR.html"><a href="C8AR.html#S8:BoxJenkins"><i class="fa fa-check"></i><b>8.5</b> Box-Jenkins Modeling and Forecasting</a>
<ul>
<li class="chapter" data-level="8.5.1" data-path="C8AR.html"><a href="C8AR.html#models"><i class="fa fa-check"></i><b>8.5.1</b> Models</a></li>
<li class="chapter" data-level="8.5.2" data-path="C8AR.html"><a href="C8AR.html#forecasting-1"><i class="fa fa-check"></i><b>8.5.2</b> Forecasting</a></li>
</ul></li>
<li class="chapter" data-level="8.6" data-path="C8AR.html"><a href="C8AR.html#application-hong-kong-exchange-rates"><i class="fa fa-check"></i><b>8.6</b> Application: Hong Kong Exchange Rates</a></li>
<li class="chapter" data-level="8.7" data-path="C8AR.html"><a href="C8AR.html#further-reading-and-references-1"><i class="fa fa-check"></i><b>8.7</b> Further Reading and References</a></li>
<li class="chapter" data-level="8.8" data-path="C8AR.html"><a href="C8AR.html#exercises-1"><i class="fa fa-check"></i><b>8.8</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="9" data-path="C9Forecast.html"><a href="C9Forecast.html"><i class="fa fa-check"></i><b>9</b> Forecasting and Time Series Models</a>
<ul>
<li class="chapter" data-level="9.1" data-path="C9Forecast.html"><a href="C9Forecast.html#smoothing-with-moving-averages"><i class="fa fa-check"></i><b>9.1</b> Smoothing with Moving Averages</a></li>
<li class="chapter" data-level="9.2" data-path="C9Forecast.html"><a href="C9Forecast.html#S9:ExponSmooth"><i class="fa fa-check"></i><b>9.2</b> Exponential Smoothing</a></li>
<li class="chapter" data-level="9.3" data-path="C9Forecast.html"><a href="C9Forecast.html#S9:SeasonalTSModels"><i class="fa fa-check"></i><b>9.3</b> Seasonal Time Series Models</a></li>
<li class="chapter" data-level="9.4" data-path="C9Forecast.html"><a href="C9Forecast.html#unit-root-tests"><i class="fa fa-check"></i><b>9.4</b> Unit Root Tests</a></li>
<li class="chapter" data-level="9.5" data-path="C9Forecast.html"><a href="C9Forecast.html#archgarch-models"><i class="fa fa-check"></i><b>9.5</b> ARCH/GARCH Models</a></li>
<li class="chapter" data-level="9.6" data-path="C9Forecast.html"><a href="C9Forecast.html#further-reading-and-references-2"><i class="fa fa-check"></i><b>9.6</b> Further Reading and References</a></li>
</ul></li>
<li class="chapter" data-level="10" data-path="C10Panel.html"><a href="C10Panel.html"><i class="fa fa-check"></i><b>10</b> Longitudinal and Panel Data Models</a>
<ul>
<li class="chapter" data-level="10.1" data-path="C10Panel.html"><a href="C10Panel.html#S10:Intro"><i class="fa fa-check"></i><b>10.1</b> What are Longitudinal and Panel Data?</a></li>
<li class="chapter" data-level="10.2" data-path="C10Panel.html"><a href="C10Panel.html#S10:Visual"><i class="fa fa-check"></i><b>10.2</b> Visualizing Longitudinal and Panel Data</a></li>
<li class="chapter" data-level="10.3" data-path="C10Panel.html"><a href="C10Panel.html#S10:FEModels"><i class="fa fa-check"></i><b>10.3</b> Basic Fixed Effects Models</a></li>
<li class="chapter" data-level="10.4" data-path="C10Panel.html"><a href="C10Panel.html#S10:FEModels2"><i class="fa fa-check"></i><b>10.4</b> Extended Fixed Effects Models</a></li>
<li class="chapter" data-level="10.5" data-path="C10Panel.html"><a href="C10Panel.html#S10:REModels"><i class="fa fa-check"></i><b>10.5</b> Random Effects Models</a></li>
<li class="chapter" data-level="10.6" data-path="C10Panel.html"><a href="C10Panel.html#S10:References"><i class="fa fa-check"></i><b>10.6</b> Further Reading and References</a></li>
</ul></li>
<li class="chapter" data-level="11" data-path="C11Binary.html"><a href="C11Binary.html"><i class="fa fa-check"></i><b>11</b> Categorical Dependent Variables</a>
<ul>
<li class="chapter" data-level="11.1" data-path="C11Binary.html"><a href="C11Binary.html#S:Sec111"><i class="fa fa-check"></i><b>11.1</b> Binary Dependent Variables</a></li>
<li class="chapter" data-level="11.2" data-path="C11Binary.html"><a href="C11Binary.html#S:Sec112"><i class="fa fa-check"></i><b>11.2</b> Logistic and Probit Regression Models</a>
<ul>
<li class="chapter" data-level="11.2.1" data-path="C11Binary.html"><a href="C11Binary.html#S:Sec1121"><i class="fa fa-check"></i><b>11.2.1</b> Using Nonlinear Functions of Explanatory Variables</a></li>
<li class="chapter" data-level="11.2.2" data-path="C11Binary.html"><a href="C11Binary.html#S:Sec1122"><i class="fa fa-check"></i><b>11.2.2</b> Threshold Interpretation</a></li>
<li class="chapter" data-level="11.2.3" data-path="C11Binary.html"><a href="C11Binary.html#S:Sec1123"><i class="fa fa-check"></i><b>11.2.3</b> Random Utility Interpretation</a></li>
<li class="chapter" data-level="11.2.4" data-path="C11Binary.html"><a href="C11Binary.html#S:Sec1124"><i class="fa fa-check"></i><b>11.2.4</b> Logistic Regression</a></li>
</ul></li>
<li class="chapter" data-level="11.3" data-path="C11Binary.html"><a href="C11Binary.html#S:Sec113"><i class="fa fa-check"></i><b>11.3</b> Inference for Logistic and Probit Regression Models</a>
<ul>
<li class="chapter" data-level="11.3.1" data-path="C11Binary.html"><a href="C11Binary.html#parameter-estimation"><i class="fa fa-check"></i><b>11.3.1</b> Parameter Estimation</a></li>
<li class="chapter" data-level="11.3.2" data-path="C11Binary.html"><a href="C11Binary.html#additional-inference"><i class="fa fa-check"></i><b>11.3.2</b> Additional Inference</a></li>
</ul></li>
<li class="chapter" data-level="11.4" data-path="C11Binary.html"><a href="C11Binary.html#S:Sec114"><i class="fa fa-check"></i><b>11.4</b> Application: Medical Expenditures</a></li>
<li class="chapter" data-level="11.5" data-path="C11Binary.html"><a href="C11Binary.html#S:Sec115"><i class="fa fa-check"></i><b>11.5</b> Nominal Dependent Variables</a>
<ul>
<li class="chapter" data-level="11.5.1" data-path="C11Binary.html"><a href="C11Binary.html#S:Sec1151"><i class="fa fa-check"></i><b>11.5.1</b> Generalized Logit</a></li>
<li class="chapter" data-level="11.5.2" data-path="C11Binary.html"><a href="C11Binary.html#S:Sec1152"><i class="fa fa-check"></i><b>11.5.2</b> Multinomial Logit</a></li>
<li class="chapter" data-level="11.5.3" data-path="C11Binary.html"><a href="C11Binary.html#S:Sec1153"><i class="fa fa-check"></i><b>11.5.3</b> Nested Logit</a></li>
</ul></li>
<li class="chapter" data-level="11.6" data-path="C11Binary.html"><a href="C11Binary.html#S:Sec116"><i class="fa fa-check"></i><b>11.6</b> Ordinal Dependent Variables</a>
<ul>
<li class="chapter" data-level="11.6.1" data-path="C11Binary.html"><a href="C11Binary.html#cumulative-logit"><i class="fa fa-check"></i><b>11.6.1</b> Cumulative Logit</a></li>
<li class="chapter" data-level="11.6.2" data-path="C11Binary.html"><a href="C11Binary.html#cumulative-probit"><i class="fa fa-check"></i><b>11.6.2</b> Cumulative Probit</a></li>
</ul></li>
<li class="chapter" data-level="11.7" data-path="C11Binary.html"><a href="C11Binary.html#S:Sec117"><i class="fa fa-check"></i><b>11.7</b> Further Reading and References</a></li>
<li class="chapter" data-level="11.8" data-path="C11Binary.html"><a href="C11Binary.html#S:Sec118"><i class="fa fa-check"></i><b>11.8</b> Exercises</a></li>
<li class="chapter" data-level="11.9" data-path="C11Binary.html"><a href="C11Binary.html#S:Sec119"><i class="fa fa-check"></i><b>11.9</b> Technical Supplements - Likelihood-Based Inference</a>
<ul>
<li class="chapter" data-level="11.9.1" data-path="C11Binary.html"><a href="C11Binary.html#S:Sec1191"><i class="fa fa-check"></i><b>11.9.1</b> Properties of Likelihood Functions</a></li>
<li class="chapter" data-level="11.9.2" data-path="C11Binary.html"><a href="C11Binary.html#S:Sec1192"><i class="fa fa-check"></i><b>11.9.2</b> Maximum Likelihood Estimators</a></li>
<li class="chapter" data-level="11.9.3" data-path="C11Binary.html"><a href="C11Binary.html#S:Sec1193"><i class="fa fa-check"></i><b>11.9.3</b> Hypothesis Tests</a></li>
<li class="chapter" data-level="11.9.4" data-path="C11Binary.html"><a href="C11Binary.html#S:Sec1194"><i class="fa fa-check"></i><b>11.9.4</b> Information Criteria</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="12" data-path="C12Count.html"><a href="C12Count.html"><i class="fa fa-check"></i><b>12</b> Count Dependent Variables</a>
<ul>
<li class="chapter" data-level="12.1" data-path="C12Count.html"><a href="C12Count.html#S:Sec121"><i class="fa fa-check"></i><b>12.1</b> Poisson Regression</a>
<ul>
<li class="chapter" data-level="12.1.1" data-path="C12Count.html"><a href="C12Count.html#S:Sec1211"><i class="fa fa-check"></i><b>12.1.1</b> Poisson Distribution</a></li>
<li class="chapter" data-level="12.1.2" data-path="C12Count.html"><a href="C12Count.html#S:Sec1212"><i class="fa fa-check"></i><b>12.1.2</b> Regression Model</a></li>
<li class="chapter" data-level="12.1.3" data-path="C12Count.html"><a href="C12Count.html#S:Sec1213"><i class="fa fa-check"></i><b>12.1.3</b> Estimation</a></li>
<li class="chapter" data-level="12.1.4" data-path="C12Count.html"><a href="C12Count.html#S:Sec1214"><i class="fa fa-check"></i><b>12.1.4</b> Additional Inference</a></li>
</ul></li>
<li class="chapter" data-level="12.2" data-path="C12Count.html"><a href="C12Count.html#S:Sec122"><i class="fa fa-check"></i><b>12.2</b> Application: Singapore Automobile Insurance</a></li>
<li class="chapter" data-level="12.3" data-path="C12Count.html"><a href="C12Count.html#S:Sec123"><i class="fa fa-check"></i><b>12.3</b> Overdispersion and Negative Binomial Models</a></li>
<li class="chapter" data-level="12.4" data-path="C12Count.html"><a href="C12Count.html#S:Sec124"><i class="fa fa-check"></i><b>12.4</b> Other Count Models</a>
<ul>
<li class="chapter" data-level="12.4.1" data-path="C12Count.html"><a href="C12Count.html#zero-inflated-models"><i class="fa fa-check"></i><b>12.4.1</b> Zero-Inflated Models</a></li>
<li class="chapter" data-level="12.4.2" data-path="C12Count.html"><a href="C12Count.html#hurdle-models"><i class="fa fa-check"></i><b>12.4.2</b> Hurdle Models</a></li>
<li class="chapter" data-level="12.4.3" data-path="C12Count.html"><a href="C12Count.html#heterogeneity-models"><i class="fa fa-check"></i><b>12.4.3</b> Heterogeneity Models</a></li>
<li class="chapter" data-level="12.4.4" data-path="C12Count.html"><a href="C12Count.html#latent-class-models"><i class="fa fa-check"></i><b>12.4.4</b> Latent Class Models</a></li>
</ul></li>
<li class="chapter" data-level="12.5" data-path="C12Count.html"><a href="C12Count.html#S:Sec125"><i class="fa fa-check"></i><b>12.5</b> Further Reading and References</a></li>
<li class="chapter" data-level="12.6" data-path="C12Count.html"><a href="C12Count.html#S:Sec126"><i class="fa fa-check"></i><b>12.6</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="13" data-path="C13GLM.html"><a href="C13GLM.html"><i class="fa fa-check"></i><b>13</b> Generalized Linear Models</a>
<ul>
<li class="chapter" data-level="13.1" data-path="C13GLM.html"><a href="C13GLM.html#S:Sec131"><i class="fa fa-check"></i><b>13.1</b> Introduction</a></li>
<li class="chapter" data-level="13.2" data-path="C13GLM.html"><a href="C13GLM.html#S:Sec132"><i class="fa fa-check"></i><b>13.2</b> GLM Model</a>
<ul>
<li class="chapter" data-level="13.2.1" data-path="C13GLM.html"><a href="C13GLM.html#S:Sec1321"><i class="fa fa-check"></i><b>13.2.1</b> Linear Exponential Family of Distributions</a></li>
<li class="chapter" data-level="13.2.2" data-path="C13GLM.html"><a href="C13GLM.html#S:Sec1322"><i class="fa fa-check"></i><b>13.2.2</b> Link Functions</a></li>
</ul></li>
<li class="chapter" data-level="13.3" data-path="C13GLM.html"><a href="C13GLM.html#S:Sec133"><i class="fa fa-check"></i><b>13.3</b> Estimation</a>
<ul>
<li class="chapter" data-level="13.3.1" data-path="C13GLM.html"><a href="C13GLM.html#S:Sec1331"><i class="fa fa-check"></i><b>13.3.1</b> Maximum Likelihood Estimation for Canonical Links</a></li>
<li class="chapter" data-level="13.3.2" data-path="C13GLM.html"><a href="C13GLM.html#overdispersion"><i class="fa fa-check"></i><b>13.3.2</b> Overdispersion</a></li>
<li class="chapter" data-level="13.3.3" data-path="C13GLM.html"><a href="C13GLM.html#S:Sec1333"><i class="fa fa-check"></i><b>13.3.3</b> Goodness of Fit Statistics</a></li>
</ul></li>
<li class="chapter" data-level="13.4" data-path="C13GLM.html"><a href="C13GLM.html#S:Sec134"><i class="fa fa-check"></i><b>13.4</b> Application: Medical Expenditures</a></li>
<li class="chapter" data-level="13.5" data-path="C13GLM.html"><a href="C13GLM.html#S:Sec135"><i class="fa fa-check"></i><b>13.5</b> Residuals</a></li>
<li class="chapter" data-level="13.6" data-path="C13GLM.html"><a href="C13GLM.html#S:Sec136"><i class="fa fa-check"></i><b>13.6</b> Tweedie Distribution</a></li>
<li class="chapter" data-level="13.7" data-path="C13GLM.html"><a href="C13GLM.html#S:Sec137"><i class="fa fa-check"></i><b>13.7</b> Further Reading and References</a></li>
<li class="chapter" data-level="13.8" data-path="C13GLM.html"><a href="C13GLM.html#S:Sec138"><i class="fa fa-check"></i><b>13.8</b> Exercises</a></li>
<li class="chapter" data-level="13.9" data-path="C13GLM.html"><a href="C13GLM.html#S:Sec139"><i class="fa fa-check"></i><b>13.9</b> Technical Supplements - Exponential Family</a>
<ul>
<li class="chapter" data-level="13.9.1" data-path="C13GLM.html"><a href="C13GLM.html#S:Sec1391"><i class="fa fa-check"></i><b>13.9.1</b> Linear Exponential Family of Distributions</a></li>
<li class="chapter" data-level="13.9.2" data-path="C13GLM.html"><a href="C13GLM.html#S:Sec1392"><i class="fa fa-check"></i><b>13.9.2</b> Moments</a></li>
<li class="chapter" data-level="13.9.3" data-path="C13GLM.html"><a href="C13GLM.html#S:Sec1393"><i class="fa fa-check"></i><b>13.9.3</b> Maximum Likelihood Estimation for General Links</a></li>
<li class="chapter" data-level="13.9.4" data-path="C13GLM.html"><a href="C13GLM.html#S:Sec1394"><i class="fa fa-check"></i><b>13.9.4</b> Iterated Reweighted Least Squares</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="14" data-path="C14Survival.html"><a href="C14Survival.html"><i class="fa fa-check"></i><b>14</b> Survival Models</a>
<ul>
<li class="chapter" data-level="14.1" data-path="C14Survival.html"><a href="C14Survival.html#introduction-2"><i class="fa fa-check"></i><b>14.1</b> Introduction</a></li>
<li class="chapter" data-level="14.2" data-path="C14Survival.html"><a href="C14Survival.html#S:Sec142"><i class="fa fa-check"></i><b>14.2</b> Censoring and Truncation</a>
<ul>
<li class="chapter" data-level="14.2.1" data-path="C14Survival.html"><a href="C14Survival.html#definitions-and-examples"><i class="fa fa-check"></i><b>14.2.1</b> Definitions and Examples</a></li>
<li class="chapter" data-level="14.2.2" data-path="C14Survival.html"><a href="C14Survival.html#likelihood-inference"><i class="fa fa-check"></i><b>14.2.2</b> Likelihood Inference</a></li>
<li class="chapter" data-level="14.2.3" data-path="C14Survival.html"><a href="C14Survival.html#product-limit-estimator"><i class="fa fa-check"></i><b>14.2.3</b> Product-Limit Estimator</a></li>
</ul></li>
<li class="chapter" data-level="14.3" data-path="C14Survival.html"><a href="C14Survival.html#S:Sec143"><i class="fa fa-check"></i><b>14.3</b> Accelerated Failure Time Model</a></li>
<li class="chapter" data-level="14.4" data-path="C14Survival.html"><a href="C14Survival.html#S:Sec144"><i class="fa fa-check"></i><b>14.4</b> Proportional Hazards Model</a>
<ul>
<li class="chapter" data-level="14.4.1" data-path="C14Survival.html"><a href="C14Survival.html#S:Sec1441"><i class="fa fa-check"></i><b>14.4.1</b> Proportional Hazards</a></li>
<li class="chapter" data-level="14.4.2" data-path="C14Survival.html"><a href="C14Survival.html#S:Sec1442"><i class="fa fa-check"></i><b>14.4.2</b> Inference</a></li>
</ul></li>
<li class="chapter" data-level="14.5" data-path="C14Survival.html"><a href="C14Survival.html#S:Sec145"><i class="fa fa-check"></i><b>14.5</b> Recurrent Events</a></li>
<li class="chapter" data-level="14.6" data-path="C14Survival.html"><a href="C14Survival.html#S:Sec146"><i class="fa fa-check"></i><b>14.6</b> Further Reading and References</a></li>
</ul></li>
<li class="chapter" data-level="15" data-path="C15Misc.html"><a href="C15Misc.html"><i class="fa fa-check"></i><b>15</b> Miscellaneous Regression Topics</a>
<ul>
<li class="chapter" data-level="15.1" data-path="C15Misc.html"><a href="C15Misc.html#S:Sec151"><i class="fa fa-check"></i><b>15.1</b> Mixed Linear Models</a>
<ul>
<li class="chapter" data-level="15.1.1" data-path="C15Misc.html"><a href="C15Misc.html#weighted-least-squares-2"><i class="fa fa-check"></i><b>15.1.1</b> Weighted Least Squares</a></li>
<li class="chapter" data-level="15.1.2" data-path="C15Misc.html"><a href="C15Misc.html#S:Sec1512"><i class="fa fa-check"></i><b>15.1.2</b> Variance Components Estimation</a></li>
<li class="chapter" data-level="15.1.3" data-path="C15Misc.html"><a href="C15Misc.html#best-linear-unbiased-prediction"><i class="fa fa-check"></i><b>15.1.3</b> Best Linear Unbiased Prediction</a></li>
</ul></li>
<li class="chapter" data-level="15.2" data-path="C15Misc.html"><a href="C15Misc.html#bayesian-regression"><i class="fa fa-check"></i><b>15.2</b> Bayesian Regression</a></li>
<li class="chapter" data-level="15.3" data-path="C15Misc.html"><a href="C15Misc.html#S:Sec153"><i class="fa fa-check"></i><b>15.3</b> Density Estimation and Scatterplot Smoothing}</a></li>
<li class="chapter" data-level="15.4" data-path="C15Misc.html"><a href="C15Misc.html#S:Sec154"><i class="fa fa-check"></i><b>15.4</b> Generalized Additive Models</a></li>
<li class="chapter" data-level="15.5" data-path="C15Misc.html"><a href="C15Misc.html#bootstrapping"><i class="fa fa-check"></i><b>15.5</b> Bootstrapping</a></li>
<li class="chapter" data-level="15.6" data-path="C15Misc.html"><a href="C15Misc.html#further-reading-and-references-3"><i class="fa fa-check"></i><b>15.6</b> Further Reading and References</a></li>
</ul></li>
<li class="chapter" data-level="16" data-path="C16FreqSev.html"><a href="C16FreqSev.html"><i class="fa fa-check"></i><b>16</b> Frequency-Severity Models</a>
<ul>
<li class="chapter" data-level="16.1" data-path="C16FreqSev.html"><a href="C16FreqSev.html#S:Sec161"><i class="fa fa-check"></i><b>16.1</b> Introduction</a></li>
<li class="chapter" data-level="16.2" data-path="C16FreqSev.html"><a href="C16FreqSev.html#S:Sec162"><i class="fa fa-check"></i><b>16.2</b> Tobit Model</a></li>
<li class="chapter" data-level="16.3" data-path="C16FreqSev.html"><a href="C16FreqSev.html#S:Sec163"><i class="fa fa-check"></i><b>16.3</b> Application: Medical Expenditures</a></li>
<li class="chapter" data-level="16.4" data-path="C16FreqSev.html"><a href="C16FreqSev.html#S:Sec164"><i class="fa fa-check"></i><b>16.4</b> Two-Part Model</a></li>
<li class="chapter" data-level="16.5" data-path="C16FreqSev.html"><a href="C16FreqSev.html#S:Sec165"><i class="fa fa-check"></i><b>16.5</b> Aggregate Loss Model</a></li>
<li class="chapter" data-level="16.6" data-path="C16FreqSev.html"><a href="C16FreqSev.html#S:Sec166"><i class="fa fa-check"></i><b>16.6</b> Further Reading and References</a></li>
<li class="chapter" data-level="16.7" data-path="C16FreqSev.html"><a href="C16FreqSev.html#S:Sec167"><i class="fa fa-check"></i><b>16.7</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="17" data-path="C17Fat.html"><a href="C17Fat.html"><i class="fa fa-check"></i><b>17</b> Fat-Tailed Regression Models</a>
<ul>
<li class="chapter" data-level="17.1" data-path="C17Fat.html"><a href="C17Fat.html#introduction-3"><i class="fa fa-check"></i><b>17.1</b> Introduction</a></li>
<li class="chapter" data-level="17.2" data-path="C17Fat.html"><a href="C17Fat.html#S:Sec172"><i class="fa fa-check"></i><b>17.2</b> Transformations</a></li>
<li class="chapter" data-level="17.3" data-path="C17Fat.html"><a href="C17Fat.html#S:Sec173"><i class="fa fa-check"></i><b>17.3</b> Generalized Linear Models</a>
<ul>
<li class="chapter" data-level="17.3.1" data-path="C17Fat.html"><a href="C17Fat.html#S:Sec1731"><i class="fa fa-check"></i><b>17.3.1</b> What is “Fat-Tailed?”</a></li>
<li class="chapter" data-level="17.3.2" data-path="C17Fat.html"><a href="C17Fat.html#S:Sec1732"><i class="fa fa-check"></i><b>17.3.2</b> Application: Wisconsin Nursing Homes</a></li>
</ul></li>
<li class="chapter" data-level="17.4" data-path="C17Fat.html"><a href="C17Fat.html#S:Sec174"><i class="fa fa-check"></i><b>17.4</b> Generalized Distributions</a>
<ul>
<li class="chapter" data-level="" data-path="C17Fat.html"><a href="C17Fat.html#applicationwisconsin-nursing-homes"><i class="fa fa-check"></i>Application:Wisconsin Nursing Homes</a></li>
</ul></li>
<li class="chapter" data-level="17.5" data-path="C17Fat.html"><a href="C17Fat.html#S:Sec175"><i class="fa fa-check"></i><b>17.5</b> Quantile Regression</a></li>
<li class="chapter" data-level="17.6" data-path="C17Fat.html"><a href="C17Fat.html#S:Sec176"><i class="fa fa-check"></i><b>17.6</b> Extreme Value Models</a></li>
<li class="chapter" data-level="17.7" data-path="C17Fat.html"><a href="C17Fat.html#further-reading-and-references-4"><i class="fa fa-check"></i><b>17.7</b> Further Reading and References</a></li>
<li class="chapter" data-level="17.8" data-path="C17Fat.html"><a href="C17Fat.html#exercises-2"><i class="fa fa-check"></i><b>17.8</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="18" data-path="C18Cred.html"><a href="C18Cred.html"><i class="fa fa-check"></i><b>18</b> Credibility and Bonus-Malus</a>
<ul>
<li class="chapter" data-level="18.1" data-path="C18Cred.html"><a href="C18Cred.html#risk-classification-and-experience-rating"><i class="fa fa-check"></i><b>18.1</b> Risk Classification and Experience Rating</a></li>
<li class="chapter" data-level="18.2" data-path="C18Cred.html"><a href="C18Cred.html#S:Sec182"><i class="fa fa-check"></i><b>18.2</b> Credibility</a>
<ul>
<li class="chapter" data-level="18.2.1" data-path="C18Cred.html"><a href="C18Cred.html#S:Sec1821"><i class="fa fa-check"></i><b>18.2.1</b> Limited Fluctuation Credibility</a></li>
<li class="chapter" data-level="18.2.2" data-path="C18Cred.html"><a href="C18Cred.html#S:Sec1822"><i class="fa fa-check"></i><b>18.2.2</b> Greatest Accuracy Credibility</a></li>
</ul></li>
<li class="chapter" data-level="18.3" data-path="C18Cred.html"><a href="C18Cred.html#S:Sec183"><i class="fa fa-check"></i><b>18.3</b> Credibility and Regression</a>
<ul>
<li class="chapter" data-level="18.3.1" data-path="C18Cred.html"><a href="C18Cred.html#one-way-random-effects-model"><i class="fa fa-check"></i><b>18.3.1</b> One-Way Random Effects Model</a></li>
<li class="chapter" data-level="18.3.2" data-path="C18Cred.html"><a href="C18Cred.html#longitudinal-models"><i class="fa fa-check"></i><b>18.3.2</b> Longitudinal Models</a></li>
</ul></li>
<li class="chapter" data-level="18.4" data-path="C18Cred.html"><a href="C18Cred.html#S:Sec184"><i class="fa fa-check"></i><b>18.4</b> Bonus-Malus</a></li>
</ul></li>
<li class="chapter" data-level="19" data-path="C19Triangles.html"><a href="C19Triangles.html"><i class="fa fa-check"></i><b>19</b> Claims Triangles</a>
<ul>
<li class="chapter" data-level="19.1" data-path="C19Triangles.html"><a href="C19Triangles.html#introduction-4"><i class="fa fa-check"></i><b>19.1</b> Introduction</a>
<ul>
<li class="chapter" data-level="19.1.1" data-path="C19Triangles.html"><a href="C19Triangles.html#S:Sec1911"><i class="fa fa-check"></i><b>19.1.1</b> Claims Evolution</a></li>
<li class="chapter" data-level="19.1.2" data-path="C19Triangles.html"><a href="C19Triangles.html#S:Sec1912"><i class="fa fa-check"></i><b>19.1.2</b> Claims Triangles</a></li>
<li class="chapter" data-level="19.1.3" data-path="C19Triangles.html"><a href="C19Triangles.html#S:Sec1913"><i class="fa fa-check"></i><b>19.1.3</b> Chain Ladder Method</a></li>
</ul></li>
<li class="chapter" data-level="19.2" data-path="C19Triangles.html"><a href="C19Triangles.html#S:Sec192"><i class="fa fa-check"></i><b>19.2</b> Regression Using Functions of Time as Explanatory Variables</a>
<ul>
<li class="chapter" data-level="19.2.1" data-path="C19Triangles.html"><a href="C19Triangles.html#S:Sec1921"><i class="fa fa-check"></i><b>19.2.1</b> Lognormal Model</a></li>
<li class="chapter" data-level="19.2.2" data-path="C19Triangles.html"><a href="C19Triangles.html#S:Sec1922"><i class="fa fa-check"></i><b>19.2.2</b> Hoerl Curve</a></li>
<li class="chapter" data-level="19.2.3" data-path="C19Triangles.html"><a href="C19Triangles.html#S:Sec1923"><i class="fa fa-check"></i><b>19.2.3</b> Poisson Models</a></li>
</ul></li>
<li class="chapter" data-level="19.3" data-path="C19Triangles.html"><a href="C19Triangles.html#S:Sec193"><i class="fa fa-check"></i><b>19.3</b> Using Past Developments</a>
<ul>
<li class="chapter" data-level="19.3.1" data-path="C19Triangles.html"><a href="C19Triangles.html#S:Sec1931"><i class="fa fa-check"></i><b>19.3.1</b> Mack Model</a></li>
<li class="chapter" data-level="19.3.2" data-path="C19Triangles.html"><a href="C19Triangles.html#S:Sec1932"><i class="fa fa-check"></i><b>19.3.2</b> Distributional Models</a></li>
</ul></li>
<li class="chapter" data-level="19.4" data-path="C19Triangles.html"><a href="C19Triangles.html#further-reading-and-references-5"><i class="fa fa-check"></i><b>19.4</b> Further Reading and References</a></li>
<li class="chapter" data-level="19.5" data-path="C19Triangles.html"><a href="C19Triangles.html#exercises-3"><i class="fa fa-check"></i><b>19.5</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="20" data-path="C20Report.html"><a href="C20Report.html"><i class="fa fa-check"></i><b>20</b> Report Writing: Communicating Data Analysis Results</a>
<ul>
<li class="chapter" data-level="20.1" data-path="C20Report.html"><a href="C20Report.html#S20:Overview"><i class="fa fa-check"></i><b>20.1</b> Overview</a></li>
<li class="chapter" data-level="20.2" data-path="C20Report.html"><a href="C20Report.html#S20:Methods"><i class="fa fa-check"></i><b>20.2</b> Methods for Communicating Data</a>
<ul>
<li class="chapter" data-level="" data-path="C20Report.html"><a href="C20Report.html#within-text-data"><i class="fa fa-check"></i>Within Text Data</a></li>
<li class="chapter" data-level="" data-path="C20Report.html"><a href="C20Report.html#graphs"><i class="fa fa-check"></i>Graphs</a></li>
</ul></li>
<li class="chapter" data-level="20.3" data-path="C20Report.html"><a href="C20Report.html#S20:Organize"><i class="fa fa-check"></i><b>20.3</b> How to Organize</a>
<ul>
<li class="chapter" data-level="" data-path="C20Report.html"><a href="C20Report.html#title-and-abstract"><i class="fa fa-check"></i>Title and Abstract</a></li>
<li class="chapter" data-level="" data-path="C20Report.html"><a href="C20Report.html#introduction-5"><i class="fa fa-check"></i>Introduction</a></li>
<li class="chapter" data-level="" data-path="C20Report.html"><a href="C20Report.html#model-selection-and-interpretation"><i class="fa fa-check"></i>Model Selection and Interpretation</a></li>
<li class="chapter" data-level="" data-path="C20Report.html"><a href="C20Report.html#references-and-appendix"><i class="fa fa-check"></i>References and Appendix</a></li>
</ul></li>
<li class="chapter" data-level="20.4" data-path="C20Report.html"><a href="C20Report.html#further-suggestions-for-report-writing"><i class="fa fa-check"></i><b>20.4</b> Further Suggestions for Report Writing</a></li>
<li class="chapter" data-level="20.5" data-path="C20Report.html"><a href="C20Report.html#case-study-swedish-automobile-claims"><i class="fa fa-check"></i><b>20.5</b> Case Study: Swedish Automobile Claims</a></li>
<li class="chapter" data-level="20.6" data-path="C20Report.html"><a href="C20Report.html#further-reading-and-references-6"><i class="fa fa-check"></i><b>20.6</b> Further Reading and References</a></li>
<li class="chapter" data-level="20.7" data-path="C20Report.html"><a href="C20Report.html#exercises-4"><i class="fa fa-check"></i><b>20.7</b> Exercises</a></li>
</ul></li>
<li class="chapter" data-level="21" data-path="C21Design.html"><a href="C21Design.html"><i class="fa fa-check"></i><b>21</b> Designing Effective Graphs</a>
<ul>
<li class="chapter" data-level="21.1" data-path="C21Design.html"><a href="C21Design.html#S21:Intro"><i class="fa fa-check"></i><b>21.1</b> Introduction</a></li>
<li class="chapter" data-level="21.2" data-path="C21Design.html"><a href="C21Design.html#S21:GDesign"><i class="fa fa-check"></i><b>21.2</b> Graphic Design Choices Make a Difference</a></li>
<li class="chapter" data-level="21.3" data-path="C21Design.html"><a href="C21Design.html#S21:DesignGuide"><i class="fa fa-check"></i><b>21.3</b> Design Guidelines</a>
<ul>
<li class="chapter" data-level="" data-path="C21Design.html"><a href="C21Design.html#guideline-one-avoid-chartjunk"><i class="fa fa-check"></i>Guideline One: Avoid Chartjunk</a></li>
<li class="chapter" data-level="" data-path="C21Design.html"><a href="C21Design.html#guideline-two-use-small-multiples-to-promote-comparisons-and-assess-change"><i class="fa fa-check"></i>Guideline Two: Use Small Multiples to Promote Comparisons and Assess Change</a></li>
<li class="chapter" data-level="" data-path="C21Design.html"><a href="C21Design.html#guideline-three-use-complex-graphs-to-portray-complex-patterns"><i class="fa fa-check"></i>Guideline Three: Use Complex Graphs to Portray Complex Patterns</a></li>
<li class="chapter" data-level="" data-path="C21Design.html"><a href="C21Design.html#guideline-four-relate-graph-size-to-information-content"><i class="fa fa-check"></i>Guideline Four: Relate Graph Size to Information Content</a></li>
<li class="chapter" data-level="" data-path="C21Design.html"><a href="C21Design.html#guideline-five-use-graphical-forms-that-promote-comparisons"><i class="fa fa-check"></i>Guideline Five: Use Graphical Forms That Promote Comparisons</a></li>
<li class="chapter" data-level="" data-path="C21Design.html"><a href="C21Design.html#guideline-six-integrate-graphs-and-text"><i class="fa fa-check"></i>Guideline Six: Integrate Graphs and Text</a></li>
<li class="chapter" data-level="" data-path="C21Design.html"><a href="C21Design.html#guideline-seven-demonstrate-an-important-message"><i class="fa fa-check"></i>Guideline Seven: Demonstrate an Important Message</a></li>
<li class="chapter" data-level="" data-path="C21Design.html"><a href="C21Design.html#guideline-eight-know-your-audience"><i class="fa fa-check"></i>Guideline Eight: Know Your Audience</a></li>
</ul></li>
<li class="chapter" data-level="21.4" data-path="C21Design.html"><a href="C21Design.html#S21:EmpiricalFoundations"><i class="fa fa-check"></i><b>21.4</b> Empirical Foundations For Guidelines</a>
<ul>
<li class="chapter" data-level="21.4.1" data-path="C21Design.html"><a href="C21Design.html#graphs-as-units-of-study"><i class="fa fa-check"></i><b>21.4.1</b> Graphs as Units of Study</a></li>
</ul></li>
<li class="chapter" data-level="21.5" data-path="C21Design.html"><a href="C21Design.html#S21:Conclude"><i class="fa fa-check"></i><b>21.5</b> Concluding Remarks</a></li>
<li class="chapter" data-level="21.6" data-path="C21Design.html"><a href="C21Design.html#S21:References"><i class="fa fa-check"></i><b>21.6</b> Further Reading and References</a></li>
</ul></li>
<li class="chapter" data-level="22" data-path="appendices.html"><a href="appendices.html"><i class="fa fa-check"></i><b>22</b> Appendices</a>
<ul>
<li class="chapter" data-level="" data-path="appendices.html"><a href="appendices.html#appendix-a1.-basic-statistical-inference"><i class="fa fa-check"></i>Appendix A1. Basic Statistical Inference</a>
<ul>
<li class="chapter" data-level="" data-path="appendices.html"><a href="appendices.html#distributions-of-functions-of-random-variables"><i class="fa fa-check"></i>Distributions of Functions of Random Variables</a></li>
<li class="chapter" data-level="" data-path="appendices.html"><a href="appendices.html#estimation-and-prediction"><i class="fa fa-check"></i>Estimation and Prediction</a></li>
<li class="chapter" data-level="" data-path="appendices.html"><a href="appendices.html#testing-hypotheses"><i class="fa fa-check"></i>Testing Hypotheses</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="appendices.html"><a href="appendices.html#appendix-a2.-matrix-algebra"><i class="fa fa-check"></i>Appendix A2. Matrix Algebra</a>
<ul>
<li class="chapter" data-level="" data-path="appendices.html"><a href="appendices.html#basic-definitions"><i class="fa fa-check"></i>Basic Definitions</a></li>
<li class="chapter" data-level="" data-path="appendices.html"><a href="appendices.html#review-of-basic-operations"><i class="fa fa-check"></i>Review of Basic Operations</a></li>
<li class="chapter" data-level="" data-path="appendices.html"><a href="appendices.html#further-definitions"><i class="fa fa-check"></i>Further Definitions</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="appendices.html"><a href="appendices.html#appendix-a3.-probability-tables"><i class="fa fa-check"></i>Appendix A3. Probability Tables</a>
<ul>
<li class="chapter" data-level="" data-path="appendices.html"><a href="appendices.html#normal-distribution"><i class="fa fa-check"></i>Normal Distribution</a></li>
<li class="chapter" data-level="" data-path="appendices.html"><a href="appendices.html#chi-square-distribution"><i class="fa fa-check"></i>Chi-Square Distribution</a></li>
<li class="chapter" data-level="" data-path="appendices.html"><a href="appendices.html#t-distribution"><i class="fa fa-check"></i><em>t</em>-Distribution</a></li>
<li class="chapter" data-level="" data-path="appendices.html"><a href="appendices.html#f-distribution"><i class="fa fa-check"></i><em>F</em>-Distribution</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="" data-path="brief-answers-to-selected-exercises.html"><a href="brief-answers-to-selected-exercises.html"><i class="fa fa-check"></i>Brief Answers to Selected Exercises</a></li>
<li class="divider"></li>
<li><a href="https://github.com/OpenActTextDev/RegressionSpanish/" target="blank">Spanish Regression on GitHub</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Regression Modeling with Actuarial and Financial Applications</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="appendices" class="section level1 hasAnchor" number="22">
<h1><span class="header-section-number">Chapter 22</span> Appendices<a href="appendices.html#appendices" class="anchor-section" aria-label="Anchor link to header"></a></h1>
<div id="appendix-a1.-basic-statistical-inference" class="section level2 unnumbered hasAnchor">
<h2>Appendix A1. Basic Statistical Inference<a href="appendices.html#appendix-a1.-basic-statistical-inference" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p><em>Appendix Preview.</em> This appendix provides
definitions and facts from a course in basic statistical inference
that are needed in one’s study of regression analysis.</p>
<div id="distributions-of-functions-of-random-variables" class="section level3 unnumbered hasAnchor">
<h3>Distributions of Functions of Random Variables<a href="appendices.html#distributions-of-functions-of-random-variables" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p><strong>Statistics and Sampling Distributions.</strong> A <em>statistic</em> summarizes information in a sample and hence is a function of observations <span class="math inline">\(y_1,\ldots,y_n\)</span>. Because observations are realizations of random variables, the study of distributions of functions of random variables is really the study of the distributions of statistics, known as <em>sampling distributions</em>. Linear combinations of the form <span class="math inline">\(\sum_{i=1}^n a_i y_i\)</span> represent an important type of function. Here, <span class="math inline">\(a_1,\ldots,a_n\)</span> are known constants. To begin, we suppose that <span class="math inline">\(y_1,\ldots,y_n\)</span> are mutually independent random variables with <span class="math inline">\(\mathrm{E~}y_i = \mu_i\)</span> and <span class="math inline">\(\mathrm{ Var~}y_i = \sigma_i^2\)</span>. Then, by the <em>linearity of expectations</em>, we have
<span class="math display">\[
\mathrm{E}\left( \sum_{i=1}^n a_i y_i \right) = \sum_{i=1}^n a_i \mu_i~~~\mathrm{and}~~~\mathrm{Var}\left( \sum_{i=1}^n a_i y_i \right) = \sum_{i=1}^n a_i^2 \sigma_i^2.
\]</span>
An important theorem in mathematical statistics is that, if each random variable is normally distributed, then linear combinations are also normally distributed. That is, we have:</p>
<p><strong>Linearity of Normal Random Variables.</strong> Suppose that <span class="math inline">\(y_1,\ldots,y_n\)</span> are mutually independent random variables with <span class="math inline">\(y_i \sim N(\mu_i,\sigma_i^2)\)</span>. (Read ” <span class="math inline">\(\sim\)</span> ” to mean “is distributed as.”) Then,
<span class="math display">\[
\sum_{i=1}^n a_i y_i \sim N\left( \sum_{i=1}^n a_i \mu_i, \sum_{i=1}^n a_i^2 \sigma_i^2 \right) .
\]</span>
There are several applications of this important property. First, it can be checked that if <span class="math inline">\(y \sim N(\mu ,\sigma^2)\)</span>, then <span class="math inline">\((y - \mu)/\sigma \sim N(0,1)\)</span>. Second, assume that <span class="math inline">\(y_1,\ldots,y_n\)</span> are identically and independently distributed (<em>i.i.d.</em>) as <span class="math inline">\(N(\mu, \sigma^2)\)</span> and take <span class="math inline">\(a_i = n^{-1}\)</span>. Then, we have
<span class="math display">\[
\overline{y} = \frac{1}{n}\sum_{i=1}^n y_i \sim N\left( \mu ,\frac{\sigma^2}{n}\right) .
\]</span>
Equivalently, <span class="math inline">\(\sqrt{n}\left( \overline{y}-\mu \right) /\sigma\)</span> is standard normal.</p>
<p>Thus, the important sample statistic <span class="math inline">\(\overline{y}\)</span> has a normal distribution. Further, the distribution of the sample variance <span class="math inline">\(s_y^2\)</span> can also be calculated. For <span class="math inline">\(y_1,\ldots,y_n\)</span> are i.i.d. <span class="math inline">\(N(\mu ,\sigma^2)\)</span>, we have that <span class="math inline">\(\left( n-1\right) s_y^2 /\sigma^2\sim \chi_{n-1}^2\)</span>, a <span class="math inline">\(\chi^2\)</span> (chi-square) distribution with <span class="math inline">\(n-1\)</span> degrees of freedom. Further, <span class="math inline">\(\overline{y}\)</span> is independent of <span class="math inline">\(s_y^2\)</span>. From these two results, we have that
<span class="math display">\[
\frac{\sqrt{n}}{s_y}\left( \overline{y}-\mu \right) \sim t_{n-1},
\]</span>
a <span class="math inline">\(t\)</span>-distribution with <span class="math inline">\(n-1\)</span> degrees of freedom.</p>
</div>
<div id="estimation-and-prediction" class="section level3 unnumbered hasAnchor">
<h3>Estimation and Prediction<a href="appendices.html#estimation-and-prediction" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Suppose that <span class="math inline">\(y_1,\ldots,y_n\)</span> are i.i.d. random variables from a distribution that can be summarized by an unknown parameter <span class="math inline">\(\theta\)</span>. We are interested in the quality of an estimate of <span class="math inline">\(\theta\)</span> and denote <span class="math inline">\(\widehat{\theta}\)</span> as this estimator. For example, we consider <span class="math inline">\(\theta = \mu\)</span> with <span class="math inline">\(\widehat{\theta} = \overline{y}\)</span> and <span class="math inline">\(\theta = \sigma^2\)</span> with <span class="math inline">\(\widehat{\theta} = s_y^2\)</span> as our leading examples.</p>
<p><strong>Point Estimation and Unbiasedness.</strong> Because <span class="math inline">\(\widehat{\theta}\)</span> provides a (single) approximation of <span class="math inline">\(\theta\)</span>, it is referred to as a <em>point estimate</em> of <span class="math inline">\(\theta\)</span>. As a statistic, <span class="math inline">\(\widehat{\theta}\)</span> is a function of the observations <span class="math inline">\(y_1,\ldots,y_n\)</span> that varies from one sample to the next. Thus, values of <span class="math inline">\(\widehat{\theta}\)</span> vary from one sample to the next. To examine how close <span class="math inline">\(\widehat{\theta}\)</span> tends to be to <span class="math inline">\(\theta\)</span>, we examine several properties of <span class="math inline">\(\widehat{\theta}\)</span>, in particular, the <em>bias</em> and <em>consistency</em>. A point estimator <span class="math inline">\(\widehat{\theta}\)</span> is said to be an <em>unbiased estimator</em> of <span class="math inline">\(\theta\)</span> if <span class="math inline">\(\mathrm{E~}\widehat{\theta} = \theta\)</span>. For example, since <span class="math inline">\(\mathrm{E~}\overline{y} = \mu\)</span>, <span class="math inline">\(\overline{y}\)</span> is an unbiased estimator of <span class="math inline">\(\mu\)</span>.</p>
<p><strong>Finite Sample versus Large Sample Properties of Estimators.</strong> Biasedness is said to be a <em>finite sample</em> property since it is valid for each sample size <span class="math inline">\(n\)</span>. A <em>limiting</em>, or <em>large sample</em> property is <em>consistency</em>. Consistency is expressed in two ways, <em>weak</em> and <em>strong</em> consistency. An estimator is said to be <em>weakly consistent</em> if
<span class="math display">\[
\lim_{n\rightarrow \infty }\Pr \left( |\widehat{\theta }-\theta |&lt;h\right) = 1,
\]</span>
for each positive <span class="math inline">\(h\)</span>. An estimator is said to be <em>strongly consistent</em> if <span class="math inline">\(\lim_{n\rightarrow \infty }~\widehat{\theta }=\theta\)</span>, with probability one.</p>
<p><strong>Least Squares Estimation Principle.</strong> In this text, two main estimation principles are used, <em>least squares</em> estimation and <em>maximum likelihood</em> estimation. For the least squares procedure, consider independent random variables <span class="math inline">\(y_1,\ldots,y_n\)</span> with means <span class="math inline">\(\mathrm{E~}y_i = \mathrm{g}_i(\theta )\)</span>. Here, <span class="math inline">\(\mathrm{g}_i(.)\)</span> is a known function up to <span class="math inline">\(\theta\)</span>, the unknown parameter. The least squares estimator is that value of <span class="math inline">\(\theta\)</span> that minimizes the sum of squares
<span class="math display">\[
\mathrm{SS}(\theta )=\sum_{i=1}^n\left( y_i-\mathrm{g}_i(\theta )\right)^2.
\]</span></p>
<p><strong>Maximum Likelihood Estimation Principle.</strong> Maximum likelihood estimates are values of the parameter that are “most likely” to have been produced by the data. Consider the independent random variables <span class="math inline">\(y_1,\ldots,y_n\)</span> with probability function <span class="math inline">\(\mathrm{f}_i(a_i,\theta )\)</span>. Here, <span class="math inline">\(\mathrm{f}_i(a_i,\theta )\)</span> is interpreted to be a probability mass function for discrete <span class="math inline">\(y_i\)</span> or a probability density function for continuous <span class="math inline">\(y_i\)</span>, evaluated at <span class="math inline">\(a_i\)</span>, the realization of <span class="math inline">\(y_i\)</span>. The function <span class="math inline">\(\mathrm{f}_i(a_i,\theta )\)</span> is assumed known up to <span class="math inline">\(\theta\)</span>, the unknown parameter. The likelihood of the random variables <span class="math inline">\(y_1,\ldots,y_n\)</span> taking on values <span class="math inline">\(a_1,\ldots,a_n\)</span> is
<span class="math display">\[
\mathrm{L}(\theta )=\prod\limits_{i=1}^n \mathrm{f}_i(a_i,\theta ).
\]</span></p>
<p>The value of <span class="math inline">\(\theta\)</span> that maximizes <span class="math inline">\(\mathrm{L}(\theta )\)</span> is called the <em>maximum likelihood estimator</em>.</p>
<p><strong>Confidence Intervals.</strong> Although point estimates provide a single approximation to parameters, <em>interval estimates</em> provide a range that includes parameters with a certain prespecified level of probability, or <em>confidence</em>. A pair of statistics, <span class="math inline">\(\widehat{\theta }_1\)</span> and <span class="math inline">\(\widehat{\theta }_{2}\)</span>, provide an interval of the form <span class="math inline">\(\left[ \widehat{\theta }_1 &lt; \widehat{\theta }_{2}\right]\)</span>. This interval is a <span class="math inline">\(100(1-\alpha )\%\)</span> confidence interval for <span class="math inline">\(\theta\)</span> if
<span class="math display">\[
\Pr \left( \widehat{\theta }_1 &lt; \theta &lt; \widehat{\theta }_{2}\right) \geq 1-\alpha .
\]</span>
For example, suppose that <span class="math inline">\(y_1,\ldots,y_n\)</span> are i.i.d. <span class="math inline">\(N(\mu ,\sigma^2)\)</span> random variables. Recall that <span class="math inline">\(\sqrt{n}\left( \overline{y}-\mu\right) /s_y\sim t_{n-1}\)</span>. This fact allows us to develop a <span class="math inline">\(100(1-\alpha )\%\)</span> confidence interval for <span class="math inline">\(\mu\)</span> of the form <span class="math inline">\(\overline{y}\pm (t-value)s_y/ \sqrt{n}\)</span>, where <span class="math inline">\(t-value\)</span> is the <span class="math inline">\((1-\alpha /2)^{th}\)</span> percentile from a <span class="math inline">\(t\)</span>-distribution with <span class="math inline">\(n-1\)</span> degrees of freedom.</p>
<p><strong>Prediction Intervals.</strong> Prediction intervals have the same form as confidence intervals. However, a confidence interval provides a range for a parameter whereas a prediction interval provides a range for external values of the observations. Based on observations <span class="math inline">\(y_1,\ldots,y_n\)</span>, we seek to construct statistics <span class="math inline">\(\widehat{\theta }_1\)</span> and <span class="math inline">\(\widehat{\theta }_{2}\)</span> such that
<span class="math display">\[
\Pr \left( \widehat{\theta }_1 &lt; y^{\ast } &lt; \widehat{\theta }_{2}\right) \geq 1-\alpha .
\]</span>
Here, <span class="math inline">\(y^{\ast }\)</span> is an additional observation that is not a part of the sample.</p>
</div>
<div id="testing-hypotheses" class="section level3 unnumbered hasAnchor">
<h3>Testing Hypotheses<a href="appendices.html#testing-hypotheses" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p><strong>Null and Alternative Hypotheses and Test Statistics.</strong> An important statistical procedure involves verifying ideas about parameters. That is, before the data are observed, certain ideas about the parameters are formulated. In this text, we consider a <em>null hypothesis</em> of the form
<span class="math inline">\(H_0:\theta =\theta_0\)</span> versus an <em>alternative hypothesis</em>. We consider both a <em>two-sided alternative</em>, <span class="math inline">\(H_{a}:\theta \neq \theta_0\)</span>, and <em>one-sided alternatives</em>, either <span class="math inline">\(H_{a}:\theta &gt;\theta_0\)</span> or <span class="math inline">\(H_{a}:\theta &lt;\theta_0\)</span>. To choose between these competing hypotheses, we use a test statistic <span class="math inline">\(T_n\)</span> that is typically a point estimate of <span class="math inline">\(\theta\)</span> or a version that is rescaled to conform to a reference distribution under <span class="math inline">\(H_0\)</span>. For example, to test <span class="math inline">\(H_0:\mu =\mu_0\)</span>, we often use <span class="math inline">\(T_n= \overline{y}\)</span> or <span class="math inline">\(T_n=\sqrt{n}\left( \overline{y}-\mu_0\right) /s_y\)</span>. Note that the latter choice has a <span class="math inline">\(t_{n-1}\)</span> distribution, under the assumptions of i.i.d. normal data.</p>
<p><strong>Rejection Regions and Significance Level.</strong> With a statistic in hand, we now establish a criterion for deciding between the two competing hypotheses. This can be done by establishing a <em>rejection</em>, or <em>critical, region</em>. The critical region consists of all possible outcomes of <span class="math inline">\(T_n\)</span> that leads us to reject <span class="math inline">\(H_0\)</span> in favor of <span class="math inline">\(H_{a}\)</span>. In order to specify the critical region, we first quantify the types of errors that can be made in the decision-making procedure. A <em>Type I error</em> consists of rejecting <span class="math inline">\(H_0\)</span> falsely and a <em>Type II error</em> consists of rejecting <span class="math inline">\(H_{a}\)</span> falsely. The probability of a Type I error is called the <em>significance level</em>. Prespecifying the significance level is often enough to determine the critical region. For example, suppose that <span class="math inline">\(y_1,\ldots,y_n\)</span> are i.i.d. <span class="math inline">\(N(\mu ,\sigma^2)\)</span> and we are interested in deciding between <span class="math inline">\(H_0:\mu =\mu_0\)</span> and <span class="math inline">\(H_{a}:\mu &gt; \mu_0\)</span>. Thinking of our test statistic <span class="math inline">\(T_n=\overline{y}\)</span>, we know that we would like to reject <span class="math inline">\(H_0\)</span> if <span class="math inline">\(\overline{y}\)</span> is larger than <span class="math inline">\(\mu_0\)</span>. The question is how much larger? Specifying a significance level <span class="math inline">\(\alpha\)</span>, we wish to find a critical region of the form <span class="math inline">\(\{\overline{y}&gt;c\}\)</span> for some constant <span class="math inline">\(c\)</span>. To this end, we have
<span class="math display">\[
\begin{array}{ll}
\alpha  &amp;= \Pr \mathrm{(Type~I~error)} = \Pr (\mathrm{Reject~}H_0 \mathrm{~assuming~} H_0:\mu =\mu_0 \mathrm{~is~true)} \\
&amp; = \Pr (\overline{y}&gt;c) = \Pr \left(\sqrt{n}\left( \overline{y}-\mu_0\right)/s_y&gt;\sqrt{n}\left( c-\mu_0 \right)/s_y\right) \\
&amp;= \Pr \left(t_{n-1}&gt;\sqrt{n}\left( c-\mu_0 \right)/s_y\right).
\end{array}
\]</span></p>
<p>With <span class="math inline">\(df=n-1\)</span> degrees of freedom, we have that <span class="math inline">\(t-value = \sqrt{n}\left( c-\mu_0\right)/s_y\)</span> where the <span class="math inline">\(t-value\)</span> is the <span class="math inline">\((1-\alpha)^{th}\)</span> percentile from a <span class="math inline">\(t\)</span>-distribution. Thus, solving for <span class="math inline">\(c\)</span>, our critical region is of the form <span class="math inline">\(\{\overline{y} &gt; \mu_0 + (t-value)/s_y/\sqrt{n}\}\)</span>.</p>
<p><strong>Relationship between Confidence Intervals and Hypothesis Tests.</strong> Similar calculations show, for testing <span class="math inline">\(H_0:\mu = \mu_0\)</span> versus <span class="math inline">\(H_{a}:\theta \neq \theta_0\)</span>, that the critical region is of the form
<span class="math display">\[
\{ \overline{y} &gt; \mu_0 + (t-value)/s_y/\sqrt{n} ~\mathrm{or~} \overline{y} &gt; \mu_0 + (t-value)/s_y/\sqrt{n}\} .
\]</span>
Here, the <span class="math inline">\(t\)</span>-value is a <span class="math inline">\((1-\alpha /2)^{th}\)</span> percentile from a <span class="math inline">\(t\)</span>-distribution with <span class="math inline">\(df=n-1\)</span> degrees of freedom. It is interesting to note that the event of falling in this two-sided critical region is equivalent to the event of <span class="math inline">\(\mu_0\)</span> falling outside the confidence interval <span class="math inline">\(\overline{y}\pm (t-value)s_y/\sqrt{n}\)</span>. This establishes the fact that confidence intervals and hypothesis tests are really reporting the same evidence with different emphasis on interpretation of the statistical inference.</p>
<p><strong><span class="math inline">\(p\)</span>-value.</strong> Another useful concept in hypothesis testing is the <span class="math inline">\(p\)</span>-value, which is short for <em>probability value</em>. For a data set, a <span class="math inline">\(p\)</span>-value is defined to be the smallest significance level for which the null hypothesis would be rejected. The <span class="math inline">\(p\)</span>-value is a useful summary statistic for the data analyst to report since it allows the reader to understand the strength of the deviation from the null hypothesis.</p>
</div>
</div>
<div id="appendix-a2.-matrix-algebra" class="section level2 unnumbered hasAnchor">
<h2>Appendix A2. Matrix Algebra<a href="appendices.html#appendix-a2.-matrix-algebra" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<div id="basic-definitions" class="section level3 unnumbered hasAnchor">
<h3>Basic Definitions<a href="appendices.html#basic-definitions" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<ul>
<li><p><em>Matrix</em> - a rectangular array of numbers arranged in rows and columns (the plural of matrix is matrices).</p></li>
<li><p><em>Dimension</em> of the matrix - the number of rows and columns of the matrix.</p></li>
<li><p>Consider a matrix <span class="math inline">\(\mathbf{A}\)</span> that has dimension <span class="math inline">\(m \times k\)</span>. Let <span class="math inline">\(a_{ij}\)</span> be the symbol for the number in the <span class="math inline">\(i\)</span>th row and <span class="math inline">\(j\)</span>th column of <span class="math inline">\(\mathbf{A}\)</span>. In general, we work with matrices of the form
<span class="math display">\[
\mathbf{A} = \left(
\begin{array}{cccc}
a_{11} &amp; a_{12} &amp; \cdots &amp; a_{1k} \\
a_{21} &amp; a_{22} &amp; \cdots &amp; a_{2k} \\
\vdots &amp; \vdots &amp; \ddots &amp; \vdots \\
a_{m1} &amp; a_{m2} &amp; \cdots &amp; a_{mk}
\end{array}
\right) .
\]</span></p></li>
<li><p><em>Vector</em> - a (column) vector is a matrix containing only one row (<span class="math inline">\(m=1\)</span>).</p></li>
<li><p><em>Row vector</em> - a matrix containing only one column (<span class="math inline">\(k=1\)</span>).</p></li>
<li><p><em>Transpose</em> - transpose of a matrix <span class="math inline">\(\mathbf{A}\)</span> is defined by interchanging the rows and columns and is denoted by <span class="math inline">\(\mathbf{A}^{\prime}\)</span> (or <span class="math inline">\(\mathbf{A}^{\mathrm{T}}\)</span>). Thus, if <span class="math inline">\(\mathbf{A}\)</span> has dimension <span class="math inline">\(m \times k\)</span>, then <span class="math inline">\(\mathbf{A}^{\prime}\)</span> has dimension <span class="math inline">\(k \times m\)</span>.</p></li>
<li><p><em>Square matrix</em> - a matrix where the number of rows equals the number of columns, that is, <span class="math inline">\(m=k\)</span>.</p></li>
<li><p><em>Diagonal element</em> – the number in the <span class="math inline">\(r\)</span>th row and column of a square matrix, <span class="math inline">\(r=1,2,\ldots\)</span></p></li>
<li><p><em>Diagonal matrix</em> - a square matrix where all non-diagonal numbers are equal to zero.</p></li>
<li><p><em>Identity matrix</em> - a diagonal matrix where all the diagonal elements are equal to one and is denoted by <span class="math inline">\(\mathbf{I}\)</span>.</p></li>
<li><p><em>Symmetric matrix</em> - a square matrix <span class="math inline">\(\mathbf{A}\)</span> such that the matrix remains unchanged if we interchange the roles of the rows and columns, that is, if <span class="math inline">\(\mathbf{A} = \mathbf{A}^{\prime}\)</span>. Note that a diagonal matrix is a symmetric matrix.</p></li>
</ul>
</div>
<div id="review-of-basic-operations" class="section level3 unnumbered hasAnchor">
<h3>Review of Basic Operations<a href="appendices.html#review-of-basic-operations" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<ul>
<li><p><em>Scalar multiplication</em>. Let <span class="math inline">\(c\)</span> be a real number, called a <em>scalar</em> (a <span class="math inline">\(1 \times 1\)</span> matrix). Multiplying a scalar <span class="math inline">\(c\)</span> by a matrix <span class="math inline">\(\mathbf{A}\)</span> is denoted by <span class="math inline">\(c \mathbf{A}\)</span> and defined by
<span class="math display">\[
c\mathbf{A} = \left(
\begin{array}{cccc}
ca_{11} &amp; ca_{12} &amp; \cdots &amp; ca_{1k} \\
ca_{21} &amp; ca_{22} &amp; \cdots &amp; ca_{2k} \\
\vdots &amp; \vdots &amp; \ddots &amp; \vdots \\
ca_{m1} &amp; ca_{m2} &amp; \cdots &amp; ca_{mk}
\end{array}
\right) .
\]</span></p></li>
<li><p><em>Matrix addition and subtraction</em>. Let <span class="math inline">\(\mathbf{A}\)</span> and <span class="math inline">\(\mathbf{B}\)</span> be matrices, each with dimension <span class="math inline">\(m \times k\)</span>. Use <span class="math inline">\(a_{ij}\)</span> and <span class="math inline">\(b_{ij}\)</span> to denote the numbers in the <span class="math inline">\(i\)</span>th row and <span class="math inline">\(j\)</span>th column of <span class="math inline">\(\mathbf{A}\)</span> and <span class="math inline">\(\mathbf{B}\)</span>, respectively. Then, the matrix <span class="math inline">\(\mathbf{C} = \mathbf{A} + \mathbf{B}\)</span> is defined to be the matrix with the number <span class="math inline">\((a_{ij} + b_{ij})\)</span> to denote the number in the <span class="math inline">\(i\)</span>th row and <span class="math inline">\(j\)</span>th column. Similarly, the matrix <span class="math inline">\(\mathbf{C} = \mathbf{A} - \mathbf{B}\)</span> is defined to be the matrix with the number <span class="math inline">\((a_{ij} - b_{ij})\)</span> to denote the numbers in the <span class="math inline">\(i\)</span>th row and <span class="math inline">\(j\)</span>th column.</p></li>
<li><p><em>Matrix multiplication</em>. If <span class="math inline">\(\mathbf{A}\)</span> is a matrix of dimension <span class="math inline">\(m \times c\)</span> and <span class="math inline">\(\mathbf{B}\)</span> is a matrix of dimension <span class="math inline">\(c \times k\)</span>, then <span class="math inline">\(\mathbf{C} = \mathbf{A} \mathbf{B}\)</span> is a matrix of dimension <span class="math inline">\(m \times k\)</span>. The number in the <span class="math inline">\(i\)</span>th row and <span class="math inline">\(j\)</span>th column of <span class="math inline">\(\mathbf{C}\)</span> is <span class="math inline">\(\sum_{s=1}^c a_{is} b_{sj}\)</span>.</p></li>
<li><p><em>Determinant</em> - a function of a square matrix, denoted by <span class="math inline">\(\mathrm{det}(\mathbf{A})\)</span>, or <span class="math inline">\(|\mathbf{A}|\)</span>. For a <span class="math inline">\(1 \times 1\)</span> matrix, the determinant is <span class="math inline">\(\mathrm{det}(\mathbf{A}) = a_{11}\)</span>. To define determinants for larger matrices, we need two additional concepts. Let <span class="math inline">\(\mathbf{A}_{rs}\)</span> be the <span class="math inline">\((m-1) \times (m-1)\)</span> submatrix of <span class="math inline">\(\mathbf{A}\)</span> defined by removing the <span class="math inline">\(r\)</span>th row and <span class="math inline">\(s\)</span>th column. Recursively, define <span class="math inline">\(\mathrm{det}(\mathbf{A}) = \sum_{s=1}^m (-1)^{r+s} a_{rs} \mathrm{det}(\mathbf{A}_{rs})\)</span>, for any <span class="math inline">\(r=1,\ldots,m\)</span>. For example, for <span class="math inline">\(m=2\)</span>, we have <span class="math inline">\(\mathrm{det}(\mathbf{A}) = a_{11}a_{22} - a_{12}a_{21}\)</span>.</p></li>
<li><p><em>Matrix inverse</em>. In matrix algebra, there is no concept of division. Instead, we extend the concept of reciprocals of real numbers. To begin, suppose that <span class="math inline">\(\mathbf{A}\)</span> is a square matrix of dimension <span class="math inline">\(m \times m\)</span> such that <span class="math inline">\(\mathrm{det}(\mathbf{A}) \neq 0\)</span>. Further, let <span class="math inline">\(\mathbf{I}\)</span> be the <span class="math inline">\(m \times m\)</span> identity matrix. If there exists a <span class="math inline">\(m \times m\)</span> matrix <span class="math inline">\(\mathbf{B}\)</span> such that <span class="math inline">\(\mathbf{AB = I = BA}\)</span>, then <span class="math inline">\(\mathbf{B}\)</span> is called the <em>inverse</em> of <span class="math inline">\(\mathbf{A}\)</span> and is written as <span class="math inline">\(\mathbf{B} = \mathbf{A}^{-1}\)</span>.</p></li>
</ul>
</div>
<div id="further-definitions" class="section level3 unnumbered hasAnchor">
<h3>Further Definitions<a href="appendices.html#further-definitions" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<ul>
<li><p><em>Linearly dependent vectors</em> – a set of vectors <span class="math inline">\(\mathbf{c}_{1},\ldots,\mathbf{c}_{k}\)</span> is said to be linearly dependent if one of the vectors in the set can be written as a linear combination of the others.</p></li>
<li><p><em>Linearly independent vectors</em> – a set of vectors <span class="math inline">\(\mathbf{c}_{1},\ldots,\mathbf{c}_{k}\)</span> is said to be linearly independent if they are not linearly dependent. Specifically, a set of vectors <span class="math inline">\(\mathbf{c}_{1},\ldots,\mathbf{c}_{k}\)</span> is said to be linearly independent if and only if the only solution of the equation <span class="math inline">\(x_{1}\mathbf{c}_{1} + \ldots + x_{k}\mathbf{c}_{k} = 0\)</span> is <span class="math inline">\(x_{1} = \ldots = x_{k} = 0\)</span>.</p></li>
<li><p><em>Rank of a matrix</em> – the largest number of linearly independent columns (or rows) of a matrix.</p></li>
<li><p><em>Singular matrix</em> – a square matrix <span class="math inline">\(\mathbf{A}\)</span> such that <span class="math inline">\(\mathrm{det}(\mathbf{A}) = 0\)</span>.</p></li>
<li><p><em>Non-singular matrix</em> – a square matrix <span class="math inline">\(\mathbf{A}\)</span> such that <span class="math inline">\(\mathrm{det}(\mathbf{A}) \neq 0\)</span>.</p></li>
<li><p><em>Positive definite matrix</em> – a symmetric square matrix <span class="math inline">\(\mathbf{A}\)</span> such that <span class="math inline">\(\mathbf{x}^{\prime}\mathbf{Ax} &gt; 0\)</span> for <span class="math inline">\(\mathbf{x} \neq 0\)</span>.</p></li>
<li><p><em>Non-negative definite matrix</em> – a symmetric square matrix <span class="math inline">\(\mathbf{A}\)</span> such that <span class="math inline">\(\mathbf{x}^{\prime}\mathbf{Ax} \geq 0\)</span> for <span class="math inline">\(\mathbf{x} \neq 0\)</span>.</p></li>
<li><p><em>Orthogonal</em> – two matrices <span class="math inline">\(\mathbf{A}\)</span> and <span class="math inline">\(\mathbf{B}\)</span> are orthogonal if <span class="math inline">\(\mathbf{A}^{\prime}\mathbf{B} = 0\)</span>, a zero matrix.</p></li>
<li><p><em>Idempotent</em> – a square matrix such that <span class="math inline">\(\mathbf{AA = A}\)</span>.</p></li>
<li><p><em>Trace</em> – the sum of all diagonal elements of a square matrix.</p></li>
<li><p><em>Eigenvalues</em> – the solutions of the <span class="math inline">\(n\)</span>th degree polynomial <span class="math inline">\(\mathrm{det}(\mathbf{A} - \lambda \mathbf{I}) = 0\)</span>. Also known as <em>characteristic roots</em> and <em>latent roots</em>.</p></li>
<li><p><em>Eigenvector</em> – a vector <span class="math inline">\(\mathbf{x}\)</span> such that <span class="math inline">\(\mathbf{Ax} = \lambda \mathbf{x}\)</span>, where <span class="math inline">\(\lambda\)</span> is an eigenvalue of <span class="math inline">\(\mathbf{A}\)</span>. Also known as a <em>characteristic vector</em> and <em>latent vector</em>.</p></li>
<li><p><em>Generalized inverse</em> - of a matrix <span class="math inline">\(\mathbf{A}\)</span> is a matrix <span class="math inline">\(\mathbf{B}\)</span> such that <span class="math inline">\(\mathbf{ABA = A}\)</span>. We use the notation <span class="math inline">\(\mathbf{A}^{-}\)</span> to denote the generalized inverse of <span class="math inline">\(\mathbf{A}\)</span>. In the case that <span class="math inline">\(\mathbf{A}\)</span> is invertible, then <span class="math inline">\(\mathbf{A}^{-}\)</span> is unique and equals <span class="math inline">\(\mathbf{A}^{-1}\)</span>. Although there are several definitions of generalized inverses, the above definition suffices for our purposes. See Searle (1987) for further discussion of alternative definitions of generalized inverses.</p></li>
<li><p><em>Gradient vector</em> – a vector of partial derivatives. If <span class="math inline">\(\mathrm{f}(.)\)</span> is a function of the vector <span class="math inline">\(\mathbf{x} = (x_1,\ldots,x_m)^{\prime}\)</span>, then the gradient vector is <span class="math inline">\(\partial \mathrm{f}(\mathbf{x})/\partial \mathbf{x}\)</span>. The <span class="math inline">\(i\)</span>th row of the gradient vector is <span class="math inline">\(\partial \mathrm{f}(\mathbf{x})/\partial x_i\)</span>.</p></li>
<li><p><em>Hessian matrix</em> – a matrix of second derivatives. If <span class="math inline">\(\mathrm{f}(.)\)</span> is a function of the vector <span class="math inline">\(\mathbf{x} = (x_1,\ldots,x_m)^{\prime}\)</span>, then the Hessian matrix is <span class="math inline">\(\partial^2 \mathrm{f}(\mathbf{x})/\partial \mathbf{x}\partial \mathbf{x}^{\prime}\)</span>. The element in the <span class="math inline">\(i\)</span>th row and <span class="math inline">\(j\)</span>th column of the Hessian matrix is <span class="math inline">\(\partial^{2}\mathrm{f}(\mathbf{x})/\partial x_i\partial x_j\)</span>.</p></li>
</ul>
</div>
</div>
<div id="appendix-a3.-probability-tables" class="section level2 unnumbered hasAnchor">
<h2>Appendix A3. Probability Tables<a href="appendices.html#appendix-a3.-probability-tables" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<div id="normal-distribution" class="section level3 unnumbered hasAnchor">
<h3>Normal Distribution<a href="appendices.html#normal-distribution" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Recall from equation (1.1) that the probability density function is defined by
<span class="math display">\[
\mathrm{f}(y) = \frac{1}{\sigma \sqrt{2\pi }}\exp \left( -\frac{1}{2\sigma^2 }\left( y-\mu \right)^2\right)
\]</span>
where <span class="math inline">\(\mu\)</span> and <span class="math inline">\(\sigma^2\)</span> are parameters that describe the curve. In this case, we write <span class="math inline">\(y \sim N(\mu,\sigma^2)\)</span>. Straightforward calculations show that
<span class="math display">\[
\mathrm{E}~y = \int_{-\infty}^{\infty} y \mathrm{f}(y) \, dy = \int_{-\infty}^{\infty}  y \frac{1}{\sigma \sqrt{2\pi }}\exp \left( -\frac{1}{2\sigma^2 }\left( y-\mu \right)^2 \right)  \, dy  = \mu
\]</span>
and
<span class="math display">\[
\mathrm{Var}~y = \int_{-\infty}^{\infty} (y-\mu)^2 \mathrm{f}(y) \, dy = \int_{-\infty}^{\infty} (y-\mu)^2 \frac{1}{\sigma \sqrt{2\pi }}\exp \left( -\frac{1}{2\sigma^2 }\left( y-\mu \right)^2 \right) \, dy = \sigma^2 .
\]</span>
Thus, the notation <span class="math inline">\(y \sim N(\mu,\sigma^2)\)</span> is interpreted to mean the random variable is distributed normally with mean <span class="math inline">\(\mu\)</span> and variance <span class="math inline">\(\sigma^2\)</span>. If <span class="math inline">\(y \sim N(0,1)\)</span>, then <span class="math inline">\(y\)</span> is said to be <em>standard normal</em>.</p>

<div class="figure" style="text-align: center"><span style="display:block;" id="fig:FigA1"></span>
<img src="RegressionMarkdown_files/figure-html/FigA1-1.png" alt="Standard normal probability density function" width="60%" />
<p class="caption">
Figure 22.1: <strong>Standard normal probability density function</strong>
</p>
</div>
<table style="width:100%;">
<caption><span id="tab:unnamed-chunk-676">Table 22.1: </span><strong>Standard Normal Distribution Function</strong></caption>
<colgroup>
<col width="4%" />
<col width="9%" />
<col width="9%" />
<col width="9%" />
<col width="9%" />
<col width="9%" />
<col width="9%" />
<col width="9%" />
<col width="9%" />
<col width="9%" />
<col width="9%" />
</colgroup>
<thead>
<tr class="header">
<th align="right">x</th>
<th align="right">0.0</th>
<th align="right">0.1</th>
<th align="right">0.2</th>
<th align="right">0.3</th>
<th align="right">0.4</th>
<th align="right">0.5</th>
<th align="right">0.6</th>
<th align="right">0.7</th>
<th align="right">0.8</th>
<th align="right">0.9</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="right">0</td>
<td align="right">0.5000</td>
<td align="right">0.5398</td>
<td align="right">0.5793</td>
<td align="right">0.6179</td>
<td align="right">0.6554</td>
<td align="right">0.6915</td>
<td align="right">0.7257</td>
<td align="right">0.7580</td>
<td align="right">0.7881</td>
<td align="right">0.8159</td>
</tr>
<tr class="even">
<td align="right">1</td>
<td align="right">0.8413</td>
<td align="right">0.8643</td>
<td align="right">0.8849</td>
<td align="right">0.9032</td>
<td align="right">0.9192</td>
<td align="right">0.9332</td>
<td align="right">0.9452</td>
<td align="right">0.9554</td>
<td align="right">0.9641</td>
<td align="right">0.9713</td>
</tr>
<tr class="odd">
<td align="right">2</td>
<td align="right">0.9772</td>
<td align="right">0.9821</td>
<td align="right">0.9861</td>
<td align="right">0.9893</td>
<td align="right">0.9918</td>
<td align="right">0.9938</td>
<td align="right">0.9953</td>
<td align="right">0.9965</td>
<td align="right">0.9974</td>
<td align="right">0.9981</td>
</tr>
<tr class="even">
<td align="right">3</td>
<td align="right">0.9987</td>
<td align="right">0.9990</td>
<td align="right">0.9993</td>
<td align="right">0.9995</td>
<td align="right">0.9997</td>
<td align="right">0.9998</td>
<td align="right">0.9998</td>
<td align="right">0.9999</td>
<td align="right">0.9999</td>
<td align="right">1.0000</td>
</tr>
</tbody>
</table>
<p><em>Notes</em>: Probabilities can be found by looking at the appropriate row for the lead digit and column for the decimal. For example, <span class="math inline">\(\Pr ( y \le 0.1) = 0.5398\)</span>.</p>
</div>
<div id="chi-square-distribution" class="section level3 unnumbered hasAnchor">
<h3>Chi-Square Distribution<a href="appendices.html#chi-square-distribution" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p><strong>Chi-Square Distribution</strong>. Several important distributions can be linked to the normal distribution. If <span class="math inline">\(y_1, \ldots, y_n\)</span> are i.i.d. random variables such that each <span class="math inline">\(y_i \sim N(0,1)\)</span>, then <span class="math inline">\(\sum_{i=1}^n y_i^2\)</span> is said to have a <em>chi-square distribution</em> with parameter <span class="math inline">\(n\)</span>. More generally, a random variable <span class="math inline">\(w\)</span> with probability density function
<span class="math display">\[
\mathrm{f}(w) = \frac{2^{-k/2}}{\Gamma(k/2)} w^{k/2-1} \exp (-w/2), ~~~~~~w &gt; 0
\]</span>
is said to have a chi-square with <span class="math inline">\(df = k\)</span> degrees of freedom, written <span class="math inline">\(w \sim \chi_k^2\)</span>. Easy calculations show that for <span class="math inline">\(w \sim \chi_k^2\)</span>, we have <span class="math inline">\(\mathrm{E}~w = k\)</span> and <span class="math inline">\(\mathrm{Var}~w = 2k\)</span>. In general, the degrees of freedom parameter need not be an integer, although it is for the applications of this text.</p>

<div class="figure" style="text-align: center"><span style="display:block;" id="fig:FigA2"></span>
<img src="RegressionMarkdown_files/figure-html/FigA2-1.png" alt="Several chi-square probability density functions. Shown are curves for \(df\) = 3, \(df\) = 5, and \(df\) = 10. Greater degrees of freedom lead to curves that are less skewed." width="60%" />
<p class="caption">
Figure 22.2: <strong>Several chi-square probability density functions.</strong> Shown are curves for <span class="math inline">\(df\)</span> = 3, <span class="math inline">\(df\)</span> = 5, and <span class="math inline">\(df\)</span> = 10. Greater degrees of freedom lead to curves that are less skewed.
</p>
</div>
<table style="width:100%;">
<caption><span id="tab:unnamed-chunk-677">Table 22.2: </span><strong>Percentiles from Several Chi-Square Distributions</strong></caption>
<colgroup>
<col width="5%" />
<col width="9%" />
<col width="9%" />
<col width="9%" />
<col width="9%" />
<col width="9%" />
<col width="9%" />
<col width="9%" />
<col width="9%" />
<col width="9%" />
<col width="9%" />
</colgroup>
<thead>
<tr class="header">
<th align="right">df</th>
<th align="right">0.6</th>
<th align="right">0.7</th>
<th align="right">0.8</th>
<th align="right">0.9</th>
<th align="right">0.95</th>
<th align="right">0.975</th>
<th align="right">0.99</th>
<th align="right">0.995</th>
<th align="right">0.9975</th>
<th align="right">0.999</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="right">1</td>
<td align="right">0.71</td>
<td align="right">1.07</td>
<td align="right">1.64</td>
<td align="right">2.71</td>
<td align="right">3.84</td>
<td align="right">5.02</td>
<td align="right">6.63</td>
<td align="right">7.88</td>
<td align="right">9.14</td>
<td align="right">10.83</td>
</tr>
<tr class="even">
<td align="right">2</td>
<td align="right">1.83</td>
<td align="right">2.41</td>
<td align="right">3.22</td>
<td align="right">4.61</td>
<td align="right">5.99</td>
<td align="right">7.38</td>
<td align="right">9.21</td>
<td align="right">10.60</td>
<td align="right">11.98</td>
<td align="right">13.82</td>
</tr>
<tr class="odd">
<td align="right">3</td>
<td align="right">2.95</td>
<td align="right">3.66</td>
<td align="right">4.64</td>
<td align="right">6.25</td>
<td align="right">7.81</td>
<td align="right">9.35</td>
<td align="right">11.34</td>
<td align="right">12.84</td>
<td align="right">14.32</td>
<td align="right">16.27</td>
</tr>
<tr class="even">
<td align="right">4</td>
<td align="right">4.04</td>
<td align="right">4.88</td>
<td align="right">5.99</td>
<td align="right">7.78</td>
<td align="right">9.49</td>
<td align="right">11.14</td>
<td align="right">13.28</td>
<td align="right">14.86</td>
<td align="right">16.42</td>
<td align="right">18.47</td>
</tr>
<tr class="odd">
<td align="right">5</td>
<td align="right">5.13</td>
<td align="right">6.06</td>
<td align="right">7.29</td>
<td align="right">9.24</td>
<td align="right">11.07</td>
<td align="right">12.83</td>
<td align="right">15.09</td>
<td align="right">16.75</td>
<td align="right">18.39</td>
<td align="right">20.52</td>
</tr>
<tr class="even">
<td align="right">10</td>
<td align="right">10.47</td>
<td align="right">11.78</td>
<td align="right">13.44</td>
<td align="right">15.99</td>
<td align="right">18.31</td>
<td align="right">20.48</td>
<td align="right">23.21</td>
<td align="right">25.19</td>
<td align="right">27.11</td>
<td align="right">29.59</td>
</tr>
<tr class="odd">
<td align="right">15</td>
<td align="right">15.73</td>
<td align="right">17.32</td>
<td align="right">19.31</td>
<td align="right">22.31</td>
<td align="right">25.00</td>
<td align="right">27.49</td>
<td align="right">30.58</td>
<td align="right">32.80</td>
<td align="right">34.95</td>
<td align="right">37.70</td>
</tr>
<tr class="even">
<td align="right">20</td>
<td align="right">20.95</td>
<td align="right">22.77</td>
<td align="right">25.04</td>
<td align="right">28.41</td>
<td align="right">31.41</td>
<td align="right">34.17</td>
<td align="right">37.57</td>
<td align="right">40.00</td>
<td align="right">42.34</td>
<td align="right">45.31</td>
</tr>
<tr class="odd">
<td align="right">25</td>
<td align="right">26.14</td>
<td align="right">28.17</td>
<td align="right">30.68</td>
<td align="right">34.38</td>
<td align="right">37.65</td>
<td align="right">40.65</td>
<td align="right">44.31</td>
<td align="right">46.93</td>
<td align="right">49.44</td>
<td align="right">52.62</td>
</tr>
<tr class="even">
<td align="right">30</td>
<td align="right">31.32</td>
<td align="right">33.53</td>
<td align="right">36.25</td>
<td align="right">40.26</td>
<td align="right">43.77</td>
<td align="right">46.98</td>
<td align="right">50.89</td>
<td align="right">53.67</td>
<td align="right">56.33</td>
<td align="right">59.70</td>
</tr>
<tr class="odd">
<td align="right">35</td>
<td align="right">36.47</td>
<td align="right">38.86</td>
<td align="right">41.78</td>
<td align="right">46.06</td>
<td align="right">49.80</td>
<td align="right">53.20</td>
<td align="right">57.34</td>
<td align="right">60.27</td>
<td align="right">63.08</td>
<td align="right">66.62</td>
</tr>
<tr class="even">
<td align="right">40</td>
<td align="right">41.62</td>
<td align="right">44.16</td>
<td align="right">47.27</td>
<td align="right">51.81</td>
<td align="right">55.76</td>
<td align="right">59.34</td>
<td align="right">63.69</td>
<td align="right">66.77</td>
<td align="right">69.70</td>
<td align="right">73.40</td>
</tr>
<tr class="odd">
<td align="right">60</td>
<td align="right">62.13</td>
<td align="right">65.23</td>
<td align="right">68.97</td>
<td align="right">74.40</td>
<td align="right">79.08</td>
<td align="right">83.30</td>
<td align="right">88.38</td>
<td align="right">91.95</td>
<td align="right">95.34</td>
<td align="right">99.61</td>
</tr>
<tr class="even">
<td align="right">120</td>
<td align="right">123.29</td>
<td align="right">127.62</td>
<td align="right">132.81</td>
<td align="right">140.23</td>
<td align="right">146.57</td>
<td align="right">152.21</td>
<td align="right">158.95</td>
<td align="right">163.65</td>
<td align="right">168.08</td>
<td align="right">173.62</td>
</tr>
</tbody>
</table>
</div>
<div id="t-distribution" class="section level3 unnumbered hasAnchor">
<h3><em>t</em>-Distribution<a href="appendices.html#t-distribution" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Suppose that <span class="math inline">\(y\)</span> and <span class="math inline">\(w\)</span> are independent with <span class="math inline">\(y \sim N(0,1)\)</span> and <span class="math inline">\(w \sim \chi_k^2\)</span>. Then, the random variable <span class="math inline">\(t = y / \sqrt{w/k}\)</span> is said to have a <span class="math inline">\(t\)</span>-distribution with <span class="math inline">\(df = k\)</span> degrees of freedom. The probability density function is
<span class="math display">\[
\mathrm{f}(t) = \frac{\Gamma \left( k+ \frac{1}{2} \right)}{\Gamma(k/2)} \left( k \pi \right)^{-1/2} \left( 1 + \frac{t^2}{k} \right)^{-(k+1/2)}, ~~~~~~-\infty &lt; t &lt; \infty
\]</span>
This has mean 0, for <span class="math inline">\(k &gt; 1\)</span>, and variance <span class="math inline">\(k/(k-2)\)</span> for <span class="math inline">\(k &gt; 2\)</span>.</p>

<div class="figure" style="text-align: center"><span style="display:block;" id="fig:FigA3"></span>
<img src="RegressionMarkdown_files/figure-html/FigA3-1.png" alt="Several \(t\)-distribution probability density functions. The \(t\)-distribution with \(df = \infty\) is the standard normal distribution. Shown are curves for \(df\) = 1, \(df\) = 5 (not labeled), and \(df\) = ∞. A lower \(df\) means fatter tails." width="60%" />
<p class="caption">
Figure 22.3: <strong>Several <span class="math inline">\(t\)</span>-distribution probability density functions.</strong> The <span class="math inline">\(t\)</span>-distribution with <span class="math inline">\(df = \infty\)</span> is the standard normal distribution. Shown are curves for <span class="math inline">\(df\)</span> = 1, <span class="math inline">\(df\)</span> = 5 (not labeled), and <span class="math inline">\(df\)</span> = ∞. A lower <span class="math inline">\(df\)</span> means fatter tails.
</p>
</div>
<table style="width:100%;">
<caption><span id="tab:unnamed-chunk-678">Table 22.3: </span><strong>Percentiles from Several <span class="math inline">\(t-\)</span>Distributions</strong></caption>
<colgroup>
<col width="5%" />
<col width="8%" />
<col width="8%" />
<col width="8%" />
<col width="8%" />
<col width="8%" />
<col width="9%" />
<col width="9%" />
<col width="9%" />
<col width="11%" />
<col width="11%" />
</colgroup>
<thead>
<tr class="header">
<th align="left">df</th>
<th align="right">0.6</th>
<th align="right">0.7</th>
<th align="right">0.8</th>
<th align="right">0.9</th>
<th align="right">0.95</th>
<th align="right">0.975</th>
<th align="right">0.99</th>
<th align="right">0.995</th>
<th align="right">0.9975</th>
<th align="right">0.999</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">1</td>
<td align="right">0.325</td>
<td align="right">0.727</td>
<td align="right">1.376</td>
<td align="right">3.078</td>
<td align="right">6.314</td>
<td align="right">12.706</td>
<td align="right">31.821</td>
<td align="right">63.657</td>
<td align="right">127.321</td>
<td align="right">318.309</td>
</tr>
<tr class="even">
<td align="left">2</td>
<td align="right">0.289</td>
<td align="right">0.617</td>
<td align="right">1.061</td>
<td align="right">1.886</td>
<td align="right">2.920</td>
<td align="right">4.303</td>
<td align="right">6.965</td>
<td align="right">9.925</td>
<td align="right">14.089</td>
<td align="right">22.327</td>
</tr>
<tr class="odd">
<td align="left">3</td>
<td align="right">0.277</td>
<td align="right">0.584</td>
<td align="right">0.978</td>
<td align="right">1.638</td>
<td align="right">2.353</td>
<td align="right">3.182</td>
<td align="right">4.541</td>
<td align="right">5.841</td>
<td align="right">7.453</td>
<td align="right">10.215</td>
</tr>
<tr class="even">
<td align="left">4</td>
<td align="right">0.271</td>
<td align="right">0.569</td>
<td align="right">0.941</td>
<td align="right">1.533</td>
<td align="right">2.132</td>
<td align="right">2.776</td>
<td align="right">3.747</td>
<td align="right">4.604</td>
<td align="right">5.598</td>
<td align="right">7.173</td>
</tr>
<tr class="odd">
<td align="left">5</td>
<td align="right">0.267</td>
<td align="right">0.559</td>
<td align="right">0.920</td>
<td align="right">1.476</td>
<td align="right">2.015</td>
<td align="right">2.571</td>
<td align="right">3.365</td>
<td align="right">4.032</td>
<td align="right">4.773</td>
<td align="right">5.893</td>
</tr>
<tr class="even">
<td align="left">10</td>
<td align="right">0.260</td>
<td align="right">0.542</td>
<td align="right">0.879</td>
<td align="right">1.372</td>
<td align="right">1.812</td>
<td align="right">2.228</td>
<td align="right">2.764</td>
<td align="right">3.169</td>
<td align="right">3.581</td>
<td align="right">4.144</td>
</tr>
<tr class="odd">
<td align="left">15</td>
<td align="right">0.258</td>
<td align="right">0.536</td>
<td align="right">0.866</td>
<td align="right">1.341</td>
<td align="right">1.753</td>
<td align="right">2.131</td>
<td align="right">2.602</td>
<td align="right">2.947</td>
<td align="right">3.286</td>
<td align="right">3.733</td>
</tr>
<tr class="even">
<td align="left">20</td>
<td align="right">0.257</td>
<td align="right">0.533</td>
<td align="right">0.860</td>
<td align="right">1.325</td>
<td align="right">1.725</td>
<td align="right">2.086</td>
<td align="right">2.528</td>
<td align="right">2.845</td>
<td align="right">3.153</td>
<td align="right">3.552</td>
</tr>
<tr class="odd">
<td align="left">25</td>
<td align="right">0.256</td>
<td align="right">0.531</td>
<td align="right">0.856</td>
<td align="right">1.316</td>
<td align="right">1.708</td>
<td align="right">2.060</td>
<td align="right">2.485</td>
<td align="right">2.787</td>
<td align="right">3.078</td>
<td align="right">3.450</td>
</tr>
<tr class="even">
<td align="left">30</td>
<td align="right">0.256</td>
<td align="right">0.530</td>
<td align="right">0.854</td>
<td align="right">1.310</td>
<td align="right">1.697</td>
<td align="right">2.042</td>
<td align="right">2.457</td>
<td align="right">2.750</td>
<td align="right">3.030</td>
<td align="right">3.385</td>
</tr>
<tr class="odd">
<td align="left">35</td>
<td align="right">0.255</td>
<td align="right">0.529</td>
<td align="right">0.852</td>
<td align="right">1.306</td>
<td align="right">1.690</td>
<td align="right">2.030</td>
<td align="right">2.438</td>
<td align="right">2.724</td>
<td align="right">2.996</td>
<td align="right">3.340</td>
</tr>
<tr class="even">
<td align="left">40</td>
<td align="right">0.255</td>
<td align="right">0.529</td>
<td align="right">0.851</td>
<td align="right">1.303</td>
<td align="right">1.684</td>
<td align="right">2.021</td>
<td align="right">2.423</td>
<td align="right">2.704</td>
<td align="right">2.971</td>
<td align="right">3.307</td>
</tr>
<tr class="odd">
<td align="left">60</td>
<td align="right">0.254</td>
<td align="right">0.527</td>
<td align="right">0.848</td>
<td align="right">1.296</td>
<td align="right">1.671</td>
<td align="right">2.000</td>
<td align="right">2.390</td>
<td align="right">2.660</td>
<td align="right">2.915</td>
<td align="right">3.232</td>
</tr>
<tr class="even">
<td align="left">120</td>
<td align="right">0.254</td>
<td align="right">0.526</td>
<td align="right">0.845</td>
<td align="right">1.289</td>
<td align="right">1.658</td>
<td align="right">1.980</td>
<td align="right">2.358</td>
<td align="right">2.617</td>
<td align="right">2.860</td>
<td align="right">3.160</td>
</tr>
<tr class="odd">
<td align="left">∞</td>
<td align="right">0.253</td>
<td align="right">0.524</td>
<td align="right">0.842</td>
<td align="right">1.282</td>
<td align="right">1.645</td>
<td align="right">1.960</td>
<td align="right">2.326</td>
<td align="right">2.576</td>
<td align="right">2.807</td>
<td align="right">3.090</td>
</tr>
</tbody>
</table>
</div>
<div id="f-distribution" class="section level3 unnumbered hasAnchor">
<h3><em>F</em>-Distribution<a href="appendices.html#f-distribution" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Suppose that <span class="math inline">\(w_1\)</span> and <span class="math inline">\(w_2\)</span> are independent with distributions <span class="math inline">\(w_1 \sim \chi_m^2\)</span> and <span class="math inline">\(w_2 \sim \chi_n^2\)</span>. Then, the random variable <span class="math inline">\(F = (w_1/m) / (w_2/n)\)</span> has an <span class="math inline">\(F\)</span>-distribution with parameters <span class="math inline">\(df_1 = m\)</span> and <span class="math inline">\(df_2 = n\)</span>, respectively. The probability density function is
<span class="math display">\[
\mathrm{f}(y) = \frac{\Gamma \left(\frac{m+n}{2} \right)}{\Gamma(m/2)\Gamma(n/2)} \left( \frac{m}{n} \right)^{m/2} \frac{y^{(m-2)/2}} {\left( 1 + \frac{m}{n}y \right)^{m+n+2}} , ~~~~~~y &gt; 0
\]</span>
This has mean <span class="math inline">\(n/(n-2)\)</span>, for <span class="math inline">\(n &gt; 2\)</span>, and variance <span class="math inline">\(2n^2(m+n-2)/[m(n-2)^2(n-4)]\)</span> for <span class="math inline">\(n &gt; 4\)</span>.</p>

<div class="figure" style="text-align: center"><span style="display:block;" id="fig:FigA4"></span>
<img src="RegressionMarkdown_files/figure-html/FigA4-1.png" alt="Several \(F\)-distribution probability density functions. Shown are curves for (i) \(df_1\) = 1, \(df_2\) = 5, (ii) \(df_1\) = 5, \(df_2\) = 1 (not labeled), and (iii) \(df_1\) = 60, \(df_2\) = 60. As \(df_2\) tends to \(\infty\), the \(F\)-distribution tends to a chi-square distribution." width="60%" />
<p class="caption">
Figure 22.4: <strong>Several <span class="math inline">\(F\)</span>-distribution probability density functions</strong>. Shown are curves for (i) <span class="math inline">\(df_1\)</span> = 1, <span class="math inline">\(df_2\)</span> = 5, (ii) <span class="math inline">\(df_1\)</span> = 5, <span class="math inline">\(df_2\)</span> = 1 (not labeled), and (iii) <span class="math inline">\(df_1\)</span> = 60, <span class="math inline">\(df_2\)</span> = 60. As <span class="math inline">\(df_2\)</span> tends to <span class="math inline">\(\infty\)</span>, the <span class="math inline">\(F\)</span>-distribution tends to a chi-square distribution.
</p>
</div>
<table>
<caption><span id="tab:unnamed-chunk-679">Table 22.4: </span><strong>Percentiles from Several <span class="math inline">\(F-\)</span>Distributions</strong></caption>
<thead>
<tr class="header">
<th align="right"><span class="math inline">\(df_1\)</span></th>
<th align="right">1</th>
<th align="right">3</th>
<th align="right">5</th>
<th align="right">10</th>
<th align="right">20</th>
<th align="right">30</th>
<th align="right">40</th>
<th align="right">60</th>
<th align="right">120</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="right">1</td>
<td align="right">161.45</td>
<td align="right">10.13</td>
<td align="right">6.61</td>
<td align="right">4.96</td>
<td align="right">4.35</td>
<td align="right">4.17</td>
<td align="right">4.08</td>
<td align="right">4.00</td>
<td align="right">3.92</td>
</tr>
<tr class="even">
<td align="right">2</td>
<td align="right">199.50</td>
<td align="right">9.55</td>
<td align="right">5.79</td>
<td align="right">4.10</td>
<td align="right">3.49</td>
<td align="right">3.32</td>
<td align="right">3.23</td>
<td align="right">3.15</td>
<td align="right">3.07</td>
</tr>
<tr class="odd">
<td align="right">3</td>
<td align="right">215.71</td>
<td align="right">9.28</td>
<td align="right">5.41</td>
<td align="right">3.71</td>
<td align="right">3.10</td>
<td align="right">2.92</td>
<td align="right">2.84</td>
<td align="right">2.76</td>
<td align="right">2.68</td>
</tr>
<tr class="even">
<td align="right">4</td>
<td align="right">224.58</td>
<td align="right">9.12</td>
<td align="right">5.19</td>
<td align="right">3.48</td>
<td align="right">2.87</td>
<td align="right">2.69</td>
<td align="right">2.61</td>
<td align="right">2.53</td>
<td align="right">2.45</td>
</tr>
<tr class="odd">
<td align="right">5</td>
<td align="right">230.16</td>
<td align="right">9.01</td>
<td align="right">5.05</td>
<td align="right">3.33</td>
<td align="right">2.71</td>
<td align="right">2.53</td>
<td align="right">2.45</td>
<td align="right">2.37</td>
<td align="right">2.29</td>
</tr>
<tr class="even">
<td align="right">10</td>
<td align="right">241.88</td>
<td align="right">8.79</td>
<td align="right">4.74</td>
<td align="right">2.98</td>
<td align="right">2.35</td>
<td align="right">2.16</td>
<td align="right">2.08</td>
<td align="right">1.99</td>
<td align="right">1.91</td>
</tr>
<tr class="odd">
<td align="right">15</td>
<td align="right">245.95</td>
<td align="right">8.70</td>
<td align="right">4.62</td>
<td align="right">2.85</td>
<td align="right">2.20</td>
<td align="right">2.01</td>
<td align="right">1.92</td>
<td align="right">1.84</td>
<td align="right">1.75</td>
</tr>
<tr class="even">
<td align="right">20</td>
<td align="right">248.01</td>
<td align="right">8.66</td>
<td align="right">4.56</td>
<td align="right">2.77</td>
<td align="right">2.12</td>
<td align="right">1.93</td>
<td align="right">1.84</td>
<td align="right">1.75</td>
<td align="right">1.66</td>
</tr>
<tr class="odd">
<td align="right">25</td>
<td align="right">249.26</td>
<td align="right">8.63</td>
<td align="right">4.52</td>
<td align="right">2.73</td>
<td align="right">2.07</td>
<td align="right">1.88</td>
<td align="right">1.78</td>
<td align="right">1.69</td>
<td align="right">1.60</td>
</tr>
<tr class="even">
<td align="right">30</td>
<td align="right">250.10</td>
<td align="right">8.62</td>
<td align="right">4.50</td>
<td align="right">2.70</td>
<td align="right">2.04</td>
<td align="right">1.84</td>
<td align="right">1.74</td>
<td align="right">1.65</td>
<td align="right">1.55</td>
</tr>
<tr class="odd">
<td align="right">35</td>
<td align="right">250.69</td>
<td align="right">8.60</td>
<td align="right">4.48</td>
<td align="right">2.68</td>
<td align="right">2.01</td>
<td align="right">1.81</td>
<td align="right">1.72</td>
<td align="right">1.62</td>
<td align="right">1.52</td>
</tr>
<tr class="even">
<td align="right">40</td>
<td align="right">251.14</td>
<td align="right">8.59</td>
<td align="right">4.46</td>
<td align="right">2.66</td>
<td align="right">1.99</td>
<td align="right">1.79</td>
<td align="right">1.69</td>
<td align="right">1.59</td>
<td align="right">1.50</td>
</tr>
<tr class="odd">
<td align="right">60</td>
<td align="right">252.20</td>
<td align="right">8.57</td>
<td align="right">4.43</td>
<td align="right">2.62</td>
<td align="right">1.95</td>
<td align="right">1.74</td>
<td align="right">1.64</td>
<td align="right">1.53</td>
<td align="right">1.43</td>
</tr>
<tr class="even">
<td align="right">120</td>
<td align="right">253.25</td>
<td align="right">8.55</td>
<td align="right">4.40</td>
<td align="right">2.58</td>
<td align="right">1.90</td>
<td align="right">1.68</td>
<td align="right">1.58</td>
<td align="right">1.47</td>
<td align="right">1.35</td>
</tr>
</tbody>
</table>

<!-- # Chap 1 -->
<!-- # Chap 2 -->
<!-- # Chap 3 -->
<!-- # Chap 4 -->
<!-- # Chap 5 -->
<!-- # Chap 6 -->
<!-- # Chap 7 -->
<!-- # Chap 8 -->
<!-- # Chap 9 -->
<!-- # Chap 10 -->
<!-- # Chap 11 -->
<!-- # Chap 12 -->
<!-- # Chap 13 -->
<!-- # Chap 14 -->
<!-- # Chap 15 -->
<!-- # Chap 16 -->
<!-- # Chap 17 -->
<!-- # Chap 18 -->
<!-- # Chap 19 -->
<!-- # Chap 20 -->
<!-- # Chap 21 -->
</div>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="C21Design.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="brief-answers-to-selected-exercises.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": null,
"search": {
"engine": "fuse",
"options": null
},
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/latest.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
